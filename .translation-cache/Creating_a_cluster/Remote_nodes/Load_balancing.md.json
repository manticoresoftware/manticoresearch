{
  "9fd9d25580cc8578f8bae84b230493d7b0abe22a5cd8f444830ff9ea506c6fa4": {
    "original": "# Load balancing\n\nLoad balancing is turned on by default for any [distributed table](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md) that uses [mirroring](../../Creating_a_cluster/Remote_nodes/Mirroring.md). By default, queries are distributed randomly among the mirrors. You can change this behavior by using the [ha_strategy](../../Creating_a_cluster/Remote_nodes/Load_balancing.md).\n\n## ha_strategy\n\nCODE_BLOCK_0\n\nThe mirror selection strategy for load balancing is optional and is set to `random` by default.\n\nThe strategy used for mirror selection, or in other words, choosing a specific [agent mirror](../../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors) in a distributed table, is controlled by this directive. Essentially, this directive controls how master performs the load balancing between the configured mirror agent nodes. The following strategies are implemented:\n\n### Simple random balancing\n\n<!-- example conf balancing 1 -->\n\nThe default balancing mode is simple linear random distribution among the mirrors. This means that equal selection probabilities are assigned to each mirror. This is similar to round-robin (RR), but does not impose a strict selection order.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\n### Adaptive randomized balancing\n\nThe default simple random strategy does not take into account the status of mirrors, error rates, and most importantly, actual response latencies. To address heterogeneous clusters and temporary spikes in agent node load, there are a group of balancing strategies that dynamically adjust the probabilities based on the actual query latencies observed by the master.\n\nThe adaptive strategies based on **latency-weighted probabilities**  work as follows:\n\n1. Latency stats are accumulated in blocks of ha_period_karma seconds.\n\n2. Latency-weighted probabilities are recomputed once per karma period.\n\n3. The \"dead or alive\" flag is adjusted once per request, including ping requests.\n\nInitially, the probabilities are equal. On every step, they are scaled by the inverse of the latencies observed during the last karma period, and then renormalized. For example, if during the first 60 seconds after the master startup, 4 mirrors had latencies of 10 ms, 5 ms, 30 ms, and 3 ms respectively, the first adjustment step would go as follows:\n\n1. Initial percentages: 0.25, 0.25, 0.25, 0.25.\n\n2. Observed latencies: 10 ms, 5 ms, 30 ms, 3 ms.\n\n3. Inverse latencies: 0.1, 0.2, 0.0333, 0.333.\n\n4. Scaled percentages: 0.025, 0.05, 0.008333, 0.0833.\n\n5. Renormalized percentages: 0.15, 0.30, 0.05, 0.50.\n\nThis means that the first mirror would have a 15% chance of being chosen during the next karma period, the second one a 30% chance, the third one (slowest at 30 ms) only a 5% chance, and the fourth and fastest one (at 3 ms) a 50% chance. After that period, the second adjustment step would update those chances again, and so on.\n\nThe idea is that once the  **observed latencies** stabilize, the **latency weighted probabilities** will stabilize as well. All these adjustment iterations are meant to converge at a point where the average latencies are roughly equal across all mirrors.\n\n<!-- example conf balancing 2 -->\n\n#### nodeads\n\nLatency-weighted probabilities, but dead mirrors are excluded from the selection. A \"dead\" mirror is defined as a mirror that has resulted in multiple hard errors (e.g. network failure, or no answer, etc) in a row.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n<!-- example conf balancing 3 -->\n\n#### noerrors\n\nLatency-weighted probabilities, but mirrors with a worse error/success ratio are excluded from selection.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\n### Round-robin balancing\n\n<!-- example conf balancing 4 -->\n\nSimple round-robin selection, that is, selecting the first mirror in the list, then the second one, then the third one, etc, and then repeating the process once the last mirror in the list is reached. Unlike with the randomized strategies, RR imposes a strict querying order (1, 2, 3, ..., N-1, N, 1, 2, 3, ..., and so on) and *guarantees* that no two consecutive queries will be sent to the same mirror.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n## Instance-wide options\n\n### ha_period_karma\n\nCODE_BLOCK_5\n\n`ha_period_karma` defines the size of the agent mirror statistics window, in seconds (or a time suffix). Optional, the default is 60.\n\nFor a distributed table with agent mirrors, the server tracks several different per-mirror counters. These counters are then used for failover and balancing. (The server picks the best mirror to use based on the counters.) Counters are accumulated in blocks of `ha_period_karma` seconds.\n\nAfter beginning a new block, the master may still use the accumulated values from the previous one until the new one is half full. Thus, any previous history stops affecting the mirror choice after at most 1.5 times ha_period_karma seconds.\n\nAlthough at most 2 blocks are used for mirror selection, up to 15 last blocks are actually stored for instrumentation purposes. They can be inspected using the `SHOW AGENT STATUS` statement.\n\n### ha_ping_interval\n\nCODE_BLOCK_6\n\n`ha_ping_interval` directive defines the interval between pings sent to the agent mirrors, in milliseconds (or with a time suffix). This option is optional and its default value is 1000.\n\nFor a distributed table with agent mirrors, the server sends all mirrors a ping command during idle periods to track their current status (whether they are alive or dead, network roundtrip time, etc.). The interval between pings is determined by the ha_ping_interval setting.\n\nIf you want to disable pings, set ha_ping_interval to 0.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "# 负载均衡\n\n对于使用[镜像](../../Creating_a_cluster/Remote_nodes/Mirroring.md)的任何[分布式表](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md)，默认启用负载均衡。默认情况下，查询会在镜像之间随机分配。您可以使用[ha_strategy](../../Creating_a_cluster/Remote_nodes/Load_balancing.md)来更改此行为。\n\n## ha_strategy\n\nCODE_BLOCK_0\n\n负载均衡的镜像选择策略是可选的，默认设置为`random`。\n\n用于镜像选择的策略，换句话说，就是在分布式表中选择特定的[代理镜像](../../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors)，由此指令控制。本质上，该指令控制主节点如何在配置的镜像代理节点之间执行负载均衡。实现了以下策略：\n\n### 简单随机均衡\n\n<!-- example conf balancing 1 -->\n\n默认的均衡模式是在镜像之间简单线性随机分布。这意味着为每个镜像分配相等的选择概率。这类似于轮询（RR），但不强制执行严格的选择顺序。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\n### 自适应随机均衡\n\n默认的简单随机策略不考虑镜像的状态、错误率，最重要的是实际响应延迟。为了解决异构集群和代理节点负载的临时峰值，存在一组基于实际查询延迟动态调整概率的均衡策略。\n\n基于**延迟加权概率**的自适应策略工作原理如下：\n\n1. 延迟统计以ha_period_karma秒为块进行累积。\n\n2. 延迟加权概率每个karma周期重新计算一次。\n\n3. “存活或死亡”标志每个请求调整一次，包括ping请求。\n\n初始时，概率是相等的。每一步，它们按上一个karma周期观察到的延迟的倒数进行缩放，然后重新归一化。例如，如果在主节点启动后的前60秒内，4个镜像的延迟分别为10毫秒、5毫秒、30毫秒和3毫秒，第一次调整步骤如下：\n\n1. 初始百分比：0.25，0.25，0.25，0.25。\n\n2. 观察到的延迟：10毫秒，5毫秒，30毫秒，3毫秒。\n\n3. 延迟倒数：0.1，0.2，0.0333，0.333。\n\n4. 缩放后的百分比：0.025，0.05，0.008333，0.0833。\n\n5. 重新归一化的百分比：0.15，0.30，0.05，0.50。\n\n这意味着在下一个karma周期内，第一个镜像被选中的概率为15%，第二个为30%，第三个（最慢的30毫秒）仅为5%，第四个（最快的3毫秒）为50%。之后，第二次调整步骤将再次更新这些概率，依此类推。\n\n其思想是，一旦**观察到的延迟**稳定，**延迟加权概率**也将稳定。所有这些调整迭代旨在收敛到一个点，使所有镜像的平均延迟大致相等。\n\n<!-- example conf balancing 2 -->\n\n#### nodeads\n\n延迟加权概率，但排除“死亡”镜像。定义“死亡”镜像为连续出现多个硬错误（例如网络故障或无响应等）的镜像。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n<!-- example conf balancing 3 -->\n\n#### noerrors\n\n延迟加权概率，但排除错误/成功率较差的镜像。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\n### 轮询均衡\n\n<!-- example conf balancing 4 -->\n\n简单的轮询选择，即依次选择列表中的第一个镜像，然后是第二个，第三个，依此类推，直到列表末尾后重复该过程。与随机策略不同，RR强制执行严格的查询顺序（1，2，3，...，N-1，N，1，2，3，...，依此类推），并*保证*不会连续两次查询发送到同一镜像。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n## 实例范围选项\n\n### ha_period_karma\n\nCODE_BLOCK_5\n\n`ha_period_karma`定义代理镜像统计窗口的大小，单位为秒（或带时间后缀）。可选，默认值为60。\n\n对于带有代理镜像的分布式表，服务器跟踪多个不同的每镜像计数器。这些计数器用于故障转移和负载均衡。（服务器基于计数器选择最佳镜像。）计数器以`ha_period_karma`秒为块进行累积。\n\n开始新块后，主节点可能仍使用前一个块的累积值，直到新块填充到一半。因此，任何之前的历史最多在1.5倍ha_period_karma秒后停止影响镜像选择。\n\n虽然最多使用2个块进行镜像选择，但实际上会存储最多15个最近的块用于监控目的。可以使用`SHOW AGENT STATUS`语句查看。\n\n### ha_ping_interval\n\nCODE_BLOCK_6\n\n`ha_ping_interval`指令定义发送给代理镜像的ping间隔，单位为毫秒（或带时间后缀）。此选项为可选，默认值为1000。\n\n对于带有代理镜像的分布式表，服务器在空闲期间向所有镜像发送ping命令，以跟踪其当前状态（是否存活，网络往返时间等）。ping间隔由ha_ping_interval设置决定。\n\n如果想禁用ping，将ha_ping_interval设置为0。\n\n<!-- proofread -->",
      "russian": "# Балансировка нагрузки\n\nБалансировка нагрузки включена по умолчанию для любой [распределённой таблицы](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md), которая использует [зеркалирование](../../Creating_a_cluster/Remote_nodes/Mirroring.md). По умолчанию запросы распределяются случайным образом между зеркалами. Вы можете изменить это поведение, используя [ha_strategy](../../Creating_a_cluster/Remote_nodes/Load_balancing.md).\n\n## ha_strategy\n\nCODE_BLOCK_0\n\nСтратегия выбора зеркала для балансировки нагрузки является необязательной и по умолчанию установлена в `random`.\n\nСтратегия, используемая для выбора зеркала, или, другими словами, выбора конкретного [агентского зеркала](../../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors) в распределённой таблице, контролируется этой директивой. По сути, эта директива управляет тем, как мастер выполняет балансировку нагрузки между настроенными агентскими узлами зеркал. Реализованы следующие стратегии:\n\n### Простая случайная балансировка\n\n<!-- example conf balancing 1 -->\n\nРежим балансировки по умолчанию — простое линейное случайное распределение между зеркалами. Это означает, что каждому зеркалу назначаются равные вероятности выбора. Это похоже на круговой обход (round-robin, RR), но не накладывает строгий порядок выбора.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\n### Адаптивная рандомизированная балансировка\n\nПростая стратегия случайного выбора по умолчанию не учитывает состояние зеркал, уровень ошибок и, что самое важное, фактические задержки отклика. Чтобы справиться с неоднородными кластерами и временными пиками нагрузки на агентские узлы, существует группа стратегий балансировки, которые динамически корректируют вероятности на основе фактических задержек запросов, наблюдаемых мастером.\n\nАдаптивные стратегии, основанные на **вероятностях, взвешенных по задержкам**, работают следующим образом:\n\n1. Статистика задержек накапливается блоками по ha_period_karma секунд.\n\n2. Вероятности, взвешенные по задержкам, пересчитываются один раз за период karma.\n\n3. Флаг \"живой или мёртвый\" корректируется один раз за запрос, включая ping-запросы.\n\nИзначально вероятности равны. На каждом шаге они масштабируются обратно пропорционально задержкам, наблюдаемым за последний период karma, а затем нормализуются. Например, если в первые 60 секунд после запуска мастера 4 зеркала имели задержки 10 мс, 5 мс, 30 мс и 3 мс соответственно, первый шаг корректировки будет следующим:\n\n1. Начальные проценты: 0.25, 0.25, 0.25, 0.25.\n\n2. Наблюдаемые задержки: 10 мс, 5 мс, 30 мс, 3 мс.\n\n3. Обратные задержки: 0.1, 0.2, 0.0333, 0.333.\n\n4. Масштабированные проценты: 0.025, 0.05, 0.008333, 0.0833.\n\n5. Нормализованные проценты: 0.15, 0.30, 0.05, 0.50.\n\nЭто означает, что первое зеркало будет выбрано с вероятностью 15% в течение следующего периода karma, второе — с вероятностью 30%, третье (самое медленное с 30 мс) — только с 5%, а четвёртое и самое быстрое (3 мс) — с 50%. После этого периода второй шаг корректировки снова обновит эти вероятности и так далее.\n\nИдея в том, что как только **наблюдаемые задержки** стабилизируются, **вероятности, взвешенные по задержкам**, также стабилизируются. Все эти итерации корректировки предназначены для сходимости к точке, где средние задержки примерно равны для всех зеркал.\n\n<!-- example conf balancing 2 -->\n\n#### nodeads\n\nВероятности, взвешенные по задержкам, но мёртвые зеркала исключаются из выбора. \"Мёртвым\" зеркалом считается зеркало, которое вызвало несколько последовательных серьёзных ошибок (например, сбой сети или отсутствие ответа и т. п.).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n<!-- example conf balancing 3 -->\n\n#### noerrors\n\nВероятности, взвешенные по задержкам, но зеркала с худшим соотношением ошибок и успешных ответов исключаются из выбора.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\n### Балансировка круговым обходом (Round-robin)\n\n<!-- example conf balancing 4 -->\n\nПростой выбор по круговому обходу, то есть выбор первого зеркала в списке, затем второго, затем третьего и так далее, а после достижения последнего зеркала процесс повторяется. В отличие от рандомизированных стратегий, RR накладывает строгий порядок запросов (1, 2, 3, ..., N-1, N, 1, 2, 3, ... и так далее) и *гарантирует*, что два последовательных запроса не будут отправлены одному и тому же зеркалу.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n## Глобальные параметры\n\n### ha_period_karma\n\nCODE_BLOCK_5\n\n`ha_period_karma` определяет размер окна статистики агентских зеркал в секундах (или с суффиксом времени). Опционально, по умолчанию 60.\n\nДля распределённой таблицы с агентскими зеркалами сервер отслеживает несколько различных счётчиков для каждого зеркала. Эти счётчики затем используются для отказоустойчивости и балансировки. (Сервер выбирает лучшее зеркало на основе счётчиков.) Счётчики накапливаются блоками по `ha_period_karma` секунд.\n\nПосле начала нового блока мастер может использовать накопленные значения из предыдущего блока, пока новый блок не заполнится наполовину. Таким образом, любая предыдущая история перестаёт влиять на выбор зеркала максимум через 1.5 раза ha_period_karma секунд.\n\nХотя для выбора зеркала используется максимум 2 блока, до 15 последних блоков фактически сохраняются для целей инструментирования. Их можно просмотреть с помощью оператора `SHOW AGENT STATUS`.\n\n### ha_ping_interval\n\nCODE_BLOCK_6\n\nДиректива `ha_ping_interval` определяет интервал между ping-запросами, отправляемыми агентским зеркалам, в миллисекундах (или с суффиксом времени). Этот параметр опционален, значение по умолчанию — 1000.\n\nДля распределённой таблицы с агентскими зеркалами сервер отправляет всем зеркалам команду ping в периоды простоя, чтобы отслеживать их текущее состояние (живы они или мертвы, время сетевого отклика и т. п.). Интервал между ping-запросами определяется настройкой ha_ping_interval.\n\nЕсли вы хотите отключить ping-запросы, установите ha_ping_interval в 0.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  }
}
