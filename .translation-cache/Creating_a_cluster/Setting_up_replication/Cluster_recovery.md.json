{
  "576f5d59febeb759ba3cd59b9c570d58f893550abe6127945e0d8273ae3d0a3f": {
    "original": "Split-brain can cause the cluster to transition into a non-primary state. For example, consider a cluster comprised of an even number of nodes (four), such as two pairs of nodes located in different data centers. If a network failure interrupts the connection between the data centers, split-brain occurs as each group of nodes holds exactly half of the quorum. As a result, both groups stop handling write transactions, since the Galera replication model prioritizes data consistency, and the cluster cannot accept write transactions without a quorum. However, nodes in both groups attempt to reconnect with the nodes from the other group in an effort to restore the cluster.\n\n<!-- example case 7 -->\n\nIf someone wants to restore the cluster before the network is restored, the same steps outlined in [Case 5](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-5) hould be taken, but only at one group of nodes.\n\nAfter the statement is executed, the group with the node that it was run on will be able to handle write transactions once again.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_2\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\nHowever, it's important to note that if the statement is issued at both groups, it will result in the formation of two separate clusters, and the subsequent network recovery will not result in the groups rejoining.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "Split-brain 可能导致集群转变为非主状态。例如，考虑一个由偶数个节点（四个）组成的集群，比如位于不同数据中心的两对节点。如果网络故障中断了数据中心之间的连接，就会发生 split-brain，因为每组节点恰好持有半数的法定人数。因此，两个组都停止处理写事务，因为 Galera 复制模型优先保证数据一致性，且集群在没有法定人数的情况下无法接受写事务。然而，两个组的节点都会尝试重新连接另一组的节点，以恢复集群。\n\n<!-- example case 7 -->\n\n如果有人想在网络恢复之前恢复集群，应按照[案例 5](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-5)中概述的相同步骤操作，但只针对其中一组节点。\n\n执行该语句后，运行该语句的节点所在的组将能够再次处理写事务。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_2\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\n但是，需要注意的是，如果该语句在两个组都执行，将导致形成两个独立的集群，随后网络恢复时这两个组不会重新合并。\n\n<!-- proofread -->",
      "russian": "Split-brain может привести к переходу кластера в состояние неосновного узла. Например, рассмотрим кластер, состоящий из четного числа узлов (четыре), таких как две пары узлов, расположенных в разных дата-центрах. Если сетевая ошибка прерывает соединение между дата-центрами, возникает split-brain, так как каждая группа узлов удерживает ровно половину кворума. В результате обе группы прекращают обработку транзакций записи, поскольку модель репликации Galera отдает приоритет согласованности данных, и кластер не может принимать транзакции записи без кворума. Однако узлы в обеих группах пытаются переподключиться к узлам из другой группы в попытке восстановить кластер.\n\n<!-- example case 7 -->\n\nЕсли кто-то хочет восстановить кластер до восстановления сети, следует выполнить те же шаги, описанные в [Case 5](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-5), но только для одной группы узлов.\n\nПосле выполнения оператора группа с узлом, на котором он был выполнен, сможет снова обрабатывать транзакции записи.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_2\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- end -->\n\nОднако важно отметить, что если оператор будет выполнен в обеих группах, это приведет к формированию двух отдельных кластеров, и последующее восстановление сети не приведет к повторному объединению групп.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "3f07c17d71e2a1b4ec302bd2ea52ee79c69f9589484dfb8ffc95840c02339057": {
    "original": "# Cluster recovery\n\nIn the event that the Manticore search daemon stops with no remaining nodes in the cluster to serve requests, recovery is necessary. Due to the multi-master nature of the Galera library used for replication, Manticore replication cluster is a single logical entity that maintains the consistency of its nodes and data, and the status of the entire cluster. This allows for safe writes on multiple nodes simultaneously and ensures the integrity of the cluster.\n\nHowever, this also poses challenges. Let's examine several scenarios, using a cluster of nodes A, B, and C, to see what needs to be done when some or all nodes become unavailable.\n\n### Case 1\n\n When node A is stopped, the other nodes receive a \"normal shutdown\" message. The cluster size is reduced, and a quorum re-calculation takes place.\n\nUpon starting node A, it joins the cluster and will not serve any write transactions until it is fully synchronized with the cluster. If the writeset cache on donor nodes B or C (which can be controlled with the Galera cluster's [gcache.size](https://galeracluster.com/library/documentation/galera-parameters.html#gcache-size)) still contains all of the transactions missed at node A, node A will receive a fast incremental state transfer ([IST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-ist)), that is, a transfer of only missed transactions. If not, a snapshot state transfer  ([SST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-sst)) will occur, which involves the transfer of table files.\n\n### Case 2\n\nIn the scenario where nodes A and B are stopped, the cluster size is reduced to one, with node C forming the primary component to handle write transactions.\n\nNodes A and B can then be started as usual and will join the cluster after start-up. Node C acts as the donor, providing the state transfer to nodes A and B.\n\n### Case 3\n\nAll nodes are stopped as usual and the cluster is off.\n\nThe problem now is how to initialize the cluster. It's important that on a clean shutdown of searchd the nodes write the number of last executed transaction into the cluster directory [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) file along with flag `safe_to_bootstrap`. The node which was stopped last will have option `safe_to_bootstrap: 1` and the most advanced `seqno` number.\n\nIt is important that this node starts first to form the cluster. To bootstrap a cluster the server should be started on this node with flag [--new-cluster](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md). On Linux you can also run `manticore_new_cluster` which will start Manticore in `--new-cluster` mode via systemd.\n\nIf another node starts first and bootstraps the cluster, then the most advanced node joins that cluster, performs full SST and receives a table file where some transactions are missed in comparison with the table files it got before. That is why it is important to start first the node which was shut down last, it should have flag `safe_to_bootstrap: 1` in [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md).\n\n### Case 4\n\nIn the event of a crash or network failure causing Node A to disappear from the cluster, nodes B and C will attempt to reconnect with Node A. Upon failure, they will remove Node A from the cluster. With two out of the three nodes still running, the cluster maintains its quorum and continues to operate normally.\n\nWhen Node A is restarted, it will join the cluster automatically, as outlined in [Case 1](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-1).\n\n### Case 5\n\nNodes A and B have gone offline. Node C is unable to form a quorum on its own as 1 node is less than half of the total nodes (3). As a result, the cluster on node C is shifted to a non-primary state and rejects any write transactions with an error message.\n\nMeanwhile, node C waits for the other nodes to connect and also tries to connect to them. If this happens, and the network is restored and nodes A and B are back online, the cluster will automatically reform. If nodes A and B are just temporarily disconnected from node C but can still communicate with each other, they will continue to operate as normal, as they still form the quorum.\n\n<!-- example case 5 -->\n\nHowever, if both nodes A and B have crashed or restarted due to a power failure, someone must activate the primary component on node C using the following command:\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\nt's important to note that before executing this command, you must confirm that the other nodes are truly unreachable. Otherwise, a split-brain scenario may occur and separate clusters may form.\n\n### Case 6\n\nAll nodes have crashed. In this situation, the [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) file in the cluster directory has not been updated and does not contain a valid `seqno`sequence number.\n\nIf this occurs, someone needs to locate the node with the most recent data and start the server on it using the [--new-cluster-force](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) command line key. All other nodes will start as normal, as described in [Case 3](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-3)).\n\nOn Linux, you can also use the `manticore_new_cluster --force`, command, which will start Manticore in `--new-cluster-force` mode via systemd.\n\n### Case 7",
    "translations": {
      "chinese": "# 集群恢复\n\n当 Manticore 搜索守护进程停止且集群中没有剩余节点可提供服务时，需要进行恢复。由于用于复制的 Galera 库具有多主特性，Manticore 复制集群是一个单一的逻辑实体，维护其节点和数据的一致性，以及整个集群的状态。这允许多个节点同时安全写入，并确保集群的完整性。\n\n然而，这也带来了挑战。让我们通过使用节点 A、B 和 C 的集群来检查几种场景，看看当部分或全部节点不可用时需要做什么。\n\n### 情况 1\n\n当节点 A 停止时，其他节点会收到“正常关闭”消息。集群规模减少，并重新计算法定人数。\n\n启动节点 A 后，它会加入集群，并且在完全与集群同步之前不会处理任何写事务。如果捐赠节点 B 或 C 上的写集缓存（可以通过 Galera 集群的 [gcache.size](https://galeracluster.com/library/documentation/galera-parameters.html#gcache-size) 控制）仍包含节点 A 错过的所有事务，节点 A 将接收快速增量状态传输（[IST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-ist)），即仅传输错过的事务。如果没有，则会进行快照状态传输（[SST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-sst)），涉及表文件的传输。\n\n### 情况 2\n\n在节点 A 和 B 停止的情况下，集群规模减少到一个，节点 C 形成主组件以处理写事务。\n\n然后，节点 A 和 B 可以像往常一样启动，并在启动后加入集群。节点 C 作为捐赠者，向节点 A 和 B 提供状态传输。\n\n### 情况 3\n\n所有节点都像往常一样停止，集群关闭。\n\n现在的问题是如何初始化集群。重要的是，在 searchd 的干净关闭时，节点会将最后执行的事务编号写入集群目录中的 [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) 文件，并带有标志 `safe_to_bootstrap`。最后停止的节点将具有选项 `safe_to_bootstrap: 1` 和最先进的 `seqno` 编号。\n\n重要的是该节点应首先启动以形成集群。要引导集群，应在该节点上使用标志 [--new-cluster](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) 启动服务器。在 Linux 上，你也可以运行 `manticore_new_cluster`，它将通过 systemd 以 `--new-cluster` 模式启动 Manticore。\n\n如果另一个节点先启动并引导集群，则最先进的节点加入该集群，执行完整 SST，并接收一个表文件，其中某些事务与之前获得的表文件相比缺失。这就是为什么重要的是先启动最后关闭的节点，该节点在 [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) 中应有标志 `safe_to_bootstrap: 1`。\n\n### 情况 4\n\n在发生崩溃或网络故障导致节点 A 从集群中消失的情况下，节点 B 和 C 会尝试重新连接节点 A。连接失败后，它们会将节点 A 从集群中移除。由于三个节点中仍有两个节点运行，集群保持法定人数并继续正常运行。\n\n当节点 A 重启时，它将自动加入集群，如 [情况 1](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-1) 所述。\n\n### 情况 5\n\n节点 A 和 B 已离线。节点 C 无法单独形成法定人数，因为 1 个节点少于总节点数（3）的一半。因此，节点 C 上的集群被转移到非主状态，并拒绝任何写事务，返回错误消息。\n\n同时，节点 C 等待其他节点连接，并尝试连接它们。如果发生这种情况，网络恢复且节点 A 和 B 重新上线，集群将自动重组。如果节点 A 和 B 只是暂时与节点 C 断开连接，但仍能相互通信，它们将继续正常运行，因为它们仍然形成法定人数。\n\n<!-- example case 5 -->\n\n但是，如果节点 A 和 B 都因断电崩溃或重启，则必须有人使用以下命令在节点 C 上激活主组件：\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\n重要的是，在执行此命令之前，必须确认其他节点确实无法访问。否则，可能发生脑裂（split-brain）场景，形成分离的集群。\n\n### 情况 6\n\n所有节点都崩溃。在这种情况下，集群目录中的 [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) 文件未更新，且不包含有效的 `seqno` 序列号。\n\n如果发生这种情况，需要有人找到数据最新的节点，并使用命令行参数 [--new-cluster-force](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) 启动该节点上的服务器。所有其他节点将按正常方式启动，如 [情况 3](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-3) 所述。\n\n在 Linux 上，你也可以使用 `manticore_new_cluster --force` 命令，它将通过 systemd 以 `--new-cluster-force` 模式启动 Manticore。\n\n### 情况 7",
      "russian": "# Восстановление кластера\n\nВ случае, если демон поиска Manticore останавливается и в кластере не остается узлов для обслуживания запросов, необходимо восстановление. Благодаря мульти-мастерной природе библиотеки Galera, используемой для репликации, кластер репликации Manticore является единой логической сущностью, которая поддерживает согласованность своих узлов и данных, а также состояние всего кластера. Это позволяет безопасно выполнять записи на нескольких узлах одновременно и обеспечивает целостность кластера.\n\nОднако это также создает определенные сложности. Рассмотрим несколько сценариев, используя кластер из узлов A, B и C, чтобы понять, что нужно делать, когда некоторые или все узлы становятся недоступными.\n\n### Случай 1\n\nКогда узел A останавливается, другие узлы получают сообщение о \"нормальном завершении работы\". Размер кластера уменьшается, и происходит перерасчет кворума.\n\nПри запуске узел A присоединяется к кластеру и не будет обслуживать транзакции записи, пока полностью не синхронизируется с кластером. Если кэш writeset на донорских узлах B или C (который можно контролировать с помощью параметра Galera кластера [gcache.size](https://galeracluster.com/library/documentation/galera-parameters.html#gcache-size)) все еще содержит все транзакции, пропущенные узлом A, узел A получит быстрый инкрементальный перенос состояния ([IST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-ist)), то есть перенос только пропущенных транзакций. Если нет, произойдет перенос состояния снимка ([SST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-sst)), который включает передачу файлов таблиц.\n\n### Случай 2\n\nВ сценарии, когда узлы A и B остановлены, размер кластера уменьшается до одного, и узел C формирует основной компонент для обработки транзакций записи.\n\nУзлы A и B затем могут быть запущены как обычно и присоединятся к кластеру после запуска. Узел C выступает в роли донора, предоставляя перенос состояния узлам A и B.\n\n### Случай 3\n\nВсе узлы остановлены как обычно, и кластер выключен.\n\nПроблема теперь в том, как инициализировать кластер. Важно, чтобы при корректном завершении работы searchd узлы записывали номер последней выполненной транзакции в файл [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) в каталоге кластера вместе с флагом `safe_to_bootstrap`. Узел, который был остановлен последним, будет иметь опцию `safe_to_bootstrap: 1` и самый продвинутый номер `seqno`.\n\nВажно, чтобы этот узел запускался первым для формирования кластера. Для инициализации кластера сервер должен быть запущен на этом узле с флагом [--new-cluster](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md). В Linux также можно запустить `manticore_new_cluster`, который запустит Manticore в режиме `--new-cluster` через systemd.\n\nЕсли другой узел запускается первым и инициализирует кластер, тогда самый продвинутый узел присоединится к этому кластеру, выполнит полный SST и получит файл таблицы, в котором некоторые транзакции отсутствуют по сравнению с файлами таблиц, которые он имел ранее. Поэтому важно запускать первым узел, который был остановлен последним, он должен иметь флаг `safe_to_bootstrap: 1` в [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md).\n\n### Случай 4\n\nВ случае сбоя или сетевой ошибки, из-за которой узел A исчезает из кластера, узлы B и C попытаются переподключиться к узлу A. При неудаче они удалят узел A из кластера. При этом два из трех узлов продолжают работать, кластер сохраняет кворум и функционирует нормально.\n\nПри перезапуске узел A автоматически присоединится к кластеру, как описано в [Случае 1](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-1).\n\n### Случай 5\n\nУзлы A и B вышли из строя. Узел C не может сформировать кворум самостоятельно, так как 1 узел меньше половины от общего числа узлов (3). В результате кластер на узле C переходит в состояние non-primary и отклоняет любые транзакции записи с сообщением об ошибке.\n\nТем временем узел C ждет подключения других узлов и также пытается к ним подключиться. Если это происходит, и сеть восстанавливается, а узлы A и B возвращаются в онлайн, кластер автоматически восстанавливается. Если узлы A и B просто временно отключены от узла C, но могут общаться друг с другом, они продолжат работать нормально, так как все еще формируют кворум.\n\n<!-- example case 5 -->\n\nОднако, если оба узла A и B вышли из строя или перезапустились из-за отключения питания, кто-то должен активировать основной компонент на узле C с помощью следующей команды:\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- end -->\n\nВажно отметить, что перед выполнением этой команды необходимо убедиться, что другие узлы действительно недоступны. В противном случае может возникнуть ситуация \"split-brain\" и сформируются отдельные кластеры.\n\n### Случай 6\n\nВсе узлы вышли из строя. В этой ситуации файл [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) в каталоге кластера не был обновлен и не содержит действительного номера последовательности `seqno`.\n\nЕсли это произошло, необходимо найти узел с самыми свежими данными и запустить сервер на нем с использованием ключа командной строки [--new-cluster-force](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md). Все остальные узлы запустятся как обычно, как описано в [Случае 3](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-3)).\n\nВ Linux также можно использовать команду `manticore_new_cluster --force`, которая запустит Manticore в режиме `--new-cluster-force` через systemd.\n\n### Случай 7"
    },
    "is_code_or_comment": false
  }
}
