{
  "18b1df758771bdcadce2a35021a9961c3a958e7697b816b2d159989738fae284": {
    "original": "<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_47\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\nAll queries that modify tables in the cluster are now replicated to all nodes in the cluster.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_47\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\nAll queries that modify tables in the cluster are now replicated to all nodes in the cluster.\n\n<!-- proofread -->",
      "russian": "<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_47\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\nAll queries that modify tables in the cluster are now replicated to all nodes in the cluster.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": true
  },
  "3b00868207458cd77ce3ba6222d2b5d634fefa0a60659dae92b75f69ad216803": {
    "original": "# Setting up replication\n\nWith Manticore, write transactions (such as `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE`, `UPDATE`, `COMMIT`) can be replicated to other cluster nodes before the transaction is fully applied on the current node. Currently, replication is supported for `percolate`, `rt` and `distributed` tables in Linux and macOS.\n\n[Native Windows binaries](../../Installation/Windows.md#Installing-Manticore-as-native-Windows-binaries) for Manticore do not support replication. We recommend [installing Manticore via WSL](../../Installation/Windows.md#Installing-or-enabling-WSL2) (Windows Subsystem for Linux).\n\nOn [macOS](../../Installation/MacOS.md), replication has limited support and is recommended only for development purposes.\n\nManticore's replication is powered by the [Galera library](https://github.com/codership/galera) and boasts several impressive features:\n\n* True multi-master: read and write to any node at any time.\n\n* [Virtually synchronous replication](https://galeracluster.com/library/documentation/overview.html) no slave lag and no data loss after a node crash.\n\n* Hot standby: no downtime during failover (since there is no failover).\n\n* Tightly coupled: all nodes hold the same state and no diverged data between nodes is allowed.\n\n* Automatic node provisioning: no need to manually backup the database and restore it on a new node.\n\n* Easy to use and deploy.\n\n* Detection and automatic eviction of unreliable nodes.\n\n* Certification-based replication.\n\nTo set up replication in Manticore Search:\n\n* The [data_dir](../../Server_settings/Searchd.md#data_dir) option must be set in the \"searchd\" section of the configuration file. Replication is not supported in plain mode.\n\n* A [listen](../../Server_settings/Searchd.md#listen)  directive must be specified, containing an IP address accessible by other nodes, or a [node_address](../../Server_settings/Searchd.md#node_address) with an accessible IP address.\n\n* Optionally, you can set unique values for [server_id](../../Server_settings/Searchd.md#server_id) on each cluster node. If no value is set, the node will attempt to use the MAC address or a random number to generate the `server_id`.\n\nIf there is no `replication` [listen](../../Server_settings/Searchd.md#listen) directive set, Manticore will use the first two free ports in the range of 200 ports after the default protocol listening port for each created cluster. To set replication ports manually, the [listen](../../Server_settings/Searchd.md#listen) directive (of `replication` type) port range must be defined and the address/port range pairs must not intersect between different nodes on the same server. As a rule of thumb, the port range should specify at least two ports per cluster. When you define a replication listener with a port range (e.g., `listen = 192.168.0.1:9320-9328:replication`), Manticore doesn't immediately start listening on these ports. Instead, it will take random free ports from the specified range only when you start using replication.\n\n## Replication cluster\n\nA replication cluster is a group of nodes in which a write transaction is replicated. Replication is set up on a per-table basis, meaning that one table can only belong to one cluster. There is no limit on the number of tables that a cluster can have. All transactions such as `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE` on any percolate or real-time table that belongs to a cluster are replicated to all the other nodes in that cluster. [Distributed](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md#Creating-a-distributed-table) tables can also be part of the replication process. Replication is multi-master, so writes to any node or multiple nodes simultaneously will work just as well.\n\nTo create a cluster, you can typically use the command [create cluster](../../Creating_a_cluster/Setting_up_replication/Creating_a_replication_cluster.md#Creating-a-replication-cluster) with `CREATE CLUSTER <cluster name>`, and to join a cluster, you can use [join cluster](../../Creating_a_cluster/Setting_up_replication/Joining_a_replication_cluster.md#Joining-a-replication-cluster) with `JOIN CLUSTER <cluster name> at 'host:port'`. However, in some rare cases, you may want to fine-tune the behavior of `CREATE/JOIN CLUSTER`. The available options are:\n\n### name\n\nThis option specifies the name of the cluster. It should be unique among all the clusters in the system.\n\n> **Note:** The maximum allowable hostname length for the `JOIN` command is **253** characters. If you exceed this limit, searchd will generate an error.\n\n### path\n\nThe path option specifies the data directory for [write-set cache replication](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-gcache) and incoming tables from other nodes. This value should be unique among all the clusters in the system and should be specified as a relative path to the [data_dir](../../Server_settings/Searchd.md#data_dir). directory. By default, it is set to the value of [data_dir](../../Server_settings/Searchd.md#data_dir).\n\n### nodes\n\nThe `nodes` option is a list of address:port pairs for all the nodes in the cluster, separated by commas. This list should be obtained using the node's API interface and can include the address of the current node as well. It is used to join the node to the cluster and to rejoin it after a restart.\n\n### options\n\nThe `options` option allows you to pass additional options directly to the Galera replication plugin, as described in the [Galera Documentation Parameters](https://galeracluster.com/library/documentation/galera-parameters.html)\n\n## Write statements\n\n<!-- example write statements 1 -->\n\nWhen working with a replication cluster, all write statements such as  `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE`, `UPDATE` that modify the content of a cluster's table must use the`cluster_name:table_name` expression instead of the table name. This ensures that the changes are propagated to all replicas in the cluster. If the correct expression is not used, an error will be triggered.",
    "translations": {
      "chinese": "# 设置复制\n\n使用 Manticore，写事务（如 `INSERT`、`REPLACE`、`DELETE`、`TRUNCATE`、`UPDATE`、`COMMIT`）可以在当前节点完全应用事务之前复制到其他集群节点。目前，复制支持 Linux 和 macOS 上的 `percolate`、`rt` 和 `distributed` 表。\n\nManticore 的[原生 Windows 二进制文件](../../Installation/Windows.md#Installing-Manticore-as-native-Windows-binaries)不支持复制。我们建议通过 [WSL 安装 Manticore](../../Installation/Windows.md#Installing-or-enabling-WSL2)（Windows 子系统 Linux）。\n\n在 [macOS](../../Installation/MacOS.md) 上，复制支持有限，仅建议用于开发目的。\n\nManticore 的复制由 [Galera 库](https://github.com/codership/galera) 提供支持，具有以下显著特性：\n\n* 真正的多主：任何时间可对任意节点进行读写。\n\n* [几乎同步复制](https://galeracluster.com/library/documentation/overview.html)，无从属延迟，节点崩溃后无数据丢失。\n\n* 热备份：故障切换期间无停机（因为没有故障切换）。\n\n* 紧密耦合：所有节点保持相同状态，不允许节点间数据分歧。\n\n* 自动节点配置：无需手动备份数据库并在新节点恢复。\n\n* 易于使用和部署。\n\n* 不可靠节点的检测和自动剔除。\n\n* 基于认证的复制。\n\n要在 Manticore Search 中设置复制：\n\n* 必须在配置文件的 \"searchd\" 部分设置 [data_dir](../../Server_settings/Searchd.md#data_dir) 选项。纯模式不支持复制。\n\n* 必须指定一个包含其他节点可访问 IP 地址的 [listen](../../Server_settings/Searchd.md#listen) 指令，或带有可访问 IP 地址的 [node_address](../../Server_settings/Searchd.md#node_address)。\n\n* 可选地，可以在每个集群节点上为 [server_id](../../Server_settings/Searchd.md#server_id) 设置唯一值。如果未设置，节点将尝试使用 MAC 地址或随机数生成 `server_id`。\n\n如果未设置 `replication` 类型的 [listen](../../Server_settings/Searchd.md#listen) 指令，Manticore 将在默认协议监听端口之后的 200 端口范围内为每个创建的集群使用前两个空闲端口。要手动设置复制端口，必须定义 [listen](../../Server_settings/Searchd.md#listen) 指令（`replication` 类型）的端口范围，且同一服务器上不同节点的地址/端口范围对不得相交。一般来说，端口范围应为每个集群指定至少两个端口。当定义带端口范围的复制监听器（例如 `listen = 192.168.0.1:9320-9328:replication`）时，Manticore 不会立即开始监听这些端口，而是在开始使用复制时从指定范围中随机选择空闲端口。\n\n## 复制集群\n\n复制集群是一组节点，写事务会在其中复制。复制按表设置，意味着一个表只能属于一个集群。集群中表的数量没有限制。属于集群的任何 percolate 或实时表上的所有事务，如 `INSERT`、`REPLACE`、`DELETE`、`TRUNCATE`，都会复制到该集群的所有其他节点。[分布式](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md#Creating-a-distributed-table) 表也可以参与复制过程。复制是多主的，因此对任意节点或多个节点同时写入都能正常工作。\n\n要创建集群，通常可以使用命令 [create cluster](../../Creating_a_cluster/Setting_up_replication/Creating_a_replication_cluster.md#Creating-a-replication-cluster) 通过 `CREATE CLUSTER <cluster name>`，要加入集群，可以使用 [join cluster](../../Creating_a_cluster/Setting_up_replication/Joining_a_replication_cluster.md#Joining-a-replication-cluster) 通过 `JOIN CLUSTER <cluster name> at 'host:port'`。不过，在某些罕见情况下，您可能想微调 `CREATE/JOIN CLUSTER` 的行为。可用选项如下：\n\n### name\n\n此选项指定集群名称。它应在系统中所有集群中唯一。\n\n> **注意：** `JOIN` 命令允许的最大主机名长度为 **253** 个字符。超过此限制，searchd 会报错。\n\n### path\n\npath 选项指定用于[写集缓存复制](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-gcache)和来自其他节点的传入表的数据目录。此值应在系统中所有集群中唯一，并应作为相对于 [data_dir](../../Server_settings/Searchd.md#data_dir) 目录的相对路径指定。默认设置为 [data_dir](../../Server_settings/Searchd.md#data_dir) 的值。\n\n### nodes\n\n`nodes` 选项是集群中所有节点的地址:端口对列表，使用逗号分隔。此列表应通过节点的 API 接口获取，也可以包含当前节点的地址。它用于将节点加入集群以及重启后重新加入。\n\n### options\n\n`options` 选项允许您直接向 Galera 复制插件传递额外选项，详见 [Galera 文档参数](https://galeracluster.com/library/documentation/galera-parameters.html)\n\n## 写语句\n\n<!-- example write statements 1 -->\n\n在使用复制集群时，所有修改集群表内容的写语句，如 `INSERT`、`REPLACE`、`DELETE`、`TRUNCATE`、`UPDATE`，必须使用 `cluster_name:table_name` 表达式替代表名。这确保更改传播到集群中的所有副本。如果未使用正确表达式，将触发错误。",
      "russian": "# Настройка репликации\n\nС Manticore транзакции записи (такие как `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE`, `UPDATE`, `COMMIT`) могут реплицироваться на другие узлы кластера до полного применения транзакции на текущем узле. В настоящее время репликация поддерживается для таблиц `percolate`, `rt` и `distributed` в Linux и macOS.\n\n[Нативные бинарные файлы для Windows](../../Installation/Windows.md#Installing-Manticore-as-native-Windows-binaries) для Manticore не поддерживают репликацию. Мы рекомендуем [устанавливать Manticore через WSL](../../Installation/Windows.md#Installing-or-enabling-WSL2) (Подсистема Windows для Linux).\n\nНа [macOS](../../Installation/MacOS.md) репликация имеет ограниченную поддержку и рекомендуется только для целей разработки.\n\nРепликация Manticore основана на библиотеке [Galera](https://github.com/codership/galera) и обладает несколькими впечатляющими функциями:\n\n* Истинный multi-master: чтение и запись на любой узел в любое время.\n\n* [Практически синхронная репликация](https://galeracluster.com/library/documentation/overview.html) — отсутствие задержек у слейвов и отсутствие потери данных после сбоя узла.\n\n* Горячее резервирование: отсутствие простоев при переключении (так как переключения нет).\n\n* Плотная связность: все узлы имеют одинаковое состояние, и не допускается расхождение данных между узлами.\n\n* Автоматическое добавление узлов: нет необходимости вручную создавать резервные копии базы данных и восстанавливать их на новом узле.\n\n* Простота использования и развертывания.\n\n* Обнаружение и автоматическое исключение ненадежных узлов.\n\n* Репликация на основе сертификации.\n\nДля настройки репликации в Manticore Search:\n\n* Опция [data_dir](../../Server_settings/Searchd.md#data_dir) должна быть установлена в разделе \"searchd\" конфигурационного файла. Репликация не поддерживается в plain режиме.\n\n* Должна быть указана директива [listen](../../Server_settings/Searchd.md#listen), содержащая IP-адрес, доступный другим узлам, или [node_address](../../Server_settings/Searchd.md#node_address) с доступным IP-адресом.\n\n* По желанию, вы можете задать уникальные значения для [server_id](../../Server_settings/Searchd.md#server_id) на каждом узле кластера. Если значение не задано, узел попытается использовать MAC-адрес или случайное число для генерации `server_id`.\n\nЕсли не задана директива `replication` [listen](../../Server_settings/Searchd.md#listen), Manticore использует первые два свободных порта из диапазона 200 портов после порта прослушивания протокола по умолчанию для каждого созданного кластера. Для ручной настройки портов репликации необходимо определить диапазон портов в директиве [listen](../../Server_settings/Searchd.md#listen) (типа `replication`), и пары адрес/диапазон портов не должны пересекаться между разными узлами на одном сервере. В качестве правила, диапазон портов должен содержать как минимум два порта на кластер. При определении слушателя репликации с диапазоном портов (например, `listen = 192.168.0.1:9320-9328:replication`), Manticore не начинает сразу прослушивать эти порты. Вместо этого он будет брать случайные свободные порты из указанного диапазона только при начале использования репликации.\n\n## Кластер репликации\n\nКластер репликации — это группа узлов, в которой реплицируется транзакция записи. Репликация настраивается на уровне таблицы, то есть одна таблица может принадлежать только одному кластеру. Нет ограничений на количество таблиц в кластере. Все транзакции, такие как `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE` для любой таблицы percolate или real-time, принадлежащей кластеру, реплицируются на все остальные узлы этого кластера. [Distributed](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md#Creating-a-distributed-table) таблицы также могут участвовать в процессе репликации. Репликация является multi-master, поэтому запись на любой узел или несколько узлов одновременно работает одинаково хорошо.\n\nДля создания кластера обычно используется команда [create cluster](../../Creating_a_cluster/Setting_up_replication/Creating_a_replication_cluster.md#Creating-a-replication-cluster) с `CREATE CLUSTER <cluster name>`, а для присоединения к кластеру — команда [join cluster](../../Creating_a_cluster/Setting_up_replication/Joining_a_replication_cluster.md#Joining-a-replication-cluster) с `JOIN CLUSTER <cluster name> at 'host:port'`. Однако в некоторых редких случаях может потребоваться тонкая настройка поведения `CREATE/JOIN CLUSTER`. Доступные опции:\n\n### name\n\nЭта опция задает имя кластера. Оно должно быть уникальным среди всех кластеров в системе.\n\n> **Примечание:** Максимальная допустимая длина имени хоста для команды `JOIN` составляет **253** символа. Если этот лимит превышен, searchd выдаст ошибку.\n\n### path\n\nОпция path задает каталог данных для [write-set cache replication](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-gcache) и входящих таблиц с других узлов. Это значение должно быть уникальным среди всех кластеров в системе и указываться как относительный путь к каталогу [data_dir](../../Server_settings/Searchd.md#data_dir). По умолчанию оно равно значению [data_dir](../../Server_settings/Searchd.md#data_dir).\n\n### nodes\n\nОпция `nodes` — это список пар адрес:порт для всех узлов кластера, разделенных запятыми. Этот список должен быть получен через API интерфейс узла и может включать адрес текущего узла. Используется для присоединения узла к кластеру и повторного присоединения после перезапуска.\n\n### options\n\nОпция `options` позволяет передавать дополнительные параметры напрямую плагину репликации Galera, как описано в [Galera Documentation Parameters](https://galeracluster.com/library/documentation/galera-parameters.html)\n\n## Операторы записи\n\n<!-- example write statements 1 -->\n\nПри работе с кластером репликации все операторы записи, такие как `INSERT`, `REPLACE`, `DELETE`, `TRUNCATE`, `UPDATE`, которые изменяют содержимое таблицы кластера, должны использовать выражение `cluster_name:table_name` вместо имени таблицы. Это гарантирует, что изменения будут распространены на все реплики в кластере. Если не использовать правильное выражение, будет вызвана ошибка."
    },
    "is_code_or_comment": false
  },
  "61ca3d98d131361e583043bb9141f12794b49e1c7c17b967e13c0104267253ae": {
    "original": "In the JSON interface, the `cluster` property must be set along with the `table` name for all write statements to a cluster's table. Failure to set the `cluster` property will result in an error.\n\nThe [Auto ID](../../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-ID) for a table in a cluster should be valid as long as the [server_id](../../Server_settings/Searchd.md#server_id) is correctly configured.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- request PHP -->\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n## Read statements\n\n<!-- example write statements 2 -->\n\nRead statements such as `SELECT`, `CALL PQ`, `DESCRIBE` can either use regular table names that are not prepended with a cluster name, or they can use the  `cluster_name:table_name`format. If the latter is used, the `cluster_name` component is ignored.\n\nWhen using the HTTP endpoint `json/search`, the `cluster` property can be specified if desired, but it can also be omitted.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_9\n\n<!-- request JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n## Cluster parameters\n\n<!-- example cluster parameters 1 -->\n\nReplication plugin options can be adjusted using the `SET` statement.\n\nA list of available options can be found in the [Galera Documentation Parameters](https://galeracluster.com/library/documentation/galera-parameters.html) .\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_11\n\n<!-- request JSON -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n## Cluster with diverged nodes\n\n<!-- example cluster with diverged nodes  1 -->\n\nIt's possible for replicated nodes to diverge from one another, leading to a state where all nodes are labeled as `non-primary`. This can occur as a result of a network split between nodes, a cluster crash, or if the replication plugin experiences an exception when determining the `primary component`. In such a scenario, it's necessary to select a node and promote it to the role of `primary component`.\n\nTo identify the node that needs to be promoted, you should compare the `last_committed` cluster status variable value on all nodes. If all the servers are currently running, there's no need to restart the cluster. Instead, you can simply promote the node with the highest last_committed value to the `primary component` using the `SET` statement (as demonstrated in the example).\n\nThe other nodes will then reconnect to the primary component and resynchronize their data based on this node.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_13\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n## Replication and cluster\n\n<!-- example replication and cluster 1 -->\n\nTo use replication, you need to define one [listen](../../Server_settings/Searchd.md#listen) port for SphinxAPI protocol and one  [listen](../../Server_settings/Searchd.md#listen) for replication address and port range in the configuration file. Also, specify the  [data_dir](../../Server_settings/Searchd.md#data_dir) folder to receive incoming tables.\n\n<!-- intro -->\n\n##### ini:\n\n<!-- request ini -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example replication and cluster 2 -->\n\nTo replicate tables, you must create a cluster on the server that has the local tables to be replicated.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- request JSON -->\n\nCODE_BLOCK_17\n\n<!-- request PHP -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example replication and cluster 3 -->\n\nAdd these local tables to the cluster\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_25\n\n<!-- request JSON -->\n\nCODE_BLOCK_26\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n<!-- example replication and cluster 4 -->\n\nAll other nodes that wish to receive a replica of the cluster's tables should join the cluster as follows:\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_34\n\n<!-- request JSON -->\n\nCODE_BLOCK_35\n\n<!-- request PHP -->\n\nCODE_BLOCK_36\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n<!-- example replication and cluster 5 -->\n\nWhen running queries, prepend the table name with the cluster name `posts`: or use the `cluster` property for HTTP request object.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_43\n\n<!-- request JSON -->\n\nCODE_BLOCK_44\n\n<!-- request PHP -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_46",
    "translations": {
      "chinese": "在 JSON 接口中，所有写入集群表的语句必须同时设置 `cluster` 属性和 `table` 名称。未设置 `cluster` 属性将导致错误。\n\n只要正确配置了 [server_id](../../Server_settings/Searchd.md#server_id)，集群中表的 [Auto ID](../../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-ID) 应该是有效的。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- request PHP -->\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n## 读取语句\n\n<!-- example write statements 2 -->\n\n读取语句如 `SELECT`、`CALL PQ`、`DESCRIBE` 可以使用未加集群名前缀的常规表名，也可以使用 `cluster_name:table_name` 格式。如果使用后者，`cluster_name` 部分会被忽略。\n\n使用 HTTP 端点 `json/search` 时，可以选择指定 `cluster` 属性，也可以省略。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_9\n\n<!-- request JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n## 集群参数\n\n<!-- example cluster parameters 1 -->\n\n可以使用 `SET` 语句调整复制插件选项。\n\n可用选项列表见 [Galera Documentation Parameters](https://galeracluster.com/library/documentation/galera-parameters.html) 。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_11\n\n<!-- request JSON -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n## 节点分歧的集群\n\n<!-- example cluster with diverged nodes  1 -->\n\n复制节点可能会出现分歧，导致所有节点都被标记为 `non-primary`。这可能是由于节点间网络分割、集群崩溃，或复制插件在确定 `primary component` 时发生异常。此时需要选择一个节点并将其提升为 `primary component`。\n\n要确定需要提升的节点，应比较所有节点上的 `last_committed` 集群状态变量值。如果所有服务器都在运行，则无需重启集群。只需使用 `SET` 语句将具有最高 last_committed 值的节点提升为 `primary component`（如示例所示）。\n\n其他节点随后将重新连接到主组件，并基于该节点重新同步数据。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_13\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n## 复制与集群\n\n<!-- example replication and cluster 1 -->\n\n要使用复制，需要在配置文件中定义一个用于 SphinxAPI 协议的 [listen](../../Server_settings/Searchd.md#listen) 端口，以及一个用于复制地址和端口范围的 [listen](../../Server_settings/Searchd.md#listen) 。还需指定接收传入表的 [data_dir](../../Server_settings/Searchd.md#data_dir) 文件夹。\n\n<!-- intro -->\n\n##### ini:\n\n<!-- request ini -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example replication and cluster 2 -->\n\n要复制表，必须在拥有本地表的服务器上创建集群。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- request JSON -->\n\nCODE_BLOCK_17\n\n<!-- request PHP -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example replication and cluster 3 -->\n\n将这些本地表添加到集群中\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_25\n\n<!-- request JSON -->\n\nCODE_BLOCK_26\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n<!-- example replication and cluster 4 -->\n\n所有希望接收集群表副本的其他节点应按如下方式加入集群：\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_34\n\n<!-- request JSON -->\n\nCODE_BLOCK_35\n\n<!-- request PHP -->\n\nCODE_BLOCK_36\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n<!-- example replication and cluster 5 -->\n\n运行查询时，在表名前加上集群名 `posts`：或在 HTTP 请求对象中使用 `cluster` 属性。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_43\n\n<!-- request JSON -->\n\nCODE_BLOCK_44\n\n<!-- request PHP -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_46",
      "russian": "В JSON-интерфейсе свойство `cluster` должно быть установлено вместе с именем `table` для всех операторов записи в таблицу кластера. Если свойство `cluster` не установлено, возникнет ошибка.\n\n[Auto ID](../../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-ID) для таблицы в кластере должен быть действительным, если правильно настроен [server_id](../../Server_settings/Searchd.md#server_id).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_0\n\n<!-- request JSON -->\n\nCODE_BLOCK_1\n\n<!-- request PHP -->\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n## Операторы чтения\n\n<!-- example write statements 2 -->\n\nОператоры чтения, такие как `SELECT`, `CALL PQ`, `DESCRIBE`, могут использовать либо обычные имена таблиц без префикса с именем кластера, либо формат `cluster_name:table_name`. Если используется второй вариант, компонент `cluster_name` игнорируется.\n\nПри использовании HTTP-эндпоинта `json/search` свойство `cluster` можно указать при желании, но его также можно опустить.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_9\n\n<!-- request JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n## Параметры кластера\n\n<!-- example cluster parameters 1 -->\n\nОпции плагина репликации можно настроить с помощью оператора `SET`.\n\nСписок доступных опций можно найти в [Galera Documentation Parameters](https://galeracluster.com/library/documentation/galera-parameters.html).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_11\n\n<!-- request JSON -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n## Кластер с расходящимися узлами\n\n<!-- example cluster with diverged nodes  1 -->\n\nВозможно, что реплицируемые узлы расходятся друг с другом, что приводит к состоянию, когда все узлы помечены как `non-primary`. Это может произойти из-за сетевого разрыва между узлами, сбоя кластера или если плагин репликации сталкивается с исключением при определении `primary component`. В таком случае необходимо выбрать узел и повысить его до роли `primary component`.\n\nЧтобы определить узел, который нужно повысить, следует сравнить значение переменной статуса кластера `last_committed` на всех узлах. Если все серверы в данный момент работают, перезапуск кластера не требуется. Вместо этого можно просто повысить узел с наибольшим значением last_committed до `primary component` с помощью оператора `SET` (как показано в примере).\n\nОстальные узлы затем переподключатся к primary component и синхронизируют свои данные на основе этого узла.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_13\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n## Репликация и кластер\n\n<!-- example replication and cluster 1 -->\n\nДля использования репликации необходимо определить один [listen](../../Server_settings/Searchd.md#listen) порт для протокола SphinxAPI и один [listen](../../Server_settings/Searchd.md#listen) для адреса репликации и диапазона портов в конфигурационном файле. Также укажите папку [data_dir](../../Server_settings/Searchd.md#data_dir) для приема входящих таблиц.\n\n<!-- intro -->\n\n##### ini:\n\n<!-- request ini -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example replication and cluster 2 -->\n\nДля репликации таблиц необходимо создать кластер на сервере, где находятся локальные таблицы для репликации.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- request JSON -->\n\nCODE_BLOCK_17\n\n<!-- request PHP -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example replication and cluster 3 -->\n\nДобавьте эти локальные таблицы в кластер\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_25\n\n<!-- request JSON -->\n\nCODE_BLOCK_26\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n<!-- example replication and cluster 4 -->\n\nВсе остальные узлы, которые хотят получить реплику таблиц кластера, должны присоединиться к кластеру следующим образом:\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_34\n\n<!-- request JSON -->\n\nCODE_BLOCK_35\n\n<!-- request PHP -->\n\nCODE_BLOCK_36\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n<!-- example replication and cluster 5 -->\n\nПри выполнении запросов добавляйте к имени таблицы префикс с именем кластера `posts`: или используйте свойство `cluster` в объекте HTTP-запроса.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_43\n\n<!-- request JSON -->\n\nCODE_BLOCK_44\n\n<!-- request PHP -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_46"
    },
    "is_code_or_comment": false
  }
}
