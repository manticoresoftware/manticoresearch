{
  "e00f36cff46644995977af9c75667b84bce0cd3da1efd9efb84e5ec53e5b1569": {
    "original": "### Natural language processing specific settings\n\nThe following settings are supported. They are all described in section [NLP and tokenization](../../Creating_a_table/NLP_and_tokenization/Data_tokenization.md).\n\n* [bigram_freq_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_freq_words)\n\n* [bigram_index](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index)\n\n* [blend_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars)\n\n* [blend_mode](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_mode)\n\n* [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)\n\n* [dict](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#dict)\n\n* [embedded_limit](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#embedded_limit)\n\n* [exceptions](../../Creating_a_table/NLP_and_tokenization/Exceptions.md)\n\n* [expand_keywords](../../Searching/Options.md#expand_keywords)\n\n* [global_idf](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#global_idf)\n\n* [hitless_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#hitless_words)\n\n* [html_index_attrs](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_index_attrs)\n\n* [html_remove_elements](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_remove_elements)\n\n* [html_strip](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_strip)\n\n* [ignore_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars)\n\n* [index_exact_words](../../Creating_a_table/NLP_and_tokenization/Morphology.md#index_exact_words)\n\n* [index_field_lengths](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_field_lengths)\n\n* [index_sp](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_sp)\n\n* [index_token_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter)\n\n* [index_zones](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_zones)\n\n* [infix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#infix_fields)\n\n* [killlist_target](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#killlist_target)\n\n* [max_substring_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#max_substring_len)\n\n* [min_infix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_infix_len)\n\n* [min_prefix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_prefix_len)\n\n* [min_stemming_len](../../Creating_a_table/NLP_and_tokenization/Morphology.md#min_stemming_len)\n\n* [min_word_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len)\n\n* [morphology](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology)\n\n* [morphology_skip_fields](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology_skip_fields)\n\n* [ngram_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_chars)\n\n* [ngram_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_len)\n\n* [overshort_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#overshort_step)\n\n* [phrase_boundary](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary)\n\n* [phrase_boundary_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary_step)\n\n* [prefix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#prefix_fields)\n\n* [regexp_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#regexp_filter)\n\n* [stopwords](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords)\n\n* [stopword_step](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopword_step)\n\n* [stopwords_unstemmed](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords_unstemmed)\n\n* [stored_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#stored_fields)\n\n* [stored_only_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md)\n\n* [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms)\n\n<!-- proofread -->",
    "translations": {
      "chinese": "### 自然语言处理特定设置\n\n支持以下设置。它们均在章节 [NLP 和分词](../../Creating_a_table/NLP_and_tokenization/Data_tokenization.md) 中进行了描述。\n\n* [bigram_freq_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_freq_words)\n\n* [bigram_index](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index)\n\n* [blend_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars)\n\n* [blend_mode](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_mode)\n\n* [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)\n\n* [dict](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#dict)\n\n* [embedded_limit](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#embedded_limit)\n\n* [exceptions](../../Creating_a_table/NLP_and_tokenization/Exceptions.md)\n\n* [expand_keywords](../../Searching/Options.md#expand_keywords)\n\n* [global_idf](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#global_idf)\n\n* [hitless_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#hitless_words)\n\n* [html_index_attrs](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_index_attrs)\n\n* [html_remove_elements](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_remove_elements)\n\n* [html_strip](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_strip)\n\n* [ignore_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars)\n\n* [index_exact_words](../../Creating_a_table/NLP_and_tokenization/Morphology.md#index_exact_words)\n\n* [index_field_lengths](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_field_lengths)\n\n* [index_sp](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_sp)\n\n* [index_token_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter)\n\n* [index_zones](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_zones)\n\n* [infix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#infix_fields)\n\n* [killlist_target](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#killlist_target)\n\n* [max_substring_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#max_substring_len)\n\n* [min_infix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_infix_len)\n\n* [min_prefix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_prefix_len)\n\n* [min_stemming_len](../../Creating_a_table/NLP_and_tokenization/Morphology.md#min_stemming_len)\n\n* [min_word_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len)\n\n* [morphology](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology)\n\n* [morphology_skip_fields](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology_skip_fields)\n\n* [ngram_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_chars)\n\n* [ngram_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_len)\n\n* [overshort_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#overshort_step)\n\n* [phrase_boundary](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary)\n\n* [phrase_boundary_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary_step)\n\n* [prefix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#prefix_fields)\n\n* [regexp_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#regexp_filter)\n\n* [stopwords](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords)\n\n* [stopword_step](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopword_step)\n\n* [stopwords_unstemmed](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords_unstemmed)\n\n* [stored_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#stored_fields)\n\n* [stored_only_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md)\n\n* [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms)\n\n<!-- proofread -->",
      "russian": "### Специфические настройки обработки естественного языка\n\nПоддерживаются следующие настройки. Все они описаны в разделе [NLP и токенизация](../../Creating_a_table/NLP_and_tokenization/Data_tokenization.md).\n\n* [bigram_freq_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_freq_words)\n\n* [bigram_index](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index)\n\n* [blend_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars)\n\n* [blend_mode](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_mode)\n\n* [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)\n\n* [dict](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#dict)\n\n* [embedded_limit](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#embedded_limit)\n\n* [exceptions](../../Creating_a_table/NLP_and_tokenization/Exceptions.md)\n\n* [expand_keywords](../../Searching/Options.md#expand_keywords)\n\n* [global_idf](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#global_idf)\n\n* [hitless_words](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#hitless_words)\n\n* [html_index_attrs](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_index_attrs)\n\n* [html_remove_elements](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_remove_elements)\n\n* [html_strip](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#html_strip)\n\n* [ignore_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars)\n\n* [index_exact_words](../../Creating_a_table/NLP_and_tokenization/Morphology.md#index_exact_words)\n\n* [index_field_lengths](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_field_lengths)\n\n* [index_sp](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_sp)\n\n* [index_token_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter)\n\n* [index_zones](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#index_zones)\n\n* [infix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#infix_fields)\n\n* [killlist_target](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#killlist_target)\n\n* [max_substring_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#max_substring_len)\n\n* [min_infix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_infix_len)\n\n* [min_prefix_len](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#min_prefix_len)\n\n* [min_stemming_len](../../Creating_a_table/NLP_and_tokenization/Morphology.md#min_stemming_len)\n\n* [min_word_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len)\n\n* [morphology](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology)\n\n* [morphology_skip_fields](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology_skip_fields)\n\n* [ngram_chars](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_chars)\n\n* [ngram_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ngram_len)\n\n* [overshort_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#overshort_step)\n\n* [phrase_boundary](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary)\n\n* [phrase_boundary_step](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary_step)\n\n* [prefix_fields](../../Creating_a_table/NLP_and_tokenization/Wildcard_searching_settings.md#prefix_fields)\n\n* [regexp_filter](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#regexp_filter)\n\n* [stopwords](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords)\n\n* [stopword_step](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopword_step)\n\n* [stopwords_unstemmed](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords_unstemmed)\n\n* [stored_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#stored_fields)\n\n* [stored_only_fields](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md)\n\n* [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms)\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "71bf3be41482ed42157bc89f5132a8ce48338d85630aadc8f29d609bda94f19c": {
    "original": "In real-time mode, you can adjust the size limit of RAM chunks and the maximum number of disk chunks using the `ALTER TABLE` statement. To set `rt_mem_limit` to 1 gigabyte for the table \"t\", run the following query: `ALTER TABLE t rt_mem_limit='1G'`. To change the maximum number of disk chunks, run the query: `ALTER TABLE t optimize_cutoff='5'`.\n\nIn the plain mode, you can change the values of `rt_mem_limit` and `optimize_cutoff` by updating the table configuration or running the command `ALTER TABLE <table_name> RECONFIGURE`\n\n##### Important notes about RAM chunks\n\n* Real-time tables are similar to [distributed](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table) consisting of multiple local tables, also known as disk chunks.\n\n* Each RAM chunk is made up of multiple segments, which are special RAM-only tables.\n\n* While disk chunks are stored on disk, RAM chunks are stored in memory.\n\n* Each transaction made to a real-time table generates a new segment, and RAM chunk segments are merged after each transaction commit. It is more efficient to perform bulk INSERTs of hundreds or thousands of documents rather than multiple separate INSERTs with one document to reduce the overhead from merging RAM chunk segments.\n\n* When the number of segments exceeds 32, they will be merged to keep the count below 32.\n\n* Real-time tables always have one RAM chunk (which may be empty) and one or more disk chunks.\n\n* Merging larger segments takes longer, so it's best to avoid having a very large RAM chunk (and therefore `rt_mem_limit`).\n\n* The number of disk chunks depends on the data in the table and the `rt_mem_limit` setting.\n\n* Searchd flushes the RAM chunk to disk (as a persisted file, not as a disk chunk) on shutdown and periodically according to the [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period) setting. Flushing several gigabytes to disk may take some time.\n\n* A large RAM chunk puts more pressure on storage, both when flushing to disk into the `.ram` file and when the RAM chunk is full and dumped to disk as a disk chunk.\n\n* The RAM chunk is backed up by a [binary log](../../Logging/Binary_logging.md) until it is flushed to disk, and a larger `rt_mem_limit`, setting will increase the time it takes to replay the binary log and recover the RAM chunk.\n\n* The RAM chunk may be slightly slower than a disk chunk.\n\n* Although the RAM chunk itself doesn't take up more memory than `rt_mem_limit`, Manticore may take up more memory in some cases, such as when you start a transaction to insert data and don't commit it for a while. In this case, the data you have already transmitted within the transaction will remain in memory.\n\n##### RAM chunk flushing conditions\n\nIn addition to `rt_mem_limit`, the flushing behavior of RAM chunks is also influenced by the following options and conditions:\n\n* Frozen state. If the table is [frozen](../../Securing_and_compacting_a_table/Freezing_a_table.md), flushing is deferred. That is a permanent rule; nothing can override it. If the `rt_mem_limit` condition is reached while the table is frozen, all further inserts will be delayed until the table is unfrozen.\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout): This option defines the timeout (in seconds) for auto-flushing a RAM chunk if there are no writes to it.  If no write occurs within this time, the chunk will be flushed to disk. Setting it to `-1` disables auto-flushing based on write activity. The default value is 1 second.\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout): This option sets the timeout (in seconds) for preventing auto-flushing a RAM chunk if there are no searches in the table. Auto-flushing will only occur if there has been at least one search within this time. The default value is 30 seconds.\n\n* ongoing optimization: If an optimization process is currently running, and the number of existing disk chunks has\n\n  reached or exceeded a configured internal `cutoff` threshold, the flush triggered by the `diskchunk_flush_write_timeout` or `diskchunk_flush_search_timeout` timeout will be skipped.\n\n* too few documents in RAM segments: If the number of documents across RAM segments is below a minimum threshold (8192),\n\n  the flush triggered by the `diskchunk_flush_write_timeout` or `diskchunk_flush_search_timeout` timeout will be skipped to avoid creating very small disk chunks. This helps minimize unnecessary disk writes and chunk fragmentation.\n\nThese timeouts work in conjunction.  A RAM chunk will be flushed if *either* timeout is reached.  This ensures that even if there are no writes, the data will eventually be persisted to disk, and conversely, even if there are constant writes but no searches, the data will also be persisted.  These settings provide more granular control over how frequently RAM chunks are flushed, balancing the need for data durability with performance considerations.  Per-table directives for these settings have higher priority and will override the instance-wide defaults.\n\n### Plain table settings:\n\n#### source\n\nCODE_BLOCK_47\n\nThe source field specifies the source from which documents will be obtained during indexing of the current table. There must be at least one source. The sources can be of different types (e.g. one could be MySQL, another PostgreSQL). For more information on indexing from external storages, [read here](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\nValue: The name of the source is **mandatory**. Multiple values are allowed.\n\n#### killlist_target\n\nCODE_BLOCK_48",
    "translations": {
      "chinese": "在实时模式下，您可以使用 `ALTER TABLE` 语句调整 RAM 块的大小限制和磁盘块的最大数量。要将表 \"t\" 的 `rt_mem_limit` 设置为 1 GB，请运行以下查询：`ALTER TABLE t rt_mem_limit='1G'`。要更改磁盘块的最大数量，请运行查询：`ALTER TABLE t optimize_cutoff='5'`。\n\n在普通模式下，您可以通过更新表配置或运行命令 `ALTER TABLE <table_name> RECONFIGURE` 来更改 `rt_mem_limit` 和 `optimize_cutoff` 的值。\n\n##### 关于 RAM 块的重要说明\n\n* 实时表类似于由多个本地表组成的[分布式表](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table)，这些本地表也称为磁盘块。\n\n* 每个 RAM 块由多个段组成，这些段是特殊的仅限 RAM 的表。\n\n* 磁盘块存储在磁盘上，而 RAM 块存储在内存中。\n\n* 对实时表的每个事务都会生成一个新段，RAM 块段在每次事务提交后合并。执行数百或数千文档的批量 INSERT 比多次单文档 INSERT 更高效，以减少合并 RAM 块段的开销。\n\n* 当段的数量超过 32 时，它们将被合并以保持数量低于 32。\n\n* 实时表始终有一个 RAM 块（可能为空）和一个或多个磁盘块。\n\n* 合并较大的段需要更长时间，因此最好避免拥有非常大的 RAM 块（因此也避免设置过大的 `rt_mem_limit`）。\n\n* 磁盘块的数量取决于表中的数据和 `rt_mem_limit` 设置。\n\n* Searchd 在关闭时以及根据 [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period) 设置定期将 RAM 块刷新到磁盘（作为持久化文件，而非磁盘块）。刷新几个 GB 到磁盘可能需要一些时间。\n\n* 大的 RAM 块在刷新到磁盘的 `.ram` 文件以及 RAM 块满时转储为磁盘块时，会对存储造成更大压力。\n\n* RAM 块由[二进制日志](../../Logging/Binary_logging.md)备份，直到刷新到磁盘，较大的 `rt_mem_limit` 设置会增加重放二进制日志和恢复 RAM 块所需的时间。\n\n* RAM 块的速度可能略慢于磁盘块。\n\n* 虽然 RAM 块本身占用的内存不会超过 `rt_mem_limit`，但在某些情况下，Manticore 可能会占用更多内存，例如当您启动一个插入数据的事务但长时间不提交时，此时您已传输的数据会保留在内存中。\n\n##### RAM 块刷新条件\n\n除了 `rt_mem_limit`，RAM 块的刷新行为还受以下选项和条件影响：\n\n* 冻结状态。如果表处于[冻结](../../Securing_and_compacting_a_table/Freezing_a_table.md)状态，刷新将被推迟。这是永久规则，无法被覆盖。如果在表冻结时达到 `rt_mem_limit` 条件，所有后续插入将被延迟，直到表解冻。\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout)：此选项定义了如果没有写入操作，自动刷新 RAM 块的超时时间（秒）。如果在此时间内没有写入，块将被刷新到磁盘。设置为 `-1` 禁用基于写入活动的自动刷新。默认值为 1 秒。\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout)：此选项设置如果表中没有搜索，防止自动刷新 RAM 块的超时时间（秒）。只有在此时间内至少有一次搜索时，才会自动刷新。默认值为 30 秒。\n\n* 正在进行的优化：如果当前有优化进程运行，且现有磁盘块数量已达到或超过配置的内部 `cutoff` 阈值，则由 `diskchunk_flush_write_timeout` 或 `diskchunk_flush_search_timeout` 超时触发的刷新将被跳过。\n\n* RAM 段中文档数量过少：如果 RAM 段中的文档总数低于最小阈值（8192），则由 `diskchunk_flush_write_timeout` 或 `diskchunk_flush_search_timeout` 超时触发的刷新将被跳过，以避免创建非常小的磁盘块。这有助于减少不必要的磁盘写入和块碎片。\n\n这些超时设置是协同工作的。只要达到任一超时，RAM 块就会被刷新。这确保即使没有写入，数据最终也会持久化到磁盘；反之，即使有持续写入但没有搜索，数据也会被持久化。这些设置提供了更细粒度的控制，平衡数据持久性和性能考虑。每个表的指令优先级更高，会覆盖实例范围的默认值。\n\n### 普通表设置：\n\n#### source\n\nCODE_BLOCK_47\n\nsource 字段指定在当前表索引期间将从哪个源获取文档。必须至少有一个源。源可以是不同类型的（例如，一个可能是 MySQL，另一个是 PostgreSQL）。有关从外部存储索引的更多信息，[请阅读这里](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\n值：源名称是**必需的**。允许多个值。\n\n#### killlist_target\n\nCODE_BLOCK_48",
      "russian": "В режиме реального времени вы можете настроить ограничение размера RAM-чанков и максимальное количество дисковых чанков с помощью оператора `ALTER TABLE`. Чтобы установить `rt_mem_limit` в 1 гигабайт для таблицы \"t\", выполните следующий запрос: `ALTER TABLE t rt_mem_limit='1G'`. Чтобы изменить максимальное количество дисковых чанков, выполните запрос: `ALTER TABLE t optimize_cutoff='5'`.\n\nВ обычном режиме вы можете изменить значения `rt_mem_limit` и `optimize_cutoff`, обновив конфигурацию таблицы или выполнив команду `ALTER TABLE <table_name> RECONFIGURE`\n\n##### Важные заметки о RAM-чанках\n\n* Таблицы реального времени похожи на [распределённые](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table), состоящие из нескольких локальных таблиц, также известных как дисковые чанки.\n\n* Каждый RAM-чанк состоит из нескольких сегментов, которые являются специальными таблицами, работающими только в памяти.\n\n* В то время как дисковые чанки хранятся на диске, RAM-чанки хранятся в памяти.\n\n* Каждая транзакция, выполненная с таблицей реального времени, создаёт новый сегмент, и сегменты RAM-чанка объединяются после каждого коммита транзакции. Более эффективно выполнять массовые INSERT-запросы сотнями или тысячами документов, чем множество отдельных INSERT-запросов с одним документом, чтобы уменьшить накладные расходы на слияние сегментов RAM-чанка.\n\n* Когда количество сегментов превышает 32, они объединяются, чтобы сохранить количество ниже 32.\n\n* Таблицы реального времени всегда имеют один RAM-чанк (который может быть пустым) и один или несколько дисковых чанков.\n\n* Слияние больших сегментов занимает больше времени, поэтому лучше избегать очень большого RAM-чанка (и, следовательно, большого значения `rt_mem_limit`).\n\n* Количество дисковых чанков зависит от данных в таблице и настройки `rt_mem_limit`.\n\n* Searchd сбрасывает RAM-чанк на диск (в виде сохранённого файла, а не как дисковый чанк) при завершении работы и периодически в соответствии с настройкой [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period). Сброс нескольких гигабайт на диск может занять некоторое время.\n\n* Большой RAM-чанк создаёт большую нагрузку на хранилище как при сбросе на диск в файл `.ram`, так и когда RAM-чанк заполняется и сбрасывается на диск как дисковый чанк.\n\n* RAM-чанк поддерживается [бинарным журналом](../../Logging/Binary_logging.md) до тех пор, пока не будет сброшен на диск, и более высокое значение `rt_mem_limit` увеличит время воспроизведения бинарного журнала и восстановления RAM-чанка.\n\n* RAM-чанк может работать немного медленнее, чем дисковый чанк.\n\n* Хотя сам RAM-чанк не занимает больше памяти, чем `rt_mem_limit`, Manticore может занимать больше памяти в некоторых случаях, например, когда вы начинаете транзакцию для вставки данных и не коммитите её некоторое время. В этом случае данные, которые вы уже передали в рамках транзакции, останутся в памяти.\n\n##### Условия сброса RAM-чанка\n\nПомимо `rt_mem_limit`, поведение сброса RAM-чанков также зависит от следующих опций и условий:\n\n* Состояние заморозки. Если таблица [заморожена](../../Securing_and_compacting_a_table/Freezing_a_table.md), сброс откладывается. Это постоянное правило; ничто не может его переопределить. Если условие `rt_mem_limit` достигнуто, пока таблица заморожена, все последующие вставки будут задержаны до разморозки таблицы.\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout): Эта опция задаёт тайм-аут (в секундах) для автоматического сброса RAM-чанка, если в него не происходит запись. Если в течение этого времени запись не происходит, чанк будет сброшен на диск. Установка значения `-1` отключает автоматический сброс на основе активности записи. Значение по умолчанию — 1 секунда.\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout): Эта опция задаёт тайм-аут (в секундах) для предотвращения автоматического сброса RAM-чанка, если в таблице не выполняются поиски. Автоматический сброс произойдёт только если в течение этого времени был хотя бы один поиск. Значение по умолчанию — 30 секунд.\n\n* Текущая оптимизация: Если в данный момент выполняется процесс оптимизации, и количество существующих дисковых чанков достигло или превысило настроенный внутренний порог `cutoff`, сброс, вызванный тайм-аутом `diskchunk_flush_write_timeout` или `diskchunk_flush_search_timeout`, будет пропущен.\n\n* Слишком мало документов в RAM-сегментах: Если количество документов во всех RAM-сегментах ниже минимального порога (8192),\n\n  сброс, вызванный тайм-аутом `diskchunk_flush_write_timeout` или `diskchunk_flush_search_timeout`, будет пропущен, чтобы избежать создания очень маленьких дисковых чанков. Это помогает минимизировать ненужные записи на диск и фрагментацию чанков.\n\nЭти тайм-ауты работают совместно. RAM-чанк будет сброшен, если достигнут *любой* из тайм-аутов. Это гарантирует, что даже при отсутствии записей данные в конечном итоге будут сохранены на диск, и наоборот, даже при постоянных записях, но отсутствии поисков, данные также будут сохранены. Эти настройки обеспечивают более тонкий контроль над частотой сброса RAM-чанков, балансируя между необходимостью сохранности данных и производительностью. Директивы на уровне таблицы имеют более высокий приоритет и переопределяют значения по умолчанию для всего экземпляра.\n\n### Настройки обычной таблицы:\n\n#### source\n\nCODE_BLOCK_47\n\nПоле source указывает источник, из которого будут получены документы при индексировании текущей таблицы. Должен быть как минимум один источник. Источники могут быть разных типов (например, один может быть MySQL, другой PostgreSQL). Для получения дополнительной информации об индексировании из внешних хранилищ [читайте здесь](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\nЗначение: Имя источника является **обязательным**. Допускается несколько значений.\n\n#### killlist_target\n\nCODE_BLOCK_48"
    },
    "is_code_or_comment": false
  },
  "8d0b641fbff36cbacbdae0d26691d16917283a5059dae0e6e4f0caaf019ecaca": {
    "original": "CODE_BLOCK_25\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_30\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### Real-time table settings:\n\n#### diskchunk_flush_search_timeout\n\nCODE_BLOCK_32\n\nThe timeout for preventing auto-flushing a RAM chunk if there are no searches in the table. Learn more [here](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout).\n\n#### diskchunk_flush_write_timeout\n\nCODE_BLOCK_33\n\nThe timeout for auto-flushing a RAM chunk if there are no writes to it. Learn more [here](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout).\n\n#### optimize_cutoff\n\nThe maximum number of disk chunks for the RT table. Learn more [here](../../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks).\n\n#### rt_field\n\nCODE_BLOCK_34\n\nThis field declaration determines the full-text fields that will be indexed. The field names must be unique, and the order is preserved. When inserting data, the field values must be in the same order as specified in the configuration.\n\nThis is a multi-value, optional field.\n\n#### rt_attr_uint\n\nCODE_BLOCK_35\n\nThis declaration defines an unsigned integer attribute.\n\nValue: the field name or field_name:N (where N is the maximum number of bits to keep).\n\n#### rt_attr_bigint\n\nCODE_BLOCK_36\n\nThis declaration defines a BIGINT attribute.\n\nValue: field name, multiple records allowed.\n\n#### rt_attr_multi\n\nCODE_BLOCK_37\n\nDeclares a multi-valued attribute (MVA) with unsigned 32-bit integer values.\n\nValue: field name. Multiple records allowed.\n\n#### rt_attr_multi_64\n\nCODE_BLOCK_38\n\nDeclares a multi-valued attribute (MVA) with signed 64-bit BIGINT values.\n\nValue: field name. Multiple records allowed.\n\n#### rt_attr_float\n\nCODE_BLOCK_39\n\nDeclares floating point attributes with single precision, 32-bit IEEE 754 format.\n\nValue: field name. Multiple records allowed.\n\n#### rt_attr_float_vector\n\nCODE_BLOCK_40\n\nDeclares a vector of floating-point values for storing embeddings and enabling k-nearest neighbor (KNN) vector searches.\n\nValue: field name. Multiple records allowed.\n\nEach vector attribute stores an array of floating-point numbers that represent data (such as text, images, or other content) as high-dimensional vectors. These vectors are typically generated by machine learning models and can be used for similarity search, recommendations, semantic search, and other AI-powered features.\n\n**Important:** Float vector attributes require additional KNN configuration to enable vector search capabilities.\n\n##### Configuring KNN for vector attributes\n\nTo enable KNN searches on float vector attributes, you must add a `knn` configuration that specifies the indexing parameters:\n\nCODE_BLOCK_41\n\n**Required KNN parameters:**\n\n- `name`: The name of the vector attribute (must match the `rt_attr_float_vector` name)\n\n- `type`: Index type, currently only `\"hnsw\"` is supported\n\n- `dims`: Number of dimensions in the vectors (must match your embedding model's output)\n\n- `hnsw_similarity`: Distance function - `\"L2\"`, `\"IP\"` (inner product), or `\"COSINE\"`\n\n**Optional KNN parameters:**\n\n- `hnsw_m`: Maximum connections in the graph\n\n- `hnsw_ef_construction`: Construction time/accuracy trade-off\n\nFor more details on KNN vector search, see the [KNN documentation](../../Searching/KNN.md).\n\n#### rt_attr_bool\n\nCODE_BLOCK_42\n\nDeclares a boolean attribute with 1-bit unsigned integer values.\n\nValue: field name.\n\n#### rt_attr_string\n\nCODE_BLOCK_43\n\nString attribute declaration.\n\nValue: field name.\n\n#### rt_attr_json\n\nCODE_BLOCK_44\n\nDeclares a JSON attribute.\n\nValue: field name.\n\n#### rt_attr_timestamp\n\nCODE_BLOCK_45\n\nDeclares a timestamp attribute.\n\nValue: field name.\n\n#### rt_mem_limit\n\nCODE_BLOCK_46\n\nMemory limit for a RAM chunk of the table. Optional, default is 128M.\n\nRT tables store some data in memory, known as the \"RAM chunk\", and also maintain a number of on-disk tables, referred to as \"disk chunks.\" This directive allows you to control the size of the RAM chunk. When there is too much data to keep in memory, RT tables will flush it to disk, activate a newly created disk chunk, and reset the RAM chunk.\n\nPlease note that the limit is strict, and RT tables will never allocate more memory than what is specified in the rt_mem_limit. Additionally, memory is not preallocated, so specifying a 512MB limit and only inserting 3MB of data will result in allocating only 3MB, not 512MB.\n\nThe `rt_mem_limit` is never exceeded, but the actual RAM chunk size can be significantly lower than the limit. RT tables adapt to the data insertion pace and adjust the actual limit dynamically to minimize memory usage and maximize data write speed. This is how it works:\n\n* By default, the RAM chunk size is 50% of the  `rt_mem_limit`, referred to as the  \"`rt_mem_limit` limit\".\n\n* As soon as the RAM chunk accumulates data equivalent to `rt_mem_limit * rate` data (50% of `rt_mem_limit` by default), Manticore starts saving the RAM chunk as a new disk chunk.\n\n* While a new disk chunk is being saved, Manticore assesses the number of new/updated documents.\n\n* After saving a new disk chunk, the `rt_mem_limit` rate is updated.\n\n* The rate is reset to 50% each time you restart the searchd.\n\nFor instance, if 90MB of data is saved to a disk chunk and an additional 10MB of data arrives while the save is in progress, the rate would be 90%. Next time, the RT table will collect up to 90% of `rt_mem_limit` before flushing the data. The faster the insertion pace, the lower the `rt_mem_limit` rate. The rate varies between 33.3% to 95%. You can view the current rate of a table using the [SHOW TABLE <tbl> STATUS](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_STATUS.md) command.\n\n##### How to change rt_mem_limit and optimize_cutoff",
    "translations": {
      "chinese": "CODE_BLOCK_25\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_30\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### 实时表设置：\n\n#### diskchunk_flush_search_timeout\n\nCODE_BLOCK_32\n\n防止自动刷新RAM块的超时时间，如果表中没有搜索。更多信息请参见[这里](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout)。\n\n#### diskchunk_flush_write_timeout\n\nCODE_BLOCK_33\n\n如果没有写入操作，自动刷新RAM块的超时时间。更多信息请参见[这里](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout)。\n\n#### optimize_cutoff\n\nRT表的最大磁盘块数量。更多信息请参见[这里](../../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks)。\n\n#### rt_field\n\nCODE_BLOCK_34\n\n此字段声明确定将被索引的全文字段。字段名称必须唯一，且顺序保持不变。插入数据时，字段值必须与配置中指定的顺序相同。\n\n这是一个多值的可选字段。\n\n#### rt_attr_uint\n\nCODE_BLOCK_35\n\n此声明定义一个无符号整数属性。\n\n值：字段名或 field_name:N（其中N是要保留的最大位数）。\n\n#### rt_attr_bigint\n\nCODE_BLOCK_36\n\n此声明定义一个BIGINT属性。\n\n值：字段名，允许多条记录。\n\n#### rt_attr_multi\n\nCODE_BLOCK_37\n\n声明一个多值属性（MVA），值为无符号32位整数。\n\n值：字段名。允许多条记录。\n\n#### rt_attr_multi_64\n\nCODE_BLOCK_38\n\n声明一个多值属性（MVA），值为有符号64位BIGINT。\n\n值：字段名。允许多条记录。\n\n#### rt_attr_float\n\nCODE_BLOCK_39\n\n声明单精度浮点属性，采用32位IEEE 754格式。\n\n值：字段名。允许多条记录。\n\n#### rt_attr_float_vector\n\nCODE_BLOCK_40\n\n声明一个浮点向量属性，用于存储嵌入向量并支持k近邻（KNN）向量搜索。\n\n值：字段名。允许多条记录。\n\n每个向量属性存储一个浮点数数组，表示数据（如文本、图像或其他内容）的高维向量。这些向量通常由机器学习模型生成，可用于相似度搜索、推荐、语义搜索及其他AI驱动的功能。\n\n**重要：** 浮点向量属性需要额外的KNN配置以启用向量搜索功能。\n\n##### 配置向量属性的KNN\n\n要在浮点向量属性上启用KNN搜索，必须添加一个`knn`配置，指定索引参数：\n\nCODE_BLOCK_41\n\n**必需的KNN参数：**\n\n- `name`：向量属性名称（必须与`rt_attr_float_vector`名称匹配）\n\n- `type`：索引类型，目前仅支持`\"hnsw\"`\n\n- `dims`：向量维度数（必须与嵌入模型输出匹配）\n\n- `hnsw_similarity`：距离函数 - `\"L2\"`、`\"IP\"`（内积）或`\"COSINE\"`\n\n**可选的KNN参数：**\n\n- `hnsw_m`：图中的最大连接数\n\n- `hnsw_ef_construction`：构建时的准确度与速度权衡\n\n更多关于KNN向量搜索的细节，请参见[KNN文档](../../Searching/KNN.md)。\n\n#### rt_attr_bool\n\nCODE_BLOCK_42\n\n声明一个布尔属性，值为1位无符号整数。\n\n值：字段名。\n\n#### rt_attr_string\n\nCODE_BLOCK_43\n\n字符串属性声明。\n\n值：字段名。\n\n#### rt_attr_json\n\nCODE_BLOCK_44\n\n声明一个JSON属性。\n\n值：字段名。\n\n#### rt_attr_timestamp\n\nCODE_BLOCK_45\n\n声明一个时间戳属性。\n\n值：字段名。\n\n#### rt_mem_limit\n\nCODE_BLOCK_46\n\n表的RAM块内存限制。可选，默认值为128M。\n\nRT表将部分数据存储在内存中，称为“RAM块”，同时维护多个磁盘表，称为“磁盘块”。此指令允许您控制RAM块的大小。当内存中数据过多时，RT表会将其刷新到磁盘，激活新创建的磁盘块，并重置RAM块。\n\n请注意，该限制是严格的，RT表绝不会分配超过rt_mem_limit指定的内存。此外，内存不会预分配，因此指定512MB限制但仅插入3MB数据时，只会分配3MB，而非512MB。\n\n`rt_mem_limit`不会被超出，但实际RAM块大小可能远低于限制。RT表会根据数据插入速度动态调整实际限制，以最小化内存使用并最大化数据写入速度。其工作原理如下：\n\n* 默认情况下，RAM块大小为`rt_mem_limit`的50%，称为“`rt_mem_limit`限制”。\n\n* 一旦RAM块积累的数据达到`rt_mem_limit * rate`（默认50%），Manticore开始将RAM块保存为新的磁盘块。\n\n* 在保存新磁盘块期间，Manticore评估新增/更新文档数量。\n\n* 保存新磁盘块后，更新`rt_mem_limit`的rate值。\n\n* 每次重启searchd时，rate重置为50%。\n\n例如，如果保存到磁盘块的数据为90MB，且保存过程中又有10MB数据到达，则rate为90%。下次RT表将在达到`rt_mem_limit`的90%时刷新数据。插入速度越快，`rt_mem_limit`的rate越低。rate范围在33.3%到95%之间。您可以使用[SHOW TABLE <tbl> STATUS](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_STATUS.md)命令查看表的当前rate。\n\n##### 如何更改rt_mem_limit和optimize_cutoff",
      "russian": "CODE_BLOCK_25\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_30\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### Настройки таблицы в реальном времени:\n\n#### diskchunk_flush_search_timeout\n\nCODE_BLOCK_32\n\nТаймаут для предотвращения автоматической очистки RAM-чанка, если в таблице нет поисковых запросов. Подробнее см. [здесь](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout).\n\n#### diskchunk_flush_write_timeout\n\nCODE_BLOCK_33\n\nТаймаут для автоматической очистки RAM-чанка, если в него не записываются данные. Подробнее см. [здесь](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout).\n\n#### optimize_cutoff\n\nМаксимальное количество дисковых чанков для RT-таблицы. Подробнее см. [здесь](../../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks).\n\n#### rt_field\n\nCODE_BLOCK_34\n\nЭто объявление поля определяет полнотекстовые поля, которые будут индексироваться. Имена полей должны быть уникальными, порядок сохраняется. При вставке данных значения полей должны быть в том же порядке, что и указано в конфигурации.\n\nЭто поле с множественными значениями, необязательное.\n\n#### rt_attr_uint\n\nCODE_BLOCK_35\n\nЭто объявление определяет атрибут беззнакового целого числа.\n\nЗначение: имя поля или field_name:N (где N — максимальное количество бит для хранения).\n\n#### rt_attr_bigint\n\nCODE_BLOCK_36\n\nЭто объявление определяет атрибут BIGINT.\n\nЗначение: имя поля, допускается несколько записей.\n\n#### rt_attr_multi\n\nCODE_BLOCK_37\n\nОбъявляет атрибут с множественными значениями (MVA) с беззнаковыми 32-битными целочисленными значениями.\n\nЗначение: имя поля. Допускается несколько записей.\n\n#### rt_attr_multi_64\n\nCODE_BLOCK_38\n\nОбъявляет атрибут с множественными значениями (MVA) с знаковыми 64-битными значениями BIGINT.\n\nЗначение: имя поля. Допускается несколько записей.\n\n#### rt_attr_float\n\nCODE_BLOCK_39\n\nОбъявляет атрибуты с плавающей точкой одинарной точности, формат IEEE 754, 32-битный.\n\nЗначение: имя поля. Допускается несколько записей.\n\n#### rt_attr_float_vector\n\nCODE_BLOCK_40\n\nОбъявляет вектор значений с плавающей точкой для хранения эмбеддингов и обеспечения поиска по векторам методом k-ближайших соседей (KNN).\n\nЗначение: имя поля. Допускается несколько записей.\n\nКаждый векторный атрибут хранит массив чисел с плавающей точкой, которые представляют данные (например, текст, изображения или другой контент) в виде векторов высокой размерности. Эти векторы обычно генерируются моделями машинного обучения и могут использоваться для поиска по сходству, рекомендаций, семантического поиска и других функций на базе ИИ.\n\n**Важно:** Атрибуты с векторами с плавающей точкой требуют дополнительной конфигурации KNN для включения возможностей векторного поиска.\n\n##### Настройка KNN для векторных атрибутов\n\nЧтобы включить поиск KNN по векторным атрибутам с плавающей точкой, необходимо добавить конфигурацию `knn`, которая задает параметры индексирования:\n\nCODE_BLOCK_41\n\n**Обязательные параметры KNN:**\n\n- `name`: имя векторного атрибута (должно совпадать с именем `rt_attr_float_vector`)\n\n- `type`: тип индекса, в настоящее время поддерживается только `\"hnsw\"`\n\n- `dims`: количество измерений в векторах (должно соответствовать выходу вашей модели эмбеддингов)\n\n- `hnsw_similarity`: функция расстояния — `\"L2\"`, `\"IP\"` (внутреннее произведение) или `\"COSINE\"`\n\n**Необязательные параметры KNN:**\n\n- `hnsw_m`: максимальное количество связей в графе\n\n- `hnsw_ef_construction`: компромисс между временем построения и точностью\n\nДля подробностей о векторном поиске KNN смотрите [документацию KNN](../../Searching/KNN.md).\n\n#### rt_attr_bool\n\nCODE_BLOCK_42\n\nОбъявляет булев атрибут с 1-битными беззнаковыми целочисленными значениями.\n\nЗначение: имя поля.\n\n#### rt_attr_string\n\nCODE_BLOCK_43\n\nОбъявление строкового атрибута.\n\nЗначение: имя поля.\n\n#### rt_attr_json\n\nCODE_BLOCK_44\n\nОбъявляет JSON-атрибут.\n\nЗначение: имя поля.\n\n#### rt_attr_timestamp\n\nCODE_BLOCK_45\n\nОбъявляет атрибут временной метки.\n\nЗначение: имя поля.\n\n#### rt_mem_limit\n\nCODE_BLOCK_46\n\nОграничение памяти для RAM-чанка таблицы. Необязательно, по умолчанию 128M.\n\nRT-таблицы хранят часть данных в памяти, известную как \"RAM-чанк\", а также поддерживают несколько таблиц на диске, называемых \"дисковыми чанками\". Эта директива позволяет контролировать размер RAM-чанка. Когда данных слишком много для хранения в памяти, RT-таблицы сбрасывают их на диск, активируют вновь созданный дисковый чанк и сбрасывают RAM-чанк.\n\nОбратите внимание, что ограничение строгое, и RT-таблицы никогда не выделяют памяти больше, чем указано в rt_mem_limit. Кроме того, память не выделяется заранее, поэтому при указании лимита 512 МБ и вставке только 3 МБ данных будет выделено только 3 МБ, а не 512 МБ.\n\n`rt_mem_limit` никогда не превышается, но фактический размер RAM-чанка может быть значительно меньше лимита. RT-таблицы адаптируются к скорости вставки данных и динамически регулируют фактический лимит, чтобы минимизировать использование памяти и максимизировать скорость записи данных. Вот как это работает:\n\n* По умолчанию размер RAM-чанка составляет 50% от `rt_mem_limit`, это называется \"`rt_mem_limit` лимит\".\n\n* Как только RAM-чанк накапливает данных, эквивалентных `rt_mem_limit * rate` (по умолчанию 50% от `rt_mem_limit`), Manticore начинает сохранять RAM-чанк как новый дисковый чанк.\n\n* Во время сохранения нового дискового чанка Manticore оценивает количество новых/обновленных документов.\n\n* После сохранения нового дискового чанка значение `rt_mem_limit` rate обновляется.\n\n* Rate сбрасывается до 50% при каждом перезапуске searchd.\n\nНапример, если на диск сохранено 90 МБ данных, и во время сохранения поступило еще 10 МБ, rate будет 90%. В следующий раз RT-таблица будет собирать до 90% от `rt_mem_limit` перед сбросом данных. Чем быстрее скорость вставки, тем ниже rate `rt_mem_limit`. Rate варьируется от 33.3% до 95%. Текущий rate таблицы можно посмотреть с помощью команды [SHOW TABLE <tbl> STATUS](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_STATUS.md).\n\n##### Как изменить rt_mem_limit и optimize_cutoff"
    },
    "is_code_or_comment": false
  },
  "4fe3cc7956ebe16297101750280c4a3924db1c564bafd994d82bd9ff81d2db6d": {
    "original": "This setting controls the size of blocks used by the document storage. The default value is 16kb. When original document text is stored using stored_fields or stored_only_fields, it is stored within the table and compressed for efficiency. To optimize disk access and compression ratios for small documents, these documents are concatenated into blocks. The indexing process collects documents until their total size reaches the threshold specified by this option. At that point, the block of documents is compressed. This option can be adjusted to achieve better compression ratios (by increasing the block size) or faster access to document text (by decreasing the block size).\n\nValue: size, default **16k**.\n\n#### docstore_compression\n\nCODE_BLOCK_57\n\nThis setting determines the type of compression used for compressing blocks of documents stored in document storage. If stored_fields or stored_only_fields are specified, the document storage stores compressed document blocks. 'lz4' offers fast compression and decompression speeds, while 'lz4hc' (high compression) sacrifices some compression speed for a better compression ratio. 'none' disables compression completely.\n\nValues: **lz4** (default), lz4hc, none.\n\n#### docstore_compression_level\n\nCODE_BLOCK_58\n\nThe compression level used when 'lz4hc' compression is applied in document storage. By adjusting the compression level, you can find the right balance between performance and compression ratio when using 'lz4hc' compression. Note that this option is not applicable when using 'lz4' compression.\n\nValue: An integer between 1 and 12, with a default of **9**.\n\n#### preopen\n\nCODE_BLOCK_59\n\nThis setting indicates that searchd should open all table files on startup or rotation, and keep them open while running. By default, the files are not pre-opened. Pre-opened tables require a few file descriptors per table, but they eliminate the need for per-query open() calls and are immune to race conditions that might occur during table rotation under high load. However, if you are serving many tables, it may still be more efficient to open them on a per-query basis in order to conserve file descriptors.\n\nValue: **0** (default), or 1.\n\n#### read_buffer_docs\n\nCODE_BLOCK_60\n\nBuffer size for storing the list of documents per keyword. Increasing this value will result in higher memory usage during query execution, but may reduce I/O time.\n\nValue: size, default **256k**, minimum value is 8k.\n\n#### read_buffer_hits\n\nCODE_BLOCK_61\n\nBuffer size for storing the list of hits per keyword. Increasing this value will result in higher memory usage during query execution, but may reduce I/O time.\n\nValue: size, default **256k**, minimum value is 8k.\n\n### Plain table disk footprint settings\n\n#### inplace_enable\n\n<!-- example inplace_enable -->\n\nCODE_BLOCK_62\n\nEnables in-place table inversion. Optional, default is 0 (uses separate temporary files).\n\nThe `inplace_enable` option reduces the disk footprint during indexing of plain tables, while slightly slowing down indexing (it uses approximately 2 times less disk, but yields around 90-95% of the original performance).\n\nIndexing is comprised of two primary phases. During the first phase, documents are collected, processed, and partially sorted by keyword, and the intermediate results are written to temporary files (.tmp*). During the second phase, the documents are fully sorted and the final table files are created. Rebuilding a production table on-the-fly requires approximately 3 times the peak disk footprint: first for the intermediate temporary files, second for the newly constructed copy, and third for the old table that will be serving production queries in the meantime. (Intermediate data is comparable in size to the final table.) This may be too much disk footprint for large data collections, and the `inplace_enable` option can be used to reduce it. When enabled, it reuses the temporary files, outputs the final data back to them, and renames them upon completion. However, this may require additional temporary data chunk relocation, which is where the performance impact comes from.\n\nThis directive has no effect on [searchd](../../Starting_the_server/Manually.md), it only affects the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool).\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n#### inplace_hit_gap\n\n<!-- example inplace_hit_gap -->\n\nCODE_BLOCK_64\n\nThe option [In-place inversion](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#inplace_enable) fine-tuning option. Controls preallocated hitlist gap size. Optional, default is 0.\n\nThis directive only affects the [searchd](../../Starting_the_server/Manually.md) tool, and does not have any impact on the  [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool).\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n#### inplace_reloc_factor\n\n<!-- example inplace_reloc_factor -->\n\nCODE_BLOCK_66\n\nThe inplace_reloc_factor setting determines the size of the relocation buffer within the memory arena used during indexing. The default value is 0.1.\n\nThis option is optional and only affects the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool) tool, not the [searchd](../../Starting_the_server/Manually.md)  server.\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n#### inplace_write_factor\n\n<!-- example inplace_write_factor -->\n\nCODE_BLOCK_68\n\nControls the size of the buffer used for in-place writing during indexing. Optional, with a default value of 0.1.\n\nIt's important to note that this directive only impacts the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool) tool and not the [searchd](../../Starting_the_server/Manually.md) server.\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_69\n\n<!-- end -->",
    "translations": {
      "chinese": "此设置控制文档存储使用的块大小。默认值为16kb。当使用stored_fields或stored_only_fields存储原始文档文本时，文本存储在表内并进行压缩以提高效率。为了优化小文档的磁盘访问和压缩比，这些文档会被连接成块。索引过程会收集文档，直到它们的总大小达到此选项指定的阈值。此时，文档块会被压缩。可以调整此选项以实现更好的压缩比（通过增加块大小）或更快的文档文本访问速度（通过减小块大小）。\n\n值：大小，默认 **16k**。\n\n#### docstore_compression\n\nCODE_BLOCK_57\n\n此设置决定用于压缩存储在文档存储中的文档块的压缩类型。如果指定了stored_fields或stored_only_fields，文档存储会存储压缩的文档块。‘lz4’提供快速的压缩和解压速度，而‘lz4hc’（高压缩）牺牲部分压缩速度以获得更好的压缩比。‘none’完全禁用压缩。\n\n值：**lz4**（默认），lz4hc，none。\n\n#### docstore_compression_level\n\nCODE_BLOCK_58\n\n当文档存储中使用‘lz4hc’压缩时使用的压缩级别。通过调整压缩级别，可以在使用‘lz4hc’压缩时找到性能和压缩比之间的平衡。请注意，此选项在使用‘lz4’压缩时不适用。\n\n值：1到12之间的整数，默认值为 **9**。\n\n#### preopen\n\nCODE_BLOCK_59\n\n此设置指示searchd在启动或轮换时应打开所有表文件，并在运行时保持打开状态。默认情况下，文件不会预先打开。预先打开的表每个表需要几个文件描述符，但它们消除了每次查询调用open()的需求，并且在高负载下表轮换时不会发生竞争条件。然而，如果您服务许多表，按查询打开它们可能更有效以节省文件描述符。\n\n值：**0**（默认），或1。\n\n#### read_buffer_docs\n\nCODE_BLOCK_60\n\n用于存储每个关键字文档列表的缓冲区大小。增加此值将在查询执行期间导致更高的内存使用，但可能减少I/O时间。\n\n值：大小，默认 **256k**，最小值为8k。\n\n#### read_buffer_hits\n\nCODE_BLOCK_61\n\n用于存储每个关键字命中列表的缓冲区大小。增加此值将在查询执行期间导致更高的内存使用，但可能减少I/O时间。\n\n值：大小，默认 **256k**，最小值为8k。\n\n### 纯表磁盘占用设置\n\n#### inplace_enable\n\n<!-- example inplace_enable -->\n\nCODE_BLOCK_62\n\n启用就地表反转。可选，默认值为0（使用单独的临时文件）。\n\n`inplace_enable`选项在索引纯表时减少磁盘占用，同时略微降低索引速度（它使用大约2倍更少的磁盘，但性能约为原始的90-95%）。\n\n索引由两个主要阶段组成。第一阶段，收集文档，处理并按关键字部分排序，中间结果写入临时文件（.tmp*）。第二阶段，文档完全排序并创建最终表文件。在线重建生产表大约需要3倍峰值磁盘占用：首先是中间临时文件，其次是新构建的副本，第三是同时为生产查询服务的旧表。（中间数据大小与最终表相当。）对于大型数据集合，这可能占用过多磁盘，`inplace_enable`选项可用于减少它。启用时，它重用临时文件，将最终数据写回这些文件，并在完成时重命名它们。但这可能需要额外的临时数据块重定位，这就是性能影响的来源。\n\n此指令对[searchd](../../Starting_the_server/Manually.md)无效，仅影响[indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool)。\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n#### inplace_hit_gap\n\n<!-- example inplace_hit_gap -->\n\nCODE_BLOCK_64\n\n[就地反转](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#inplace_enable)的微调选项。控制预分配的命中列表间隙大小。可选，默认值为0。\n\n此指令仅影响[searchd](../../Starting_the_server/Manually.md)工具，对[indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool)无影响。\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n#### inplace_reloc_factor\n\n<!-- example inplace_reloc_factor -->\n\nCODE_BLOCK_66\n\ninplace_reloc_factor设置决定索引期间内存区域中重定位缓冲区的大小。默认值为0.1。\n\n此选项为可选，仅影响[indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool)工具，不影响[searchd](../../Starting_the_server/Manually.md)服务器。\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n#### inplace_write_factor\n\n<!-- example inplace_write_factor -->\n\nCODE_BLOCK_68\n\n控制索引期间就地写入使用的缓冲区大小。可选，默认值为0.1。\n\n请注意，此指令仅影响[indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool)工具，不影响[searchd](../../Starting_the_server/Manually.md)服务器。\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_69\n\n<!-- end -->",
      "russian": "This setting controls the size of blocks used by the document storage. The default value is 16kb. When original document text is stored using stored_fields or stored_only_fields, it is stored within the table and compressed for efficiency. To optimize disk access and compression ratios for small documents, these documents are concatenated into blocks. The indexing process collects documents until their total size reaches the threshold specified by this option. At that point, the block of documents is compressed. This option can be adjusted to achieve better compression ratios (by increasing the block size) or faster access to document text (by decreasing the block size).\n\nValue: size, default **16k**.\n\n#### docstore_compression\n\nCODE_BLOCK_57\n\nThis setting determines the type of compression used for compressing blocks of documents stored in document storage. If stored_fields or stored_only_fields are specified, the document storage stores compressed document blocks. 'lz4' offers fast compression and decompression speeds, while 'lz4hc' (high compression) sacrifices some compression speed for a better compression ratio. 'none' disables compression completely.\n\nValues: **lz4** (default), lz4hc, none.\n\n#### docstore_compression_level\n\nCODE_BLOCK_58\n\nThe compression level used when 'lz4hc' compression is applied in document storage. By adjusting the compression level, you can find the right balance between performance and compression ratio when using 'lz4hc' compression. Note that this option is not applicable when using 'lz4' compression.\n\nValue: An integer between 1 and 12, with a default of **9**.\n\n#### preopen\n\nCODE_BLOCK_59\n\nThis setting indicates that searchd should open all table files on startup or rotation, and keep them open while running. By default, the files are not pre-opened. Pre-opened tables require a few file descriptors per table, but they eliminate the need for per-query open() calls and are immune to race conditions that might occur during table rotation under high load. However, if you are serving many tables, it may still be more efficient to open them on a per-query basis in order to conserve file descriptors.\n\nValue: **0** (default), or 1.\n\n#### read_buffer_docs\n\nCODE_BLOCK_60\n\nBuffer size for storing the list of documents per keyword. Increasing this value will result in higher memory usage during query execution, but may reduce I/O time.\n\nValue: size, default **256k**, minimum value is 8k.\n\n#### read_buffer_hits\n\nCODE_BLOCK_61\n\nBuffer size for storing the list of hits per keyword. Increasing this value will result in higher memory usage during query execution, but may reduce I/O time.\n\nValue: size, default **256k**, minimum value is 8k.\n\n### Plain table disk footprint settings\n\n#### inplace_enable\n\n<!-- example inplace_enable -->\n\nCODE_BLOCK_62\n\nEnables in-place table inversion. Optional, default is 0 (uses separate temporary files).\n\nThe `inplace_enable` option reduces the disk footprint during indexing of plain tables, while slightly slowing down indexing (it uses approximately 2 times less disk, but yields around 90-95% of the original performance).\n\nIndexing is comprised of two primary phases. During the first phase, documents are collected, processed, and partially sorted by keyword, and the intermediate results are written to temporary files (.tmp*). During the second phase, the documents are fully sorted and the final table files are created. Rebuilding a production table on-the-fly requires approximately 3 times the peak disk footprint: first for the intermediate temporary files, second for the newly constructed copy, and third for the old table that will be serving production queries in the meantime. (Intermediate data is comparable in size to the final table.) This may be too much disk footprint for large data collections, and the `inplace_enable` option can be used to reduce it. When enabled, it reuses the temporary files, outputs the final data back to them, and renames them upon completion. However, this may require additional temporary data chunk relocation, which is where the performance impact comes from.\n\nThis directive has no effect on [searchd](../../Starting_the_server/Manually.md), it only affects the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool).\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n#### inplace_hit_gap\n\n<!-- example inplace_hit_gap -->\n\nCODE_BLOCK_64\n\nThe option [In-place inversion](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#inplace_enable) fine-tuning option. Controls preallocated hitlist gap size. Optional, default is 0.\n\nThis directive only affects the [searchd](../../Starting_the_server/Manually.md) tool, and does not have any impact on the  [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool).\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n#### inplace_reloc_factor\n\n<!-- example inplace_reloc_factor -->\n\nCODE_BLOCK_66\n\nThe inplace_reloc_factor setting determines the size of the relocation buffer within the memory arena used during indexing. The default value is 0.1.\n\nThis option is optional and only affects the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool) tool, not the [searchd](../../Starting_the_server/Manually.md)  server.\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n#### inplace_write_factor\n\n<!-- example inplace_write_factor -->\n\nCODE_BLOCK_68\n\nControls the size of the buffer used for in-place writing during indexing. Optional, with a default value of 0.1.\n\nIt's important to note that this directive only impacts the [indexer](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md#Indexer-tool) tool and not the [searchd](../../Starting_the_server/Manually.md) server.\n\n<!-- intro -->\n\n##### CONFIG:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_69\n\n<!-- end -->"
    },
    "is_code_or_comment": false
  },
  "71821c4ae3a217de4e43f7ead69b1f8246d249614ed6869c16178a0cdb098510": {
    "original": "# Plain and real-time table settings\n\n<!-- example config -->\n\n## Defining table schema in a configuration file\n\nCODE_BLOCK_0\n\n<!-- intro -->\n\n##### Example of a plain table in a configuration file\n\n<!-- request Plain -->\n\nCODE_BLOCK_1\n\n<!-- intro -->\n\n##### Example of a real-time table in a configuration file\n\n<!-- request Real-time -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### Common plain and real-time tables settings\n\n#### type\n\nCODE_BLOCK_3\n\nTable type: \"plain\" or \"rt\" (real-time)\n\nValue: **plain** (default), rt\n\n#### path\n\nCODE_BLOCK_4\n\nThe path to where the table will be stored or located, either absolute or relative, without the extension. \n\nValue: The path to the table, **mandatory**\n\n#### stored_fields\n\nCODE_BLOCK_5\n\n<!-- example stored_fields -->\n\nBy default, the original content of full-text fields is indexed and stored when a table is defined in a configuration file. This setting allows you to specify the fields that should have their original values stored.\n\nValue: A comma-separated list of **full-text** fields that should be stored. An empty value (i.e. `stored_fields =` ) disables the storage of original values for all fields.\n\nNote: In the case of a real-time table, the fields listed in `stored_fields` should also be declared as [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field).\n\nAlso, note that you don't need to list attributes in `stored_fields`, since their original values are stored anyway. `stored_fields` can only be used for full-text fields.\n\nSee also [docstore_block_size](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_block_size), [docstore_compression](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_compression) for document storage compression options.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_6\n\n<!-- request JSON -->\n\nCODE_BLOCK_7\n\n<!-- request PHP -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_13\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_14\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_16\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n#### stored_only_fields\n\nCODE_BLOCK_18\n\nUse `stored_only_fields` when you want Manticore to store some fields of a plain or real-time table **on disk but not index them**. These fields won't be searchable with full-text queries, but you can still retrieve their values in search results.\n\nFor example, this is useful if you want to store data like JSON documents that should be returned with each result, but don't need to be searched, filtered, or grouped. In that case, storing them only — and not indexing them — saves memory and improves performance.\n\nYou can do this in two ways:\n\n- In [plain mode](../../Creating_a_table/Local_tables.md#Defining-table-schema-in-config-%28Plain-mode%29) in a table config, use the `stored_only_fields` setting.\n\n- In the SQL interface ([RT mode](../../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29)), use the [stored](../../Creating_a_table/Data_types.md#Storing-binary-data-in-Manticore) property when defining a text field (instead of `indexed` or `indexed stored`). In SQL, you don't need to include `stored_only_fields` — it's not supported in `CREATE TABLE` statements.\n\nThe value of `stored_only_fields` is a comma-separated list of field names. By default, it's empty. If you're using a real-time table, each field listed in `stored_only_fields` must also be declared as an [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field).\n\nNote: you don't need to list attributes in `stored_only_fields`, since their original values are stored anyway.\n\nHow stored-only fields compare to string attributes:\n\n- **Stored-only field**:\n\n  - Stored on disk only\n\n  - Compressed format\n\n  - Can only be retrieved (not used for filtering, sorting, etc.)\n\n- **String attribute**:\n\n  - Stored on disk and in memory\n\n  - Uncompressed format (unless you are using columnar storage)\n\n  - Can be used for sorting, filtering, grouping, etc.\n\nIf you are looking to have Manticore store text data for you that you _only_ want stored on disk (eg: json data that is returned with every result), and not in memory or searchable/filterable/groupable, use `stored_only_fields`, or `stored` as your text field property.\n\nWhen creating your tables using the SQL interface, label your text field as `stored` (and not `indexed` or `indexed stored`). You will not need the `stored_only_fields` option in your `CREATE TABLE` statement; including it may result in a failed query.\n\n#### json_secondary_indexes\n\nCODE_BLOCK_19\n\n<!-- example json_secondary_indexes -->\n\nBy default, secondary indexes are generated for all attributes except JSON attributes. However, secondary indexes for JSON attributes can be explicitly generated using the `json_secondary_indexes` setting. When a JSON attribute is included in this option, its contents are flattened into multiple secondary indexes. These indexes can be used by the query optimizer to speed up queries.\n\nYou can view the available secondary indexes using the [SHOW TABLE <tbl> INDEXES](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_INDEXES.md) command.\n\nValue: A comma-separated list of JSON attributes for which secondary indexes should be generated.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_20\n\n<!-- request JSON -->\n\nCODE_BLOCK_21\n\n<!-- request PHP -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_24\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->",
    "translations": {
      "chinese": "# 普通表和实时表设置\n\n<!-- example config -->\n\n## 在配置文件中定义表模式\n\nCODE_BLOCK_0\n\n<!-- intro -->\n\n##### 配置文件中普通表的示例\n\n<!-- request Plain -->\n\nCODE_BLOCK_1\n\n<!-- intro -->\n\n##### 配置文件中实时表的示例\n\n<!-- request Real-time -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### 普通表和实时表的常见设置\n\n#### type\n\nCODE_BLOCK_3\n\n表类型：\"plain\" 或 \"rt\"（实时）\n\n取值：**plain**（默认），rt\n\n#### path\n\nCODE_BLOCK_4\n\n表存储或所在路径，可以是绝对路径或相对路径，不带扩展名。\n\n取值：表的路径，**必填**\n\n#### stored_fields\n\nCODE_BLOCK_5\n\n<!-- example stored_fields -->\n\n默认情况下，当在配置文件中定义表时，全文字段的原始内容会被索引并存储。此设置允许您指定应存储其原始值的字段。\n\n取值：以逗号分隔的应存储的**全文**字段列表。空值（即 `stored_fields =`）表示禁用所有字段的原始值存储。\n\n注意：对于实时表，`stored_fields` 中列出的字段也应声明为 [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field)。\n\n另外，您无需在 `stored_fields` 中列出属性字段，因为它们的原始值无论如何都会被存储。`stored_fields` 只能用于全文字段。\n\n另请参见文档存储压缩选项 [docstore_block_size](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_block_size)、[docstore_compression](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_compression)。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_6\n\n<!-- request JSON -->\n\nCODE_BLOCK_7\n\n<!-- request PHP -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_13\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_14\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_16\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n#### stored_only_fields\n\nCODE_BLOCK_18\n\n当您希望 Manticore 将普通表或实时表的某些字段**存储到磁盘但不索引**时，请使用 `stored_only_fields`。这些字段不会通过全文查询进行搜索，但您仍然可以在搜索结果中检索它们的值。\n\n例如，如果您想存储像 JSON 文档这样的数据，并希望每个结果都返回这些数据，但不需要对其进行搜索、过滤或分组，这种方式非常有用。在这种情况下，仅存储而不索引可以节省内存并提高性能。\n\n您可以通过两种方式实现：\n\n- 在表配置的[普通模式](../../Creating_a_table/Local_tables.md#Defining-table-schema-in-config-%28Plain-mode%29)中，使用 `stored_only_fields` 设置。\n\n- 在 SQL 接口（[实时模式](../../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29)）中，定义文本字段时使用 [stored](../../Creating_a_table/Data_types.md#Storing-binary-data-in-Manticore) 属性（而非 `indexed` 或 `indexed stored`）。在 SQL 中，您无需包含 `stored_only_fields` — `CREATE TABLE` 语句不支持该选项。\n\n`stored_only_fields` 的值是以逗号分隔的字段名列表。默认值为空。如果使用实时表，`stored_only_fields` 中列出的每个字段也必须声明为 [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field)。\n\n注意：您无需在 `stored_only_fields` 中列出属性字段，因为它们的原始值无论如何都会被存储。\n\n存储仅字段与字符串属性的比较：\n\n- **存储仅字段**：\n\n  - 仅存储在磁盘上\n\n  - 压缩格式\n\n  - 只能检索（不能用于过滤、排序等）\n\n- **字符串属性**：\n\n  - 存储在磁盘和内存中\n\n  - 非压缩格式（除非使用列存储）\n\n  - 可用于排序、过滤、分组等\n\n如果您希望 Manticore 存储文本数据，仅存储在磁盘上（例如：每个结果返回的 json 数据），且不存储在内存中或可搜索/过滤/分组，请使用 `stored_only_fields`，或将文本字段属性设置为 `stored`。\n\n使用 SQL 接口创建表时，将文本字段标记为 `stored`（而非 `indexed` 或 `indexed stored`）。在 `CREATE TABLE` 语句中不需要 `stored_only_fields` 选项；包含该选项可能导致查询失败。\n\n#### json_secondary_indexes\n\nCODE_BLOCK_19\n\n<!-- example json_secondary_indexes -->\n\n默认情况下，除 JSON 属性外，所有属性都会生成二级索引。但是，可以通过 `json_secondary_indexes` 设置显式生成 JSON 属性的二级索引。当 JSON 属性包含在此选项中时，其内容会被展平成多个二级索引。查询优化器可以使用这些索引来加速查询。\n\n您可以使用 [SHOW TABLE <tbl> INDEXES](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_INDEXES.md) 命令查看可用的二级索引。\n\n取值：应生成二级索引的 JSON 属性的逗号分隔列表。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_20\n\n<!-- request JSON -->\n\nCODE_BLOCK_21\n\n<!-- request PHP -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_24\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->",
      "russian": "# Настройки обычных и реального времени таблиц\n\n<!-- example config -->\n\n## Определение схемы таблицы в конфигурационном файле\n\nCODE_BLOCK_0\n\n<!-- intro -->\n\n##### Пример обычной таблицы в конфигурационном файле\n\n<!-- request Plain -->\n\nCODE_BLOCK_1\n\n<!-- intro -->\n\n##### Пример таблицы реального времени в конфигурационном файле\n\n<!-- request Real-time -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### Общие настройки обычных и реального времени таблиц\n\n#### type\n\nCODE_BLOCK_3\n\nТип таблицы: \"plain\" или \"rt\" (реального времени)\n\nЗначение: **plain** (по умолчанию), rt\n\n#### path\n\nCODE_BLOCK_4\n\nПуть к месту, где таблица будет храниться или расположена, абсолютный или относительный, без расширения.\n\nЗначение: Путь к таблице, **обязательно**\n\n#### stored_fields\n\nCODE_BLOCK_5\n\n<!-- example stored_fields -->\n\nПо умолчанию оригинальное содержимое полнотекстовых полей индексируется и сохраняется при определении таблицы в конфигурационном файле. Эта настройка позволяет указать поля, для которых должны сохраняться оригинальные значения.\n\nЗначение: Список полнотекстовых полей, разделённых запятыми, которые должны сохраняться. Пустое значение (т.е. `stored_fields =`) отключает сохранение оригинальных значений для всех полей.\n\nПримечание: В случае таблицы реального времени поля, перечисленные в `stored_fields`, также должны быть объявлены как [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field).\n\nТакже обратите внимание, что не нужно включать атрибуты в `stored_fields`, так как их оригинальные значения сохраняются в любом случае. `stored_fields` можно использовать только для полнотекстовых полей.\n\nСмотрите также [docstore_block_size](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_block_size), [docstore_compression](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#docstore_compression) для опций сжатия хранения документов.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_6\n\n<!-- request JSON -->\n\nCODE_BLOCK_7\n\n<!-- request PHP -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_13\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_14\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request Typescript -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request Go -->\n\nCODE_BLOCK_16\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n#### stored_only_fields\n\nCODE_BLOCK_18\n\nИспользуйте `stored_only_fields`, когда хотите, чтобы Manticore сохранял некоторые поля обычной или реального времени таблицы **на диске, но не индексировал их**. Эти поля не будут доступны для полнотекстового поиска, но вы всё равно сможете получать их значения в результатах поиска.\n\nНапример, это полезно, если вы хотите хранить данные, такие как JSON-документы, которые должны возвращаться с каждым результатом, но не нуждаются в поиске, фильтрации или группировке. В этом случае хранение только — без индексации — экономит память и повышает производительность.\n\nВы можете сделать это двумя способами:\n\n- В [обычном режиме](../../Creating_a_table/Local_tables.md#Defining-table-schema-in-config-%28Plain-mode%29) в конфигурации таблицы используйте настройку `stored_only_fields`.\n\n- В SQL-интерфейсе ([RT режим](../../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29)) используйте свойство [stored](../../Creating_a_table/Data_types.md#Storing-binary-data-in-Manticore) при определении текстового поля (вместо `indexed` или `indexed stored`). В SQL не нужно включать `stored_only_fields` — оно не поддерживается в операторах `CREATE TABLE`.\n\nЗначение `stored_only_fields` — это список имён полей, разделённых запятыми. По умолчанию пусто. Если вы используете таблицу реального времени, каждое поле, указанное в `stored_only_fields`, также должно быть объявлено как [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field).\n\nПримечание: не нужно включать атрибуты в `stored_only_fields`, так как их оригинальные значения сохраняются в любом случае.\n\nСравнение полей только для хранения и строковых атрибутов:\n\n- **Поле только для хранения**:\n\n  - Хранится только на диске\n\n  - Сжатый формат\n\n  - Можно только получить (не используется для фильтрации, сортировки и т.д.)\n\n- **Строковый атрибут**:\n\n  - Хранится на диске и в памяти\n\n  - Несжатый формат (если не используется колоночное хранение)\n\n  - Может использоваться для сортировки, фильтрации, группировки и т.д.\n\nЕсли вы хотите, чтобы Manticore хранил текстовые данные, которые вы _только_ хотите хранить на диске (например, json данные, возвращаемые с каждым результатом), и не хранить в памяти или делать их доступными для поиска/фильтрации/группировки, используйте `stored_only_fields` или `stored` как свойство текстового поля.\n\nПри создании таблиц через SQL-интерфейс пометьте текстовое поле как `stored` (а не `indexed` или `indexed stored`). Вам не понадобится опция `stored_only_fields` в операторе `CREATE TABLE`; её включение может привести к ошибке запроса.\n\n#### json_secondary_indexes\n\nCODE_BLOCK_19\n\n<!-- example json_secondary_indexes -->\n\nПо умолчанию вторичные индексы создаются для всех атрибутов, кроме JSON-атрибутов. Однако вторичные индексы для JSON-атрибутов могут быть явно созданы с помощью настройки `json_secondary_indexes`. Когда JSON-атрибут включён в эту опцию, его содержимое разворачивается в несколько вторичных индексов. Эти индексы могут использоваться оптимизатором запросов для ускорения выполнения запросов.\n\nВы можете просмотреть доступные вторичные индексы с помощью команды [SHOW TABLE <tbl> INDEXES](../../Node_info_and_management/Table_settings_and_status/SHOW_TABLE_INDEXES.md).\n\nЗначение: Список JSON-атрибутов, разделённых запятыми, для которых должны быть созданы вторичные индексы.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_20\n\n<!-- request JSON -->\n\nCODE_BLOCK_21\n\n<!-- request PHP -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_24\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request Javascript -->"
    },
    "is_code_or_comment": false
  },
  "1b2343953797fc680732443db2e2d1b9ae2b7d96c7a21a248c64786d205f7bc5": {
    "original": "In seek+read mode, the server uses the `pread` system call to read document lists and keyword positions, represented by the `*.spd` and `*.spp`  files. The server uses internal read buffers to optimize the reading process, and the size of these buffers can be adjusted using the options [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) and [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits).There is also the option  [preopen](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#preopen) that controls how Manticore opens files at start.\n\nIn mmap access mode, the search server maps the table's file into memory using the `mmap` system call, and the OS caches the file contents. The options [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) and [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits) have no effect for corresponding files in this mode. The mmap reader can also lock the table's data in memory using the`mlock` privileged call, which prevents the OS from swapping the cached data out to disk.\n\nTo control which access mode to use, the options **access_plain_attrs**, **access_blob_attrs**, **access_doclists**, **access_hitlists** and **access_dict**  are available, with the following values:\n\n| Value | Description |\n\n| - | - |\n\n| file | server reads the table files from disk with seek+read using internal buffers on file access |\n\n| mmap | server maps the table files into memory and OS caches up its contents on file access |\n\n| mmap_preread | server maps the table files into memory and a background thread reads it once to warm up the cache |\n\n| mlock | server maps the table files into memory and then executes the mlock() system call to cache up the file contents and lock it into memory to prevent it being swapped out |\n\n| Setting | Values | Description |\n\n| - | - | - |\n\n| access_plain_attrs  | mmap, **mmap_preread** (default), mlock | controls how `*.spa` (plain attributes) `*.spe` (skip lists) `*.spt` (lookups) `*.spm` (killed docs) will be read |\n\n| access_blob_attrs   | mmap, **mmap_preread** (default), mlock  | controls how `*.spb` (blob attributes) (string, mva and json attributes) will be read |\n\n| access_doclists   | **file** (default), mmap, mlock  | controls how `*.spd` (doc lists) data will be read |\n\n| access_hitlists   | **file** (default), mmap, mlock  | controls how `*.spp` (hit lists) data will be read |\n\n| access_dict   | mmap, **mmap_preread** (default), mlock  | controls how `*.spi` (dictionary) will be read |\n\nHere is a table which can help you select your desired mode:\n\n| table part |\tkeep it on disk |\tkeep it in memory |\tcached in memory on server start | lock it in memory |\n\n| - | - | - | - | - |\n\n| plain attributes in [row-wise](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) (non-columnar) storage, skip lists, word lists, lookups, killed docs | \tmmap | mmap |\t**mmap_preread** (default) | mlock |\n\n| row-wise string, multi-value attributes (MVA) and json attributes | mmap | mmap | **mmap_preread** (default) | mlock |\n\n| [columnar](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) numeric, string and multi-value attributes | always  | only by means of OS  | no  | not supported |\n\n| doc lists | **file** (default) | mmap | no\t| mlock |\n\n| hit lists | **file** (default) | mmap | no\t| mlock |\n\n| dictionary | mmap | mmap | **mmap_preread** (default) | mlock |\n\n##### The recommendations are:\n\n* For the **fastest search response time** and ample memory availability, use [row-wise](../../Creating_a_table/Data_types.md#JSON) attributes and lock them in memory using `mlock`. Additionally, use mlock for doclists/hitlists.\n\n* If you prioritize **can't afford lower performance after start** and are willing to accept longer startup time, use the [--force-preread](../../Starting_the_server/Manually.md#searchd-command-line-options). option. If you desire faster searchd restart, stick to the default  `mmap_preread` option.\n\n* If you are looking to **conserve memory**, while still having enough memory for all attributes, skip the use of `mlock`. The operating system will determine what should be kept in memory based on frequent disk reads.\n\n* If row-wise attributes  **do not fit into memory**, opt for [columnar attributes](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages)\n\n* If full-text search **performance is not a concern**, and you wish to save memory, use `access_doclists/access_hitlists=file`\n\nThe default mode offers a balance of:\n\n* mmap,\n\n* Prereading non-columnar attributes,\n\n* Seeking and reading columnar attributes with no preread,\n\n* Seeking and reading doclists/hitlists with no preread.\n\nThis provides a decent search performance, optimal memory utilization, and faster searchd restart in most scenarios.\n\n### Other performance related settings\n\n#### attr_update_reserve\n\nCODE_BLOCK_55\n\nThis setting reserves extra space for updates to blob attributes such as multi-value attributes (MVA), strings, and JSON. The default value is 128k. When updating these attributes, their length may change. If the updated string is shorter than the previous one, it will overwrite the old data in the `*.spb` file. If the updated string is longer, it will be written to the end of the `*.spb` file. This file is memory-mapped, making resizing it a potentially slow process, depending on the operating system's memory-mapped file implementation. To avoid frequent resizing, you can use this setting to reserve extra space at the end of the .spb file.\n\nValue: size, default **128k**.\n\n#### docstore_block_size\n\nCODE_BLOCK_56",
    "translations": {
      "chinese": "在 seek+read 模式下，服务器使用 `pread` 系统调用读取文档列表和关键字位置，这些由 `*.spd` 和 `*.spp` 文件表示。服务器使用内部读取缓冲区来优化读取过程，这些缓冲区的大小可以通过选项 [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) 和 [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits) 进行调整。还有一个选项 [preopen](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#preopen) 用于控制 Manticore 启动时如何打开文件。\n\n在 mmap 访问模式下，搜索服务器使用 `mmap` 系统调用将表文件映射到内存中，操作系统缓存文件内容。选项 [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) 和 [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits) 对该模式下的相应文件无效。mmap 读取器还可以使用特权调用 `mlock` 锁定表数据在内存中，防止操作系统将缓存数据交换到磁盘。\n\n为了控制使用哪种访问模式，提供了选项 **access_plain_attrs**、**access_blob_attrs**、**access_doclists**、**access_hitlists** 和 **access_dict**，其取值如下：\n\n| 值 | 描述 |\n\n| - | - |\n\n| file | 服务器使用内部缓冲区通过 seek+read 从磁盘读取表文件 |\n\n| mmap | 服务器将表文件映射到内存，操作系统缓存其内容 |\n\n| mmap_preread | 服务器将表文件映射到内存，后台线程会读取一次以预热缓存 |\n\n| mlock | 服务器将表文件映射到内存，然后执行 mlock() 系统调用缓存文件内容并锁定在内存中，防止被交换出去 |\n\n| 设置 | 取值 | 描述 |\n\n| - | - | - |\n\n| access_plain_attrs  | mmap, **mmap_preread** (默认), mlock | 控制如何读取 `*.spa`（普通属性）、`*.spe`（跳跃列表）、`*.spt`（查找表）、`*.spm`（已删除文档） |\n\n| access_blob_attrs   | mmap, **mmap_preread** (默认), mlock  | 控制如何读取 `*.spb`（blob 属性）（字符串、多值和 json 属性） |\n\n| access_doclists   | **file** (默认), mmap, mlock  | 控制如何读取 `*.spd`（文档列表）数据 |\n\n| access_hitlists   | **file** (默认), mmap, mlock  | 控制如何读取 `*.spp`（命中列表）数据 |\n\n| access_dict   | mmap, **mmap_preread** (默认), mlock  | 控制如何读取 `*.spi`（字典） |\n\n下面的表格可以帮助您选择所需的模式：\n\n| 表部分 |\t保留在磁盘 |\t保留在内存 |\t服务器启动时缓存到内存 | 锁定在内存 |\n\n| - | - | - | - | - |\n\n| [行存储](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages)（非列存储）的普通属性、跳跃列表、词表、查找表、已删除文档 | \tmmap | mmap |\t**mmap_preread** (默认) | mlock |\n\n| 行存储的字符串、多值属性（MVA）和 json 属性 | mmap | mmap | **mmap_preread** (默认) | mlock |\n\n| [列存储](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) 的数值、字符串和多值属性 | 始终 | 仅通过操作系统 | 否 | 不支持 |\n\n| 文档列表 | **file** (默认) | mmap | 否\t| mlock |\n\n| 命中列表 | **file** (默认) | mmap | 否\t| mlock |\n\n| 字典 | mmap | mmap | **mmap_preread** (默认) | mlock |\n\n##### 推荐如下：\n\n* 若追求 **最快的搜索响应时间** 且内存充足，使用 [行存储](../../Creating_a_table/Data_types.md#JSON) 属性并通过 `mlock` 锁定在内存中。同时，对文档列表/命中列表也使用 mlock。\n\n* 如果优先考虑 **启动后不允许性能下降**，且愿意接受更长的启动时间，可使用 [--force-preread](../../Starting_the_server/Manually.md#searchd-command-line-options) 选项。若希望更快的 searchd 重启，则保持默认的 `mmap_preread` 选项。\n\n* 若希望 **节省内存**，但仍有足够内存容纳所有属性，则跳过使用 `mlock`。操作系统将根据频繁的磁盘读取决定保留哪些内容在内存中。\n\n* 如果行存储属性 **无法全部放入内存**，则选择 [列存储属性](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages)。\n\n* 如果全文搜索 **性能不是重点**，且希望节省内存，则使用 `access_doclists/access_hitlists=file`。\n\n默认模式提供了以下平衡：\n\n* mmap，\n\n* 预读非列存储属性，\n\n* 对列存储属性无预读的 seek+read，\n\n* 对文档列表/命中列表无预读的 seek+read。\n\n这在大多数场景下提供了良好的搜索性能、内存利用率和更快的 searchd 重启。\n\n### 其他性能相关设置\n\n#### attr_update_reserve\n\nCODE_BLOCK_55\n\n此设置为更新 blob 属性（如多值属性 MVA、字符串和 JSON）预留额外空间。默认值为 128k。更新这些属性时，其长度可能变化。如果更新后的字符串比之前短，则会覆盖 `*.spb` 文件中的旧数据；如果更新后的字符串更长，则写入 `*.spb` 文件末尾。该文件是内存映射的，调整其大小可能较慢，具体取决于操作系统的内存映射文件实现。为避免频繁调整大小，可使用此设置在 .spb 文件末尾预留额外空间。\n\n取值：大小，默认 **128k**。\n\n#### docstore_block_size\n\nCODE_BLOCK_56",
      "russian": "В режиме seek+read сервер использует системный вызов `pread` для чтения списков документов и позиций ключевых слов, представленных файлами `*.spd` и `*.spp`. Сервер использует внутренние буферы чтения для оптимизации процесса чтения, и размер этих буферов можно настроить с помощью опций [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) и [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits). Также существует опция [preopen](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#preopen), которая контролирует, как Manticore открывает файлы при запуске.\n\nВ режиме доступа mmap поисковый сервер отображает файл таблицы в память с помощью системного вызова `mmap`, а ОС кэширует содержимое файла. Опции [read_buffer_docs](../../Server_settings/Searchd.md#read_buffer_docs) и [read_buffer_hits](../../Server_settings/Searchd.md#read_buffer_hits) не влияют на соответствующие файлы в этом режиме. mmap-ридер также может заблокировать данные таблицы в памяти с помощью привилегированного вызова `mlock`, что предотвращает выгрузку кэшированных данных на диск ОС.\n\nДля управления используемым режимом доступа доступны опции **access_plain_attrs**, **access_blob_attrs**, **access_doclists**, **access_hitlists** и **access_dict** со следующими значениями:\n\n| Значение | Описание |\n\n| - | - |\n\n| file | сервер читает файлы таблицы с диска с помощью seek+read, используя внутренние буферы при доступе к файлу |\n\n| mmap | сервер отображает файлы таблицы в память, и ОС кэширует их содержимое при доступе к файлу |\n\n| mmap_preread | сервер отображает файлы таблицы в память, и фоновый поток один раз читает их для прогрева кэша |\n\n| mlock | сервер отображает файлы таблицы в память, а затем выполняет системный вызов mlock() для кэширования содержимого файла и блокировки его в памяти, чтобы предотвратить выгрузку |\n\n| Настройка | Значения | Описание |\n\n| - | - | - |\n\n| access_plain_attrs  | mmap, **mmap_preread** (по умолчанию), mlock | контролирует, как будут читаться `*.spa` (простые атрибуты), `*.spe` (skip lists), `*.spt` (lookups), `*.spm` (killed docs) |\n\n| access_blob_attrs   | mmap, **mmap_preread** (по умолчанию), mlock  | контролирует, как будут читаться `*.spb` (blob-атрибуты) (строковые, MVA и JSON атрибуты) |\n\n| access_doclists   | **file** (по умолчанию), mmap, mlock  | контролирует, как будут читаться данные `*.spd` (списки документов) |\n\n| access_hitlists   | **file** (по умолчанию), mmap, mlock  | контролирует, как будут читаться данные `*.spp` (списки попаданий) |\n\n| access_dict   | mmap, **mmap_preread** (по умолчанию), mlock  | контролирует, как будет читаться `*.spi` (словарь) |\n\nНиже приведена таблица, которая поможет выбрать желаемый режим:\n\n| часть таблицы |\tоставлять на диске |\tхранить в памяти |\tкэшировать в памяти при запуске сервера | блокировать в памяти |\n\n| - | - | - | - | - |\n\n| простые атрибуты в [построчном](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) (не колоночном) хранении, skip lists, списки слов, lookups, killed docs | \tmmap | mmap |\t**mmap_preread** (по умолчанию) | mlock |\n\n| построчные строковые, мультизначные атрибуты (MVA) и JSON атрибуты | mmap | mmap | **mmap_preread** (по умолчанию) | mlock |\n\n| [колоночные](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) числовые, строковые и мультизначные атрибуты | всегда  | только средствами ОС  | нет  | не поддерживается |\n\n| списки документов | **file** (по умолчанию) | mmap | нет\t| mlock |\n\n| списки попаданий | **file** (по умолчанию) | mmap | нет\t| mlock |\n\n| словарь | mmap | mmap | **mmap_preread** (по умолчанию) | mlock |\n\n##### Рекомендации:\n\n* Для **максимально быстрого времени отклика поиска** и достаточного объема памяти используйте [построчные](../../Creating_a_table/Data_types.md#JSON) атрибуты и блокируйте их в памяти с помощью `mlock`. Дополнительно используйте mlock для doclists/hitlists.\n\n* Если вы отдаёте предпочтение тому, что **нельзя допустить снижение производительности после запуска** и готовы принять более длительное время запуска, используйте опцию [--force-preread](../../Starting_the_server/Manually.md#searchd-command-line-options). Если вы хотите более быстрый перезапуск searchd, придерживайтесь опции по умолчанию `mmap_preread`.\n\n* Если вы хотите **экономить память**, при этом имея достаточно памяти для всех атрибутов, избегайте использования `mlock`. Операционная система сама определит, что следует держать в памяти, исходя из частоты чтения с диска.\n\n* Если построчные атрибуты **не помещаются в память**, выберите [колоночные атрибуты](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages).\n\n* Если производительность полнотекстового поиска **не является приоритетом**, и вы хотите сэкономить память, используйте `access_doclists/access_hitlists=file`.\n\nРежим по умолчанию предлагает баланс:\n\n* mmap,\n\n* предварительное чтение неколоночных атрибутов,\n\n* seek+read колоночных атрибутов без предварительного чтения,\n\n* seek+read doclists/hitlists без предварительного чтения.\n\nЭто обеспечивает достойную производительность поиска, оптимальное использование памяти и более быстрый перезапуск searchd в большинстве сценариев.\n\n### Другие настройки, связанные с производительностью\n\n#### attr_update_reserve\n\nCODE_BLOCK_55\n\nЭта настройка резервирует дополнительное пространство для обновлений blob-атрибутов, таких как мультизначные атрибуты (MVA), строки и JSON. Значение по умолчанию — 128k. При обновлении этих атрибутов их длина может изменяться. Если обновленная строка короче предыдущей, она перезапишет старые данные в файле `*.spb`. Если обновленная строка длиннее, она будет записана в конец файла `*.spb`. Этот файл отображается в память, что делает изменение его размера потенциально медленным процессом, в зависимости от реализации отображения файлов в память в операционной системе. Чтобы избежать частого изменения размера, можно использовать эту настройку для резервирования дополнительного пространства в конце файла .spb.\n\nЗначение: размер, по умолчанию **128k**.\n\n#### docstore_block_size\n\nCODE_BLOCK_56"
    },
    "is_code_or_comment": false
  },
  "e1cfeedd1a133dcde42b914755096aa267e31ff481e4194655b7ba8ca10da293": {
    "original": "This setting determines the table(s) to which the kill-list will be applied. Matches in the targeted table that are updated or deleted in the current table will be suppressed. In `:kl` mode, the documents to suppress are taken from the [kill-list](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md). In `:id` mode, all document IDs from the current table are suppressed in the targeted one. If neither is specified, both modes will take effect. [Learn more about kill-lists here](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md)\n\nValue: **not specified** (default), target_table_name:kl, target_table_name:id, target_table_name. Multiple values are allowed\n\n#### columnar_attrs\n\nCODE_BLOCK_49\n\nThis configuration setting determines which attributes should be stored in [the columnar storage](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) instead of the row-wise storage.\n\nYou can set `columnar_attrs = *` to store all supported data types in the columnar storage.\n\nAdditionally, `id` is a supported attribute to store in the columnar storage.\n\n#### columnar_strings_no_hash\n\nCODE_BLOCK_50\n\nBy default, all string attributes stored in columnar storage store pre-calculated hashes. These hashes are used for grouping and filtering. However, they occupy extra space, and if you don't need to group by that attribute, you can save space by disabling hash generation.\n\n### Creating a real-time table online via CREATE TABLE\n\n<!-- example rt_mode -->\n\n##### General syntax of CREATE TABLE\n\nCODE_BLOCK_51\n\n##### Data types:\n\nFor more information on data types, see [more about data types here](../../Creating_a_table/Data_types.md).\n\n| Type | Equivalent in a configuration file | Notes | Aliases |\n\n| - | - | - | - |\n\n| [text](../../Creating_a_table/Data_types.md#Text) | [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field)  | Options: indexed, stored. Default: **both**. To keep text stored, but indexed, specify \"stored\" only. To keep text indexed only, specify \"indexed\" only. | string |\n\n| [integer](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint)\t| integer\t | int, uint |\n\n| [bigint](../../Creating_a_table/Data_types.md#Big-Integer) | [rt_attr_bigint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bigint)\t| big integer\t |   |\n\n| [float](../../Creating_a_table/Data_types.md#Float) | [rt_attr_float](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float)   | float  |   |\n\n| [float_vector](../../Creating_a_table/Data_types.md#Float-vector) | [rt_attr_float_vector](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float_vector) | a vector of float values  |   |\n\n| [multi](../../Creating_a_table/Data_types.md#Multi-value-integer-%28MVA%29) | [rt_attr_multi](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi)   | multi-integer |   |\n\n| [multi64](../../Creating_a_table/Data_types.md#Multi-value-big-integer) | [rt_attr_multi_64](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi_64) | multi-bigint  |   |\n\n| [bool](../../Creating_a_table/Data_types.md#Boolean) | [rt_attr_bool](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bool) | boolean |   |\n\n| [json](../../Creating_a_table/Data_types.md#JSON) | [rt_attr_json](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_json) | JSON |   |\n\n| [string](../../Creating_a_table/Data_types.md#String) | [rt_attr_string](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_string) | string. Option `indexed, attribute` will make the value full-text indexed and filterable, sortable and groupable at the same time  |   |\n\n| [timestamp](../../Creating_a_table/Data_types.md#Timestamps) |\t[rt_attr_timestamp](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_timestamp) | timestamp  |   |\n\n| [bit(n)](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint field_name:N](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint) | N is the max number of bits to keep  |   |\n\n<!-- intro -->\n\n##### Examples of creating a real-time table via CREATE TABLE\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\nThis creates the \"products\" table with two fields: \"title\" (full-text) and \"price\" (float), and sets the \"morphology\" to \"stem_en\".\n\nCODE_BLOCK_53\n\nThis creates the \"products\" table with three fields:\n\n* \"title\" is indexed, but not stored.\n\n* \"description\" is stored, but not indexed.\n\n* \"author\" is both stored and indexed.\n\n<!-- end -->\n\n## Engine\n\nCODE_BLOCK_54\n\nThe engine setting changes the default [attribute storage](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) for all attributes in the table. You can also specify `engine` [separately for each attribute](../../Creating_a_table/Data_types.md#How-to-switch-between-the-storages).\n\nFor information on how to enable columnar storage for a plain table, see [columnar_attrs](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#columnar_attrs) .\n\nValues:\n\n* columnar - Enables columnar storage for all table attributes, except for [json](../../Creating_a_table/Data_types.md#JSON)\n\n* **rowwise (default)** - Doesn't change anything and uses the traditional row-wise storage for the table.\n\n## Other settings\n\nThe following settings are applicable for both real-time and plain tables, regardless of whether they are specified in a configuration file or set online using the `CREATE` or `ALTER` command.\n\n### Performance related\n\n#### Accessing table files\n\nManticore supports two access modes for reading table data: seek+read and mmap.",
    "translations": {
      "chinese": "此设置确定将应用 kill-list 的表。当前表中更新或删除的目标表中的匹配项将被抑制。在 `:kl` 模式下，要抑制的文档取自 [kill-list](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md)。在 `:id` 模式下，当前表中的所有文档 ID 都会在目标表中被抑制。如果两者都未指定，则两种模式都会生效。[在此了解有关 kill-list 的更多信息](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md)\n\n值：**未指定**（默认），target_table_name:kl，target_table_name:id，target_table_name。允许多个值\n\n#### columnar_attrs\n\nCODE_BLOCK_49\n\n此配置设置确定哪些属性应存储在[列存储](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages)中，而非行存储中。\n\n您可以设置 `columnar_attrs = *` 以将所有支持的数据类型存储在列存储中。\n\n此外，`id` 是支持存储在列存储中的属性。\n\n#### columnar_strings_no_hash\n\nCODE_BLOCK_50\n\n默认情况下，存储在列存储中的所有字符串属性都会存储预计算的哈希值。这些哈希用于分组和过滤。然而，它们占用额外空间，如果您不需要按该属性分组，可以通过禁用哈希生成来节省空间。\n\n### 通过 CREATE TABLE 在线创建实时表\n\n<!-- example rt_mode -->\n\n##### CREATE TABLE 的通用语法\n\nCODE_BLOCK_51\n\n##### 数据类型：\n\n有关数据类型的更多信息，请参见[此处关于数据类型的更多内容](../../Creating_a_table/Data_types.md)。\n\n| 类型 | 配置文件中的等价项 | 说明 | 别名 |\n\n| - | - | - | - |\n\n| [text](../../Creating_a_table/Data_types.md#Text) | [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field)  | 选项：indexed, stored。默认：**两者**。若只想存储文本但不索引，指定 \"stored\"。若只想索引文本不存储，指定 \"indexed\"。 | string |\n\n| [integer](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint)\t| 整数\t | int, uint |\n\n| [bigint](../../Creating_a_table/Data_types.md#Big-Integer) | [rt_attr_bigint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bigint)\t| 大整数\t |   |\n\n| [float](../../Creating_a_table/Data_types.md#Float) | [rt_attr_float](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float)   | 浮点数  |   |\n\n| [float_vector](../../Creating_a_table/Data_types.md#Float-vector) | [rt_attr_float_vector](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float_vector) | 浮点值向量  |   |\n\n| [multi](../../Creating_a_table/Data_types.md#Multi-value-integer-%28MVA%29) | [rt_attr_multi](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi)   | 多值整数 |   |\n\n| [multi64](../../Creating_a_table/Data_types.md#Multi-value-big-integer) | [rt_attr_multi_64](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi_64) | 多值大整数  |   |\n\n| [bool](../../Creating_a_table/Data_types.md#Boolean) | [rt_attr_bool](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bool) | 布尔值 |   |\n\n| [json](../../Creating_a_table/Data_types.md#JSON) | [rt_attr_json](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_json) | JSON |   |\n\n| [string](../../Creating_a_table/Data_types.md#String) | [rt_attr_string](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_string) | 字符串。选项 `indexed, attribute` 会使值同时具备全文索引、可过滤、可排序和可分组功能  |   |\n\n| [timestamp](../../Creating_a_table/Data_types.md#Timestamps) |\t[rt_attr_timestamp](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_timestamp) | 时间戳  |   |\n\n| [bit(n)](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint field_name:N](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint) | N 是要保留的最大位数  |   |\n\n<!-- intro -->\n\n##### 通过 CREATE TABLE 创建实时表的示例\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\n这将创建一个名为 \"products\" 的表，包含两个字段：\"title\"（全文索引）和 \"price\"（浮点数），并将 \"morphology\" 设置为 \"stem_en\"。\n\nCODE_BLOCK_53\n\n这将创建一个名为 \"products\" 的表，包含三个字段：\n\n* \"title\" 被索引，但不存储。\n\n* \"description\" 被存储，但不索引。\n\n* \"author\" 同时被存储和索引。\n\n<!-- end -->\n\n## 引擎\n\nCODE_BLOCK_54\n\nengine 设置更改表中所有属性的默认[属性存储](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages)。您也可以为[每个属性单独指定 engine](../../Creating_a_table/Data_types.md#How-to-switch-between-the-storages)。\n\n有关如何为普通表启用列存储的信息，请参见 [columnar_attrs](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#columnar_attrs)。\n\n取值：\n\n* columnar - 为所有表属性启用列存储，除了 [json](../../Creating_a_table/Data_types.md#JSON)\n\n* **rowwise（默认）** - 不做任何更改，使用传统的行存储。\n\n## 其他设置\n\n以下设置适用于实时表和普通表，无论是在配置文件中指定还是通过 `CREATE` 或 `ALTER` 命令在线设置。\n\n### 性能相关\n\n#### 访问表文件\n\nManticore 支持两种读取表数据的访问模式：seek+read 和 mmap。",
      "russian": "Этот параметр определяет таблицу(ы), к которым будет применяться kill-list. Совпадения в целевой таблице, которые обновляются или удаляются в текущей таблице, будут подавлены. В режиме `:kl` документы для подавления берутся из [kill-list](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md). В режиме `:id` все идентификаторы документов из текущей таблицы подавляются в целевой. Если ни один из режимов не указан, будут применяться оба режима. [Подробнее о kill-list здесь](../../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md)\n\nЗначение: **не указано** (по умолчанию), target_table_name:kl, target_table_name:id, target_table_name. Допускается несколько значений\n\n#### columnar_attrs\n\nCODE_BLOCK_49\n\nЭтот параметр конфигурации определяет, какие атрибуты должны храниться в [колоночном хранилище](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) вместо построчного хранилища.\n\nВы можете установить `columnar_attrs = *`, чтобы хранить все поддерживаемые типы данных в колоночном хранилище.\n\nКроме того, `id` является поддерживаемым атрибутом для хранения в колоночном хранилище.\n\n#### columnar_strings_no_hash\n\nCODE_BLOCK_50\n\nПо умолчанию все строковые атрибуты, хранящиеся в колоночном хранилище, сохраняют предварительно вычисленные хэши. Эти хэши используются для группировки и фильтрации. Однако они занимают дополнительное место, и если вам не нужно группировать по этому атрибуту, вы можете сэкономить место, отключив генерацию хэшей.\n\n### Создание таблицы реального времени онлайн через CREATE TABLE\n\n<!-- example rt_mode -->\n\n##### Общий синтаксис CREATE TABLE\n\nCODE_BLOCK_51\n\n##### Типы данных:\n\nДля получения дополнительной информации о типах данных смотрите [подробнее о типах данных здесь](../../Creating_a_table/Data_types.md).\n\n| Тип | Эквивалент в конфигурационном файле | Примечания | Псевдонимы |\n\n| - | - | - | - |\n\n| [text](../../Creating_a_table/Data_types.md#Text) | [rt_field](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_field)  | Опции: indexed, stored. По умолчанию: **оба**. Чтобы сохранить текст хранимым, но индексированным, укажите только \"stored\". Чтобы сохранить текст только индексированным, укажите только \"indexed\". | string |\n\n| [integer](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint)\t| целое число\t | int, uint |\n\n| [bigint](../../Creating_a_table/Data_types.md#Big-Integer) | [rt_attr_bigint](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bigint)\t| большое целое число\t |   |\n\n| [float](../../Creating_a_table/Data_types.md#Float) | [rt_attr_float](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float)   | число с плавающей точкой  |   |\n\n| [float_vector](../../Creating_a_table/Data_types.md#Float-vector) | [rt_attr_float_vector](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_float_vector) | вектор чисел с плавающей точкой  |   |\n\n| [multi](../../Creating_a_table/Data_types.md#Multi-value-integer-%28MVA%29) | [rt_attr_multi](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi)   | мульти-целое число |   |\n\n| [multi64](../../Creating_a_table/Data_types.md#Multi-value-big-integer) | [rt_attr_multi_64](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_multi_64) | мульти-большое целое число  |   |\n\n| [bool](../../Creating_a_table/Data_types.md#Boolean) | [rt_attr_bool](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_bool) | булево значение |   |\n\n| [json](../../Creating_a_table/Data_types.md#JSON) | [rt_attr_json](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_json) | JSON |   |\n\n| [string](../../Creating_a_table/Data_types.md#String) | [rt_attr_string](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_string) | строка. Опция `indexed, attribute` сделает значение полнотекстово индексируемым и одновременно фильтруемым, сортируемым и группируемым  |   |\n\n| [timestamp](../../Creating_a_table/Data_types.md#Timestamps) |\t[rt_attr_timestamp](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_timestamp) | временная метка  |   |\n\n| [bit(n)](../../Creating_a_table/Data_types.md#Integer) | [rt_attr_uint field_name:N](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_attr_uint) | N — максимальное количество бит для хранения  |   |\n\n<!-- intro -->\n\n##### Примеры создания таблицы реального времени через CREATE TABLE\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\nЭто создаёт таблицу \"products\" с двумя полями: \"title\" (полнотекстовый) и \"price\" (число с плавающей точкой), и устанавливает \"morphology\" в \"stem_en\".\n\nCODE_BLOCK_53\n\nЭто создаёт таблицу \"products\" с тремя полями:\n\n* \"title\" индексируется, но не хранится.\n\n* \"description\" хранится, но не индексируется.\n\n* \"author\" хранится и индексируется одновременно.\n\n<!-- end -->\n\n## Engine\n\nCODE_BLOCK_54\n\nПараметр engine изменяет стандартное [хранилище атрибутов](../../Creating_a_table/Data_types.md#Row-wise-and-columnar-attribute-storages) для всех атрибутов в таблице. Вы также можете указать `engine` [отдельно для каждого атрибута](../../Creating_a_table/Data_types.md#How-to-switch-between-the-storages).\n\nДля информации о том, как включить колоночное хранилище для простой таблицы, смотрите [columnar_attrs](../../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#columnar_attrs).\n\nЗначения:\n\n* columnar - Включает колоночное хранилище для всех атрибутов таблицы, кроме [json](../../Creating_a_table/Data_types.md#JSON)\n\n* **rowwise (по умолчанию)** - Не изменяет ничего и использует традиционное построчное хранилище для таблицы.\n\n## Другие настройки\n\nСледующие настройки применимы как для таблиц реального времени, так и для простых таблиц, независимо от того, указаны ли они в конфигурационном файле или установлены онлайн с помощью команды `CREATE` или `ALTER`.\n\n### Связанные с производительностью\n\n#### Доступ к файлам таблицы\n\nManticore поддерживает два режима доступа для чтения данных таблицы: seek+read и mmap."
    },
    "is_code_or_comment": false
  },
  "1ba772a9fa5ac7f1ca0131f056bff242ad849fe0f70d2457334e1305cd1651d4": {
    "original": "In real-time mode, you can adjust the size limit of RAM chunks and the maximum number of disk chunks using the `ALTER TABLE` statement. To set `rt_mem_limit` to 1 gigabyte for the table \"t\", run the following query: `ALTER TABLE t rt_mem_limit='1G'`. To change the maximum number of disk chunks, run the query: `ALTER TABLE t optimize_cutoff='5'`.\n\nIn the plain mode, you can change the values of `rt_mem_limit` and `optimize_cutoff` by updating the table configuration or running the command `ALTER TABLE <table_name> RECONFIGURE`\n\n##### Important notes about RAM chunks\n\n* Real-time tables are similar to [distributed](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table) consisting of multiple local tables, also known as disk chunks.\n\n* Each RAM chunk is made up of multiple segments, which are special RAM-only tables.\n\n* While disk chunks are stored on disk, RAM chunks are stored in memory.\n\n* Each transaction made to a real-time table generates a new segment, and RAM chunk segments are merged after each transaction commit. It is more efficient to perform bulk INSERTs of hundreds or thousands of documents rather than multiple separate INSERTs with one document to reduce the overhead from merging RAM chunk segments.\n\n* When the number of segments exceeds 32, they will be merged to keep the count below 32.\n\n* Real-time tables always have one RAM chunk (which may be empty) and one or more disk chunks.\n\n* Merging larger segments takes longer, so it's best to avoid having a very large RAM chunk (and therefore `rt_mem_limit`).\n\n* The number of disk chunks depends on the data in the table and the `rt_mem_limit` setting.\n\n* Searchd flushes the RAM chunk to disk (as a persisted file, not as a disk chunk) on shutdown and periodically according to the [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period) setting. Flushing several gigabytes to disk may take some time.\n\n* A large RAM chunk puts more pressure on storage, both when flushing to disk into the `.ram` file and when the RAM chunk is full and dumped to disk as a disk chunk.\n\n* The RAM chunk is backed up by a [binary log](../../Logging/Binary_logging.md) until it is flushed to disk, and a larger `rt_mem_limit`, setting will increase the time it takes to replay the binary log and recover the RAM chunk.\n\n* The RAM chunk may be slightly slower than a disk chunk.\n\n* Although the RAM chunk itself doesn't take up more memory than `rt_mem_limit`, Manticore may take up more memory in some cases, such as when you start a transaction to insert data and don't commit it for a while. In this case, the data you have already transmitted within the transaction will remain in memory.\n\n##### RAM chunk flushing conditions\n\nIn addition to `rt_mem_limit`, the flushing behavior of RAM chunks is also influenced by the following options and conditions:\n\n* Frozen state. If the table is [frozen](../../Securing_and_compacting_a_table/Freezing_and_locking_a_table.md), flushing is deferred. That is a permanent rule; nothing can override it. If the `rt_mem_limit` condition is reached while the table is frozen, all further inserts will be delayed until the table is unfrozen.\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout): This option defines the timeout (in seconds) for auto-flushing a RAM chunk if there are no writes to it.  If no write occurs within this time, the chunk will be flushed to disk. Setting it to `-1` disables auto-flushing based on write activity. The default value is 1 second.\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout): This option sets the timeout (in seconds) for preventing auto-flushing a RAM chunk if there are no searches in the table. Auto-flushing will only occur if there has been at least one search within this time. The default value is 30 seconds.\n\n* ongoing optimization: If an optimization process is currently running, and the number of existing disk chunks has\n\n  reached or exceeded a configured internal `cutoff` threshold, the flush triggered by the `diskchunk_flush_write_timeout` or `diskchunk_flush_search_timeout` timeout will be skipped.\n\n* too few documents in RAM segments: If the number of documents across RAM segments is below a minimum threshold (8192),\n\n  the flush triggered by the `diskchunk_flush_write_timeout` or `diskchunk_flush_search_timeout` timeout will be skipped to avoid creating very small disk chunks. This helps minimize unnecessary disk writes and chunk fragmentation.\n\nThese timeouts work in conjunction.  A RAM chunk will be flushed if *either* timeout is reached.  This ensures that even if there are no writes, the data will eventually be persisted to disk, and conversely, even if there are constant writes but no searches, the data will also be persisted.  These settings provide more granular control over how frequently RAM chunks are flushed, balancing the need for data durability with performance considerations.  Per-table directives for these settings have higher priority and will override the instance-wide defaults.\n\n### Plain table settings:\n\n#### source\n\nCODE_BLOCK_47\n\nThe source field specifies the source from which documents will be obtained during indexing of the current table. There must be at least one source. The sources can be of different types (e.g. one could be MySQL, another PostgreSQL). For more information on indexing from external storages, [read here](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\nValue: The name of the source is **mandatory**. Multiple values are allowed.\n\n#### killlist_target\n\nCODE_BLOCK_48",
    "translations": {
      "chinese": "在实时模式下，您可以使用 `ALTER TABLE` 语句调整 RAM 块的大小限制和磁盘块的最大数量。要将表 \"t\" 的 `rt_mem_limit` 设置为 1 GB，请运行以下查询：`ALTER TABLE t rt_mem_limit='1G'`。要更改磁盘块的最大数量，请运行查询：`ALTER TABLE t optimize_cutoff='5'`。\n\n在普通模式下，您可以通过更新表配置或运行命令 `ALTER TABLE <table_name> RECONFIGURE` 来更改 `rt_mem_limit` 和 `optimize_cutoff` 的值。\n\n##### 关于 RAM 块的重要说明\n\n* 实时表类似于由多个本地表组成的[分布式表](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table)，这些本地表也称为磁盘块。\n\n* 每个 RAM 块由多个段组成，这些段是特殊的仅限 RAM 的表。\n\n* 磁盘块存储在磁盘上，而 RAM 块存储在内存中。\n\n* 对实时表的每个事务都会生成一个新段，RAM 块段在每次事务提交后合并。执行数百或数千条文档的批量 INSERT 比多次单文档 INSERT 更高效，以减少合并 RAM 块段的开销。\n\n* 当段数超过 32 时，它们将被合并以保持段数低于 32。\n\n* 实时表始终有一个 RAM 块（可能为空）和一个或多个磁盘块。\n\n* 合并较大的段需要更长时间，因此最好避免拥有非常大的 RAM 块（因此也避免设置过大的 `rt_mem_limit`）。\n\n* 磁盘块的数量取决于表中的数据和 `rt_mem_limit` 设置。\n\n* Searchd 在关闭时以及根据 [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period) 设置定期将 RAM 块刷新到磁盘（作为持久化文件，而非磁盘块）。刷新几个 GB 到磁盘可能需要一些时间。\n\n* 大的 RAM 块在刷新到磁盘的 `.ram` 文件时以及 RAM 块满时转储为磁盘块时，会对存储造成更大压力。\n\n* RAM 块由[二进制日志](../../Logging/Binary_logging.md)备份，直到刷新到磁盘，较大的 `rt_mem_limit` 设置会增加重放二进制日志和恢复 RAM 块所需的时间。\n\n* RAM 块的速度可能略慢于磁盘块。\n\n* 虽然 RAM 块本身占用的内存不会超过 `rt_mem_limit`，但在某些情况下，Manticore 可能会占用更多内存，例如当您启动一个插入数据的事务但长时间不提交时，此时事务中已传输的数据会保留在内存中。\n\n##### RAM 块刷新条件\n\n除了 `rt_mem_limit`，RAM 块的刷新行为还受以下选项和条件影响：\n\n* 冻结状态。如果表处于[冻结](../../Securing_and_compacting_a_table/Freezing_and_locking_a_table.md)状态，刷新将被推迟。这是永久规则，无法被覆盖。如果在表冻结时达到 `rt_mem_limit` 条件，所有后续插入将被延迟，直到表解冻。\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout)：此选项定义了如果没有写入操作，自动刷新 RAM 块的超时时间（秒）。如果在此时间内没有写入，块将被刷新到磁盘。设置为 `-1` 禁用基于写入活动的自动刷新。默认值为 1 秒。\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout)：此选项设置防止自动刷新 RAM 块的超时时间（秒），如果表中没有搜索操作。只有在此时间内至少有一次搜索时，才会自动刷新。默认值为 30 秒。\n\n* 正在进行的优化：如果当前有优化进程运行，且现有磁盘块数量已达到或超过配置的内部 `cutoff` 阈值，则由 `diskchunk_flush_write_timeout` 或 `diskchunk_flush_search_timeout` 超时触发的刷新将被跳过。\n\n* RAM 段中文档数量过少：如果 RAM 段中的文档总数低于最小阈值（8192），则由 `diskchunk_flush_write_timeout` 或 `diskchunk_flush_search_timeout` 超时触发的刷新将被跳过，以避免创建非常小的磁盘块。这有助于减少不必要的磁盘写入和块碎片。\n\n这些超时设置是协同工作的。只要达到任一超时，RAM 块就会被刷新。这确保即使没有写入，数据最终也会持久化到磁盘；反之，即使有持续写入但没有搜索，数据也会被持久化。这些设置提供了更细粒度的控制，平衡了数据持久性和性能考虑。每个表的指令优先级更高，会覆盖实例范围的默认值。\n\n### 普通表设置：\n\n#### source\n\nCODE_BLOCK_47\n\nsource 字段指定在当前表索引期间将从哪个源获取文档。必须至少有一个源。源可以是不同类型的（例如，一个可能是 MySQL，另一个是 PostgreSQL）。有关从外部存储索引的更多信息，[请阅读这里](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\n值：必须指定源的名称。允许多个值。\n\n#### killlist_target\n\nCODE_BLOCK_48",
      "russian": "В режиме реального времени вы можете настроить ограничение размера RAM-чанков и максимальное количество дисковых чанков с помощью оператора `ALTER TABLE`. Чтобы установить `rt_mem_limit` в 1 гигабайт для таблицы \"t\", выполните следующий запрос: `ALTER TABLE t rt_mem_limit='1G'`. Чтобы изменить максимальное количество дисковых чанков, выполните запрос: `ALTER TABLE t optimize_cutoff='5'`.\n\nВ обычном режиме вы можете изменить значения `rt_mem_limit` и `optimize_cutoff`, обновив конфигурацию таблицы или выполнив команду `ALTER TABLE <table_name> RECONFIGURE`\n\n##### Важные заметки о RAM-чанках\n\n* Таблицы реального времени похожи на [распределённые](../../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md#Creating-a-local-distributed-table), состоящие из нескольких локальных таблиц, также известных как дисковые чанки.\n\n* Каждый RAM-чанк состоит из нескольких сегментов, которые являются специальными таблицами, работающими только в памяти.\n\n* В то время как дисковые чанки хранятся на диске, RAM-чанки хранятся в памяти.\n\n* Каждая транзакция, выполненная с таблицей реального времени, создаёт новый сегмент, и сегменты RAM-чанка объединяются после каждого коммита транзакции. Более эффективно выполнять массовые INSERT-операции сотнями или тысячами документов, чем множество отдельных INSERT-операций с одним документом, чтобы уменьшить накладные расходы на слияние сегментов RAM-чанка.\n\n* Когда количество сегментов превышает 32, они объединяются, чтобы сохранить количество ниже 32.\n\n* Таблицы реального времени всегда имеют один RAM-чанк (который может быть пустым) и один или несколько дисковых чанков.\n\n* Слияние больших сегментов занимает больше времени, поэтому лучше избегать очень большого RAM-чанка (и, следовательно, большого значения `rt_mem_limit`).\n\n* Количество дисковых чанков зависит от данных в таблице и настройки `rt_mem_limit`.\n\n* Searchd сбрасывает RAM-чанк на диск (в виде сохранённого файла, а не как дисковый чанк) при завершении работы и периодически в соответствии с настройкой [rt_flush_period](../../Server_settings/Searchd.md#rt_flush_period). Сброс нескольких гигабайт на диск может занять некоторое время.\n\n* Большой RAM-чанк создаёт большую нагрузку на хранилище как при сбросе в файл `.ram`, так и когда RAM-чанк заполняется и сбрасывается на диск как дисковый чанк.\n\n* RAM-чанк поддерживается [бинарным журналом](../../Logging/Binary_logging.md) до тех пор, пока не будет сброшен на диск, и большая настройка `rt_mem_limit` увеличит время воспроизведения бинарного журнала и восстановления RAM-чанка.\n\n* RAM-чанк может работать немного медленнее, чем дисковый чанк.\n\n* Хотя сам RAM-чанк не занимает больше памяти, чем `rt_mem_limit`, Manticore может занимать больше памяти в некоторых случаях, например, когда вы начинаете транзакцию для вставки данных и не коммитите её некоторое время. В этом случае данные, которые вы уже передали в рамках транзакции, останутся в памяти.\n\n##### Условия сброса RAM-чанка\n\nПомимо `rt_mem_limit`, поведение сброса RAM-чанков также зависит от следующих опций и условий:\n\n* Состояние заморозки. Если таблица [заморожена](../../Securing_and_compacting_a_table/Freezing_and_locking_a_table.md), сброс откладывается. Это постоянное правило; ничто не может его переопределить. Если условие `rt_mem_limit` достигнуто, пока таблица заморожена, все последующие вставки будут задержаны до разморозки таблицы.\n\n* [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout): Эта опция задаёт тайм-аут (в секундах) для автоматического сброса RAM-чанка, если в него не происходит запись. Если в течение этого времени запись не происходит, чанк будет сброшен на диск. Установка значения `-1` отключает автоматический сброс на основе активности записи. Значение по умолчанию — 1 секунда.\n\n* [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout): Эта опция задаёт тайм-аут (в секундах) для предотвращения автоматического сброса RAM-чанка, если в таблице не выполняются поиски. Автоматический сброс произойдёт только если в течение этого времени был хотя бы один поиск. Значение по умолчанию — 30 секунд.\n\n* Текущая оптимизация: Если в данный момент выполняется процесс оптимизации, и количество существующих дисковых чанков достигло или превысило настроенный внутренний порог `cutoff`, сброс, вызванный тайм-аутом `diskchunk_flush_write_timeout` или `diskchunk_flush_search_timeout`, будет пропущен.\n\n* Слишком мало документов в RAM-сегментах: Если количество документов во всех RAM-сегментах ниже минимального порога (8192),\n\n  сброс, вызванный тайм-аутом `diskchunk_flush_write_timeout` или `diskchunk_flush_search_timeout`, будет пропущен, чтобы избежать создания очень маленьких дисковых чанков. Это помогает минимизировать ненужные записи на диск и фрагментацию чанков.\n\nЭти тайм-ауты работают совместно. RAM-чанк будет сброшен, если достигнут *любой* из тайм-аутов. Это гарантирует, что даже при отсутствии записей данные в конечном итоге будут сохранены на диск, и наоборот, даже при постоянных записях, но отсутствии поисков, данные также будут сохранены. Эти настройки обеспечивают более тонкий контроль над частотой сброса RAM-чанков, балансируя потребность в сохранности данных и производительность. Директивы на уровне таблицы для этих настроек имеют более высокий приоритет и переопределяют значения по умолчанию для всего экземпляра.\n\n### Настройки обычной таблицы:\n\n#### source\n\nCODE_BLOCK_47\n\nПоле source указывает источник, из которого будут получены документы при индексировании текущей таблицы. Должен быть как минимум один источник. Источники могут быть разных типов (например, один может быть MySQL, другой PostgreSQL). Для получения дополнительной информации об индексировании из внешних хранилищ [читайте здесь](../../Data_creation_and_modification/Adding_data_from_external_storages/Plain_tables_creation.md)\n\nЗначение: Имя источника является **обязательным**. Разрешено несколько значений.\n\n#### killlist_target\n\nCODE_BLOCK_48"
    },
    "is_code_or_comment": false
  }
}
