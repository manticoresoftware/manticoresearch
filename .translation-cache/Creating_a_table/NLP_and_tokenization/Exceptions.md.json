{
  "c964d7ce130e3d95fe753684e9166439fd69b474fb0a32deb3ce6e429b2d750c": {
    "original": "# Exceptions\n\nExceptions (also known as synonyms) allow mapping one or more tokens (including tokens with characters that would normally be excluded) to a single keyword. They are similar to [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms) in that they also perform mapping but have a number of important differences.\n\nA short summary of the differences from [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms) is as follows:\n\n| Exceptions | Word forms |\n\n| - | - |\n\n| Case sensitive | Case insensitive |\n\n| Can use special characters that are not in [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) | Fully obey [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) |\n\n| Underperform on huge dictionaries | Designed to handle millions of entries |\n\n## exceptions\n\nCODE_BLOCK_0\n\n<!-- example exceptions -->\n\nTokenizing exceptions file. Optional, the default is empty.\n\nIn the RT mode, only absolute paths are allowed.\n\nThe expected file format is plain text, with one line per exception. The line format is as follows:\n\nCODE_BLOCK_1\n\nExample file:\n\nCODE_BLOCK_2\n\nAll tokens here are case sensitive and will **not** be processed by [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) rules. Thus, with the example exceptions file above, the `at&t` text will be tokenized as two keywords `at` and `t` due to lowercase letters. On the other hand, `AT&T` will match exactly and produce a single `AT&T` keyword.\n\nIf you need to use `>` or `=` as normal characters, you can escape them by preceding each with a backslash (`\\`). Both `>` and `=` should be escaped in this manner.\n\nNote that the map-to keywords:\n\n* are always interpreted as a *single* word\n\n* are both case and space sensitive\n\nIn the above sample, `ms windows` query will *not* match the document with `MS Windows` text. The query will be interpreted as a query for two keywords, `ms` and `windows`. The mapping for `MS Windows` is a single keyword `ms windows`, with a space in the middle. On the other hand, `standartenfuhrer` will retrieve documents with `Standarten Fuhrer` or `Standarten Fuehrer` contents (capitalized exactly like this), or any capitalization variant of the keyword itself, e.g., `staNdarTenfUhreR`. (It won't catch `standarten fuhrer`, however: this text does not match any of the listed exceptions because of case sensitivity and gets indexed as two separate keywords.)\n\nThe whitespace in the map-from tokens list matters, but its amount does not. Any amount of whitespace in the map-form list will match any other amount of whitespace in the indexed document or query. For instance, the `AT & T` map-from token will match `AT & T` text, whatever the amount of space in both map-from part and the indexed text. Such text will, therefore, be indexed as a special `AT&T` keyword, thanks to the very first entry from the sample.\n\nExceptions also allow capturing special characters (that are exceptions from general `charset_table` rules; hence the name). Assume that you generally do not want to treat `+` as a valid character, but still want to be able to search for some exceptions from this rule such as `C++`. The sample above will do just that, totally independent of what characters are in the table and what are not.\n\nWhen using a [plain table](../../Creating_a_table/Local_tables/Plain_table.md), it is necessary to rotate the table to incorporate changes from the exceptions file. In the case of a real-time table, changes will only apply to new documents.\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- request JSON -->\n\nCODE_BLOCK_4\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- proofread -->",
    "translations": {
      "chinese": "# 异常\n\n异常（也称为同义词）允许将一个或多个标记（包括通常会被排除的字符的标记）映射到单个关键词。它们类似于[wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms)，因为它们也执行映射，但有一些重要的区别。\n\n与[wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms)的区别简要总结如下：\n\n| 异常 | 词形 |\n\n| - | - |\n\n| 区分大小写 | 不区分大小写 |\n\n| 可以使用不在[charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)中的特殊字符 | 完全遵守[charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) |\n\n| 在庞大词典中表现较差 | 设计用于处理数百万条目 |\n\n## exceptions\n\nCODE_BLOCK_0\n\n<!-- example exceptions -->\n\n分词异常文件。可选，默认为空。\n\n在RT模式下，只允许使用绝对路径。\n\n预期的文件格式是纯文本，每行一个异常。行格式如下：\n\nCODE_BLOCK_1\n\n示例文件：\n\nCODE_BLOCK_2\n\n这里的所有标记都是区分大小写的，并且**不会**被[charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)规则处理。因此，以上示例异常文件中，`at&t`文本将被分词为两个关键词`at`和`t`，因为小写字母的原因。另一方面，`AT&T`将完全匹配并生成单个`AT&T`关键词。\n\n如果需要将`>`或`=`作为普通字符使用，可以通过在它们前面加反斜杠(`\\`)来转义。`>`和`=`都应以这种方式转义。\n\n请注意，映射到的关键词：\n\n* 总是被解释为*单个*词\n\n* 对大小写和空格都敏感\n\n在上述示例中，`ms windows`查询将*不会*匹配包含`MS Windows`文本的文档。该查询将被解释为两个关键词`ms`和`windows`的查询。`MS Windows`的映射是单个关键词`ms windows`，中间有空格。另一方面，`standartenfuhrer`将检索包含`Standarten Fuhrer`或`Standarten Fuehrer`内容（大小写完全如示例所示），或关键词本身的任何大小写变体的文档，例如`staNdarTenfUhreR`。（但它不会匹配`standarten fuhrer`：该文本由于大小写敏感性不匹配任何列出的异常，因此被索引为两个独立的关键词。）\n\n映射来源标记列表中的空白符很重要，但其数量无关紧要。映射来源列表中的任意数量空白符都将匹配索引文档或查询中的任意数量空白符。例如，`AT & T`映射来源标记将匹配`AT & T`文本，无论映射来源部分和索引文本中的空格数量如何。因此，这样的文本将被索引为特殊的`AT&T`关键词，这得益于示例中的第一条目。\n\n异常还允许捕获特殊字符（这些字符是一般`charset_table`规则的例外；因此得名）。假设你通常不想将`+`视为有效字符，但仍想能够搜索一些此规则的例外，如`C++`。上述示例完全满足此需求，完全独立于表中包含哪些字符。\n\n使用[plain table](../../Creating_a_table/Local_tables/Plain_table.md)时，必须旋转表以合并异常文件的更改。对于实时表，更改只会应用于新文档。\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- request JSON -->\n\nCODE_BLOCK_4\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- proofread -->",
      "russian": "# Исключения\n\nИсключения (также известные как синонимы) позволяют сопоставлять один или несколько токенов (включая токены с символами, которые обычно исключаются) с одним ключевым словом. Они похожи на [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms) тем, что также выполняют сопоставление, но имеют ряд важных отличий.\n\nКраткое резюме отличий от [wordforms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md#wordforms) следующее:\n\n| Исключения | Формы слов |\n\n| - | - |\n\n| Чувствительны к регистру | Не чувствительны к регистру |\n\n| Могут использовать специальные символы, отсутствующие в [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) | Полностью подчиняются [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) |\n\n| Плохо работают с огромными словарями | Предназначены для обработки миллионов записей |\n\n## exceptions\n\nCODE_BLOCK_0\n\n<!-- example exceptions -->\n\nФайл исключений для токенизации. Необязательный, по умолчанию пустой.\n\nВ режиме RT допускаются только абсолютные пути.\n\nОжидаемый формат файла — простой текст, по одному исключению на строку. Формат строки следующий:\n\nCODE_BLOCK_1\n\nПример файла:\n\nCODE_BLOCK_2\n\nВсе токены здесь чувствительны к регистру и **не** будут обрабатываться правилами [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Таким образом, с приведённым выше примером файла исключений, текст `at&t` будет токенизирован как два ключевых слова `at` и `t` из-за строчных букв. С другой стороны, `AT&T` будет точно совпадать и породит одно ключевое слово `AT&T`.\n\nЕсли вам нужно использовать `>` или `=` как обычные символы, вы можете экранировать их, предваряя каждый обратным слэшем (`\\`). И `>`, и `=` должны быть экранированы таким образом.\n\nОбратите внимание, что ключевые слова для сопоставления:\n\n* всегда интерпретируются как *одно* слово\n\n* чувствительны к регистру и пробелам\n\nВ приведённом выше примере запрос `ms windows` *не* совпадёт с документом, содержащим текст `MS Windows`. Запрос будет интерпретирован как запрос по двум ключевым словам, `ms` и `windows`. Сопоставление для `MS Windows` — это одно ключевое слово `ms windows` с пробелом посередине. С другой стороны, `standartenfuhrer` найдёт документы с содержимым `Standarten Fuhrer` или `Standarten Fuehrer` (с точным таким же регистром), или любую вариацию регистра самого ключевого слова, например, `staNdarTenfUhreR`. (Однако он не найдёт `standarten fuhrer`: этот текст не совпадает ни с одним из перечисленных исключений из-за чувствительности к регистру и индексируется как два отдельных ключевых слова.)\n\nПробелы в списке токенов для сопоставления важны, но их количество — нет. Любое количество пробелов в списке для сопоставления будет соответствовать любому другому количеству пробелов в индексированном документе или запросе. Например, токен для сопоставления `AT & T` будет соответствовать тексту `AT & T`, независимо от количества пробелов как в части для сопоставления, так и в индексированном тексте. Такой текст, следовательно, будет индексироваться как специальное ключевое слово `AT&T`, благодаря самой первой записи из примера.\n\nИсключения также позволяют захватывать специальные символы (которые являются исключениями из общих правил `charset_table`; отсюда и название). Предположим, что вы обычно не хотите рассматривать `+` как допустимый символ, но всё же хотите иметь возможность искать некоторые исключения из этого правила, например, `C++`. Приведённый выше пример сделает именно это, полностью независимо от того, какие символы есть в таблице, а каких нет.\n\nПри использовании [plain table](../../Creating_a_table/Local_tables/Plain_table.md) необходимо вращать таблицу, чтобы учесть изменения из файла исключений. В случае таблицы реального времени изменения будут применяться только к новым документам.\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- request JSON -->\n\nCODE_BLOCK_4\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  }
}
