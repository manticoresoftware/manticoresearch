{
  "2709334b00f78b4fb6df56847677523f1487a23337d239a89fbfefa005b5d898": {
    "original": "# Word forms\n\nWord forms are applied after tokenizing incoming text by [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) rules. They essentially let you replace one word with another. Normally, that would be used to bring different word forms to a single normal form (e.g. to normalize all the variants such as \"walks\", \"walked\", \"walking\" to the normal form \"walk\"). It can also be used to implement [stemming](../../Creating_a_table/NLP_and_tokenization/Morphology.md) exceptions, because stemming is not applied to words found in the forms list.\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\nWord forms dictionary. Optional, default is empty.\n\nThe word forms dictionaries are used to normalize incoming words both during indexing and searching. Therefore, when it comes to a [plain table](../../Creating_a_table/Local_tables/Plain_table.md), it's required to rotate the table in order to pick up changes in the word forms file.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Plain mode example:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nWord forms support in Manticore is designed to handle large dictionaries well. They moderately affect indexing speed; for example, a dictionary with 1 million entries slows down full-text indexing by about 1.5 times. Searching speed is not affected at all. The additional RAM impact is roughly equal to the dictionary file size, and dictionaries are shared across tables. For instance, if the very same 50 MB word forms file is specified for 10 different tables, the additional `searchd` RAM usage will be about 50 MB.\n\n<!-- example wf_simple -->\n\nThe dictionary file should be in a simple plain text format. Each line should contain source and destination word forms in UTF-8 encoding, separated by a 'greater than' sign. The rules from the [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) will be applied when the file is loaded. Therefore, if you do not modify `charset_table`, your word forms will be case-insensitive, similar to your other full-text indexed data. Below is a sample of the file contents:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\nThere is a bundled utility called [Spelldump](../../Miscellaneous_tools.md#spelldump) that helps you create a dictionary file in a format that Manticore can read. The utility can read from source `.dict` and `.aff` dictionary files in the `ispell` or `MySpell` format, as bundled with OpenOffice.\n\nYou can map several source words to a single destination word. The process happens on tokens, not the source text, so differences in whitespace and markup are ignored.\n\n<!-- example wf_more_complex -->\n\nYou can use the `=>` symbol instead of `>`. Comments (starting with `#`) are also allowed. Finally, if a line starts with a tilde (`~`), the wordform will be applied after morphology, instead of before (note that only a single source and destination word are supported in this case).\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\nIf you need to use `>`, `=` or `~` as normal characters, you can escape them by preceding each with a backslash (`\\`). Both `>` and `=` should be escaped in this manner. Here's an example:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\nYou can specify multiple destination tokens:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\nYou can specify multiple files, not just one. Masks can be used as a pattern, and all matching files will be processed in simple ascending order:\n\nIn the RT mode, only absolute paths are allowed.\n\nIf multi-byte codepages are used and file names include non-latin characters, the resulting order may not be exactly alphabetic. If the same wordform definition is found in multiple files, the latter one is used and overrides previous definitions.\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request Config -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n<!-- proofread -->",
    "translations": {
      "chinese": "# 词形变化\n\n词形变化在通过 [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) 规则对输入文本进行分词后应用。它们本质上允许你用另一个词替换一个词。通常，这用于将不同的词形归一化为单一的标准形式（例如，将所有变体如 \"walks\"、\"walked\"、\"walking\" 规范化为标准形式 \"walk\"）。它也可以用来实现 [词干提取](../../Creating_a_table/NLP_and_tokenization/Morphology.md) 的例外情况，因为词干提取不会应用于词形变化列表中的词。\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\n词形变化字典。可选，默认为空。\n\n词形变化字典用于在索引和搜索过程中规范化输入词。因此，对于 [plain table](../../Creating_a_table/Local_tables/Plain_table.md) 来说，必须旋转表以应用词形变化文件中的更改。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Plain mode example:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nManticore 中的词形变化支持设计为能够良好处理大型字典。它们对索引速度有适度影响；例如，包含 100 万条目的字典会使全文索引速度降低约 1.5 倍。搜索速度完全不受影响。额外的内存占用大致等于字典文件大小，且字典在多个表之间共享。例如，如果同一个 50 MB 的词形变化文件被指定给 10 个不同的表，额外的 `searchd` 内存使用大约为 50 MB。\n\n<!-- example wf_simple -->\n\n字典文件应为简单的纯文本格式。每行应包含源词形和目标词形，使用 UTF-8 编码，并以“大于号”分隔。加载文件时会应用 [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) 中的规则。因此，如果你不修改 `charset_table`，你的词形变化将是不区分大小写的，类似于其他全文索引的数据。以下是文件内容的示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n有一个捆绑的工具叫做 [Spelldump](../../Miscellaneous_tools.md#spelldump)，它可以帮助你创建 Manticore 可读取格式的字典文件。该工具可以读取以 `ispell` 或 `MySpell` 格式的源 `.dict` 和 `.aff` 字典文件，这些文件随 OpenOffice 一起捆绑提供。\n\n你可以将多个源词映射到一个目标词。该过程作用于分词后的词元，而非源文本，因此空白和标记的差异会被忽略。\n\n<!-- example wf_more_complex -->\n\n你可以使用 `=>` 符号代替 `>`。也允许注释（以 `#` 开头）。最后，如果一行以波浪号（`~`）开头，词形变化将在形态学处理之后应用，而非之前（注意此情况下只支持单个源词和目标词）。\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\n如果你需要将 `>`、`=` 或 `~` 作为普通字符使用，可以通过在它们前面加反斜杠（`\\`）来转义。`>` 和 `=` 都应以此方式转义。示例如下：\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\n你可以指定多个目标词元：\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\n你可以指定多个文件，而不仅仅是一个。可以使用通配符作为模式，所有匹配的文件将按简单升序处理：\n\n在 RT 模式下，只允许使用绝对路径。\n\n如果使用多字节编码页且文件名包含非拉丁字符，结果顺序可能不完全是字母顺序。如果在多个文件中发现相同的词形变化定义，后面的定义将覆盖之前的。\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request Config -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n<!-- proofread -->",
      "russian": "# Формы слов\n\nФормы слов применяются после токенизации входящего текста по правилам [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Они по сути позволяют заменить одно слово другим. Обычно это используется для приведения различных форм слова к одной нормальной форме (например, нормализация всех вариантов таких как \"walks\", \"walked\", \"walking\" к нормальной форме \"walk\"). Также это может использоваться для реализации исключений [стемминга](../../Creating_a_table/NLP_and_tokenization/Morphology.md), поскольку стемминг не применяется к словам, найденным в списке форм.\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\nСловарь форм слов. Опционально, по умолчанию пустой.\n\nСловари форм слов используются для нормализации входящих слов как при индексации, так и при поиске. Поэтому, когда речь идет о [plain table](../../Creating_a_table/Local_tables/Plain_table.md), требуется выполнить ротацию таблицы, чтобы применить изменения в файле форм слов.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Пример в Plain режиме:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nПоддержка форм слов в Manticore разработана для эффективной работы с большими словарями. Они умеренно влияют на скорость индексации; например, словарь с 1 миллионом записей замедляет полнотекстовую индексацию примерно в 1.5 раза. Скорость поиска при этом не страдает. Дополнительное потребление RAM примерно равно размеру файла словаря, и словари разделяются между таблицами. Например, если один и тот же файл форм слов размером 50 МБ указан для 10 разных таблиц, дополнительное потребление RAM `searchd` будет около 50 МБ.\n\n<!-- example wf_simple -->\n\nФайл словаря должен быть в простом текстовом формате. Каждая строка должна содержать исходную и целевую формы слова в кодировке UTF-8, разделённые знаком \"больше\" (>). Правила из [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) будут применены при загрузке файла. Поэтому, если вы не изменяете `charset_table`, ваши формы слов будут нечувствительны к регистру, как и остальные данные, индексируемые полнотекстово. Ниже приведён пример содержимого файла:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\nВ комплекте есть утилита [Spelldump](../../Miscellaneous_tools.md#spelldump), которая помогает создать файл словаря в формате, читаемом Manticore. Утилита может читать исходные файлы словарей `.dict` и `.aff` в формате `ispell` или `MySpell`, как в комплекте с OpenOffice.\n\nВы можете сопоставить несколько исходных слов с одним целевым словом. Процесс происходит на уровне токенов, а не исходного текста, поэтому различия в пробелах и разметке игнорируются.\n\n<!-- example wf_more_complex -->\n\nВы можете использовать символ `=>` вместо `>`. Также допускаются комментарии (начинающиеся с `#`). Наконец, если строка начинается с тильды (`~`), форма слова будет применена после морфологии, а не до (обратите внимание, что в этом случае поддерживается только одно исходное и одно целевое слово).\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\nЕсли вам нужно использовать `>`, `=` или `~` как обычные символы, вы можете экранировать их, предваряя обратным слэшем (`\\`). И `>`, и `=` должны быть экранированы таким образом. Вот пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\nВы можете указать несколько целевых токенов:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\nВы можете указать несколько файлов, а не только один. Маски могут использоваться как шаблоны, и все подходящие файлы будут обработаны в простом порядке возрастания:\n\nВ режиме RT допускаются только абсолютные пути.\n\nЕсли используются многобайтовые кодировки и имена файлов содержат нелатинские символы, итоговый порядок может быть не совсем алфавитным. Если одно и то же определение формы слова встречается в нескольких файлах, используется последнее, переопределяющее предыдущие.\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request Config -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "7534d78c52f2bb692da560ad5ee9d323c1d0270c1d405c2dd07d2fba90f02ddd": {
    "original": "# Word forms\n\nWord forms are applied after tokenizing incoming text by [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) rules. They essentially let you replace one word with another. Normally, that would be used to bring different word forms to a single normal form (e.g. to normalize all the variants such as \"walks\", \"walked\", \"walking\" to the normal form \"walk\"). It can also be used to implement [stemming](../../Creating_a_table/NLP_and_tokenization/Morphology.md) exceptions, because stemming is not applied to words found in the forms list.\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\nWord forms dictionary. Optional, default is empty.\n\nThe word forms dictionaries are used to normalize incoming words both during indexing and searching. Therefore, when it comes to a [plain table](../../Creating_a_table/Local_tables/Plain_table.md), it's required to rotate the table in order to pick up changes in the word forms file.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Plain mode example:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nWord forms support in Manticore is designed to handle large dictionaries well. They moderately affect indexing speed; for example, a dictionary with 1 million entries slows down full-text indexing by about 1.5 times. Searching speed is not affected at all. The additional RAM impact is roughly equal to the dictionary file size, and dictionaries are shared across tables. For instance, if the very same 50 MB word forms file is specified for 10 different tables, the additional `searchd` RAM usage will be about 50 MB.\n\n<!-- example wf_simple -->\n\nThe dictionary file should be in a simple plain text format. Each line should contain source and destination word forms in UTF-8 encoding, separated by a 'greater than' sign. The rules from the [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table) will be applied when the file is loaded. Therefore, if you do not modify `charset_table`, your word forms will be case-insensitive, similar to your other full-text indexed data. Below is a sample of the file contents:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\nThere is a bundled utility called [Spelldump](../../Miscellaneous_tools.md#spelldump) that helps you create a dictionary file in a format that Manticore can read. The utility can read from source `.dict` and `.aff` dictionary files in the `ispell` or `MySpell` format, as bundled with OpenOffice.\n\nYou can map several source words to a single destination word. The process happens on tokens, not the source text, so differences in whitespace and markup are ignored.\n\n<!-- example wf_more_complex -->\n\nYou can use the `=>` symbol instead of `>`. Comments (starting with `#`) are also allowed. Finally, if a line starts with a tilde (`~`), the wordform will be applied after morphology, instead of before (note that only a single source and destination word are supported in this case).\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\nIf you need to use `>`, `=` or `~` as normal characters, you can escape them by preceding each with a backslash (`\\`). Both `>` and `=` should be escaped in this manner. Here's an example:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\nYou can specify multiple destination tokens:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\nYou can specify multiple files, not just one. Masks can be used as a pattern, and all matching files will be processed in simple ascending order:\n\nIn the RT mode, only absolute paths are allowed.\n\nIf multi-byte codepages are used and file names include non-latin characters, the resulting order may not be exactly alphabetic. If the same wordform definition is found in multiple files, the latter one is used and overrides previous definitions.\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- request Config -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- proofread -->",
    "translations": {
      "chinese": "# 词形变化\n\n词形变化在根据[charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)规则对输入文本进行分词后应用。本质上，它们允许你用另一个单词替换一个单词。通常，这用于将不同的词形转换为单一的标准形式（例如，将所有变体如 \"walks\"、\"walked\"、\"walking\" 规范化为标准形式 \"walk\"）。它也可以用来实现[词干提取](../../Creating_a_table/NLP_and_tokenization/Morphology.md)异常，因为词干提取不会应用于词形变化列表中的单词。\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\n词形变化词典。可选，默认为空。\n\n词形变化词典用于在索引和搜索期间规范化输入的单词。因此，对于[plain table](../../Creating_a_table/Local_tables/Plain_table.md)，需要旋转表以应用词形变化文件中的更改。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Plain mode example:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nManticore 中的词形变化支持设计为能够处理大型词典。它们会适度影响索引速度；例如，包含 100 万条目的词典将使全文索引速度降低约 1.5 倍。搜索速度则完全不受影响。额外的内存开销大致等于词典文件大小，且词典在多张表之间共享。例如，如果同一个 50 MB 的词形变化文件被指定给 10 个不同的表，额外的 `searchd` 内存使用约为 50 MB。\n\n<!-- example wf_simple -->\n\n词典文件应采用简单的纯文本格式。每行应包含源词形和目标词形，使用 UTF-8 编码，并由“大于号”分隔。加载文件时会应用[charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table)中的规则。因此，如果你没有修改 `charset_table`，你的词形变化将是大小写不敏感的，类似于你的其他全文索引数据。以下是文件内容的示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n捆绑的工具[Spelldump](../../Miscellaneous_tools.md#spelldump)可帮助你创建 Manticore 可读取格式的词典文件。该工具可以读取以 `.dict` 和 `.aff` 为后缀的源词典文件，格式为 `ispell` 或 `MySpell`，这些文件通常随 OpenOffice 提供。\n\n你可以将多个源词映射到单个目标词。这个过程作用于分词结果，而非源文本，因此忽略空白和标记的差异。\n\n<!-- example wf_more_complex -->\n\n你可以使用 `=>` 符号代替 `>`。另外，允许存在注释（以 `#` 开头）。最后，如果某行以波浪号 (`~`) 开头，则该词形变化将在形态学处理之后应用，而非之前（注意此情况下只支持单个源词和目标词）。\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\n如果你需要将 `>`, `=` 或 `~` 作为普通字符使用，可以通过在前面加反斜杠 (`\\`) 来转义它们。`>` 和 `=` 都应该这样转义。示例如下：\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\n你可以指定多个目标分词：\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\n你可以指定多个文件，而不仅仅是一个。可以使用通配符作为模式，所有匹配的文件将按简单升序处理：\n\n在 RT 模式下，只允许使用绝对路径。\n\n如果使用多字节编码页且文件名包含非拉丁字符，结果排序可能不是严格的字母顺序。如果多个文件中出现相同的词形变化定义，则以后加载的文件的定义为准，覆盖之前的定义。\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- request Config -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- proofread -->",
      "russian": "# Формы слов\n\nФормы слов применяются после токенизации входящего текста по правилам [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Они по сути позволяют заменять одно слово другим. Обычно это используется для приведения разных форм слова к одной нормальной форме (например, для нормализации всех вариантов таких как \"walks\", \"walked\", \"walking\" к нормальной форме \"walk\"). Также это может применяться для реализации исключений при [стемминге](../../Creating_a_table/NLP_and_tokenization/Morphology.md), так как стемминг не применяется к словам, найденным в списке форм.\n\n## wordforms\n\nCODE_BLOCK_0\n\n<!-- example wordforms -->\n\nСловарь форм слов. Опционально, по умолчанию пустой.\n\nСловари форм слов используются для нормализации входящих слов как при индексации, так и при поиске. Поэтому, если речь идет о [простом таблице](../../Creating_a_table/Local_tables/Plain_table.md), необходимо выполнить перезапуск таблицы для учёта изменений в файле форм слов.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- request JSON -->\n\nCODE_BLOCK_2\n\n<!-- request PHP -->\n\nCODE_BLOCK_3\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Java:\n\n<!-- request Java -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Пример в режиме Plain:\n\n<!-- request CONFIG -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\nПоддержка форм слов в Manticore разработана так, чтобы эффективно работать с большими словарями. Они умеренно влияют на скорость индексации; например, словарь с 1 миллионом записей замедляет полнотекстовую индексацию примерно в 1.5 раза. Скорость поиска вовсе не затрагивается. Дополнительное потребление RAM примерно равно размеру файла словаря, и словари разделяются между таблицами. Например, если тот же самый файл форм слов размером 50 МБ указан для 10 различных таблиц, дополнительное потребление RAM процессом `searchd` будет около 50 МБ.\n\n<!-- example wf_simple -->\n\nФайл словаря должен быть в простом текстовом формате. Каждая строка должна содержать исходную и целевую формы слова в кодировке UTF-8, разделённые символом \"больше\" (>). При загрузке файла будут применены правила из [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Следовательно, если вы не изменяете `charset_table`, ваши формы слов будут нечувствительны к регистру, аналогично другим вашим данным с полнотекстовым индексированием. Ниже приведён пример содержания файла:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\nВ комплекте поставляется утилита под названием [Spelldump](../../Miscellaneous_tools.md#spelldump), которая помогает создавать файл словаря в формате, который понимает Manticore. Утилита может читать исходные `.dict` и `.aff` файлы словарей в формате `ispell` или `MySpell`, используемые в OpenOffice.\n\nВы можете сопоставить нескольким исходным словам одно целевое слово. Процесс происходит на уровне токенов, а не исходного текста, поэтому различия в пробелах и разметке игнорируются.\n\n<!-- example wf_more_complex -->\n\nВы можете использовать символ `=>` вместо `>`. Также разрешены комментарии (начинающиеся с `#`). Наконец, если строка начинается с тильды (`~`), форма слова будет применена после морфологической обработки, а не перед ней (учтите, что в этом случае поддерживается только одна исходная и одна целевая форма слова).\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n<!-- example wf_escaping -->\n\nЕсли необходимо использовать символы `>`, `=` или `~` как обычные символы, их можно экранировать, предваряя обратным слешем (`\\`). Оба символа `>` и `=` должны экранироваться таким образом. Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example wf_multiple_tokens -->\n\nВы можете указать несколько целевых токенов:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n<!-- example wf_multiple_files -->\n\nВы можете указать несколько файлов, а не только один. Можно использовать маски как шаблоны, и все соответствующие файлы будут обработаны в простом порядке возрастания:\n\nВ режиме RT разрешены только абсолютные пути.\n\nЕсли используются многобайтовые кодировки и имена файлов содержат нелатинские символы, итоговый порядок может быть не совсем алфавитным. Если одно и то же определение формы слова найдено в нескольких файлах, используется последнее, которое переопределяет предыдущие.\n\n<!-- request SQL -->\n\nCODE_BLOCK_15\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- request Config -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  }
}
