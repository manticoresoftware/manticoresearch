{
  "1d2cd2f9ea63a5017ff603f26cf760abf4a230e8de8c24e3e98c00acd6eafa4b": {
    "original": "- `SHOW MV view_table`: Shows detailed information on a specific materialized view.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_10\n\n<!-- response -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- response -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### Altering materialized views\n\n<!-- example mv_suspend -->\n\nYou can suspend data consumption by altering materialized views.\n\nIf you remove the `source` without deleting the MV, it automatically suspends. After recreating the source, unsuspend the MV manually using the `ALTER` command.\n\nCurrently, only materialized views can be altered. To change `source` parameters, drop and recreate the source.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### Sharding with Kafka\n\nYou can also specify a `partition_list` for each Kafka topic.\n\nOne of the main benefits of this approach is the ability to implement `sharding` for your table via Kafka.\n\nTo achieve this, you should create a separate chain of `source` → `materialized view` → `destination table` for each shard:\n\n**Sources:**\n\nCODE_BLOCK_20\n\n**Destination Tables:**\n\nCODE_BLOCK_21\n\n**Materialized Views:**\n\nCODE_BLOCK_22\n\n#### ⚠️ Important Notes:\n\n* In this setup, rebalancing must be managed manually.\n\n* Kafka does not distribute messages using a round-robin strategy by default.\n\n* To achieve round-robin-like distribution when sending data, make sure your Kafka producer is configured with:\n\n  * `parse.key=true`\n\n  * `key.separator={your_delimiter}`\n\nOtherwise, Kafka will distribute messages based on its own internal rules, which may lead to uneven partitioning.\n\n### Troubleshooting\n\n#### Duplicate entries\n\nKafka offsets commit after each batch or when processing times out. If the process stops unexpectedly during a materialized view query, you may see duplicate entries. To avoid this, include an `id` field in your schema, allowing Manticore Search to prevent duplicates in the table.\n\n### How it works internally\n\n- **Worker initialization:** After configuring a source and materialized view, Manticore Search sets up a dedicated worker to handle data ingestion from Kafka.\n\n- **Message mapping:** Messages are mapped according to the source configuration schema, transforming them into a structured format.\n\n- **Batching:** Messages are grouped into batches for efficient processing. Batch size can be adjusted to suit your performance and latency needs.\n\n- **Buffering:** Mapped data batches are stored in a buffer table for efficient bulk operations.\n\n- **Materialized view processing:** The view logic is applied to data in the buffer table, performing any transformations or filtering.\n\n- **Data transfer:** Processed data is then transferred to the destination real-time table.\n\n- **Cleanup:** The buffer table is cleared after each batch, ensuring it’s ready for the next set of data.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "- `SHOW MV view_table`：显示特定物化视图的详细信息。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_10\n\n<!-- response -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- response -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### 修改物化视图\n\n<!-- example mv_suspend -->\n\n您可以通过修改物化视图来暂停数据消费。\n\n如果您移除 `source` 而不删除物化视图，它会自动暂停。重新创建源后，需手动使用 `ALTER` 命令取消暂停物化视图。\n\n目前，仅支持修改物化视图。要更改 `source` 参数，请删除并重新创建源。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### 使用 Kafka 进行分片\n\n您还可以为每个 Kafka 主题指定 `partition_list`。\n\n这种方法的主要优点之一是能够通过 Kafka 实现表的 `sharding`（分片）。\n\n为此，您应为每个分片创建一条独立的链：`source` → `materialized view` → `destination table`：\n\n**源：**\n\nCODE_BLOCK_20\n\n**目标表：**\n\nCODE_BLOCK_21\n\n**物化视图：**\n\nCODE_BLOCK_22\n\n#### ⚠️ 重要提示：\n\n* 在此设置中，重新平衡必须手动管理。\n\n* Kafka 默认不使用轮询（round-robin）策略分发消息。\n\n* 若要在发送数据时实现类似轮询的分发，请确保您的 Kafka 生产者配置了：\n\n  * `parse.key=true`\n\n  * `key.separator={your_delimiter}`\n\n否则，Kafka 会根据其内部规则分发消息，可能导致分区不均。\n\n### 故障排除\n\n#### 重复条目\n\nKafka 在每个批次后或处理超时后提交偏移量。如果物化视图查询过程中进程意外停止，可能会出现重复条目。为避免此情况，请在您的模式中包含 `id` 字段，使 Manticore Search 能防止表中出现重复。\n\n### 内部工作原理\n\n- **工作线程初始化：** 配置源和物化视图后，Manticore Search 会设置专用工作线程处理来自 Kafka 的数据摄取。\n\n- **消息映射：** 根据源配置的模式映射消息，将其转换为结构化格式。\n\n- **批处理：** 将消息分组为批次以提高处理效率。批次大小可根据性能和延迟需求调整。\n\n- **缓冲：** 映射后的数据批次存储在缓冲表中，以便高效批量操作。\n\n- **物化视图处理：** 对缓冲表中的数据应用视图逻辑，执行任何转换或过滤。\n\n- **数据传输：** 处理后的数据随后传输到目标实时表。\n\n- **清理：** 每个批次处理后清空缓冲表，确保为下一批数据做好准备。\n\n<!-- proofread -->",
      "russian": "- `SHOW MV view_table`: Показывает подробную информацию о конкретном материализованном представлении.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_10\n\n<!-- response -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_16\n\n<!-- response -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### Изменение материализованных представлений\n\n<!-- example mv_suspend -->\n\nВы можете приостановить потребление данных, изменяя материализованные представления.\n\nЕсли вы удалите `source`, не удаляя MV, оно автоматически приостанавливается. После воссоздания источника снимите приостановку MV вручную с помощью команды `ALTER`.\n\nВ настоящее время можно изменять только материализованные представления. Чтобы изменить параметры `source`, удалите и создайте источник заново.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### Шардинг с Kafka\n\nВы также можете указать `partition_list` для каждой темы Kafka.\n\nОдним из основных преимуществ такого подхода является возможность реализовать `sharding` для вашей таблицы через Kafka.\n\nДля этого следует создать отдельную цепочку `source` → `materialized view` → `destination table` для каждого шарда:\n\n**Источники:**\n\nCODE_BLOCK_20\n\n**Таблицы назначения:**\n\nCODE_BLOCK_21\n\n**Материализованные представления:**\n\nCODE_BLOCK_22\n\n#### ⚠️ Важные замечания:\n\n* В этой конфигурации ребалансировка должна управляться вручную.\n\n* По умолчанию Kafka не распределяет сообщения по принципу round-robin.\n\n* Чтобы добиться распределения, похожего на round-robin при отправке данных, убедитесь, что ваш Kafka producer настроен с:\n\n  * `parse.key=true`\n\n  * `key.separator={your_delimiter}`\n\nВ противном случае Kafka будет распределять сообщения согласно своим внутренним правилам, что может привести к неравномерному распределению по партициям.\n\n### Устранение неполадок\n\n#### Дублирование записей\n\nКоммиты смещений Kafka происходят после каждой партии или при истечении времени обработки. Если процесс неожиданно остановится во время запроса к материализованному представлению, вы можете увидеть дублирующиеся записи. Чтобы этого избежать, включите поле `id` в вашу схему, что позволит Manticore Search предотвращать дублирование в таблице.\n\n### Как это работает внутри\n\n- **Инициализация воркера:** После настройки источника и материализованного представления Manticore Search запускает выделенного воркера для обработки данных из Kafka.\n\n- **Отображение сообщений:** Сообщения сопоставляются согласно схеме конфигурации источника, преобразуясь в структурированный формат.\n\n- **Группировка:** Сообщения группируются в партии для эффективной обработки. Размер партии можно настроить под ваши требования по производительности и задержке.\n\n- **Буферизация:** Партии отображенных данных сохраняются в буферной таблице для эффективных пакетных операций.\n\n- **Обработка материализованного представления:** Логика представления применяется к данным в буферной таблице, выполняя необходимые преобразования или фильтрацию.\n\n- **Передача данных:** Обработанные данные затем передаются в целевую таблицу реального времени.\n\n- **Очистка:** Буферная таблица очищается после каждой партии, чтобы быть готовой к следующему набору данных.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "c11c6312239e832d0b9651d8584a6515a644a76c2414712a30e94f9a7c5528ab": {
    "original": "# Syncing from Kafka\n\n> NOTE: this functionality requires [Manticore Buddy](../Installation/Manticore_Buddy.md). If it doesn't work, make sure Buddy is installed.\n\nManticore supports integration with [Apache Kafka](https://kafka.apache.org/) real-time data ingestion through Kafka sources and materialized views, allowing for real-time data indexing and search. Currently, **apache/kafka versions 3.7.0-4.1.0** are tested and supported.\n\nTo get started, you need to:\n\n1. **Define the source:** Specify the Kafka topic from which Manticore Search will read messages. This setup includes details like the broker’s host, port, and topic name.\n\n2. **Set up the destination table:** Choose a Manticore real-time table to store the incoming Kafka data.\n\n3. **Create a materialized view:** Set up a materialized view (`mv`) to handle data transformation and mapping from Kafka to the destination table in Manticore Search. Here, you’ll define field mappings, data transformations, and any filters or conditions for the incoming data stream.\n\n## Source\n\n<!-- example kafka_source -->\n\nThe `source` configuration allows you to define the `broker`, `topic list`, `consumer group`, and the message structure.\n\n#### Schema\n\nDefine the schema using Manticore field types like `int`, `float`, `text`, `json`, etc.\n\nCODE_BLOCK_0\n\nAll schema keys are case-insensitive, meaning `Products`, `products`, and `PrOdUcTs` are treated the same. They are all converted to lowercase.\n\nIf your field names don't match the [field name syntax](../Creating_a_table/Data_types.md#Field-name-syntax) allowed in Manticore Search (for example, if they contain special characters or start with numbers), you must define a schema mapping. For instance, `$keyName` or `123field` are valid keys in JSON but not valid field names in Manticore Search. If you try to use invalid field names without proper mapping, Manticore will return an error and the source creation will fail.\n\nTo handle such cases, use the following schema syntax to map invalid field names to valid ones:\n\nCODE_BLOCK_1\n\nFor example:\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n#### Options\n\n| Option | Accepted Values | Description                                                                                                         |\n\n|-|----------------|---------------------------------------------------------------------------------------------------------------------|\n\n| `type` | `kafka`        | Sets the source type. Currently, only `kafka` is supported                                                          |\n\n| `broker_list` | `host:port [, ...]` | Specifies Kafka broker URLs                                                                                         |\n\n| `topic_list` | `string [, ...]` | Lists Kafka topics to consume from                                                                                  |\n\n| `consumer_group`| `string`       | Defines the Kafka consumer group, defaulting to `manticore`.                                                        |\n\n| `num_consumers` | `int`          | Number of consumers to handle messages.                                                                             |\n\n| `partition_list` | `int [, ...]`  | List of partitions for reading [more](../Integration/Kafka.md#Sharding-with-Kafka).                                 |\n\n| `batch` | `int`          | Number of messages to process before moving on. Default is `100`; processes remaining messages on timeout otherwise |\n\n### Destination table\n\n<!-- example kafka_destination -->\n\nThe destination table is a regular real-time table where the results of Kafka message processing are stored. This table should be defined to match the schema requirements of the incoming data and optimized for the query performance needs of your application. Read more about creating real-time tables [here](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_5\n\n<!-- response -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### Materialized view\n\n<!-- example kafka_mv -->\n\nA materialized view enables data transformation from Kafka messages. You can rename fields, apply Manticore Search functions, and perform sorting, grouping, and other data operations.\n\nA materialized view acts as a query that moves data from the Kafka source to the destination table, letting you use Manticore Search syntax to customize these queries. Make sure that fields in the `select` match those in the source.\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_8\n\n<!-- response -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\nData is transferred from Kafka to Manticore Search in batches, which are cleared after each run. For calculations across batches, such as AVG, use caution, as these may not work as expected due to batch-by-batch processing.\n\n### Field Mapping\n\nHere's a mapping table based on the examples above:\n\n| Kafka           | Source   | Buffer   | MV                                | Destination |\n\n|-----------------|----------|----------|-----------------------------------|-------------|\n\n| `id`              | `id`       | `id`       | `id`                                | `id`          |\n\n| `term`            | `term`     | `term`     | `term as name`                      | `name`        |\n\n| `unnecessary_key` which we're not interested in | -        | -        |                                   |             |\n\n| `$abbrev`         | `abbrev`   | `abbrev`   | `abbrev` as `short_name`              | `short_name`  |\n\n| -                 | -        | -         | `UTC_TIMESTAMP() as received_at`  | `received_at` |\n\n| `GlossDef`        | `glossdef` | `glossdef` | `glossdef.size as size`             | `size`        |\n\n### Listing\n\n<!-- example kafka_listing -->\n\nTo view sources and materialized views in Manticore Search, use these commands:\n\n- `SHOW SOURCES`: Lists all configured sources.\n\n- `SHOW MVS`: Lists all materialized views.",
    "translations": {
      "chinese": "# 从 Kafka 同步\n\n> 注意：此功能需要 [Manticore Buddy](../Installation/Manticore_Buddy.md)。如果无法使用，请确保已安装 Buddy。\n\nManticore 支持通过 Kafka 源和物化视图与 [Apache Kafka](https://kafka.apache.org/) 实时数据摄取集成，实现实时数据索引和搜索。目前，**apache/kafka 版本 3.7.0-4.1.0** 已测试并支持。\n\n开始之前，您需要：\n\n1. **定义源：** 指定 Manticore Search 将读取消息的 Kafka 主题。此设置包括代理的主机、端口和主题名称等详细信息。\n\n2. **设置目标表：** 选择一个 Manticore 实时表来存储传入的 Kafka 数据。\n\n3. **创建物化视图：** 设置物化视图（`mv`）以处理从 Kafka 到 Manticore Search 目标表的数据转换和映射。在这里，您将定义字段映射、数据转换以及传入数据流的任何过滤器或条件。\n\n## 源\n\n<!-- example kafka_source -->\n\n`source` 配置允许您定义 `broker`、`topic list`、`consumer group` 以及消息结构。\n\n#### 架构\n\n使用 Manticore 字段类型定义架构，如 `int`、`float`、`text`、`json` 等。\n\nCODE_BLOCK_0\n\n所有架构键不区分大小写，意味着 `Products`、`products` 和 `PrOdUcTs` 被视为相同。它们都会被转换为小写。\n\n如果您的字段名不符合 Manticore Search 允许的 [字段名语法](../Creating_a_table/Data_types.md#Field-name-syntax)（例如，包含特殊字符或以数字开头），则必须定义架构映射。例如，`$keyName` 或 `123field` 在 JSON 中是有效键，但在 Manticore Search 中不是有效字段名。如果尝试使用无效字段名且未正确映射，Manticore 会返回错误，且源创建将失败。\n\n为处理此类情况，请使用以下架构语法将无效字段名映射为有效字段名：\n\nCODE_BLOCK_1\n\n例如：\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n#### 选项\n\n| 选项             | 可接受的值           | 描述                                                                                                               |\n\n|-|----------------|---------------------------------------------------------------------------------------------------------------------|\n\n| `type`          | `kafka`            | 设置源类型。目前仅支持 `kafka`                                                                                      |\n\n| `broker_list`   | `host:port [, ...]` | 指定 Kafka 代理 URL                                                                                                  |\n\n| `topic_list`    | `string [, ...]`    | 列出要消费的 Kafka 主题                                                                                              |\n\n| `consumer_group`| `string`           | 定义 Kafka 消费者组，默认为 `manticore`。                                                                             |\n\n| `num_consumers` | `int`              | 处理消息的消费者数量。                                                                                                |\n\n| `partition_list`| `int [, ...]`      | 读取的分区列表，[更多信息](../Integration/Kafka.md#Sharding-with-Kafka)。                                             |\n\n| `batch`         | `int`              | 处理多少条消息后继续。默认是 `100`；超时则处理剩余消息。                                                               |\n\n### 目标表\n\n<!-- example kafka_destination -->\n\n目标表是一个常规的实时表，用于存储 Kafka 消息处理的结果。该表应定义以匹配传入数据的架构要求，并针对应用程序的查询性能需求进行优化。有关创建实时表的更多信息，请参阅[这里](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:)。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_5\n\n<!-- response -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### 物化视图\n\n<!-- example kafka_mv -->\n\n物化视图支持对 Kafka 消息进行数据转换。您可以重命名字段，应用 Manticore Search 函数，并执行排序、分组及其他数据操作。\n\n物化视图充当一个查询，将数据从 Kafka 源移动到目标表，允许您使用 Manticore Search 语法自定义这些查询。确保 `select` 中的字段与源中的字段匹配。\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_8\n\n<!-- response -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n数据以批次方式从 Kafka 传输到 Manticore Search，每次运行后批次被清空。对于跨批次的计算（如 AVG），请谨慎使用，因为批次处理可能导致结果不符合预期。\n\n### 字段映射\n\n以下是基于上述示例的映射表：\n\n| Kafka           | 源       | 缓冲区   | 物化视图                          | 目标表       |\n\n|-----------------|----------|----------|-----------------------------------|-------------|\n\n| `id`            | `id`     | `id`     | `id`                              | `id`        |\n\n| `term`          | `term`   | `term`   | `term as name`                    | `name`      |\n\n| `unnecessary_key`（我们不感兴趣的） | -        | -        |                                   |             |\n\n| `$abbrev`       | `abbrev` | `abbrev` | `abbrev` as `short_name`          | `short_name`|\n\n| -               | -        | -        | `UTC_TIMESTAMP() as received_at` | `received_at`|\n\n| `GlossDef`      | `glossdef`| `glossdef`| `glossdef.size as size`           | `size`      |\n\n### 列表\n\n<!-- example kafka_listing -->\n\n要查看 Manticore Search 中的源和物化视图，请使用以下命令：\n\n- `SHOW SOURCES`：列出所有配置的源。\n\n- `SHOW MVS`：列出所有物化视图。",
      "russian": "# Синхронизация из Kafka\n\n> ПРИМЕЧАНИЕ: эта функциональность требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если не работает, убедитесь, что Buddy установлен.\n\nManticore поддерживает интеграцию с [Apache Kafka](https://kafka.apache.org/) для потокового приема данных в реальном времени через источники Kafka и материализованные представления, что позволяет индексировать и искать данные в реальном времени. В настоящее время поддерживаются и протестированы версии **apache/kafka 3.7.0-4.1.0**.\n\nЧтобы начать, необходимо:\n\n1. **Определить источник:** Указать тему Kafka, из которой Manticore Search будет читать сообщения. Эта настройка включает детали, такие как хост брокера, порт и имя темы.\n\n2. **Настроить таблицу назначения:** Выбрать таблицу реального времени Manticore для хранения входящих данных из Kafka.\n\n3. **Создать материализованное представление:** Настроить материализованное представление (`mv`) для обработки преобразования данных и сопоставления из Kafka в таблицу назначения Manticore Search. Здесь вы определите сопоставления полей, преобразования данных и любые фильтры или условия для входящего потока данных.\n\n## Источник\n\n<!-- example kafka_source -->\n\nКонфигурация `source` позволяет определить `broker`, `topic list`, `consumer group` и структуру сообщений.\n\n#### Схема\n\nОпределите схему, используя типы полей Manticore, такие как `int`, `float`, `text`, `json` и т.д.\n\nCODE_BLOCK_0\n\nВсе ключи схемы нечувствительны к регистру, то есть `Products`, `products` и `PrOdUcTs` считаются одинаковыми. Все они преобразуются в нижний регистр.\n\nЕсли имена ваших полей не соответствуют [синтаксису имен полей](../Creating_a_table/Data_types.md#Field-name-syntax), разрешенному в Manticore Search (например, содержат специальные символы или начинаются с цифр), необходимо определить сопоставление схемы. Например, `$keyName` или `123field` являются допустимыми ключами в JSON, но недопустимыми именами полей в Manticore Search. Если попытаться использовать недопустимые имена полей без правильного сопоставления, Manticore вернет ошибку, и создание источника не удастся.\n\nДля таких случаев используйте следующий синтаксис схемы для сопоставления недопустимых имен полей с допустимыми:\n\nCODE_BLOCK_1\n\nНапример:\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n#### Опции\n\n| Опция | Допустимые значения | Описание                                                                                                         |\n\n|-|----------------|---------------------------------------------------------------------------------------------------------------------|\n\n| `type` | `kafka`        | Устанавливает тип источника. В настоящее время поддерживается только `kafka`                                       |\n\n| `broker_list` | `host:port [, ...]` | Указывает URL брокеров Kafka                                                                                         |\n\n| `topic_list` | `string [, ...]` | Список тем Kafka для потребления                                                                                  |\n\n| `consumer_group`| `string`       | Определяет группу потребителей Kafka, по умолчанию `manticore`.                                                        |\n\n| `num_consumers` | `int`          | Количество потребителей для обработки сообщений.                                                                             |\n\n| `partition_list` | `int [, ...]`  | Список партиций для чтения [подробнее](../Integration/Kafka.md#Sharding-with-Kafka).                                 |\n\n| `batch` | `int`          | Количество сообщений для обработки перед переходом к следующей партии. По умолчанию `100`; в противном случае обрабатывает оставшиеся сообщения по таймауту |\n\n### Таблица назначения\n\n<!-- example kafka_destination -->\n\nТаблица назначения — это обычная таблица реального времени, в которой хранятся результаты обработки сообщений Kafka. Эта таблица должна быть определена в соответствии с требованиями схемы входящих данных и оптимизирована для производительности запросов вашего приложения. Подробнее о создании таблиц реального времени читайте [здесь](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_5\n\n<!-- response -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### Материализованное представление\n\n<!-- example kafka_mv -->\n\nМатериализованное представление позволяет преобразовывать данные из сообщений Kafka. Вы можете переименовывать поля, применять функции Manticore Search, выполнять сортировку, группировку и другие операции с данными.\n\nМатериализованное представление действует как запрос, который перемещает данные из источника Kafka в таблицу назначения, позволяя использовать синтаксис Manticore Search для настройки этих запросов. Убедитесь, что поля в `select` соответствуют полям источника.\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_8\n\n<!-- response -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\nДанные передаются из Kafka в Manticore Search партиями, которые очищаются после каждого запуска. Для вычислений по партиям, таких как AVG, будьте осторожны, так как они могут работать не так, как ожидается, из-за обработки по партиям.\n\n### Сопоставление полей\n\nВот таблица сопоставления на основе приведенных выше примеров:\n\n| Kafka           | Источник   | Буфер   | MV                                | Назначение |\n\n|-----------------|----------|----------|-----------------------------------|-------------|\n\n| `id`              | `id`       | `id`       | `id`                                | `id`          |\n\n| `term`            | `term`     | `term`     | `term as name`                      | `name`        |\n\n| `unnecessary_key`, который нас не интересует | -        | -        |                                   |             |\n\n| `$abbrev`         | `abbrev`   | `abbrev`   | `abbrev` as `short_name`              | `short_name`  |\n\n| -                 | -        | -         | `UTC_TIMESTAMP() as received_at`  | `received_at` |\n\n| `GlossDef`        | `glossdef` | `glossdef` | `glossdef.size as size`             | `size`        |\n\n### Просмотр\n\n<!-- example kafka_listing -->\n\nДля просмотра источников и материализованных представлений в Manticore Search используйте следующие команды:\n\n- `SHOW SOURCES`: Показывает все настроенные источники.\n\n- `SHOW MVS`: Показывает все материализованные представления."
    },
    "is_code_or_comment": false
  },
  "e1a969fb51a2307b53d91860383356a82a6575161987edf521972f8f17727906": {
    "original": "To view sources and materialized views in Manticore Search, use these commands:\n\n- `SHOW SOURCES`: Lists all configured sources.\n\n- `SHOW MVS`: Lists all materialized views.\n\n- `SHOW MV view_table`: Shows detailed information on a specific materialized view.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- response JSON -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_20\n\n<!-- response JSON -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_22\n\n<!-- response -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_24\n\n<!-- response JSON -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_26\n\n<!-- response -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_28\n\n<!-- response JSON -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### Altering materialized views\n\n<!-- example mv_suspend -->\n\nYou can suspend data consumption by altering materialized views.\n\nIf you remove the `source` without deleting the MV, it automatically suspends. After recreating the source, unsuspend the MV manually using the `ALTER` command.\n\nCurrently, only materialized views can be altered. To change `source` parameters, drop and recreate the source.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_30\n\n<!-- response -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_32\n\n<!-- response JSON -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### Sharding with Kafka\n\nYou can also specify a `partition_list` for each Kafka topic.\n\nOne of the main benefits of this approach is the ability to implement `sharding` for your table via Kafka.\n\nTo achieve this, you should create a separate chain of `source` → `materialized view` → `destination table` for each shard:\n\n**Sources:**\n\nCODE_BLOCK_34\n\n**Destination Tables:**\n\nCODE_BLOCK_35\n\n**Materialized Views:**\n\nCODE_BLOCK_36\n\n#### ⚠️ Important Notes:\n\n* In this setup, rebalancing must be managed manually.\n\n* Kafka does not distribute messages using a round-robin strategy by default.\n\n* To achieve round-robin-like distribution when sending data, make sure your Kafka producer is configured with:\n\n  * `parse.key=true`\n\n  * `key.separator={your_delimiter}`\n\nOtherwise, Kafka will distribute messages based on its own internal rules, which may lead to uneven partitioning.\n\n### Troubleshooting\n\n#### Duplicate entries\n\nKafka offsets commit after each batch or when processing times out. If the process stops unexpectedly during a materialized view query, you may see duplicate entries. To avoid this, include an `id` field in your schema, allowing Manticore Search to prevent duplicates in the table.\n\n### How it works internally\n\n- **Worker initialization:** After configuring a source and materialized view, Manticore Search sets up a dedicated worker to handle data ingestion from Kafka.\n\n- **Message mapping:** Messages are mapped according to the source configuration schema, transforming them into a structured format.\n\n- **Batching:** Messages are grouped into batches for efficient processing. Batch size can be adjusted to suit your performance and latency needs.\n\n- **Buffering:** Mapped data batches are stored in a buffer table for efficient bulk operations.\n\n- **Materialized view processing:** The view logic is applied to data in the buffer table, performing any transformations or filtering.\n\n- **Data transfer:** Processed data is then transferred to the destination real-time table.\n\n- **Cleanup:** The buffer table is cleared after each batch, ensuring it’s ready for the next set of data.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "要查看 Manticore Search 中的源和物化视图，请使用以下命令：\n\n- `SHOW SOURCES`：列出所有配置的源。\n\n- `SHOW MVS`：列出所有物化视图。\n\n- `SHOW MV view_table`：显示特定物化视图的详细信息。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- response JSON -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_20\n\n<!-- response JSON -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_22\n\n<!-- response -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_24\n\n<!-- response JSON -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_26\n\n<!-- response -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_28\n\n<!-- response JSON -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### 修改物化视图\n\n<!-- example mv_suspend -->\n\n您可以通过修改物化视图来暂停数据消费。\n\n如果移除 `source` 但不删除 MV，则会自动暂停。重新创建源后，需手动使用 `ALTER` 命令取消暂停 MV。\n\n当前只支持修改物化视图。要更改 `source` 参数，请删除并重新创建源。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_30\n\n<!-- response -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_32\n\n<!-- response JSON -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### 使用 Kafka 进行分片\n\n您还可以为每个 Kafka 主题指定 `partition_list`。\n\n此方法的主要优点之一是能够通过 Kafka 实现表的 `sharding`（分片）。\n\n为实现这一点，应为每个分片创建一条独立的 `source` → `materialized view` → `destination table` 链：\n\n**源：**\n\nCODE_BLOCK_34\n\n**目标表：**\n\nCODE_BLOCK_35\n\n**物化视图：**\n\nCODE_BLOCK_36\n\n#### ⚠️ 重要提示：\n\n* 在此设置中，分区重新平衡必须手动管理。\n\n* Kafka 默认不使用轮询策略分发消息。\n\n* 若要实现类似轮询的消息分发，确保 Kafka 生产者配置为：\n\n  * `parse.key=true`\n\n  * `key.separator={your_delimiter}`\n\n否则，Kafka 将依据其内部规则分发消息，可能导致分区不均匀。\n\n### 故障排查\n\n#### 重复条目\n\nKafka 在每批处理后或处理超时后提交偏移量。如果物化视图查询过程中进程意外停止，可能会出现重复条目。为避免此情况，在模式中包含 `id` 字段，可让 Manticore Search 在表中防止重复。\n\n### 内部工作原理\n\n- **工作线程初始化：** 配置源和物化视图后，Manticore Search 会设置专用工作线程处理来自 Kafka 的数据摄取。\n\n- **消息映射：** 根据源配置方案映射消息，将其转换为结构化格式。\n\n- **批处理：** 将消息分组为批次以提高处理效率。批次大小可根据性能和延迟需求调整。\n\n- **缓冲：** 映射后的数据批次存储在缓冲表中，以便高效批量操作。\n\n- **物化视图处理：** 对缓冲表中的数据应用视图逻辑，执行任何转换或过滤。\n\n- **数据转移：** 处理后的数据随后传输到目标的实时表。\n\n- **清理：** 每批处理后清空缓冲表，确保为下一批数据做好准备。\n\n<!-- proofread -->",
      "russian": "Чтобы просматривать источники и материализованные представления в Manticore Search, используйте следующие команды:\n\n- `SHOW SOURCES`: Отображает все настроенные источники.\n\n- `SHOW MVS`: Отображает все материализованные представления.\n\n- `SHOW MV view_table`: Показывает подробную информацию по конкретному материализованному представлению.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_14\n\n<!-- response -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- response JSON -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n<!-- example kafka_create_source -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_18\n\n<!-- response -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_20\n\n<!-- response JSON -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n<!-- example kafka_view -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_22\n\n<!-- response -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_24\n\n<!-- response JSON -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n<!-- example kafka_show -->\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_26\n\n<!-- response -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_28\n\n<!-- response JSON -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### Изменение материализованных представлений\n\n<!-- example mv_suspend -->\n\nВы можете приостанавливать потребление данных, изменяя материализованные представления.\n\nЕсли вы удаляете `source`, не удаляя при этом materialized view, оно автоматически приостанавливается. После воссоздания источника, снимите приостановку MV вручную с помощью команды `ALTER`.\n\nВ настоящее время можно изменять только материализованные представления. Чтобы изменить параметры `source`, удалите и создайте источник заново.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_30\n\n<!-- response -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_32\n\n<!-- response JSON -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### Шардинг с Kafka\n\nВы также можете указать `partition_list` для каждой темы Kafka.\n\nОдним из главных преимуществ такого подхода является возможность реализовать `sharding` для вашей таблицы через Kafka.\n\nДля этого следует создать отдельную цепочку `source` → `materialized view` → `destination table` для каждого шарда:\n\n**Источники:**\n\nCODE_BLOCK_34\n\n**Целевые таблицы:**\n\nCODE_BLOCK_35\n\n**Материализованные представления:**\n\nCODE_BLOCK_36\n\n#### ⚠️ Важные замечания:\n\n* В этой конфигурации балансировку нагрузки необходимо управлять вручную.\n\n* По умолчанию Kafka не распределяет сообщения по принципу round-robin.\n\n* Чтобы добиться распределения, похожего на round-robin, при отправке данных, убедитесь, что ваш Kafka producer настроен с:\n\n  * `parse.key=true`\n\n  * `key.separator={ваш_разделитель}`\n\nИначе Kafka будет распределять сообщения согласно своим внутренним правилам, что может привести к неравномерному разбиению на партиции.\n\n### Устранение неполадок\n\n#### Дублирование записей\n\nКоммиты оффсетов Kafka происходят после каждой партии или при тайм-ауте обработки. Если процесс прерывается неожиданно во время запроса к материализованному представлению, могут появиться дублированные записи. Чтобы избежать этого, включите поле `id` в схему, что позволит Manticore Search предотвращать дубликаты в таблице.\n\n### Как это работает внутри\n\n- **Инициализация воркера:** После настройки источника и материализованного представления, Manticore Search запускает выделенного воркера для обработки данных из Kafka.\n\n- **Отображение сообщений:** Сообщения сопоставляются согласно схеме источника, преобразуясь в структурированный формат.\n\n- **Группировка:** Сообщения объединяются в партии для эффективной обработки. Размер партии можно настроить под ваши требования к производительности и задержке.\n\n- **Буферизация:** Партии данных сохраняются в буферной таблице для эффективных пакетных операций.\n\n- **Обработка материализованного представления:** Логика представления применяется к данным в буферной таблице, выполняя любые преобразования или фильтрацию.\n\n- **Передача данных:** Обработанные данные затем передаются в целевую таблицу в режиме реального времени.\n\n- **Очистка:** После каждой партии буферная таблица очищается, чтобы быть готовой к следующему набору данных.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "e19a362500323f062a7554f5242193684ea99de76e521ed1ecd417d3f8d15419": {
    "original": "# Syncing from Kafka\n\n> NOTE: this functionality requires [Manticore Buddy](../Installation/Manticore_Buddy.md). If it doesn't work, make sure Buddy is installed.\n\nManticore supports integration with [Apache Kafka](https://kafka.apache.org/) real-time data ingestion through Kafka sources and materialized views, allowing for real-time data indexing and search. Currently, **apache/kafka versions 3.7.0-4.1.0** are tested and supported.\n\nTo get started, you need to:\n\n1. **Define the source:** Specify the Kafka topic from which Manticore Search will read messages. This setup includes details like the broker’s host, port, and topic name.\n\n2. **Set up the destination table:** Choose a Manticore real-time table to store the incoming Kafka data.\n\n3. **Create a materialized view:** Set up a materialized view (`mv`) to handle data transformation and mapping from Kafka to the destination table in Manticore Search. Here, you’ll define field mappings, data transformations, and any filters or conditions for the incoming data stream.\n\n## Source\n\n<!-- example kafka_source -->\n\nThe `source` configuration allows you to define the `broker`, `topic list`, `consumer group`, and the message structure.\n\n#### Schema\n\nDefine the schema using Manticore field types like `int`, `float`, `text`, `json`, etc.\n\nCODE_BLOCK_0\n\nAll schema keys are case-insensitive, meaning `Products`, `products`, and `PrOdUcTs` are treated the same. They are all converted to lowercase.\n\nIf your field names don't match the [field name syntax](../Creating_a_table/Data_types.md#Field-name-syntax) allowed in Manticore Search (for example, if they contain special characters or start with numbers), you must define a schema mapping. For instance, `$keyName` or `123field` are valid keys in JSON but not valid field names in Manticore Search. If you try to use invalid field names without proper mapping, Manticore will return an error and the source creation will fail.\n\nTo handle such cases, use the following schema syntax to map invalid field names to valid ones:\n\nCODE_BLOCK_1\n\nFor example:\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_5\n\n<!-- response JSON -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n#### Options\n\n| Option | Accepted Values | Description                                                                                                         |\n\n|-|----------------|---------------------------------------------------------------------------------------------------------------------|\n\n| `type` | `kafka`        | Sets the source type. Currently, only `kafka` is supported                                                          |\n\n| `broker_list` | `host:port [, ...]` | Specifies Kafka broker URLs                                                                                         |\n\n| `topic_list` | `string [, ...]` | Lists Kafka topics to consume from                                                                                  |\n\n| `consumer_group`| `string`       | Defines the Kafka consumer group, defaulting to `manticore`.                                                        |\n\n| `num_consumers` | `int`          | Number of consumers to handle messages.                                                                             |\n\n| `partition_list` | `int [, ...]`  | List of partitions for reading [more](../Integration/Kafka.md#Sharding-with-Kafka).                                 |\n\n| `batch` | `int`          | Number of messages to process before moving on. Default is `100`; processes remaining messages on timeout otherwise |\n\n### Destination table\n\n<!-- example kafka_destination -->\n\nThe destination table is a regular real-time table where the results of Kafka message processing are stored. This table should be defined to match the schema requirements of the incoming data and optimized for the query performance needs of your application. Read more about creating real-time tables [here](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_7\n\n<!-- response -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_9\n\n<!-- response JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### Materialized view\n\n<!-- example kafka_mv -->\n\nA materialized view enables data transformation from Kafka messages. You can rename fields, apply Manticore Search functions, and perform sorting, grouping, and other data operations.\n\nA materialized view acts as a query that moves data from the Kafka source to the destination table, letting you use Manticore Search syntax to customize these queries. Make sure that fields in the `select` match those in the source.\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\nData is transferred from Kafka to Manticore Search in batches, which are cleared after each run. For calculations across batches, such as AVG, use caution, as these may not work as expected due to batch-by-batch processing.\n\n### Field Mapping\n\nHere's a mapping table based on the examples above:\n\n| Kafka           | Source   | Buffer   | MV                                | Destination |\n\n|-----------------|----------|----------|-----------------------------------|-------------|\n\n| `id`              | `id`       | `id`       | `id`                                | `id`          |\n\n| `term`            | `term`     | `term`     | `term as name`                      | `name`        |\n\n| `unnecessary_key` which we're not interested in | -        | -        |                                   |             |\n\n| `$abbrev`         | `abbrev`   | `abbrev`   | `abbrev` as `short_name`              | `short_name`  |\n\n| -                 | -        | -         | `UTC_TIMESTAMP() as received_at`  | `received_at` |\n\n| `GlossDef`        | `glossdef` | `glossdef` | `glossdef.size as size`             | `size`        |\n\n### Listing\n\n<!-- example kafka_listing -->",
    "translations": {
      "chinese": "# 从 Kafka 同步\n\n> 注意：此功能需要 [Manticore Buddy](../Installation/Manticore_Buddy.md)。如果无法使用，请确保已安装 Buddy。\n\nManticore 支持通过 Kafka 源和物化视图与 [Apache Kafka](https://kafka.apache.org/) 实时数据摄取集成，实现实时数据索引和搜索。目前，**apache/kafka 版本 3.7.0-4.1.0** 已测试并支持。\n\n入门步骤：\n\n1. **定义源：** 指定 Manticore Search 将读取消息的 Kafka 主题。此设置包括代理的主机、端口和主题名称等详细信息。\n\n2. **设置目标表：** 选择一个 Manticore 实时表用于存储传入的 Kafka 数据。\n\n3. **创建物化视图：** 设置物化视图（`mv`），用于处理从 Kafka 到 Manticore Search 目标表的数据转换和映射。在这里，您将定义字段映射、数据转换以及任何传入数据流的过滤或条件。\n\n## 源\n\n<!-- example kafka_source -->\n\n`source` 配置允许您定义 `broker`、`topic list`、`consumer group` 和消息结构。\n\n#### 模式\n\n使用 Manticore 字段类型如 `int`、`float`、`text`、`json` 等定义模式。\n\nCODE_BLOCK_0\n\n所有模式键不区分大小写，即 `Products`、`products` 和 `PrOdUcTs` 视为相同，都会转换为小写。\n\n如果您的字段名称不符合 Manticore Search 允许的 [字段名称语法](../Creating_a_table/Data_types.md#Field-name-syntax)（例如包含特殊字符或以数字开头），必须定义一个模式映射。例如，`$keyName` 或 `123field` 在 JSON 中是有效键，但在 Manticore Search 中不是有效字段名。如果尝试使用无效字段名称且没有正确映射，Manticore 将返回错误，源创建将失败。\n\n针对这种情况，使用以下模式语法将无效字段名称映射到有效字段：\n\nCODE_BLOCK_1\n\n例如：\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_5\n\n<!-- response JSON -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n#### 选项\n\n| 选项             | 可接受的值         | 描述                                                                                                           |\n\n|-----------------|-------------------|-----------------------------------------------------------------------------------------------------------------|\n\n| `type`          | `kafka`           | 设置源类型。目前，仅支持 `kafka`                                                                               |\n\n| `broker_list`   | `host:port [, ...]` | 指定 Kafka 代理 URL                                                                                              |\n\n| `topic_list`    | `string [, ...]`  | 列出要消费的 Kafka 主题                                                                                          |\n\n| `consumer_group`| `string`          | 定义 Kafka 消费者组，默认为 `manticore`                                                                          |\n\n| `num_consumers` | `int`             | 处理消息的消费者数量                                                                                              |\n\n| `partition_list`| `int [, ...]`     | 指定读取的分区列表 [详情](../Integration/Kafka.md#Sharding-with-Kafka)                                          |\n\n| `batch`         | `int`             | 处理的消息数目，达到该数量后继续。默认是 `100`；否则超时处理剩余消息                                            |\n\n### 目标表\n\n<!-- example kafka_destination -->\n\n目标表是一个常规的实时表，用于存储 Kafka 消息处理结果。该表应定义以符合传入数据的模式需求，并优化应用程序的查询性能。更多关于创建实时表请见 [这里](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:)。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_7\n\n<!-- response -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_9\n\n<!-- response JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### 物化视图\n\n<!-- example kafka_mv -->\n\n物化视图允许对 Kafka 消息进行数据转换。您可以重命名字段、应用 Manticore Search 函数，执行排序、分组及其他数据操作。\n\n物化视图作为一个查询，将数据从 Kafka 源移动到目标表，允许您使用 Manticore Search 语法自定义这些查询。请确保 `select` 中的字段与源中的匹配。\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n数据以批量方式从 Kafka 传输到 Manticore Search，每次运行后清空该批次。对于跨批次计算（如 AVG），请谨慎使用，因为批次处理可能导致结果不符合预期。\n\n### 字段映射\n\n根据以上示例，映射表如下：\n\n| Kafka               | Source    | Buffer    | MV                                  | Destination   |\n\n|---------------------|-----------|-----------|------------------------------------|---------------|\n\n| `id`                | `id`      | `id`      | `id`                               | `id`          |\n\n| `term`              | `term`    | `term`    | `term as name`                     | `name`        |\n\n| `unnecessary_key`（我们不感兴趣的） | -         | -         |                                    |               |\n\n| `$abbrev`           | `abbrev`  | `abbrev`  | `abbrev` as `short_name`           | `short_name`  |\n\n| -                   | -         | -         | `UTC_TIMESTAMP() as received_at`  | `received_at` |\n\n| `GlossDef`          | `glossdef`| `glossdef`| `glossdef.size as size`             | `size`        |\n\n### 列表\n\n<!-- example kafka_listing -->",
      "russian": "# Синхронизация из Kafka\n\n> ПРИМЕЧАНИЕ: эта функциональность требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если она не работает, убедитесь, что Buddy установлен.\n\nManticore поддерживает интеграцию с [Apache Kafka](https://kafka.apache.org/) для потокового приема данных в реальном времени через источники Kafka и материализованные представления, позволяя индексировать и искать данные в режиме реального времени. В настоящее время поддерживаются и протестированы версии **apache/kafka 3.7.0-4.1.0**.\n\nДля начала работы нужно:\n\n1. **Определить источник:** Указать тему Kafka, из которой Manticore Search будет читать сообщения. Эта настройка включает такие детали, как хост брокера, порт и имя темы.\n\n2. **Настроить целевую таблицу:** Выбрать таблицу реального времени Manticore для хранения поступающих данных из Kafka.\n\n3. **Создать материализованное представление:** Настроить материализованное представление (`mv`) для обработки преобразования данных и их сопоставления из Kafka в целевую таблицу в Manticore Search. Здесь вы определяете сопоставления полей, преобразования данных и любые фильтры или условия для входящего потока данных.\n\n## Источник\n\n<!-- example kafka_source -->\n\nКонфигурация `source` позволяет определить `broker`, `list/topic`, `consumer group` и структуру сообщений.\n\n#### Схема\n\nОпределите схему, используя типы полей Manticore, такие как `int`, `float`, `text`, `json` и др.\n\nCODE_BLOCK_0\n\nВсе ключи схемы не чувствительны к регистру, то есть `Products`, `products` и `PrOdUcTs` считаются одинаковыми. Все они приводятся к нижнему регистру.\n\nЕсли имена полей не соответствуют [синтаксису имен полей](../Creating_a_table/Data_types.md#Field-name-syntax), допускаемому в Manticore Search (например, если они содержат специальные символы или начинаются с цифр), необходимо определить сопоставление схемы. Например, `$keyName` или `123field` — допустимые ключи в JSON, но невалидные имена полей для Manticore Search. Если попытаться использовать такие имена без корректного сопоставления, Manticore вернет ошибку, и создание источника не будет выполнено.\n\nДля обработки таких случаев используйте следующий синтаксис схемы для сопоставления недопустимых имен полей с допустимыми:\n\nCODE_BLOCK_1\n\nНапример:\n\nCODE_BLOCK_2\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_3\n\n<!-- response -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_5\n\n<!-- response JSON -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n#### Опции\n\n| Опция             | Допустимые значения      | Описание                                                                                                            |\n\n|-                  |-------------------------|---------------------------------------------------------------------------------------------------------------------|\n\n| `type`            | `kafka`                 | Устанавливает тип источника. В настоящее время поддерживается только `kafka`                                        |\n\n| `broker_list`     | `host:port [, ...]`     | Указывает URL-адреса брокеров Kafka                                                                                |\n\n| `topic_list`      | `string [, ...]`        | Список тем Kafka для потребления                                                                                   |\n\n| `consumer_group`  | `string`                | Определяет группу потребителей Kafka, по умолчанию `manticore`.                                                    |\n\n| `num_consumers`   | `int`                   | Количество потребителей для обработки сообщений.                                                                   |\n\n| `partition_list`  | `int [, ...]`           | Список партиций для чтения [подробнее](../Integration/Kafka.md#Sharding-with-Kafka).                                |\n\n| `batch`           | `int`                   | Количество сообщений для обработки перед переходом к следующему циклу. По умолчанию `100`; иначе обрабатывает оставшиеся сообщения по тайм-ауту |\n\n### Целевая таблица\n\n<!-- example kafka_destination -->\n\nЦелевая таблица — обычная таблица реального времени, в которой хранятся результаты обработки сообщений Kafka. Таблица должна быть определена в соответствии с требованиями схемы входящих данных и оптимизирована под потребности производительности запросов вашего приложения. Подробнее о создании таблиц реального времени см. [здесь](../Creating_a_table/Local_tables/Real-time_table.md#Creating-a-real-time-table:).\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_7\n\n<!-- response -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### JSON:\n\n<!-- request JSON -->\n\nCODE_BLOCK_9\n\n<!-- response JSON -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### Материализованное представление\n\n<!-- example kafka_mv -->\n\nМатериализованное представление позволяет преобразовывать данные из сообщений Kafka. Вы можете переименовывать поля, применять функции Manticore Search, выполнять сортировку, группировку и другие операции с данными.\n\nМатериализованное представление действует как запрос, который переносит данные из источника Kafka в целевую таблицу, позволяя использовать синтаксис Manticore Search для настройки таких запросов. Убедитесь, что поля в `select` соответствуют полям источника.\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_12\n\n<!-- response -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\nДанные передаются из Kafka в Manticore Search пакетами, которые очищаются после каждого выполнения. Для вычислений, охватывающих несколько пакетов, таких как AVG, следует проявлять осторожность, так как они могут работать некорректно из-за обработки пакет за пакетом.\n\n### Сопоставление полей\n\nНиже приведена таблица сопоставления на основе приведенных выше примеров:\n\n| Kafka                   | Источник | Буфер   | MV                                    | Цель        |\n\n|-------------------------|----------|---------|-------------------------------------|-------------|\n\n| `id`                    | `id`     | `id`    | `id`                                | `id`        |\n\n| `term`                  | `term`   | `term`  | `term as name`                      | `name`      |\n\n| `unnecessary_key`, который нас не интересует | -        | -       |                                     |             |\n\n| `$abbrev`               | `abbrev` | `abbrev`| `abbrev` as `short_name`            | `short_name`|\n\n| -                       | -        | -       | `UTC_TIMESTAMP() as received_at`    | `received_at`|\n\n| `GlossDef`              | `glossdef`| `glossdef`| `glossdef.size as size`             | `size`      |\n\n### Листинг\n\n<!-- example kafka_listing -->"
    },
    "is_code_or_comment": false
  }
}
