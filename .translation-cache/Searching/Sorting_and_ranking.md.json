{
  "c2d744be787746ca1d6090cc33e364e26a82a0b9270ad8fa8808bba2c176599d": {
    "original": "* `top`, which returns the highest value of the argument across all matched fields.\n\n* `max_window_hits`, manages a sliding window of hit positions to track the maximum number of hits within a specified window size. It removes outdated hits that fall outside the window and adds the latest hit, updating the maximum number of hits found within that window.\n\n### Formula expressions for all the built-in rankers\n\nMost other rankers can actually be emulated using the expression-based ranker. You just need to provide an appropriate expression. While this emulation will likely be slower than using the built-in, compiled ranker, it may still be interesting if you want to fine-tune your ranking formula starting with one of the existing ones. Additionally, the formulas describe the ranker details in a clear, readable manner.\n\n* proximity_bm25 (default ranker) = `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### Configuration of IDF formula\n\nThe historically default IDF (Inverse Document Frequency) in Manticore is equivalent to `OPTION idf='normalized,tfidf_normalized'`, and those normalizations may cause several undesired effects.\n\nFirst, `idf=normalized` causes keyword penalization. For instance, if you search for `the | something` and `the` occurs in more than 50% of the documents, then documents with both keywords `the` and`[something` will get less weight than documents with just one keyword  `something`. Using `OPTION idf=plain` avoids this.\n\nPlain IDF varies in `[0, log(N)]` range, and keywords are never penalized; while the normalized IDF varies in `[-log(N), log(N)]` range, and too frequent keywords are penalized.\n\nSecond, `idf=tfidf_normalized` causes IDF drift over queries. Historically, we additionally divided IDF by query keyword count, so that the entire `sum(tf*idf)` over all keywords would still fit into `[0,1]` range. However, that means that queries `word1` and `word1 | nonmatchingword2` would assign different weights to the exactly same result set, because the IDFs for both `word1` and `nonmatchingword2` would be divided by 2. `OPTION idf='tfidf_unnormalized'` fixes that. Note that BM25, BM25A, BM25F() ranking factors will be scale accordingly  once you disable this normalization.\n\nIDF flags can be mixed; `plain` and `normalized` are mutually exclusive;`tfidf_unnormalized` and `tfidf_normalized` are mutually exclusive; and unspecified flags in such a mutually exclusive group take their defaults. That means that `OPTION idf=plain` is equivalent to a complete `OPTION idf='plain,tfidf_normalized'` specification.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "* `top`，返回所有匹配字段中参数的最高值。\n\n* `max_window_hits`，管理一个滑动窗口的命中位置，以跟踪指定窗口大小内的最大命中数。它会移除超出窗口范围的过时命中，并添加最新命中，更新该窗口内发现的最大命中数。\n\n### 所有内置排序器的公式表达式\n\n大多数其他排序器实际上可以通过基于表达式的排序器来模拟。你只需提供一个合适的表达式。虽然这种模拟可能比使用内置的、编译的排序器慢，但如果你想从现有排序器之一开始微调你的排序公式，这仍然可能很有趣。此外，这些公式以清晰、可读的方式描述了排序器的细节。\n\n* proximity_bm25（默认排序器）= `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### IDF 公式配置\n\nManticore 历史上的默认 IDF（逆文档频率）等同于 `OPTION idf='normalized,tfidf_normalized'`，这些归一化可能会导致一些不良影响。\n\n首先，`idf=normalized` 会导致关键词惩罚。例如，如果你搜索 `the | something`，且 `the` 出现在超过 50% 的文档中，那么同时包含关键词 `the` 和 `something` 的文档权重会低于只包含关键词 `something` 的文档。使用 `OPTION idf=plain` 可以避免这种情况。\n\nPlain IDF 变化范围为 `[0, log(N)]`，关键词永远不会被惩罚；而归一化 IDF 变化范围为 `[-log(N), log(N)]`，频繁出现的关键词会被惩罚。\n\n其次，`idf=tfidf_normalized` 会导致查询间的 IDF 漂移。历史上，我们还将 IDF 除以查询关键词数，以使所有关键词的 `sum(tf*idf)` 仍然适合 `[0,1]` 范围。然而，这意味着查询 `word1` 和 `word1 | nonmatchingword2` 会对完全相同的结果集赋予不同的权重，因为 `word1` 和 `nonmatchingword2` 的 IDF 都会被除以 2。`OPTION idf='tfidf_unnormalized'` 解决了这个问题。请注意，一旦禁用此归一化，BM25、BM25A、BM25F() 排序因子将相应缩放。\n\nIDF 标志可以混合使用；`plain` 和 `normalized` 互斥；`tfidf_unnormalized` 和 `tfidf_normalized` 互斥；未指定的互斥组标志将采用默认值。这意味着 `OPTION idf=plain` 等同于完整的 `OPTION idf='plain,tfidf_normalized'` 指定。\n\n<!-- proofread -->",
      "russian": "* `top`, который возвращает наибольшее значение аргумента по всем совпадающим полям.\n\n* `max_window_hits`, управляет скользящим окном позиций попаданий для отслеживания максимального количества попаданий в пределах заданного размера окна. Он удаляет устаревшие попадания, выходящие за пределы окна, и добавляет последнее попадание, обновляя максимальное количество попаданий, найденных в этом окне.\n\n### Формулы выражений для всех встроенных ранжировщиков\n\nБольшинство других ранжировщиков на самом деле можно эмулировать с помощью ранжировщика на основе выражений. Вам просто нужно предоставить соответствующее выражение. Хотя такая эмуляция, вероятно, будет медленнее, чем использование встроенного, скомпилированного ранжировщика, она может быть интересна, если вы хотите тонко настроить свою формулу ранжирования, начиная с одной из существующих. Кроме того, формулы описывают детали ранжировщика ясно и читаемо.\n\n* proximity_bm25 (ранжировщик по умолчанию) = `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### Конфигурация формулы IDF\n\nИсторически стандартный IDF (обратная частота документа) в Manticore эквивалентен `OPTION idf='normalized,tfidf_normalized'`, и эти нормализации могут вызывать несколько нежелательных эффектов.\n\nВо-первых, `idf=normalized` вызывает штрафование ключевых слов. Например, если вы ищете `the | something` и `the` встречается более чем в 50% документов, то документы с обоими ключевыми словами `the` и `something` получат меньший вес, чем документы только с одним ключевым словом `something`. Использование `OPTION idf=plain` избегает этого.\n\nPlain IDF варьируется в диапазоне `[0, log(N)]`, и ключевые слова никогда не штрафуются; в то время как нормализованный IDF варьируется в диапазоне `[-log(N), log(N)]`, и слишком частые ключевые слова штрафуются.\n\nВо-вторых, `idf=tfidf_normalized` вызывает дрейф IDF между запросами. Исторически мы дополнительно делили IDF на количество ключевых слов в запросе, чтобы сумма `sum(tf*idf)` по всем ключевым словам оставалась в диапазоне `[0,1]`. Однако это означает, что запросы `word1` и `word1 | nonmatchingword2` будут присваивать разные веса точно одному и тому же набору результатов, потому что IDF для `word1` и `nonmatchingword2` будет делиться на 2. `OPTION idf='tfidf_unnormalized'` исправляет это. Обратите внимание, что факторы ранжирования BM25, BM25A, BM25F() будут масштабироваться соответствующим образом после отключения этой нормализации.\n\nФлаги IDF могут комбинироваться; `plain` и `normalized` взаимоисключающие; `tfidf_unnormalized` и `tfidf_normalized` взаимоисключающие; и неуказанные флаги в такой взаимоисключающей группе принимают значения по умолчанию. Это означает, что `OPTION idf=plain` эквивалентен полной спецификации `OPTION idf='plain,tfidf_normalized'`.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "2ca8933e29ad2b21453666e2998a3d34d2baccb42d37e697405579f87b19b58c": {
    "original": "| tf_idf                  | field     | float | sum(tf*idf) over matched keywords == sum(idf) over occurrences                                                     |\n\n| min_hit_pos             | field     | int   | first matched occurrence position, in words, 1-based                                                               |\n\n| min_best_span_pos       | field     | int   | first maximum LCS span position, in words, 1-based                                                                 |\n\n| exact_hit               | field     | bool  | whether query == field                                                                                             |\n\n| min_idf                 | field     | float | min(idf) over matched keywords                                                                                     |\n\n| max_idf                 | field     | float | max(idf) over matched keywords                                                                                     |\n\n| sum_idf                 | field     | float | sum(idf) over matched keywords                                                                                     |\n\n| exact_order             | field     | bool  | whether all query keywords were a) matched and b) in query order                                                   |\n\n| min_gaps                | field     | int   | minimum number of gaps between the matched keywords over the matching spans                                        |\n\n| lccs                    | field     | int   | Longest Common Contiguous Subsequence between query and document, in words                                         |\n\n| wlccs                   | field     | float | Weighted Longest Common Contiguous Subsequence, sum(idf) over contiguous keyword spans                            |\n\n| atc                     | field     | float | Aggregate Term Closeness, log(1+sum(idf1*idf2*pow(distance, -1.75)) over the best pairs of keywords               |\n\n### Document-level Ranking Factors\n\nA **document-level factor** is a numeric value computed by the ranking engine for every matched document with regards to the current query. So it differs from a plain document attribute in that the attribute does not depend on the full text query, while factors might. These factors can be used anywhere in the ranking expression. Currently implemented document-level factors are:\n\n* `bm25` (integer), a document-level BM25 estimate (computed without keyword occurrence filtering).\n\n* `max_lcs` (integer), a query-level maximum possible value that the `sum(lcs*user_weight)` expression can ever take. This can be useful for weight boost scaling. For instance, `MATCHANY` ranker formula uses this to guarantee that a full phrase match in any field ranks higher than any combination of partial matches in all fields.\n\n* `field_mask` (integer), a document-level 32-bit mask of matched fields.\n\n* `query_word_count` (integer), the number of unique keywords in a query, adjusted for the number of excluded keywords. For instance, both `(one one one one)` and `(one !two)` queries should assign a value of 1 to this factor, because there is just one unique non-excluded keyword.\n\n* `doc_word_count` (integer), the number of unique keywords matched in the entire document.\n\n### Field-level Ranking Factors\n\nA **field-level factor** is a numeric value computed by the ranking engine for every matched in-document text field regards to the current query. As more than one field can be matched by a query, but the final weight needs to be a single integer value, these values need to be folded into a single one. To achieve that, field-level factors can only be used within a field aggregation function, they can **not** be used anywhere in the expression. For example, you cannot use `(lcs+bm25)` as your ranking expression, as `lcs` takes multiple values (one in every matched field). You should use `(sum(lcs)+bm25)` instead, that expression sums `lcs` over all matching fields, and then adds `bm25` to that per-field sum. Currently implemented field-level factors are:\n\n* `lcs` (integer), the length of a maximum verbatim match between the document and the query, counted in words. LCS stands for Longest Common Subsequence (or Subset). Takes a minimum value of 1 when only stray keywords were matched in a field, and a maximum value of query keywords count when the entire query was matched in a field verbatim (in the exact query keywords order). For example, if the query is 'hello world' and the field contains these two words quoted from the query (that is, adjacent to each other, and exactly in the query order), `lcs` will be 2. For example, if the query is 'hello world program' and the field contains 'hello world', `lcs` will be 2. Note that any subset of the query keyword works, not just a subset of adjacent keywords. For example, if the query is 'hello world program' and the field contains 'hello (test program)', `lcs` will be 2 just as well, because both 'hello' and 'program' matched in the same respective positions as they were in the query. Finally, if the query is 'hello world program' and the field contains 'hello world program', `lcs` will be 3. (Hopefully that is unsurprising at this point.)\n\n* `user_weight` (integer), the user specified per-field weight (refer to [OPTION field_weights](../Searching/Options.md#field_weights) in SQL). The weights default to 1 if not specified explicitly.\n\n* `hit_count` (integer), the number of keyword occurrences that matched in the field. Note that a single keyword may occur multiple times. For example, if 'hello' occurs 3 times in a field and 'world' occurs 5 times, `hit_count` will be 8.\n\n* `word_count` (integer), the number of unique keywords matched in the field. For example, if 'hello' and 'world' occur anywhere in a field, `word_count` will be 2, regardless of how many times both keywords occur.",
    "translations": {
      "chinese": "| tf_idf                  | field     | float | 匹配关键词的 sum(tf*idf) == 出现次数的 sum(idf)                                                     |\n\n| min_hit_pos             | field     | int   | 第一个匹配出现位置，按词计，基于1                                                               |\n\n| min_best_span_pos       | field     | int   | 第一个最大 LCS 区间位置，按词计，基于1                                                                 |\n\n| exact_hit               | field     | bool  | 查询是否等于字段                                                                                             |\n\n| min_idf                 | field     | float | 匹配关键词的最小 idf                                                                                     |\n\n| max_idf                 | field     | float | 匹配关键词的最大 idf                                                                                     |\n\n| sum_idf                 | field     | float | 匹配关键词的 idf 之和                                                                                     |\n\n| exact_order             | field     | bool  | 是否所有查询关键词 a) 被匹配且 b) 按查询顺序排列                                                   |\n\n| min_gaps                | field     | int   | 匹配区间中匹配关键词之间的最小间隙数                                        |\n\n| lccs                    | field     | int   | 查询与文档之间的最长连续公共子序列，按词计                                         |\n\n| wlccs                   | field     | float | 加权最长连续公共子序列，连续关键词区间的 idf 之和                            |\n\n| atc                     | field     | float | 聚合词项接近度，log(1+最佳关键词对的 idf1*idf2*pow(距离, -1.75) 之和)               |\n\n### 文档级排名因子\n\n**文档级因子** 是排名引擎针对当前查询为每个匹配文档计算的数值。因此它不同于普通文档属性，后者不依赖全文查询，而因子可能依赖。这些因子可以在排名表达式中任何地方使用。目前实现的文档级因子有：\n\n* `bm25`（整数），文档级 BM25 估计值（计算时不进行关键词出现过滤）。\n\n* `max_lcs`（整数），查询级最大可能值，即 `sum(lcs*user_weight)` 表达式可能达到的最大值。这对于权重提升缩放很有用。例如，`MATCHANY` 排序公式使用它来保证任何字段中的完整短语匹配排名高于所有字段中部分匹配的任意组合。\n\n* `field_mask`（整数），文档级 32 位匹配字段掩码。\n\n* `query_word_count`（整数），查询中唯一关键词的数量，调整了排除关键词的数量。例如，`(one one one one)` 和 `(one !two)` 查询都应为该因子赋值为 1，因为只有一个唯一的非排除关键词。\n\n* `doc_word_count`（整数），整个文档中匹配的唯一关键词数量。\n\n### 字段级排名因子\n\n**字段级因子** 是排名引擎针对当前查询为每个匹配的文档内文本字段计算的数值。由于查询可能匹配多个字段，但最终权重需要是单个整数值，这些值需要合并成一个。为此，字段级因子只能在字段聚合函数内使用，**不能**在表达式的其他地方使用。例如，不能使用 `(lcs+bm25)` 作为排名表达式，因为 `lcs` 在每个匹配字段中有多个值。应使用 `(sum(lcs)+bm25)`，该表达式先对所有匹配字段的 `lcs` 求和，再加上 `bm25`。目前实现的字段级因子有：\n\n* `lcs`（整数），文档与查询之间最大逐字匹配长度，按词计。LCS 代表最长公共子序列（或子集）。当字段中仅匹配零散关键词时，最小值为1；当字段中逐字匹配整个查询（且顺序完全相同）时，最大值为查询关键词数。例如，查询为“hello world”，字段包含这两个词且相邻且顺序相同，则 `lcs` 为2。再如，查询为“hello world program”，字段包含“hello world”，`lcs` 为2。注意，查询关键词的任意子集均可，不仅限于相邻关键词。例如，查询为“hello world program”，字段包含“hello (test program)”，`lcs` 也为2，因为“hello”和“program”分别匹配了查询中的相应位置。最后，查询为“hello world program”，字段包含“hello world program”，`lcs` 为3。（这点应该不令人惊讶。）\n\n* `user_weight`（整数），用户指定的每字段权重（参见 SQL 中的 [OPTION field_weights](../Searching/Options.md#field_weights)）。如果未显式指定，权重默认为1。\n\n* `hit_count`（整数），字段中匹配的关键词出现次数。注意单个关键词可能出现多次。例如，“hello”在字段中出现3次，“world”出现5次，则 `hit_count` 为8。\n\n* `word_count`（整数），字段中匹配的唯一关键词数量。例如，“hello”和“world”任意出现，`word_count` 为2，无论两者出现多少次。",
      "russian": "| tf_idf                  | field     | float | сумма(tf*idf) по совпавшим ключевым словам == сумма(idf) по вхождениям                                                     |\n\n| min_hit_pos             | field     | int   | позиция первого совпавшего вхождения, в словах, с 1                                                                  |\n\n| min_best_span_pos       | field     | int   | позиция первого максимального LCS спана, в словах, с 1                                                                |\n\n| exact_hit               | field     | bool  | совпадает ли запрос с полем                                                                                            |\n\n| min_idf                 | field     | float | min(idf) по совпавшим ключевым словам                                                                                 |\n\n| max_idf                 | field     | float | max(idf) по совпавшим ключевым словам                                                                                 |\n\n| sum_idf                 | field     | float | сумма(idf) по совпавшим ключевым словам                                                                                |\n\n| exact_order             | field     | bool  | совпадают ли все ключевые слова запроса а) были найдены и б) в порядке запроса                                         |\n\n| min_gaps                | field     | int   | минимальное количество пропусков между совпавшими ключевыми словами в пределах совпадающих спанов                      |\n\n| lccs                    | field     | int   | Наибольшая общая непрерывная подпоследовательность между запросом и документом, в словах                               |\n\n| wlccs                   | field     | float | Взвешенная наибольшая общая непрерывная подпоследовательность, сумма(idf) по непрерывным спанам ключевых слов          |\n\n| atc                     | field     | float | Аггрегированная близость терминов, log(1+sum(idf1*idf2*pow(distance, -1.75)) по лучшим парам ключевых слов            |\n\n### Факторы ранжирования на уровне документа\n\n**Фактор на уровне документа** — это числовое значение, вычисляемое движком ранжирования для каждого совпавшего документа относительно текущего запроса. Он отличается от простого атрибута документа тем, что атрибут не зависит от полного текстового запроса, а факторы могут зависеть. Эти факторы могут использоваться в любом месте выражения ранжирования. В настоящее время реализованы следующие факторы на уровне документа:\n\n* `bm25` (целое), оценка BM25 на уровне документа (вычисляется без фильтрации вхождений ключевых слов).\n\n* `max_lcs` (целое), максимальное возможное значение на уровне запроса, которое выражение `sum(lcs*user_weight)` может принимать. Это может быть полезно для масштабирования усиления веса. Например, формула ранжирования `MATCHANY` использует это, чтобы гарантировать, что полное совпадение фразы в любом поле ранжируется выше, чем любая комбинация частичных совпадений во всех полях.\n\n* `field_mask` (целое), 32-битная маска совпавших полей на уровне документа.\n\n* `query_word_count` (целое), количество уникальных ключевых слов в запросе, скорректированное с учётом количества исключённых ключевых слов. Например, запросы `(one one one one)` и `(one !two)` должны присваивать этому фактору значение 1, так как есть только одно уникальное не исключённое ключевое слово.\n\n* `doc_word_count` (целое), количество уникальных ключевых слов, совпавших во всём документе.\n\n### Факторы ранжирования на уровне поля\n\n**Фактор на уровне поля** — это числовое значение, вычисляемое движком ранжирования для каждого совпавшего текстового поля документа относительно текущего запроса. Поскольку запрос может совпадать с несколькими полями, а итоговый вес должен быть одним целым числом, эти значения нужно сворачивать в одно. Для этого факторы на уровне поля могут использоваться только внутри функций агрегации по полям, их **нельзя** использовать в любом другом месте выражения. Например, нельзя использовать `(lcs+bm25)` как выражение ранжирования, так как `lcs` принимает несколько значений (по одному в каждом совпавшем поле). Следует использовать `(sum(lcs)+bm25)`, это выражение суммирует `lcs` по всем совпавшим полям, а затем добавляет `bm25` к этой сумме по полям. В настоящее время реализованы следующие факторы на уровне поля:\n\n* `lcs` (целое), длина максимального дословного совпадения между документом и запросом, в словах. LCS означает Наибольшую Общую Подпоследовательность (или Подмножество). Минимальное значение 1, если в поле совпали только отдельные ключевые слова, максимальное — количество ключевых слов запроса, если весь запрос совпал в поле дословно (в точном порядке ключевых слов запроса). Например, если запрос 'hello world', а поле содержит эти два слова, взятые из запроса (то есть расположены рядом и именно в порядке запроса), `lcs` будет 2. Если запрос 'hello world program', а поле содержит 'hello world', `lcs` будет 2. Обратите внимание, что работает любое подмножество ключевых слов запроса, не обязательно смежных. Например, если запрос 'hello world program', а поле содержит 'hello (test program)', `lcs` также будет 2, потому что совпали 'hello' и 'program' в тех же позициях, что и в запросе. Наконец, если запрос 'hello world program', а поле содержит 'hello world program', `lcs` будет 3. (Надеюсь, это уже не удивительно.)\n\n* `user_weight` (целое), вес, указанный пользователем для поля (см. [OPTION field_weights](../Searching/Options.md#field_weights) в SQL). По умолчанию вес равен 1, если явно не указан.\n\n* `hit_count` (целое), количество вхождений ключевых слов, совпавших в поле. Обратите внимание, что одно ключевое слово может встречаться несколько раз. Например, если 'hello' встречается 3 раза в поле, а 'world' 5 раз, `hit_count` будет 8.\n\n* `word_count` (целое), количество уникальных ключевых слов, совпавших в поле. Например, если 'hello' и 'world' встречаются в поле, `word_count` будет 2, независимо от количества вхождений каждого слова."
    },
    "is_code_or_comment": false
  },
  "e2ee2ab6cf0946db94a57f0017369ef255d37c50674d6a08b98f181ea0dc651c": {
    "original": "Ranking (also known as weighting) of search results can be defined as a process of computing a so-called relevance (weight) for every given matched document regards to a given query that matched it. So relevance is, in the end, just a number attached to every document that estimates how relevant the document is to the query. Search results can then be sorted based on this number and/or some additional parameters, so that the most sought-after results would appear higher on the results page.\n\nThere is no single standard one-size-fits-all way to rank any document in any scenario. Moreover, there can never be such a way, because relevance is *subjective*. As in, what seems relevant to you might not seem relevant to me. Hence, in general cases, it's not just hard to compute; it's theoretically impossible.\n\nSo ranking in Manticore is configurable. It has a notion of a so-called **ranker**. A ranker can formally be defined as a function that takes a document and a query as its input and produces a relevance value as output. In layman's terms, a ranker controls exactly how (using which specific algorithm) Manticore will assign weights to the documents.\n\n## Available built-in rankers\n\nManticore ships with several built-in rankers suited for different purposes. Many of them use two factors: phrase proximity (also known as LCS) and BM25. Phrase proximity works on keyword positions, while BM25 works on keyword frequencies. Essentially, the better the degree of phrase match between the document body and the query, the higher the phrase proximity (it maxes out when the document contains the entire query as a verbatim quote). And BM25 is higher when the document contains more rare words. We'll save the detailed discussion for later.\n\nThe currently implemented rankers are:\n\n* `proximity_bm25`, the default ranking mode that uses and combines both phrase proximity and BM25 ranking.\n\n* `bm25`, a statistical ranking mode that uses BM25 ranking only (similar to most other full-text engines). This mode is faster but may result in worse quality for queries containing more than one keyword.\n\n* `none`, a no-ranking mode. This mode is obviously the fastest. A weight of 1 is assigned to all matches. This is sometimes called boolean searching, which just matches the documents but does not rank them.\n\n* `wordcount`, ranking by the keyword occurrences count. This ranker computes the per-field keyword occurrence counts, then multiplies them by field weights, and sums the resulting values.\n\n* `proximity` returns the raw phrase proximity value as a result. This mode is internally used to emulate `SPH_MATCH_ALL` queries.\n\n* `matchany` returns rank as it was computed in `SPH_MATCH_ANY` mode earlier and is internally used to emulate `SPH_MATCH_ANY` queries.\n\n* `fieldmask` returns a 32-bit mask with the N-th bit corresponding to the N-th full-text field, numbering from 0. The bit will only be set when the respective field has any keyword occurrences satisfying the query.\n\n* `sph04` is generally based on the default 'proximity_bm25' ranker, but additionally boosts matches when they occur at the very beginning or the very end of a text field. Thus, if a field equals the exact query, `sph04` should rank it higher than a field that contains the exact query but is not equal to it. (For instance, when the query is \"Hyde Park\", a document titled \"Hyde Park\" should be ranked higher than one titled \"Hyde Park, London\" or \"The Hyde Park Cafe\".)\n\n* `expr` allows you to specify the ranking formula at runtime. It exposes several internal text factors and lets you define how the final weight should be computed from those factors. You can find more details about its syntax and a reference of available factors in a [subsection below](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors).\n\nThe ranker name is case-insensitive. Example:\n\nCODE_BLOCK_58\n\n## Quick summary of the ranking factors\n\n| Name                    | Level     | Type  | Summary                                                                                                            |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | query     | int   | maximum possible LCS value for the current query                                                                   |\n\n| bm25                    | document  | int   | quick estimate of BM25(1.2, 0)                                                                                     |\n\n| bm25a(k1, b)            | document  | int   | precise BM25() value with configurable K1, B constants and syntax support                                         |\n\n| bm25f(k1, b, {field=weight, ...}) | document | int   | precise BM25F() value with extra configurable field weights                                                       |\n\n| field_mask              | document  | int   | bit mask of matched fields                                                                                         |\n\n| query_word_count        | document  | int   | number of unique inclusive keywords in a query                                                                     |\n\n| doc_word_count          | document  | int   | number of unique keywords matched in the document                                                                  |\n\n| lcs                     | field     | int   | Longest Common Subsequence between query and document, in words                                                    |\n\n| user_weight             | field     | int   | user field weight                                                                                                  |\n\n| hit_count               | field     | int   | total number of keyword occurrences                                                                                |\n\n| word_count              | field     | int   | number of unique matched keywords                                                                                  |",
    "translations": {
      "chinese": "排名（也称为加权）搜索结果可以定义为一个过程，即针对每个匹配的文档计算所谓的相关性（权重），以对应匹配它的查询。因此，相关性最终只是附加到每个文档上的一个数字，用于估计该文档与查询的相关程度。然后可以基于该数字和/或一些附加参数对搜索结果进行排序，使得最受关注的结果出现在结果页的更高位置。\n\n没有一种适用于所有场景的单一标准排名方法。更重要的是，永远不可能有这样的方式，因为相关性是*主观的*。也就是说，对你来说相关的内容，对我来说可能不相关。因此，在一般情况下，相关性不仅难以计算；从理论上讲是不可能的。\n\n所以 Manticore 中的排名是可配置的。它有一个所谓的**ranker**（排名器）的概念。排名器可以形式化定义为一个函数，输入为文档和查询，输出为相关性值。通俗地说，排名器控制 Manticore 使用哪种具体算法来为文档分配权重。\n\n## 可用的内置排名器\n\nManticore 附带了几个适用于不同用途的内置排名器。它们中的许多使用两个因素：短语接近度（也称为 LCS）和 BM25。短语接近度基于关键词位置，而 BM25 基于关键词频率。基本上，文档正文与查询之间的短语匹配程度越好，短语接近度越高（当文档包含整个查询的逐字引用时达到最大值）。而 BM25 在文档包含更多稀有词时更高。详细讨论留待后面。\n\n当前实现的排名器有：\n\n* `proximity_bm25`，默认排名模式，结合使用短语接近度和 BM25 排名。\n\n* `bm25`，统计排名模式，仅使用 BM25 排名（类似大多数其他全文引擎）。此模式更快，但对于包含多个关键词的查询可能导致质量较差。\n\n* `none`，无排名模式。此模式显然是最快的。所有匹配赋予权重 1。有时称为布尔搜索，只匹配文档但不排名。\n\n* `wordcount`，按关键词出现次数排名。该排名器计算每个字段的关键词出现次数，然后乘以字段权重，最后求和。\n\n* `proximity` 返回原始短语接近度值。此模式内部用于模拟 `SPH_MATCH_ALL` 查询。\n\n* `matchany` 返回之前在 `SPH_MATCH_ANY` 模式下计算的排名，内部用于模拟 `SPH_MATCH_ANY` 查询。\n\n* `fieldmask` 返回一个 32 位掩码，第 N 位对应第 N 个全文字段（从 0 开始编号）。只有当相应字段有满足查询的关键词出现时，该位才会被设置。\n\n* `sph04` 通常基于默认的 `proximity_bm25` 排名器，但额外提升匹配出现在文本字段开头或结尾的权重。因此，如果字段等于精确查询，`sph04` 应该将其排名高于包含精确查询但不完全相等的字段。（例如，当查询为“Hyde Park”时，标题为“Hyde Park”的文档应排名高于标题为“Hyde Park, London”或“The Hyde Park Cafe”的文档。）\n\n* `expr` 允许你在运行时指定排名公式。它暴露了几个内部文本因素，并允许你定义如何从这些因素计算最终权重。你可以在[下面的小节](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors)中找到其语法和可用因素的参考详情。\n\n排名器名称不区分大小写。示例：\n\nCODE_BLOCK_58\n\n## 排名因素快速总结\n\n| 名称                    | 级别     | 类型  | 概要                                                                                                            |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | query     | int   | 当前查询的最大可能 LCS 值                                                                                         |\n\n| bm25                    | document  | int   | BM25(1.2, 0) 的快速估计                                                                                           |\n\n| bm25a(k1, b)            | document  | int   | 具有可配置 K1、B 常数和语法支持的精确 BM25() 值                                                                   |\n\n| bm25f(k1, b, {field=weight, ...}) | document | int   | 具有额外可配置字段权重的精确 BM25F() 值                                                                           |\n\n| field_mask              | document  | int   | 匹配字段的位掩码                                                                                                   |\n\n| query_word_count        | document  | int   | 查询中唯一包含的关键词数量                                                                                         |\n\n| doc_word_count          | document  | int   | 文档中匹配的唯一关键词数量                                                                                         |\n\n| lcs                     | field     | int   | 查询与文档之间的最长公共子序列（以词为单位）                                                                       |\n\n| user_weight             | field     | int   | 用户字段权重                                                                                                      |\n\n| hit_count               | field     | int   | 关键词出现的总次数                                                                                                 |\n\n| word_count              | field     | int   | 匹配的唯一关键词数量                                                                                               |",
      "russian": "Ранжирование (также известное как взвешивание) результатов поиска можно определить как процесс вычисления так называемой релевантности (веса) для каждого найденного документа относительно данного запроса, который его сопоставил. Таким образом, релевантность — это, в конечном счёте, просто число, прикреплённое к каждому документу, которое оценивает, насколько документ релевантен запросу. Результаты поиска затем могут быть отсортированы на основе этого числа и/или некоторых дополнительных параметров, чтобы наиболее востребованные результаты появлялись выше на странице результатов.\n\nНе существует единого универсального способа ранжирования любого документа в любой ситуации. Более того, такого способа никогда не может быть, потому что релевантность *субъективна*. То есть то, что кажется релевантным вам, может не казаться релевантным мне. Следовательно, в общих случаях это не просто трудно вычислить; это теоретически невозможно.\n\nПоэтому ранжирование в Manticore настраивается. В нём есть понятие так называемого **ранкера**. Ранкер формально можно определить как функцию, которая принимает на вход документ и запрос и выдаёт значение релевантности на выходе. Простыми словами, ранкер контролирует, как именно (с помощью какого конкретного алгоритма) Manticore будет присваивать веса документам.\n\n## Доступные встроенные ранкеры\n\nManticore поставляется с несколькими встроенными ранкерами, подходящими для разных целей. Многие из них используют два фактора: близость фраз (также известную как LCS) и BM25. Близость фраз работает с позициями ключевых слов, в то время как BM25 — с частотами ключевых слов. По сути, чем лучше степень совпадения фразы между телом документа и запросом, тем выше близость фраз (она достигает максимума, когда документ содержит весь запрос как дословную цитату). А BM25 выше, когда документ содержит более редкие слова. Подробное обсуждение мы оставим на потом.\n\nВ настоящее время реализованы следующие ранкеры:\n\n* `proximity_bm25` — режим ранжирования по умолчанию, который использует и комбинирует как близость фраз, так и ранжирование BM25.\n\n* `bm25` — статистический режим ранжирования, который использует только BM25 (аналогично большинству других полнотекстовых движков). Этот режим быстрее, но может давать худшее качество для запросов, содержащих более одного ключевого слова.\n\n* `none` — режим без ранжирования. Этот режим, очевидно, самый быстрый. Всем совпадениям присваивается вес 1. Иногда это называют булевым поиском, который просто находит документы, но не ранжирует их.\n\n* `wordcount` — ранжирование по количеству вхождений ключевых слов. Этот ранкер вычисляет количество вхождений ключевых слов по каждому полю, затем умножает их на веса полей и суммирует полученные значения.\n\n* `proximity` возвращает сырое значение близости фраз в качестве результата. Этот режим внутренне используется для эмуляции запросов `SPH_MATCH_ALL`.\n\n* `matchany` возвращает ранг, как он вычислялся ранее в режиме `SPH_MATCH_ANY`, и внутренне используется для эмуляции запросов `SPH_MATCH_ANY`.\n\n* `fieldmask` возвращает 32-битную маску, где N-й бит соответствует N-му полнотекстовому полю, нумерация с 0. Бит будет установлен только если в соответствующем поле есть вхождения ключевых слов, удовлетворяющих запросу.\n\n* `sph04` в целом основан на ранкере по умолчанию 'proximity_bm25', но дополнительно повышает рейтинг совпадений, когда они встречаются в самом начале или в самом конце текстового поля. Таким образом, если поле равно точному запросу, `sph04` должен ранжировать его выше, чем поле, которое содержит точный запрос, но не равно ему. (Например, если запрос \"Hyde Park\", документ с заголовком \"Hyde Park\" должен иметь более высокий ранг, чем документ с заголовком \"Hyde Park, London\" или \"The Hyde Park Cafe\".)\n\n* `expr` позволяет задавать формулу ранжирования во время выполнения. Он предоставляет несколько внутренних текстовых факторов и позволяет определить, как из этих факторов вычислять итоговый вес. Подробнее о синтаксисе и справочник доступных факторов можно найти в [подразделе ниже](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors).\n\nИмя ранкера не чувствительно к регистру. Пример:\n\nCODE_BLOCK_58\n\n## Краткое резюме факторов ранжирования\n\n| Name                    | Level     | Type  | Summary                                                                                                            |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | query     | int   | максимальное возможное значение LCS для текущего запроса                                                           |\n\n| bm25                    | document  | int   | быстрая оценка BM25(1.2, 0)                                                                                        |\n\n| bm25a(k1, b)            | document  | int   | точное значение BM25() с настраиваемыми константами K1, B и поддержкой синтаксиса                                 |\n\n| bm25f(k1, b, {field=weight, ...}) | document | int   | точное значение BM25F() с дополнительной настройкой весов полей                                                   |\n\n| field_mask              | document  | int   | битовая маска совпавших полей                                                                                      |\n\n| query_word_count        | document  | int   | количество уникальных включённых ключевых слов в запросе                                                           |\n\n| doc_word_count          | document  | int   | количество уникальных ключевых слов, совпавших в документе                                                          |\n\n| lcs                     | field     | int   | Наибольшая общая подпоследовательность между запросом и документом, в словах                                        |\n\n| user_weight             | field     | int   | пользовательский вес поля                                                                                            |\n\n| hit_count               | field     | int   | общее количество вхождений ключевых слов                                                                            |\n\n| word_count              | field     | int   | количество уникальных совпавших ключевых слов                                                                        |"
    },
    "is_code_or_comment": false
  },
  "c2d12f6b820a3d1c6f6b880cfac09c262cd1f695597195a8c41d2093391f8512": {
    "original": "# Sorting and ranking\n\nQuery results can be sorted by full-text ranking weight, one or more attributes or expressions.\n\n**Full-text** queries return matches sorted by default. If nothing is specified, they are sorted by relevance, which is equivalent to `ORDER BY weight() DESC` in SQL format.\n\n**Non-full-text** queries do not perform any sorting by default.\n\n## Advanced sorting\n\nExtended mode is automatically enabled when you explicitly provide sorting rules by adding the `ORDER BY` clause in SQL format or using the `sort` option via HTTP JSON.\n\n### Sorting via SQL\n\nGeneral syntax:\n\nCODE_BLOCK_0\n\n<!-- example alias -->\n\nIn the sort clause, you can use any combination of up to 5 columns, each followed by `asc` or `desc`. Functions and expressions are not allowed as arguments for the sort clause, except for the `weight()` and `random()` functions (the latter can only be used via SQL in the form of `ORDER BY random()`). However, you can use any expression in the SELECT list and sort by its alias.\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- response SQL -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n## Sorting via JSON\n\n<!-- example sorting 1 -->\n\n`\"sort\"` specifies an array where each element can be an attribute name or `_score` if you want to sort by match weights or `_random` if you want radnom match order. In that case, the sort order defaults to ascending for attributes and descending for `_score`.\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- response JSON -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example sorting 2 -->\n\nYou can also specify the sort order explicitly:\n\n* `asc`: sort in ascending order\n\n* `desc`: sort in descending order\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- response JSON -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_16\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_17\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example sorting 3 -->\n\nYou can also use another syntax and specify the sort order via the `order` property:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_25\n\n<!-- response JSON -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_34\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n<!-- example sorting 4 -->\n\nSorting by MVA attributes is also supported in JSON queries. Sorting mode can be set via the `mode` property. The following modes are supported:\n\n* `min`: sort by minimum value\n\n* `max`: sort by maximum value\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_36\n\n<!-- response JSON -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_42\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_43\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_44\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n<!-- example sorting 5 -->\n\nWhen sorting on an attribute, match weight (score) calculation is disabled by default (no ranker is used). You can enable weight calculation by setting the `track_scores` property to `true`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_47\n\n<!-- response JSON -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_51\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_52\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_53\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_54\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_55\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_56\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n## Ranking overview",
    "translations": {
      "chinese": "# 排序和排名\n\n查询结果可以按全文排名权重、一个或多个属性或表达式进行排序。\n\n**全文** 查询默认返回排序的匹配项。如果未指定任何内容，则按相关性排序，这相当于 SQL 格式中的 `ORDER BY weight() DESC`。\n\n**非全文** 查询默认不执行任何排序。\n\n## 高级排序\n\n当您通过添加 SQL 格式的 `ORDER BY` 子句或通过 HTTP JSON 使用 `sort` 选项显式提供排序规则时，自动启用扩展模式。\n\n### 通过 SQL 排序\n\n通用语法：\n\nCODE_BLOCK_0\n\n<!-- example alias -->\n\n在排序子句中，您可以使用最多 5 列的任意组合，每列后跟 `asc` 或 `desc`。函数和表达式不允许作为排序子句的参数，除了 `weight()` 和 `random()` 函数（后者只能通过 SQL 以 `ORDER BY random()` 形式使用）。但是，您可以在 SELECT 列表中使用任何表达式，并按其别名排序。\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- response SQL -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n## 通过 JSON 排序\n\n<!-- example sorting 1 -->\n\n`\"sort\"` 指定一个数组，其中每个元素可以是属性名，或者如果您想按匹配权重排序则为 `_score`，如果想要随机匹配顺序则为 `_random`。在这种情况下，属性的排序顺序默认为升序，`_score` 默认为降序。\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- response JSON -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example sorting 2 -->\n\n您也可以显式指定排序顺序：\n\n* `asc`：升序排序\n\n* `desc`：降序排序\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- response JSON -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_16\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_17\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example sorting 3 -->\n\n您还可以使用另一种语法，通过 `order` 属性指定排序顺序：\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_25\n\n<!-- response JSON -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_34\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n<!-- example sorting 4 -->\n\nJSON 查询中也支持按 MVA 属性排序。排序模式可以通过 `mode` 属性设置。支持以下模式：\n\n* `min`：按最小值排序\n\n* `max`：按最大值排序\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_36\n\n<!-- response JSON -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_42\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_43\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_44\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n<!-- example sorting 5 -->\n\n当按属性排序时，默认禁用匹配权重（分数）计算（不使用排名器）。您可以通过将 `track_scores` 属性设置为 `true` 来启用权重计算：\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_47\n\n<!-- response JSON -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_51\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_52\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_53\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_54\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_55\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_56\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n## 排名概述",
      "russian": "# Сортировка и ранжирование\n\nРезультаты запроса могут быть отсортированы по весу полнотекстового ранжирования, одному или нескольким атрибутам или выражениям.\n\n**Полнотекстовые** запросы возвращают совпадения, отсортированные по умолчанию. Если ничего не указано, они сортируются по релевантности, что эквивалентно `ORDER BY weight() DESC` в формате SQL.\n\n**Не полнотекстовые** запросы по умолчанию не выполняют никакой сортировки.\n\n## Расширенная сортировка\n\nРасширенный режим автоматически включается, когда вы явно задаёте правила сортировки, добавляя к запросу `ORDER BY` в формате SQL или используя опцию `sort` через HTTP JSON.\n\n### Сортировка через SQL\n\nОбщий синтаксис:\n\nCODE_BLOCK_0\n\n<!-- example alias -->\n\nВ клаузе сортировки можно использовать любую комбинацию до 5 столбцов, за каждым из которых следует `asc` или `desc`. Функции и выражения не допускаются в качестве аргументов для клаузулы сортировки, за исключением функций `weight()` и `random()` (последняя может использоваться только через SQL в виде `ORDER BY random()`). Однако вы можете использовать любое выражение в списке SELECT и сортировать по его псевдониму.\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- response SQL -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n## Сортировка через JSON\n\n<!-- example sorting 1 -->\n\n`\"sort\"` задаёт массив, где каждый элемент может быть именем атрибута или `_score`, если вы хотите сортировать по весам совпадений, или `_random`, если хотите случайный порядок совпадений. В этом случае порядок сортировки по умолчанию — по возрастанию для атрибутов и по убыванию для `_score`.\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- response JSON -->\n\nCODE_BLOCK_4\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_5\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n<!-- example sorting 2 -->\n\nВы также можете явно указать порядок сортировки:\n\n* `asc`: сортировка по возрастанию\n\n* `desc`: сортировка по убыванию\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_14\n\n<!-- response JSON -->\n\nCODE_BLOCK_15\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_16\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_17\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n<!-- example sorting 3 -->\n\nВы также можете использовать другой синтаксис и указать порядок сортировки через свойство `order`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_25\n\n<!-- response JSON -->\n\nCODE_BLOCK_26\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_27\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_33\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_34\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n<!-- example sorting 4 -->\n\nСортировка по MVA-атрибутам также поддерживается в JSON-запросах. Режим сортировки можно задать через свойство `mode`. Поддерживаются следующие режимы:\n\n* `min`: сортировка по минимальному значению\n\n* `max`: сортировка по максимальному значению\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_36\n\n<!-- response JSON -->\n\nCODE_BLOCK_37\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_38\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_42\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_43\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_44\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n<!-- example sorting 5 -->\n\nПри сортировке по атрибуту вычисление веса совпадения (score) по умолчанию отключено (ранжировщик не используется). Вы можете включить вычисление веса, установив свойство `track_scores` в `true`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_47\n\n<!-- response JSON -->\n\nCODE_BLOCK_48\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_49\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_51\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_52\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_53\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_54\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_55\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_56\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n## Обзор ранжирования"
    },
    "is_code_or_comment": false
  },
  "a33e8769e291cba937f1ca48f86de604458f8d0b9957d605d5b5c088019dab82": {
    "original": "* `tf_idf` (float), the sum of TF/IDF over all the keywords matched in the field. IDF is the Inverse Document Frequency, a floating point value between 0 and 1 that describes how frequent the keyword is (basically, 0 for a keyword that occurs in every document indexed, and 1 for a unique keyword that occurs in just a single document). TF is the Term Frequency, the number of matched keyword occurrences in the field. As a side note, `tf_idf` is actually computed by summing IDF over all matched occurrences. That's by construction equivalent to summing TF*IDF over all matched keywords.\n\n* `min_hit_pos` (integer), the position of the first matched keyword occurrence, counted in words\n\n   Therefore, this is a relatively low-level, \"raw\" factor that you'll likely want to *adjust* before using it for ranking. The specific adjustments depend heavily on your data and the resulting formula, but here are a few ideas to start with: (a) any min_gaps-based boosts could be simply ignored when word_count<2;\n\n    (b) non-trivial min_gaps values (i.e., when word_count>=2) could be clamped with a certain \"worst-case\" constant, while trivial values (i.e., when min_gaps=0 and word_count<2) could be replaced by that constant;\n\n    (c) a transfer function like 1/(1+min_gaps) could be applied (so that better, smaller min_gaps values would maximize it, and worse, larger min_gaps values would fall off slowly); and so on.\n\n* `lccs` (integer). Longest Common Contiguous Subsequence. The length of the longest subphrase common between the query and the document, computed in keywords.\n\n    The LCCS factor is somewhat similar to LCS but more restrictive. While LCS can be greater than 1 even if no two query words are matched next to each other, LCCS will only be greater than 1 if there are *exact*, contiguous query subphrases in the document. For example, (one two three four five) query vs (one hundred three hundred five hundred) document would yield lcs=3, but lccs=1, because although the mutual dispositions of 3 keywords (one, three, five) match between the query and the document, no 2 matching positions are actually adjacent.\n\n    Note that LCCS still doesn't differentiate between frequent and rare keywords; for that, see WLCCS.\n\n* `wlccs` (float). Weighted Longest Common Contiguous Subsequence. The sum of IDFs of the keywords of the longest subphrase common between the query and the document.\n\n    WLCCS is calculated similarly to LCCS, but every \"suitable\" keyword occurrence increases it by the keyword IDF instead of just by 1 (as with LCS and LCCS). This allows ranking sequences of rarer and more important keywords higher than sequences of frequent keywords, even if the latter are longer. For example, a query `(Zanzibar bed and breakfast)` would yield lccs=1 for a `(hotels of Zanzibar)` document, but lccs=3 against `(London bed and breakfast)`, even though \"Zanzibar\" is actually somewhat rarer than the entire \"bed and breakfast\" phrase. The WLCCS factor addresses this issue by using keyword frequencies.\n\n* `atc` (float). Aggregate Term Closeness. A proximity-based measure that increases when the document contains more groups of more closely located and more important (rare) query keywords.\n\n    **WARNING:** you should use ATC with OPTION idf='plain,tfidf_unnormalized' (see [below](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); otherwise, you may get unexpected results.\n\n    ATC essentially operates as follows. For each keyword *occurrence* in the document, we compute the so-called *term closeness*. To do this, we examine all the other closest occurrences of all the query keywords (including the keyword itself) to the left and right of the subject occurrence, calculate a distance dampening coefficient as k = pow(distance, -1.75) for these occurrences, and sum the dampened IDFs. As a result, for every occurrence of each keyword, we obtain a \"closeness\" value that describes the \"neighbors\" of that occurrence. We then multiply these per-occurrence closenesses by their respective subject keyword IDF, sum them all, and finally compute a logarithm of that sum.\n\nIn other words, we process the best (closest) matched keyword pairs in the document, and compute pairwise \"closenesses\" as the product of their IDFs scaled by the distance coefficient:\n\nCODE_BLOCK_59\n\nWe then sum such closenesses, and compute the final, log-dampened ATC value:\n\nCODE_BLOCK_60\n\nNote that this final dampening logarithm is precisely the reason you should use OPTION idf=plain because, without it, the expression inside the log() could be negative.\n\nHaving closer keyword occurrences contributes *much* more to ATC than having more frequent keywords. Indeed, when the keywords are right next to each other, distance=1 and k=1; when there's just one word in between them, distance=2 and k=0.297, with two words between, distance=3 and k=0.146, and so on. At the same time, IDF attenuates somewhat slower. For example, in a 1 million document collection, the IDF values for keywords that match in 10, 100, and 1000 documents would be respectively 0.833, 0.667, and 0.500. So a keyword pair with two rather rare keywords that occur in just 10 documents each but with 2 other words in between would yield pair_tc = 0.101 and thus barely outweigh a pair with a 100-doc and a 1000-doc keyword with 1 other word between them and pair_tc = 0.099. Moreover, a pair of two *unique*, 1-doc keywords with 3 words between them would get a pair_tc = 0.088 and lose to a pair of two 1000-doc keywords located right next to each other and yielding a pair_tc = 0.25. So, basically, while ATC does combine both keyword frequency and proximity, it still somewhat favors proximity.\n\n### Ranking factor aggregation functions\n\nA **field aggregation function** is a single-argument function that accepts an expression with field-level factors, iterates over all matched fields, and computes the final results. The currently implemented field aggregation functions include:\n\n* `sum`, which adds the argument expression over all matched fields. For example `sum(1)` should return the number of matched fields.",
    "translations": {
      "chinese": "* `tf_idf` (浮点数)，字段中所有匹配关键词的 TF/IDF 之和。IDF 是逆文档频率，是一个介于 0 和 1 之间的浮点值，用来描述关键词的频率（基本上，对于出现在所有索引文档中的关键词，IDF 为 0；对于只出现在单个文档中的唯一关键词，IDF 为 1）。TF 是词频，表示字段中匹配关键词出现的次数。顺便提一下，`tf_idf` 实际上是通过对所有匹配出现的 IDF 求和计算得出的。这在构造上等同于对所有匹配关键词求和 TF*IDF。\n\n* `min_hit_pos` (整数)，第一个匹配关键词出现的位置，按词数计数\n\n   因此，这是一个相对低级的“原始”因子，您可能需要在用于排序之前对其进行*调整*。具体调整高度依赖于您的数据和最终公式，但这里有一些起点建议：（a）当 word_count<2 时，可以简单忽略任何基于 min_gaps 的提升；\n\n    （b）非平凡的 min_gaps 值（即 word_count>=2 时）可以用某个“最坏情况”常数进行限制，而平凡值（即 min_gaps=0 且 word_count<2 时）可以用该常数替代；\n\n    （c）可以应用类似 1/(1+min_gaps) 的传递函数（这样更好、更小的 min_gaps 值会使其最大化，而更差、更大的 min_gaps 值会缓慢下降）；等等。\n\n* `lccs` (整数)。最长公共连续子序列。查询和文档之间最长的公共子短语长度，以关键词计。\n\n    LCCS 因子与 LCS 有些相似，但更具限制性。虽然即使没有两个查询词相邻匹配，LCS 也可以大于 1，但只有当文档中存在*完全*连续的查询子短语时，LCCS 才会大于 1。例如，查询 `(one two three four five)` 与文档 `(one hundred three hundred five hundred)` 的 lcs=3，但 lccs=1，因为虽然三个关键词（one、three、five）在查询和文档中的相对位置匹配，但没有两个匹配位置是相邻的。\n\n    注意 LCCS 仍然不区分频繁和稀有关键词；有关这点，请参见 WLCCS。\n\n* `wlccs` (浮点数)。加权最长公共连续子序列。查询和文档之间最长公共子短语中关键词的 IDF 之和。\n\n    WLCCS 的计算方式类似于 LCCS，但每个“合适”的关键词出现会按关键词 IDF 增加，而不是像 LCS 和 LCCS 那样仅增加 1。这允许将稀有且更重要的关键词序列排名高于频繁关键词序列，即使后者更长。例如，查询 `(Zanzibar bed and breakfast)` 对文档 `(hotels of Zanzibar)` 的 lccs=1，但对 `(London bed and breakfast)` 的 lccs=3，尽管“Zanzibar”实际上比整个“bed and breakfast”短语更稀有。WLCCS 因子通过使用关键词频率解决了这个问题。\n\n* `atc` (浮点数)。聚合词语接近度。基于接近度的度量，当文档包含更多更紧密且更重要（稀有）的查询关键词组时，该值增加。\n\n    **警告：** 您应当使用 OPTION idf='plain,tfidf_unnormalized'（见[下文](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)）；否则，可能会得到意外结果。\n\n    ATC 的基本操作如下。对于文档中的每个关键词*出现*，计算所谓的*词语接近度*。为此，我们检查该出现左右两侧所有查询关键词的最近出现（包括该关键词本身），计算距离衰减系数 k = pow(distance, -1.75)，并对衰减后的 IDF 求和。结果是，对于每个关键词的每个出现，我们得到一个描述该出现“邻居”的“接近度”值。然后将这些每次出现的接近度乘以对应关键词的 IDF，求和后取对数。\n\n换句话说，我们处理文档中最佳（最近）的匹配关键词对，计算它们的成对“接近度”，即它们 IDF 的乘积乘以距离系数：\n\nCODE_BLOCK_59\n\n然后我们对这些接近度求和，并计算最终的对数衰减 ATC 值：\n\nCODE_BLOCK_60\n\n注意，这个最终的衰减对数正是您应使用 OPTION idf=plain 的原因，因为没有它，log() 内的表达式可能为负。\n\n关键词出现越接近，对 ATC 的贡献*远远*大于关键词出现越频繁。实际上，当关键词紧挨着时，distance=1，k=1；中间隔一个词时，distance=2，k=0.297；中间隔两个词时，distance=3，k=0.146，依此类推。与此同时，IDF 衰减较慢。例如，在一百万文档集合中，匹配 10、100 和 1000 个文档的关键词的 IDF 分别为 0.833、0.667 和 0.500。因此，一个由两个相当稀有的关键词组成的关键词对（每个只出现在 10 个文档中），但中间隔两个词，会产生 pair_tc = 0.101，几乎抵消了一个由一个匹配 100 个文档和一个匹配 1000 个文档的关键词组成的关键词对（中间隔一个词），其 pair_tc = 0.099。此外，一对两个*唯一*、只出现在 1 个文档中的关键词，中间隔三个词，pair_tc = 0.088，会输给一对两个紧挨着的匹配 1000 个文档的关键词，pair_tc = 0.25。因此，基本上，虽然 ATC 结合了关键词频率和接近度，但它仍然更偏向于接近度。\n\n### 排序因子聚合函数\n\n**字段聚合函数**是一个单参数函数，接受包含字段级因子的表达式，遍历所有匹配字段，并计算最终结果。目前实现的字段聚合函数包括：\n\n* `sum`，对所有匹配字段的参数表达式求和。例如，`sum(1)` 应返回匹配字段的数量。",
      "russian": "* `tf_idf` (float), сумма TF/IDF по всем ключевым словам, совпавшим в поле. IDF — это обратная частота документа, число с плавающей точкой от 0 до 1, описывающее, насколько часто встречается ключевое слово (по сути, 0 для ключевого слова, встречающегося в каждом проиндексированном документе, и 1 для уникального ключевого слова, встречающегося только в одном документе). TF — это частота термина, количество совпадений ключевого слова в поле. В качестве примечания, `tf_idf` фактически вычисляется суммированием IDF по всем совпавшим вхождениям. Это по конструкции эквивалентно суммированию TF*IDF по всем совпавшим ключевым словам.\n\n* `min_hit_pos` (integer), позиция первого совпавшего ключевого слова, считаемая в словах\n\n   Следовательно, это относительно низкоуровневый, «сырой» фактор, который, вероятно, вы захотите *скорректировать* перед использованием для ранжирования. Конкретные корректировки сильно зависят от ваших данных и итоговой формулы, но вот несколько идей для начала: (a) любые бусты на основе min_gaps можно просто игнорировать, если word_count<2;\n\n    (b) нетривиальные значения min_gaps (то есть когда word_count>=2) можно ограничить определённой «худшей» константой, в то время как тривиальные значения (то есть когда min_gaps=0 и word_count<2) можно заменить этой константой;\n\n    (c) можно применить функцию преобразования, например 1/(1+min_gaps) (чтобы лучшие, меньшие значения min_gaps максимизировали её, а худшие, большие значения min_gaps постепенно уменьшали); и так далее.\n\n* `lccs` (integer). Длина самой длинной общей непрерывной подпоследовательности. Длина самой длинной общей подфразы между запросом и документом, вычисленная в ключевых словах.\n\n    Фактор LCCS несколько похож на LCS, но более строгий. В то время как LCS может быть больше 1, даже если ни два слова запроса не совпадают рядом друг с другом, LCCS будет больше 1 только если в документе есть *точные*, непрерывные подфразы запроса. Например, запрос (one two three four five) и документ (one hundred three hundred five hundred) дадут lcs=3, но lccs=1, потому что, хотя взаимное расположение 3 ключевых слов (one, three, five) совпадает между запросом и документом, ни две совпадающие позиции фактически не соседствуют.\n\n    Обратите внимание, что LCCS всё ещё не различает частые и редкие ключевые слова; для этого смотрите WLCCS.\n\n* `wlccs` (float). Взвешенная длина самой длинной общей непрерывной подпоследовательности. Сумма IDF ключевых слов самой длинной общей подфразы между запросом и документом.\n\n    WLCCS вычисляется аналогично LCCS, но каждое «подходящее» вхождение ключевого слова увеличивает его на IDF ключевого слова, а не просто на 1 (как в LCS и LCCS). Это позволяет ранжировать последовательности более редких и важных ключевых слов выше, чем последовательности частых ключевых слов, даже если последние длиннее. Например, запрос `(Zanzibar bed and breakfast)` даст lccs=1 для документа `(hotels of Zanzibar)`, но lccs=3 для `(London bed and breakfast)`, хотя «Zanzibar» на самом деле несколько реже, чем вся фраза «bed and breakfast». Фактор WLCCS решает эту проблему, используя частоты ключевых слов.\n\n* `atc` (float). Aggregate Term Closeness. Мера близости, основанная на расположении, которая увеличивается, когда в документе содержится больше групп более близко расположенных и более важных (редких) ключевых слов запроса.\n\n    **ВНИМАНИЕ:** следует использовать ATC с OPTION idf='plain,tfidf_unnormalized' (см. [ниже](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); иначе вы можете получить неожиданные результаты.\n\n    ATC работает следующим образом. Для каждого вхождения ключевого слова в документе вычисляется так называемая *близость термина*. Для этого рассматриваются все другие ближайшие вхождения всех ключевых слов запроса (включая само ключевое слово) слева и справа от рассматриваемого вхождения, вычисляется коэффициент затухания расстояния как k = pow(distance, -1.75) для этих вхождений, и суммируются затухающие IDF. В результате для каждого вхождения каждого ключевого слова получается значение «близости», описывающее «соседей» этого вхождения. Затем эти значения близости для каждого вхождения умножаются на соответствующий IDF ключевого слова, суммируются, и в конце вычисляется логарифм этой суммы.\n\nДругими словами, мы обрабатываем лучшие (ближайшие) пары совпавших ключевых слов в документе и вычисляем попарные «близости» как произведение их IDF, масштабированное коэффициентом расстояния:\n\nCODE_BLOCK_59\n\nЗатем мы суммируем такие близости и вычисляем итоговое, логарифмически затухающее значение ATC:\n\nCODE_BLOCK_60\n\nОбратите внимание, что именно этот финальный затухающий логарифм является причиной, по которой следует использовать OPTION idf=plain, потому что без него выражение внутри log() может быть отрицательным.\n\nБолее близкие вхождения ключевых слов вносят *гораздо* больший вклад в ATC, чем более частые ключевые слова. Действительно, когда ключевые слова находятся рядом, distance=1 и k=1; если между ними одно слово, distance=2 и k=0.297, при двух словах между ними distance=3 и k=0.146 и так далее. При этом IDF затухает несколько медленнее. Например, в коллекции из 1 миллиона документов значения IDF для ключевых слов, совпадающих в 10, 100 и 1000 документах, будут соответственно 0.833, 0.667 и 0.500. Таким образом, пара ключевых слов с двумя довольно редкими ключевыми словами, встречающимися всего в 10 документах каждое, но с двумя словами между ними, даст pair_tc = 0.101 и едва превзойдёт пару с ключевыми словами из 100 и 1000 документов с одним словом между ними и pair_tc = 0.099. Более того, пара из двух *уникальных*, встречающихся в 1 документе ключевых слов с тремя словами между ними получит pair_tc = 0.088 и проиграет паре из двух ключевых слов из 1000 документов, расположенных рядом, с pair_tc = 0.25. Таким образом, в целом, хотя ATC и сочетает частоту ключевых слов и близость, он всё же несколько отдаёт предпочтение близости.\n\n### Функции агрегации факторов ранжирования\n\n**Функция агрегации по полю** — это функция с одним аргументом, которая принимает выражение с факторами на уровне поля, перебирает все совпавшие поля и вычисляет итоговые результаты. В настоящее время реализованы следующие функции агрегации по полю:\n\n* `sum`, которая суммирует аргумент по всем совпавшим полям. Например, `sum(1)` должна возвращать количество совпавших полей."
    },
    "is_code_or_comment": false
  },
  "22c0f9fe9ae33a0adc3902661e4694f7c1c391482207c2babb1bbd1122db88a3": {
    "original": "A **field aggregation function** is a single-argument function that accepts an expression with field-level factors, iterates over all matched fields, and computes the final results. The currently implemented field aggregation functions include:\n\n* `sum`, which adds the argument expression over all matched fields. For example `sum(1)` should return the number of matched fields.\n\n* `top`, which returns the highest value of the argument across all matched fields.\n\n* `max_window_hits`, manages a sliding window of hit positions to track the maximum number of hits within a specified window size. It removes outdated hits that fall outside the window and adds the latest hit, updating the maximum number of hits found within that window.\n\n### Formula expressions for all the built-in rankers\n\nMost other rankers can actually be emulated using the expression-based ranker. You just need to provide an appropriate expression. While this emulation will likely be slower than using the built-in, compiled ranker, it may still be interesting if you want to fine-tune your ranking formula starting with one of the existing ones. Additionally, the formulas describe the ranker details in a clear, readable manner.\n\n* proximity_bm25 (default ranker) = `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### Configuration of IDF formula\n\nThe historically default IDF (Inverse Document Frequency) in Manticore is equivalent to `OPTION idf='normalized,tfidf_normalized'`, and those normalizations may cause several undesired effects.\n\nFirst, `idf=normalized` causes keyword penalization. For instance, if you search for `the | something` and `the` occurs in more than 50% of the documents, then documents with both keywords `the` and`[something` will get less weight than documents with just one keyword  `something`. Using `OPTION idf=plain` avoids this.\n\nPlain IDF varies in `[0, log(N)]` range, and keywords are never penalized; while the normalized IDF varies in `[-log(N), log(N)]` range, and too frequent keywords are penalized.\n\nSecond, `idf=tfidf_normalized` causes IDF drift over queries. Historically, we additionally divided IDF by query keyword count, so that the entire `sum(tf*idf)` over all keywords would still fit into `[0,1]` range. However, that means that queries `word1` and `word1 | nonmatchingword2` would assign different weights to the exactly same result set, because the IDFs for both `word1` and `nonmatchingword2` would be divided by 2. `OPTION idf='tfidf_unnormalized'` fixes that. Note that BM25, BM25A, BM25F() ranking factors will be scale accordingly  once you disable this normalization.\n\nIDF flags can be mixed; `plain` and `normalized` are mutually exclusive;`tfidf_unnormalized` and `tfidf_normalized` are mutually exclusive; and unspecified flags in such a mutually exclusive group take their defaults. That means that `OPTION idf=plain` is equivalent to a complete `OPTION idf='plain,tfidf_normalized'` specification.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "一个**字段聚合函数**是一个单参数函数，接受带有字段级因子的表达式，遍历所有匹配的字段，并计算最终结果。当前已实现的字段聚合函数包括：\n\n* `sum`，它将参数表达式在所有匹配的字段上相加。例如 `sum(1)` 应返回匹配字段的数量。\n\n* `top`，它返回所有匹配字段中参数的最高值。\n\n* `max_window_hits`，管理命中位置的滑动窗口，以跟踪指定窗口大小内的最大命中数。它移除落在窗口外的过时命中，并添加最新命中，更新在该窗口内找到的最大命中数。\n\n### 所有内置排名器的公式表达式\n\n大多数其他排名器实际上可以使用基于表达式的排名器模拟。您只需提供适当的表达式。虽然这种模拟可能比使用内置的编译排名器慢，但如果您想从现有排名器开始微调排名公式，这仍可能很有趣。此外，这些公式以清晰、可读的方式描述了排名器的细节。\n\n* proximity_bm25（默认排名器）= `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### IDF公式的配置\n\nManticore中历史上默认的IDF（逆文档频率）等同于 `OPTION idf='normalized,tfidf_normalized'`，这些归一化可能会导致几个不期望的效果。\n\n首先，`idf=normalized`会导致关键词惩罚。例如，如果您搜索 `the | something`，且 `the` 出现在超过50%的文档中，那么同时包含关键词 `the` 和 `something` 的文档将比只包含关键词 `something` 的文档权重更低。使用 `OPTION idf=plain` 可以避免这种情况。\n\n普通IDF在 `[0, log(N)]` 范围内变化，关键词不会被惩罚；而归一化IDF在 `[-log(N), log(N)]` 范围内变化，过于频繁的关键词会被惩罚。\n\n其次，`idf=tfidf_normalized`会导致查询间IDF漂移。历史上，我们额外将IDF除以查询关键词数量，以便所有关键词的 `sum(tf*idf)` 仍然保持在 `[0,1]` 范围内。然而，这意味着查询 `word1` 和 `word1 | nonmatchingword2` 会为完全相同的结果集分配不同的权重，因为 `word1` 和 `nonmatchingword2` 的IDF都会被除以2。`OPTION idf='tfidf_unnormalized'` 修复了这个问题。请注意，一旦禁用此归一化，BM25、BM25A、BM25F()排名因子将相应缩放。\n\nIDF标志可以混合使用；`plain` 和 `normalized` 是互斥的；`tfidf_unnormalized` 和 `tfidf_normalized` 是互斥的；而在这种互斥组中未指定的标志将采用其默认值。这意味着 `OPTION idf=plain` 等同于完整的 `OPTION idf='plain,tfidf_normalized'` 规范。\n\n<!-- proofread -->",
      "russian": "**Функция агрегации поля** - это функция с одним аргументом, которая принимает выражение с факторами на уровне полей, выполняет итерацию по всем совпадающим полям и вычисляет окончательные результаты. В настоящее время реализованы следующие функции агрегации полей:\n\n* `sum`, который суммирует аргумент-выражение по всем совпадающим полям. Например, `sum(1)` должен вернуть количество совпадающих полей.\n\n* `top`, который возвращает наивысшее значение аргумента по всем совпадающим полям.\n\n* `max_window_hits`, управляет скользящим окном позиций попаданий для отслеживания максимального количества попаданий в пределах указанного размера окна. Он удаляет устаревшие попадания, выходящие за пределы окна, и добавляет последнее попадание, обновляя максимальное количество найденных попаданий в этом окне.\n\n### Формульные выражения для всех встроенных ранжировщиков\n\nБольшинство других ранжировщиков на самом деле можно эмулировать с помощью ранжировщика на основе выражений. Вам просто нужно предоставить соответствующее выражение. Хотя эта эмуляция, вероятно, будет медленнее, чем использование встроенного скомпилированного ранжировщика, она может быть интересна, если вы хотите тонко настроить формулу ранжирования, начав с одной из существующих. Кроме того, формулы четко и понятно описывают детали ранжировщика.\n\n* proximity_bm25 (ранжировщик по умолчанию) = `sum(lcs*user_weight)*1000+bm25`\n\n* bm25 = `sum(user_weight)*1000+bm25`\n\n* none = `1`\n\n* wordcount = `sum(hit_count*user_weight)`\n\n* proximity = `sum(lcs*user_weight)`\n\n* matchany = `sum((word_count+(lcs-1)*max_lcs)*user_weight)`\n\n* fieldmask = `field_mask`\n\n* sph04 = `sum((4*lcs+2*(min_hit_pos==1)+exact_hit)*user_weight)*1000+bm25`\n\n### Конфигурация формулы IDF\n\nИсторически используемый по умолчанию IDF (обратная частота документа) в Manticore эквивалентен `OPTION idf='normalized,tfidf_normalized'`, и эти нормализации могут вызывать несколько нежелательных эффектов.\n\nВо-первых, `idf=normalized` вызывает штрафование ключевых слов. Например, при поиске `the | something`, если `the` встречается более чем в 50% документов, то документы с обоими ключевыми словами `the` и `something` получат меньший вес, чем документы только с одним ключевым словом `something`. Использование `OPTION idf=plain` позволяет избежать этого.\n\nПростой IDF варьируется в диапазоне `[0, log(N)]`, и ключевые слова никогда не штрафуются; в то время как нормализованный IDF варьируется в диапазоне `[-log(N), log(N)]`, и слишком частые ключевые слова штрафуются.\n\nВо-вторых, `idf=tfidf_normalized` вызывает дрейф IDF между запросами. Исторически мы дополнительно делили IDF на количество ключевых слов запроса, чтобы общая сумма `sum(tf*idf)` по всем ключевым словам всё ещё укладывалась в диапазон `[0,1]`. Однако это означает, что запросы `word1` и `word1 | nonmatchingword2` будут присваивать разные веса одному и тому же набору результатов, потому что IDF для обоих `word1` и `nonmatchingword2` будут делиться на 2. `OPTION idf='tfidf_unnormalized'` исправляет это. Обратите внимание, что факторы ранжирования BM25, BM25A, BM25F() будут масштабироваться соответственно после отключения этой нормализации.\n\nФлаги IDF можно смешивать; `plain` и `normalized` являются взаимоисключающими; `tfidf_unnormalized` и `tfidf_normalized` являются взаимоисключающими; а неуказанные флаги в таких взаимоисключающих группах принимают значения по умолчанию. Это означает, что `OPTION idf=plain` эквивалентен полной спецификации `OPTION idf='plain,tfidf_normalized'`.\n\n<!-- проверено -->"
    },
    "is_code_or_comment": false
  },
  "ca642053e257a36e92934e3190ee31aedc02ca782ca0c9243984959bd87f6168": {
    "original": "| tf_idf                  | field     | float | sum(tf*idf) over matched keywords == sum(idf) over occurrences                                                     |\n\n| min_hit_pos             | field     | int   | first matched occurrence position, in words, 1-based                                                               |\n\n| min_best_span_pos       | field     | int   | first maximum LCS span position, in words, 1-based                                                                 |\n\n| exact_hit               | field     | bool  | whether query == field                                                                                             |\n\n| min_idf                 | field     | float | min(idf) over matched keywords                                                                                     |\n\n| max_idf                 | field     | float | max(idf) over matched keywords                                                                                     |\n\n| sum_idf                 | field     | float | sum(idf) over matched keywords                                                                                     |\n\n| exact_order             | field     | bool  | whether all query keywords were a) matched and b) in query order                                                   |\n\n| min_gaps                | field     | int   | minimum number of gaps between the matched keywords over the matching spans                                        |\n\n| lccs                    | field     | int   | Longest Common Contiguous Subsequence between query and document, in words                                         |\n\n| wlccs                   | field     | float | Weighted Longest Common Contiguous Subsequence, sum(idf) over contiguous keyword spans                            |\n\n| atc                     | field     | float | Aggregate Term Closeness, log(1+sum(idf1*idf2*pow(distance, -1.75)) over the best pairs of keywords               |\n\nNote: For queries using **Phrase**, **Proximity**, or **NEAR** operators with more than 31 keywords, ranking factors that rely on term frequency (like `tf`, `idf`, `bm25`, `hit_count`, `word_count`) may be under-counted for keywords at position 31 and above. This is due to an internal 32-bit mask used to track term occurrences in these complex operators.\n\n### Document-level Ranking Factors\n\nA **document-level factor** is a numeric value computed by the ranking engine for every matched document with regards to the current query. So it differs from a plain document attribute in that the attribute does not depend on the full text query, while factors might. These factors can be used anywhere in the ranking expression. Currently implemented document-level factors are:\n\n* `bm25` (integer), a document-level BM25 estimate (computed without keyword occurrence filtering).\n\n* `max_lcs` (integer), a query-level maximum possible value that the `sum(lcs*user_weight)` expression can ever take. This can be useful for weight boost scaling. For instance, `MATCHANY` ranker formula uses this to guarantee that a full phrase match in any field ranks higher than any combination of partial matches in all fields.\n\n* `field_mask` (integer), a document-level 32-bit mask of matched fields.\n\n* `query_word_count` (integer), the number of unique keywords in a query, adjusted for the number of excluded keywords. For instance, both `(one one one one)` and `(one !two)` queries should assign a value of 1 to this factor, because there is just one unique non-excluded keyword.\n\n* `doc_word_count` (integer), the number of unique keywords matched in the entire document.\n\n### Field-level Ranking Factors\n\nA **field-level factor** is a numeric value computed by the ranking engine for every matched in-document text field regards to the current query. As more than one field can be matched by a query, but the final weight needs to be a single integer value, these values need to be folded into a single one. To achieve that, field-level factors can only be used within a field aggregation function, they can **not** be used anywhere in the expression. For example, you cannot use `(lcs+bm25)` as your ranking expression, as `lcs` takes multiple values (one in every matched field). You should use `(sum(lcs)+bm25)` instead, that expression sums `lcs` over all matching fields, and then adds `bm25` to that per-field sum. Currently implemented field-level factors are:\n\n* `lcs` (integer), the length of a maximum verbatim match between the document and the query, counted in words. LCS stands for Longest Common Subsequence (or Subset). Takes a minimum value of 1 when only stray keywords were matched in a field, and a maximum value of query keywords count when the entire query was matched in a field verbatim (in the exact query keywords order). For example, if the query is 'hello world' and the field contains these two words quoted from the query (that is, adjacent to each other, and exactly in the query order), `lcs` will be 2. For example, if the query is 'hello world program' and the field contains 'hello world', `lcs` will be 2. Note that any subset of the query keyword works, not just a subset of adjacent keywords. For example, if the query is 'hello world program' and the field contains 'hello (test program)', `lcs` will be 2 just as well, because both 'hello' and 'program' matched in the same respective positions as they were in the query. Finally, if the query is 'hello world program' and the field contains 'hello world program', `lcs` will be 3. (Hopefully that is unsurprising at this point.)\n\n* `user_weight` (integer), the user specified per-field weight (refer to [OPTION field_weights](../Searching/Options.md#field_weights) in SQL). The weights default to 1 if not specified explicitly.\n\n* `hit_count` (integer), the number of keyword occurrences that matched in the field. Note that a single keyword may occur multiple times. For example, if 'hello' occurs 3 times in a field and 'world' occurs 5 times, `hit_count` will be 8.",
    "translations": {
      "chinese": "| tf_idf                  | 字段     | 浮点型 | 匹配关键词的 tf*idf 之和 == 出现次数的 idf 之和                                                     |\n\n| min_hit_pos             | 字段     | 整型   | 第一个匹配出现的位置，以词为单位，从1开始                                                               |\n\n| min_best_span_pos       | 字段     | 整型   | 第一个最大LCS跨度的位置，以词为单位，从1开始                                                                 |\n\n| exact_hit               | 字段     | 布尔型  | 查询是否 == 字段                                                                                             |\n\n| min_idf                 | 字段     | 浮点型 | 匹配关键词的最小 idf                                                                                     |\n\n| max_idf                 | 字段     | 浮点型 | 匹配关键词的最大 idf                                                                                     |\n\n| sum_idf                 | 字段     | 浮点型 | 匹配关键词的 idf 之和                                                                                     |\n\n| exact_order             | 字段     | 布尔型  | 查询关键词是否a) 全部匹配且 b) 按查询顺序                                                   |\n\n| min_gaps                | 字段     | 整型   | 匹配跨度中关键词之间的最小间隔数                                        |\n\n| lccs                    | 字段     | 整型   | 查询和文档之间的最长连续公共子序列，以词为单位                                         |\n\n| wlccs                   | 字段     | 浮点型 | 加权最长连续公共子序列，连续关键词跨度的 idf 之和                            |\n\n| atc                     | 字段     | 浮点型 | 聚合词项接近度，log(1+sum(idf1*idf2*pow(距离, -1.75)) 在最佳关键词对上               |\n\n注意：对于使用**短语**、**邻近**或**NEAR**运算符且关键词超过31个的查询，依赖词频的排名因子（如 `tf`、`idf`、`bm25`、`hit_count`、`word_count`）可能会对第31个及以上位置的关键词进行低估。这是由于内部使用了32位掩码来跟踪这些复杂运算符中的词项出现情况。\n\n### 文档级排名因子\n\n**文档级因子**是排名引擎为每个匹配文档针对当前查询计算的数值。因此它不同于普通文档属性，属性不依赖于全文查询，而因子可能会依赖。这些因子可以在排名表达式的任何位置使用。目前实现的文档级因子包括：\n\n* `bm25`（整型），文档级BM25估计（不进行关键词出现过滤）。\n\n* `max_lcs`（整型），查询级可能的最大值，`sum(lcs*user_weight)`表达式可能达到的值。这可用于权重提升缩放。例如，`MATCHANY`排名器公式使用此值以确保任何字段中的完全短语匹配都高于所有字段中任何部分匹配的组合。\n\n* `field_mask`（整型），匹配字段的32位掩码。\n\n* `query_word_count`（整型），查询中唯一关键词的数量，根据排除的关键词数量进行调整。例如，`(one one one one)`和`(one !two)`查询都应赋值为1，因为只有一个唯一的非排除关键词。\n\n* `doc_word_count`（整型），在整个文档中匹配的唯一关键词数量。\n\n### 字段级排名因子\n\n**字段级因子**是排名引擎为每个匹配的文档内文本字段针对当前查询计算的数值。由于可能有多个字段匹配查询，但最终权重需要是单一整型值，这些值需要折叠为单一值。为实现这一点，字段级因子只能在字段聚合函数中使用，**不能**在表达式的任何位置使用。例如，不能使用`(lcs+bm25)`作为排名表达式，因为`lcs`有多个值（每个匹配字段一个）。应使用`(sum(lcs)+bm25)`，该表达式对所有匹配字段的`lcs`求和，然后将`bm25`加到每字段和上。目前实现的字段级因子包括：\n\n* `lcs`（整型），文档和查询之间最大逐字匹配的长度，以词计算。LCS代表最长公共子序列（或子集）。当仅匹配零散关键词时取最小值1，当整个查询以精确查询关键词顺序在字段中逐字匹配时取最大值（查询关键词数量）。例如，如果查询是'hello world'且字段包含从查询直接引用的这两个词（即相邻且完全按查询顺序），`lcs`将为2。如果查询是'hello world program'且字段包含'hello world'，`lcs`将为2。注意，查询关键词的任何子集都可以匹配，不仅限于相邻关键词。例如，如果查询是'hello world program'且字段包含'hello (test program)'，`lcs`也将为2，因为'hello'和'program'分别在查询中的相同位置匹配。最后，如果查询是'hello world program'且字段包含'hello world program'，`lcs`将为3。（希望这一点此时已经不足为奇了。）\n\n* `user_weight`（整型），用户指定的每字段权重（参考[OPTION field_weights](../Searching/Options.md#field_weights)中的SQL）。如果未明确指定，权重默认为1。\n\n* `hit_count`（整型），字段中匹配的关键词出现次数。注意单个关键词可能出现多次。例如，如果'hello'在字段中出现3次，'world'出现5次，`hit_count`将为8。",
      "russian": "| tf_idf                  | поле     | число с плавающей точкой | сумма(tf*idf) по совпавшим ключевым словам == сумма(idf) по вхождениям                                                     |\n\n| min_hit_pos             | поле     | целое   | позиция первого совпадения, в словах, с базы 1                                                               |\n\n| min_best_span_pos       | поле     | целое   | позиция первого максимального диапазона LCS, в словах, с базы 1                                                                 |\n\n| exact_hit               | поле     | булево  | равен ли запрос полю                                                                                             |\n\n| min_idf                 | поле     | число с плавающей точкой | мин(idf) по совпавшим ключевым словам                                                                                     |\n\n| max_idf                 | поле     | число с плавающей точкой | макс(idf) по совпавшим ключевым словам                                                                                     |\n\n| sum_idf                 | поле     | число с плавающей точкой | сумма(idf) по совпавшим ключевым словам                                                                                     |\n\n| exact_order             | поле     | булево  | были ли все ключевые слова запроса a) совпавшими и b) в порядке запроса                                                   |\n\n| min_gaps                | поле     | целое   | минимальное количество разрывов между совпавшими ключевыми словами в диапазонах совпадения                                        |\n\n| lccs                    | поле     | целое   | Длина самой длинной общей непрерывной подпоследовательности между запросом и документом, в словах                                         |\n\n| wlccs                   | поле     | число с плавающей точкой | Взвешенная самая длинная общая непрерывная подпоследовательность, сумма(idf) по непрерывным диапазонам ключевых слов                            |\n\n| atc                     | поле     | число с плавающей точкой | Агрегированная близость терминов, log(1+сумма(idf1*idf2*pow(расстояние, -1.75)) по лучшим парам ключевых слов               |\n\nПримечание: Для запросов с использованием операторов **Phrase**, **Proximity** или **NEAR** с более чем 31 ключевыми словами, факторы ранжирования, зависящие от частоты термина (такие как `tf`, `idf`, `bm25`, `hit_count`, `word_count`), могут быть занижены для ключевых слов в позиции 31 и выше. Это связано с внутренней 32-битной маской, используемой для отслеживания вхождений терминов в этих сложных операторах.\n\n### Факторы ранжирования на уровне документа\n\n**Фактор на уровне документа** - это числовое значение, вычисляемое механизмом ранжирования для каждого совпавшего документа относительно текущего запроса. Таким образом, он отличается от обычного атрибута документа тем, что атрибут не зависит от полнотекстового запроса, в то время как факторы могут зависеть. Эти факторы могут использоваться в любом месте выражения ранжирования. В настоящее время реализованы следующие факторы на уровне документа:\n\n* `bm25` (целое), оценка BM25 на уровне документа (вычисленная без фильтрации вхождений ключевых слов).\n\n* `max_lcs` (целое), максимальное возможное значение на уровне запроса, которое может принять выражение `sum(lcs*user_weight)`. Это может быть полезно для масштабирования усиления веса. Например, формула ранжера `MATCHANY` использует это, чтобы гарантировать, что полное совпадение фразы в любом поле ранжируется выше, чем любая комбинация частичных совпадений во всех полях.\n\n* `field_mask` (целое), 32-битная маска совпавших полей на уровне документа.\n\n* `query_word_count` (целое), количество уникальных ключевых слов в запросе, скорректированное на количество исключенных ключевых слов. Например, как запрос `(one one one one)`, так и `(one !two)` должны присваивать этому фактору значение 1, потому что есть только одно уникальное неисключенное ключевое слово.\n\n* `doc_word_count` (целое), количество уникальных ключевых слов, совпавших во всем документе.\n\n### Факторы ранжирования на уровне полей\n\n**Фактор на уровне полей** - это числовое значение, вычисляемое механизмом ранжирования для каждого совпавшего текстового поля документа относительно текущего запроса. Поскольку более одного поля может быть совпавшим запросом, но итоговый вес должен быть одним целым значением, эти значения должны быть объединены в одно. Для этого факторы на уровне полей могут использоваться только внутри функции агрегации полей, они **не могут** использоваться где угодно в выражении. Например, нельзя использовать `(lcs+bm25)` в качестве выражения ранжирования, так как `lcs` имеет несколько значений (по одному в каждом совпавшем поле). Вместо этого следует использовать `(sum(lcs)+bm25)`, это выражение суммирует `lcs` по всем совпавшим полям, а затем добавляет `bm25` к этой сумме по полям. В настоящее время реализованы следующие факторы на уровне полей:\n\n* `lcs` (целое), длина максимального дословного совпадения между документом и запросом, подсчитанная в словах. LCS означает Longest Common Subsequence (или Subset). Принимает минимальное значение 1, когда были совпадены только отдельные ключевые слова в поле, и максимальное значение равное количеству ключевых слов запроса, когда весь запрос был совпавшим в поле дословно (в точном порядке ключевых слов запроса). Например, если запрос - 'hello world', и поле содержит эти два слова, процитированные из запроса (то есть рядом друг с другом и точно в порядке запроса), `lcs` будет равен 2. Например, если запрос - 'hello world program', и поле содержит 'hello world', `lcs` будет равен 2. Обратите внимание, что работает любое подмножество ключевых слов запроса, а не только подмножество смежных ключевых слов. Например, если запрос - 'hello world program', и поле содержит 'hello (test program)', `lcs` будет 2 так же, потому что и 'hello', и 'program' совпали в тех же соответственных позициях, что и в запросе. Наконец, если запрос - 'hello world program', и поле содержит 'hello world program', `lcs` будет 3. (Надеюсь, это неудивительно к этому моменту.)\n\n* `user_weight` (целое), указанный пользователем вес для каждого поля (см. [OPTION field_weights](../Searching/Options.md#field_weights) в SQL). Веса по умолчанию равны 1, если не указаны явно.\n\n* `hit_count` (целое), количество вхождений ключевых слов, совпавших в поле. Обратите внимание, что одно ключевое слово может встречаться несколько раз. Например, если 'hello' встречается 3 раза в поле и 'world' - 5 раз, `hit_count` будет 8."
    },
    "is_code_or_comment": false
  },
  "479426cf593446aa34540ea4a525d7a7598a92be643dc4f2bdfe196b3cc78732": {
    "original": "* `word_count` (integer), the number of unique keywords matched in the field. For example, if 'hello' and 'world' occur anywhere in a field, `word_count` will be 2, regardless of how many times both keywords occur.\n\n* `tf_idf` (float), the sum of TF/IDF over all the keywords matched in the field. IDF is the Inverse Document Frequency, a floating point value between 0 and 1 that describes how frequent the keyword is (basically, 0 for a keyword that occurs in every document indexed, and 1 for a unique keyword that occurs in just a single document). TF is the Term Frequency, the number of matched keyword occurrences in the field. As a side note, `tf_idf` is actually computed by summing IDF over all matched occurrences. That's by construction equivalent to summing TF*IDF over all matched keywords.\n\n* `min_hit_pos` (integer), the position of the first matched keyword occurrence, counted in words\n\n   Therefore, this is a relatively low-level, \"raw\" factor that you'll likely want to *adjust* before using it for ranking. The specific adjustments depend heavily on your data and the resulting formula, but here are a few ideas to start with: (a) any min_gaps-based boosts could be simply ignored when word_count<2;\n\n    (b) non-trivial min_gaps values (i.e., when word_count>=2) could be clamped with a certain \"worst-case\" constant, while trivial values (i.e., when min_gaps=0 and word_count<2) could be replaced by that constant;\n\n    (c) a transfer function like 1/(1+min_gaps) could be applied (so that better, smaller min_gaps values would maximize it, and worse, larger min_gaps values would fall off slowly); and so on.\n\n* `lccs` (integer). Longest Common Contiguous Subsequence. The length of the longest subphrase common between the query and the document, computed in keywords.\n\n    The LCCS factor is somewhat similar to LCS but more restrictive. While LCS can be greater than 1 even if no two query words are matched next to each other, LCCS will only be greater than 1 if there are *exact*, contiguous query subphrases in the document. For example, (one two three four five) query vs (one hundred three hundred five hundred) document would yield lcs=3, but lccs=1, because although the mutual dispositions of 3 keywords (one, three, five) match between the query and the document, no 2 matching positions are actually adjacent.\n\n    Note that LCCS still doesn't differentiate between frequent and rare keywords; for that, see WLCCS.\n\n* `wlccs` (float). Weighted Longest Common Contiguous Subsequence. The sum of IDFs of the keywords of the longest subphrase common between the query and the document.\n\n    WLCCS is calculated similarly to LCCS, but every \"suitable\" keyword occurrence increases it by the keyword IDF instead of just by 1 (as with LCS and LCCS). This allows ranking sequences of rarer and more important keywords higher than sequences of frequent keywords, even if the latter are longer. For example, a query `(Zanzibar bed and breakfast)` would yield lccs=1 for a `(hotels of Zanzibar)` document, but lccs=3 against `(London bed and breakfast)`, even though \"Zanzibar\" is actually somewhat rarer than the entire \"bed and breakfast\" phrase. The WLCCS factor addresses this issue by using keyword frequencies.\n\n* `atc` (float). Aggregate Term Closeness. A proximity-based measure that increases when the document contains more groups of more closely located and more important (rare) query keywords.\n\n    **WARNING:** you should use ATC with OPTION idf='plain,tfidf_unnormalized' (see [below](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); otherwise, you may get unexpected results.\n\n    ATC essentially operates as follows. For each keyword *occurrence* in the document, we compute the so-called *term closeness*. To do this, we examine all the other closest occurrences of all the query keywords (including the keyword itself) to the left and right of the subject occurrence, calculate a distance dampening coefficient as k = pow(distance, -1.75) for these occurrences, and sum the dampened IDFs. As a result, for every occurrence of each keyword, we obtain a \"closeness\" value that describes the \"neighbors\" of that occurrence. We then multiply these per-occurrence closenesses by their respective subject keyword IDF, sum them all, and finally compute a logarithm of that sum.\n\nIn other words, we process the best (closest) matched keyword pairs in the document, and compute pairwise \"closenesses\" as the product of their IDFs scaled by the distance coefficient:\n\nCODE_BLOCK_59\n\nWe then sum such closenesses, and compute the final, log-dampened ATC value:\n\nCODE_BLOCK_60\n\nNote that this final dampening logarithm is precisely the reason you should use OPTION idf=plain because, without it, the expression inside the log() could be negative.\n\nHaving closer keyword occurrences contributes *much* more to ATC than having more frequent keywords. Indeed, when the keywords are right next to each other, distance=1 and k=1; when there's just one word in between them, distance=2 and k=0.297, with two words between, distance=3 and k=0.146, and so on. At the same time, IDF attenuates somewhat slower. For example, in a 1 million document collection, the IDF values for keywords that match in 10, 100, and 1000 documents would be respectively 0.833, 0.667, and 0.500. So a keyword pair with two rather rare keywords that occur in just 10 documents each but with 2 other words in between would yield pair_tc = 0.101 and thus barely outweigh a pair with a 100-doc and a 1000-doc keyword with 1 other word between them and pair_tc = 0.099. Moreover, a pair of two *unique*, 1-doc keywords with 3 words between them would get a pair_tc = 0.088 and lose to a pair of two 1000-doc keywords located right next to each other and yielding a pair_tc = 0.25. So, basically, while ATC does combine both keyword frequency and proximity, it still somewhat favors proximity.\n\n### Ranking factor aggregation functions",
    "translations": {
      "chinese": "* `word_count`（整数），匹配字段中唯一关键词的数量。例如，如果'hello'和'world'在字段中的任何位置出现，`word_count`将为2，无论这两个关键词出现多少次。\n\n* `tf_idf`（浮点数），匹配字段中所有关键词的TF/IDF之和。IDF是逆文档频率，是介于0和1之间的浮点值，描述关键词的频率（基本上，对于出现在索引的每个文档中的关键词为0，对于仅出现在单个文档中的唯一关键词为1）。TF是词频，是字段中匹配关键词出现的次数。顺便说一下，`tf_idf`实际上是通过对所有匹配出现的IDF求和来计算的。这从构造上等同于对所有匹配关键词求TF*IDF的和。\n\n* `min_hit_pos`（整数），以单词计算的第一个匹配关键词出现的位置\n\n   因此，这是一个相对低级的\"原始\"因子，你可能需要在使用它进行排名之前进行*调整*。具体的调整取决于你的数据和最终的公式，但以下是一些起步的想法：(a) 当`word_count`<2时，可以简单地忽略任何基于min_gaps的提升；\n\n    (b) 对于非平凡的min_gaps值（即当`word_count`>=2时），可以用某个\"最坏情况\"常数进行截断，而对于平凡值（即当min_gaps=0且`word_count`<2时），可以用该常数替换；\n\n    (c) 可以应用类似1/(1+min_gaps)的传递函数（使得更好的、较小的min_gaps值会使其最大化，而更差的、较大的min_gaps值会缓慢下降）；等等。\n\n* `lccs`（整数）。最长公共连续子序列。查询和文档之间最长的公共子短语的长度，以关键词计算。\n\n    LCCS因子与LCS有些相似，但更加严格。虽然LCS即使没有两个查询词相邻也可能大于1，但LCCS只有在文档中存在*完全的*连续查询子短语时才会大于1。例如，(one two three four five)查询与(one hundred three hundred five hundred)文档会得到lcs=3，但lccs=1，因为尽管3个关键词（one, three, five）在查询和文档之间的相对位置相同，但实际上没有两个匹配位置相邻。\n\n    请注意，LCCS仍然无法区分频繁和罕见的关键词；对于这一点，请参见WLCCS。\n\n* `wlccs`（浮点数）。加权最长公共连续子序列。查询和文档之间最长子短语的关键词的IDF之和。\n\n    WLCCS的计算方式类似于LCCS，但每个\"合适的\"关键词出现会使其增加关键词的IDF，而不是像LCS和LCCS那样简单地加1。这使得能够对罕见和更重要的关键词序列进行更高的排名，即使它们比频繁关键词的序列更短。例如，查询`(Zanzibar bed and breakfast)`对于文档`(hotels of Zanzibar)`会得到lccs=1，而对于`(London bed and breakfast)`会得到lccs=3，尽管\"Zanzibar\"实际上比整个\"bed and breakfast\"短语更罕见。WLCCS因子通过使用关键词频率来解决这个问题。\n\n* `atc`（浮点数）。聚合词项接近度。一种基于接近度的度量，当文档包含更多更紧密定位且更重要（罕见）的查询关键词组时，其值会增加。\n\n    **警告：**你应该将ATC与OPTION idf='plain,tfidf_unnormalized'一起使用（见[下文](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)）；否则，你可能会得到意外的结果。\n\n    ATC基本上的工作原理如下。对于文档中的每个关键词*出现*，我们计算所谓的*词项接近度*。为此，我们检查主要出现位置左右所有查询关键词的最近其他出现位置，计算距离衰减系数k = pow(distance, -1.75)，并对这些出现位置求和衰减后的IDF。因此，对于每个关键词的每次出现，我们得到一个\"接近度\"值，描述该出现的\"邻居\"。然后我们将这些每次出现的接近度乘以其各自关键词的IDF，将它们全部求和，最后计算该和的对数。\n\n换句话说，我们处理文档中最佳（最近）的匹配关键词对，并计算成对的\"接近度\"，作为其IDF乘积并按距离系数缩放：\n\nCODE_BLOCK_59\n\n然后我们对这些接近度求和，并计算最终的对数衰减ATC值：\n\nCODE_BLOCK_60\n\n请注意，这个最终的衰减对数正是你应该使用OPTION idf=plain的原因，因为没有它，log()内的表达式可能是负数。\n\n更近的关键词出现对ATC的贡献*远远*多于更频繁的关键词。事实上，当关键词紧挨着时，distance=1且k=1；当它们之间只有一个词时，distance=2且k=0.297，两个词之间时，distance=3且k=0.146，以此类推。同时，IDF衰减得相对较慢。例如，在一个100万文档的集合中，匹配10、100和1000个文档的关键词的IDF值分别为0.833、0.667和0.500。所以，一对仅在10个文档中各出现一次但中间有2个其他词的相当罕见的关键词将产生pair_tc = 0.101，因此几乎可以与一对100个文档和1000个文档的关键词（中间有1个其他词）的pair_tc = 0.099相媲美。更重要的是，一对两个*唯一的*、1个文档的关键词（中间有3个词）将得到pair_tc = 0.088，输给一对1000个文档的关键词（紧挨着且pair_tc = 0.25）。因此，基本上，虽然ATC确实结合了关键词频率和接近度，但它仍然稍微偏好接近度。\n\n### 排名因子聚合函数",
      "russian": "* `word_count` (целое число), количество уникальных ключевых слов, совпавших в поле. Например, если 'привет' и 'мир' встречаются где-либо в поле, `word_count` будет равен 2, независимо от того, сколько раз встретились оба ключевых слова.\n\n* `tf_idf` (число с плавающей точкой), сумма TF/IDF по всем ключевым словам, совпавшим в поле. IDF - это обратная частота документа, значение с плавающей точкой между 0 и 1, которое описывает, насколько часто встречается ключевое слово (по сути, 0 для ключевого слова, встречающегося в каждом проиндексированном документе, и 1 для уникального ключевого слова, встречающегося только в одном документе). TF - это частота термина, количество вхождений ключевого слова в поле. Попутно отметим, что `tf_idf` фактически вычисляется путем суммирования IDF по всем совпавшим вхождениям. Это по определению эквивалентно суммированию TF*IDF по всем совпавшим ключевым словам.\n\n* `min_hit_pos` (целое число), позиция первого вхождения совпавшего ключевого слова, считается в словах\n\n   Таким образом, это относительно низкоуровневый, \"сырой\" фактор, который, скорее всего, вы захотите *скорректировать* перед использованием для ранжирования. Конкретные корректировки сильно зависят от ваших данных и результирующей формулы, но вот несколько идей для начала: (a) любые повышающие коэффициенты на основе min_gaps можно просто игнорировать, когда word_count<2;\n\n    (b) значения min_gaps, не являющиеся тривиальными (т.е. когда word_count>=2), можно ограничить определенной \"худшей\" константой, в то время как тривиальные значения (т.е. когда min_gaps=0 и word_count<2) можно заменить этой константой;\n\n    (c) можно применить передаточную функцию типа 1/(1+min_gaps) (чтобы лучшие, меньшие значения min_gaps максимизировали её, а худшие, большие значения снижались медленно); и так далее.\n\n* `lccs` (целое число). Longest Common Contiguous Subsequence (Самая длинная общая непрерывная подпоследовательность). Длина самой длинной общей подфразы между запросом и документом, вычисленная в ключевых словах.\n\n    Фактор LCCS somewhat похож на LCS, но более ограничен. Если LCS может быть больше 1 даже в том случае, если ни два слова запроса не совпадают рядом, то LCCS будет больше 1 только в том случае, если есть *точные*, смежные подфразы запроса в документе. Например, запрос (один два три четыре пять) и документ (один сто три сто пять сто) даст lcs=3, но lccs=1, потому что хотя взаимное расположение 3 ключевых слов (один, три, пять) совпадает между запросом и документом, никакие 2 совпадающие позиции фактически не смежны.\n\n    Обратите внимание, что LCCS все еще не различает частые и редкие ключевые слова; для этого см. WLCCS.\n\n* `wlccs` (число с плавающей точкой). Weighted Longest Common Contiguous Subsequence (Взвешенная самая длинная общая непрерывная подпоследовательность). Сумма IDF ключевых слов самой длинной общей подфразы между запросом и документом.\n\n    WLCCS рассчитывается аналогично LCCS, но каждое \"подходящее\" вхождение ключевого слова увеличивает его на IDF ключевого слова вместо простого увеличения на 1 (как в LCS и LCCS). Это позволяет выше ранжировать последовательности более редких и важных ключевых слов по сравнению с последовательностями частых ключевых слов, даже если последние длиннее. Например, запрос `(Занзибар постель и завтрак)` даст lccs=1 для документа `(отели Занзибара)`, но lccs=3 против `(Лондон постель и завтрак)`, даже несмотря на то, что \"Занзибар\" на самом деле немного реже, чем вся фраза \"постель и завтрак\". Фактор WLCCS решает эту проблему, используя частоты ключевых слов.\n\n* `atc` (число с плавающей точкой). Aggregate Term Closeness (Агрегированная близость термина). Мера близости, которая увеличивается, когда документ содержит больше групп более близко расположенных и более важных (редких) ключевых слов запроса.\n\n    **ПРЕДУПРЕЖДЕНИЕ:** вы должны использовать ATC с OPTION idf='plain,tfidf_unnormalized' (см. [ниже](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); в противном случае вы можете получить неожиданные результаты.\n\n    ATC, по существу, работает следующим образом. Для каждого *вхождения* ключевого слова в документе мы вычисляем так называемую *близость термина*. Для этого мы изучаем все ближайшие вхождения всех ключевых слов запроса (включая само ключевое слово) слева и справа от рассматриваемого вхождения, вычисляем коэффициент затухания расстояния как k = pow(расстояние, -1.75) для этих вхождений и суммируем затухающие IDF. В результате для каждого вхождения каждого ключевого слова мы получаем значение \"близости\", которое описывает \"соседей\" этого вхождения. Затем мы умножаем эти значения близости на соответствующий IDF ключевого слова, суммируем их все и, наконец, вычисляем логарифм этой суммы.\n\nИными словами, мы обрабатываем лучшие (ближайшие) совпавшие пары ключевых слов в документе и вычисляем попарную \"близость\" как произведение их IDF, масштабированное по коэффициенту расстояния:\n\nCODE_BLOCK_59\n\nЗатем мы суммируем такие близости и вычисляем окончательное, сглаженное логарифмом значение ATC:\n\nCODE_BLOCK_60\n\nОбратите внимание, что именно этот заключительный демпфирующий логарифм является точной причиной, по которой вам следует использовать OPTION idf=plain, потому что без него выражение внутри log() может быть отрицательным.\n\nБолее близкие вхождения ключевых слов вносят *гораздо* больший вклад в ATC, чем более частые ключевые слова. Действительно, когда ключевые слова находятся прямо рядом, расстояние=1 и k=1; когда между ними одно слово, расстояние=2 и k=0.297, с двумя словами между ними, расстояние=3 и k=0.146, и так далее. В то же время IDF затухает несколько медленнее. Например, в коллекции из 1 миллиона документов значения IDF для ключевых слов, совпадающих в 10, 100 и 1000 документах, будут соответственно 0.833, 0.667 и 0.500. Таким образом, пара ключевых слов с двумя довольно редкими ключевыми словами, встречающимися всего в 10 документах каждое, но с 2 другими словами между ними, даст pair_tc = 0.101 и едва перевесит пару с ключевым словом из 100 документов и ключевым словом из 1000 документов с 1 другим словом между ними и pair_tc = 0.099. Более того, пара из двух *уникальных*, встречающихся в 1 документе ключевых слов с 3 словами между ними получит pair_tc = 0.088 и проиграет паре ключевых слов из 1000 документов, расположенных прямо рядом и дающих pair_tc = 0.25. Таким образом, хотя ATC и объединяет частоту и близость ключевых слов, он все же несколько благоприятствует близости.\n\n### Функции агрегации факторов ранжирования"
    },
    "is_code_or_comment": false
  },
  "e1ccaa561d78fe425735ae054307d62511cd269492b23fccf8467ede3d7909b3": {
    "original": "* `word_count` (integer), the number of unique keywords matched in the field. For example, if 'hello' and 'world' occur anywhere in a field, `word_count` will be 2, regardless of how many times both keywords occur.\n\n* `tf_idf` (float), the sum of TF/IDF over all the keywords matched in the field. IDF is the Inverse Document Frequency, a floating point value between 0 and 1 that describes how frequent the keyword is (basically, 0 for a keyword that occurs in every document indexed, and 1 for a unique keyword that occurs in just a single document). TF is the Term Frequency, the number of matched keyword occurrences in the field. As a side note, `tf_idf` is actually computed by summing IDF over all matched occurrences. That's by construction equivalent to summing TF*IDF over all matched keywords.\n\n* `min_hit_pos` (integer), the position of the first matched keyword occurrence, counted in words\n\n   Therefore, this is a relatively low-level, \"raw\" factor that you'll likely want to *adjust* before using it for ranking. The specific adjustments depend heavily on your data and the resulting formula, but here are a few ideas to start with: (a) any min_gaps-based boosts could be simply ignored when word_count<2;\n\n    (b) non-trivial min_gaps values (i.e., when word_count>=2) could be clamped with a certain \"worst-case\" constant, while trivial values (i.e., when min_gaps=0 and word_count<2) could be replaced by that constant;\n\n    (c) a transfer function like 1/(1+min_gaps) could be applied (so that better, smaller min_gaps values would maximize it, and worse, larger min_gaps values would fall off slowly); and so on.\n\n* `lccs` (integer). Longest Common Contiguous Subsequence. The length of the longest subphrase common between the query and the document, computed in keywords.\n\n    The LCCS factor is somewhat similar to LCS but more restrictive. While LCS can be greater than 1 even if no two query words are matched next to each other, LCCS will only be greater than 1 if there are *exact*, contiguous query subphrases in the document. For example, (one two three four five) query vs (one hundred three hundred five hundred) document would yield lcs=3, but lccs=1, because although the mutual dispositions of 3 keywords (one, three, five) match between the query and the document, no 2 matching positions are actually adjacent.\n\n    Note that LCCS still doesn't differentiate between frequent and rare keywords; for that, see WLCCS.\n\n* `wlccs` (float). Weighted Longest Common Contiguous Subsequence. The sum of IDFs of the keywords of the longest subphrase common between the query and the document.\n\n    WLCCS is calculated similarly to LCCS, but every \"suitable\" keyword occurrence increases it by the keyword IDF instead of just by 1 (as with LCS and LCCS). This allows ranking sequences of rarer and more important keywords higher than sequences of frequent keywords, even if the latter are longer. For example, a query `(Zanzibar bed and breakfast)` would yield lccs=1 for a `(hotels of Zanzibar)` document, but lccs=3 against `(London bed and breakfast)`, even though \"Zanzibar\" is actually somewhat rarer than the entire \"bed and breakfast\" phrase. The WLCCS factor addresses this issue by using keyword frequencies.\n\n* `atc` (float). Aggregate Term Closeness. A proximity-based measure that increases when the document contains more groups of more closely located and more important (rare) query keywords.\n\n    **WARNING:** you should use ATC with OPTION idf='plain,tfidf_unnormalized' (see [below](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); otherwise, you may get unexpected results.\n\n    ATC essentially operates as follows. For each keyword *occurrence* in the document, we compute the so-called *term closeness*. To do this, we examine all the other closest occurrences of all the query keywords (including the keyword itself) to the left and right of the subject occurrence, calculate a distance dampening coefficient as k = pow(distance, -1.75) for these occurrences, and sum the dampened IDFs. As a result, for every occurrence of each keyword, we obtain a \"closeness\" value that describes the \"neighbors\" of that occurrence. We then multiply these per-occurrence closenesses by their respective subject keyword IDF, sum them all, and finally compute a logarithm of that sum.\n\nIn other words, we process the best (closest) matched keyword pairs in the document, and compute pairwise \"closenesses\" as the product of their IDFs scaled by the distance coefficient:\n\nCODE_BLOCK_61\n\nWe then sum such closenesses, and compute the final, log-dampened ATC value:\n\nCODE_BLOCK_62\n\nNote that this final dampening logarithm is precisely the reason you should use OPTION idf=plain because, without it, the expression inside the log() could be negative.\n\nHaving closer keyword occurrences contributes *much* more to ATC than having more frequent keywords. Indeed, when the keywords are right next to each other, distance=1 and k=1; when there's just one word in between them, distance=2 and k=0.297, with two words between, distance=3 and k=0.146, and so on. At the same time, IDF attenuates somewhat slower. For example, in a 1 million document collection, the IDF values for keywords that match in 10, 100, and 1000 documents would be respectively 0.833, 0.667, and 0.500. So a keyword pair with two rather rare keywords that occur in just 10 documents each but with 2 other words in between would yield pair_tc = 0.101 and thus barely outweigh a pair with a 100-doc and a 1000-doc keyword with 1 other word between them and pair_tc = 0.099. Moreover, a pair of two *unique*, 1-doc keywords with 3 words between them would get a pair_tc = 0.088 and lose to a pair of two 1000-doc keywords located right next to each other and yielding a pair_tc = 0.25. So, basically, while ATC does combine both keyword frequency and proximity, it still somewhat favors proximity.\n\n### Ranking factor aggregation functions",
    "translations": {
      "chinese": "* `word_count` (整数)，字段中匹配的唯一关键词数量。例如，如果字段中出现了“hello”和“world”，`word_count` 将是 2，无论这两个关键词出现了多少次。\n\n* `tf_idf` (浮点数)，字段中所有匹配关键词的 TF/IDF 之和。IDF 是逆文档频率，是介于 0 到 1 之间的浮点值，用来描述关键词的频率（基本上，出现在每个索引文档中的关键词 IDF 为 0，出现在单个文档中的唯一关键词 IDF 为 1）。TF 是词频，表示字段中匹配关键词的出现次数。顺带一提，`tf_idf` 实际上是通过对所有匹配出现计算 IDF 的总和来计算的，这在构造上等同于对所有匹配关键词计算 TF*IDF 的总和。\n\n* `min_hit_pos` (整数)，第一个匹配关键词出现的位置，按单词计数\n\n   因此，这是一个相对较低级的“原始”因子，您可能需要在将其用于排名之前进行*调整*。具体调整方法很大程度上取决于您的数据和最终公式，但这里有一些起点想法：(a) 当 word_count<2 时，任何基于 min_gaps 的提升都可以简单忽略；\n\n    (b) 非平凡的 min_gaps 值（即 word_count>=2 时）可以被限定在某个“最坏情况”常数范围内，而平凡值（即 min_gaps=0 且 word_count<2）可以用该常数替代；\n\n    (c) 可以应用类似 1/(1+min_gaps) 的转换函数（这样更好的、更小的 min_gaps 值会使其最大化，而更差的、更大的 min_gaps 值会缓慢下降）；等等。\n\n* `lccs` (整数)。最长公共连续子序列。查询与文档之间的最长公共子短语长度，以关键词计算。\n\n    LCCS 因子与 LCS 有些相似，但更具限制性。虽然即使没有两个查询词紧挨匹配，LCS 也可能大于 1，但只有当文档中有*完全相同且连续的查询子短语*时，LCCS 才会大于 1。例如，查询为（one two three four five）与文档为（one hundred three hundred five hundred）时，lcs=3，但 lccs=1，因为尽管三个关键词（one，three，five）在查询和文档中的位置相互对应，但没有两个匹配位置是相邻的。\n\n    注意，LCCS 仍然不区分频繁和稀有关键词；对此，请参见 WLCCS。\n\n* `wlccs` (浮点数)。加权最长公共连续子序列。查询与文档之间最长公共子短语的关键词 IDFs 之和。\n\n    WLCCS 的计算类似于 LCCS，但每个“合适”的关键词出现会按关键词 IDF 增加，而不是像 LCS 和 LCCS 那样只加 1。这允许对稀有且更重要的关键词序列给予更高排名，即使这些序列比频繁关键词序列短。例如，查询 `(Zanzibar bed and breakfast)` 对文档 `(hotels of Zanzibar)` 产生 lccs=1，而对 `(London bed and breakfast)` 产生 lccs=3，尽管“Zanzibar”实际上比“bed and breakfast”短语中任一词都稍稀有。WLCCS 因子通过使用关键词频率解决了这一问题。\n\n* `atc` (浮点数)。聚合词语接近度。基于接近度的度量，当文档包含更多组更紧密且更重要（稀有）的查询关键词时，该值增加。\n\n    **警告：** 您应当与 OPTION idf='plain,tfidf_unnormalized' 一同使用 ATC（见[下面](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)）；否则，可能得到意外结果。\n\n    ATC 的基本运作方式如下。对于文档中每个关键词*出现*，计算所谓的*词语接近度*。为此，我们检查该出现左右侧所有查询关键词的最近的其它出现（包括该关键词本身），按距离计算衰减系数 k = pow(distance, -1.75)，并对这些出现的 IDF 加权求和。结果是针对每个关键词出现，得到一个描述该出现“邻居”的“接近度”数值。然后，将这些每次出现的接近度乘以该关键词的 IDF，求和所有结果，最终计算该和的对数。\n\n换句话说，我们处理文档中最佳（最接近）的匹配关键词对，计算它们的成对“接近度”为 IDF 乘以距离系数的乘积：\n\nCODE_BLOCK_61\n\n然后我们对这些接近度求和，计算最终的对数衰减 ATC 值：\n\nCODE_BLOCK_62\n\n注意最终的衰减对数正是您需要使用 OPTION idf=plain 的原因，否则 log() 内部的表达式可能为负。\n\n关键词出现更接近对 ATC 的贡献远大于关键词更频繁。实际上，当关键词紧挨着时，distance=1，k=1；关键词间隔一个词时，distance=2，k=0.297；两个词之间，distance=3，k=0.146，依此类推。与此同时，IDF 衰减较慢。例如，在一百万文档集合中，匹配于 10、100 和 1000 个文档的关键词对应的 IDF 值分别是 0.833、0.667 和 0.500。因此，两个各出现在 10 个文档的较稀有关键词对且之间有两个词间隔的 pair_tc = 0.101，几乎抵消了一个由匹配 100 和 1000 文档的关键词组成且之间有一个词的 pair_tc = 0.099。此外，两词之间间隔三个词的两个*唯一*、仅出现在单个文档的关键词对的 pair_tc = 0.088，会输给两个紧挨着的、各出现在 1000 个文档的关键词对，后者 pair_tc = 0.25。因此，基本上，虽然 ATC 结合了关键词频率和接近度，但它仍更偏重接近度。\n\n### 排名因子聚合函数",
      "russian": "* `word_count` (integer), количество уникальных ключевых слов, найденных в поле. Например, если в поле встречаются слова 'hello' и 'world', `word_count` будет равен 2, независимо от того, сколько раз встречаются оба ключевых слова.\n\n* `tf_idf` (float), сумма TF/IDF по всем ключевым словам, найденным в поле. IDF — это обратная частота документа, число с плавающей точкой от 0 до 1, описывающее, насколько частым является ключевое слово (фактически 0 для ключевого слова, встречающегося в каждом индексированном документе, и 1 для уникального ключевого слова, встречающегося только в одном документе). TF — частота термина, количество вхождений ключевого слова в поле. В качестве примечания, `tf_idf` фактически вычисляется суммированием IDF по всем найденным вхождениям. По конструкции это эквивалентно суммированию TF*IDF по всем найденным ключевым словам.\n\n* `min_hit_pos` (integer), позиция первого найденного вхождения ключевого слова, считанная в словах\n\n   Поэтому это относительно низкоуровневый, «сырой» фактор, который, вероятно, вы захотите *скорректировать* перед использованием для ранжирования. Конкретные корректировки сильно зависят от ваших данных и итоговой формулы, но вот несколько идей для начала: (a) любые подъёмы на основе min_gaps можно просто игнорировать, если word_count<2;\n\n    (b) нетривиальные значения min_gaps (то есть когда word_count>=2) можно фиксировать определённой «худшей» константой, тогда как тривиальные значения (то есть min_gaps=0 и word_count<2) можно заменить этой константой;\n\n    (c) можно применить трансферную функцию, например 1/(1+min_gaps) (чтобы лучшие, меньшие значения min_gaps максимизировали этот фактор, а худшие, большие — медленно падали); и так далее.\n\n* `lccs` (integer). Longest Common Contiguous Subsequence. Длина самой длинной общей непрерывной подпоследовательности между запросом и документом, считаемая в ключевых словах.\n\n    Фактор LCCS отчасти похож на LCS, но более строгий. В то время как LCS может быть больше 1 даже если никакие два слова запроса не идут друг за другом, LCCS будет больше 1 только в случае *точных*, непрерывных подпоследовательностей запроса в документе. Например, запрос (one two three four five) и документ (one hundred three hundred five hundred) дадут lcs=3, но lccs=1, поскольку взаимное расположение 3 ключевых слов (one, three, five) совпадает между запросом и документом, но ни два совпадающих слова не стоят рядом.\n\n    Обратите внимание, что LCCS всё ещё не различает частые и редкие ключевые слова; для этого см. WLCCS.\n\n* `wlccs` (float). Weighted Longest Common Contiguous Subsequence. Сумма IDF ключевых слов самой длинной общей подпоследовательности между запросом и документом.\n\n    WLCCS вычисляется аналогично LCCS, но каждое «подходящее» вхождение ключевого слова увеличивает его на значение IDF ключевого слова вместо простого 1 (как в LCS и LCCS). Это позволяет ранжировать последовательности более редких и важных ключевых слов выше, чем последовательности частых слов, даже если последние длиннее. Например, запрос `(Zanzibar bed and breakfast)` даст lccs=1 для документа `(hotels of Zanzibar)`, но lccs=3 для `(London bed and breakfast)`, хотя «Zanzibar» на самом деле несколько реже фразы «bed and breakfast». Фактор WLCCS учитывает это, используя частоту ключевых слов.\n\n* `atc` (float). Aggregate Term Closeness. Мера близости, основанная на расстоянии, которая увеличивается, когда документ содержит больше групп тесно расположенных и более важных (редких) ключевых слов из запроса.\n\n    **ВНИМАНИЕ:** следует использовать ATC с OPTION idf='plain,tfidf_unnormalized' (см. [ниже](../Searching/Sorting_and_ranking.md#Configuration-of-IDF-formula)); в противном случае вы можете получить неожиданные результаты.\n\n    ATC работает следующим образом. Для каждого *вхождения* ключевого слова в документе вычисляется так называемая *близость термина*. Для этого рассматриваются все ближайшие вхождения всех ключевых слов запроса (включая само слово) слева и справа от данного вхождения, вычисляется коэффициент затухания расстояния как k = pow(distance, -1.75) для этих вхождений, и суммируются затухшие IDF. В результате, для каждого вхождения каждого ключевого слова получается значение «близости», описывающее «соседей» этого вхождения. Затем эти значения близости для каждого вхождения умножаются на соответствующий IDF ключевого слова, суммируются, и наконец по итоговой сумме вычисляется логарифм.\n\nДругими словами, мы обрабатываем лучшие (ближайшие) пары совпадающих ключевых слов в документе и вычисляем попарные «близости» как произведение их IDF с коэффициентом расстояния:\n\nCODE_BLOCK_61\n\nЗатем мы суммируем такие близости и вычисляем итоговое, логарифмически затухающее значение ATC:\n\nCODE_BLOCK_62\n\nОбратите внимание, что этот итоговый затухающей логарифм — именно причина, по которой следует использовать OPTION idf=plain, иначе выражение внутри log() может быть отрицательным.\n\nБолее близкие вхождения ключевых слов дают *гораздо* больший вклад в ATC, чем более частые ключевые слова. Действительно, если ключевые слова идут подряд, distance=1 и k=1; если между ними ровно одно слово, distance=2 и k=0.297, с двумя словами между ними distance=3 и k=0.146, и так далее. При этом IDF затухает несколько медленнее. Например, в коллекции из миллиона документов, значения IDF для ключевых слов, встречающихся в 10, 100 и 1000 документах будут соответственно 0.833, 0.667 и 0.500. Таким образом, пара ключевых слов с двумя достаточно редкими ключевыми словами, встречающимися по 10 документов каждое, но с 2 словами между ними даст pair_tc = 0.101 и едва превзойдет пару с 100-документным и 1000-документным ключевыми словами с одним словом между ними и pair_tc = 0.099. Более того, пара двух *уникальных*, встречающихся в 1 документе ключевых слов с 3 словами между ними даст pair_tc = 0.088 и уступит паре двух 1000-документных ключевых слов, расположенных подряд, с pair_tc = 0.25. Таким образом, в целом ATC сочетает и частоту ключевых слов, и близость, но всё же несколько предпочитает близость.\n\n### Функции агрегирования факторов ранжирования"
    },
    "is_code_or_comment": false
  },
  "325458fef4283ef1e8f304c3a04cf4722b91c5ab1a62cc4a35823fe01312f39b": {
    "original": "# Sorting and ranking\n\nQuery results can be sorted by full-text ranking weight, one or more attributes or expressions.\n\n**Full-text** queries return matches sorted by default. If nothing is specified, they are sorted by relevance, which is equivalent to `ORDER BY weight() DESC` in SQL format.\n\n**Non-full-text** queries do not perform any sorting by default.\n\n## Advanced sorting\n\nExtended mode is automatically enabled when you explicitly provide sorting rules by adding the `ORDER BY` clause in SQL format or using the `sort` option via HTTP JSON.\n\n### Sorting via SQL\n\nGeneral syntax:\n\nCODE_BLOCK_0\n\n<!--\n\ndata for the following example:\n\nDROP TABLE IF EXISTS test;\n\nCREATE TABLE test(a int, b int, f text);\n\nINSERT INTO test (a, b, f) VALUES\n\n(2, 3, 'document');\n\n-->\n\n<!-- example alias -->\n\nIn the sort clause, you can use any combination of up to 5 columns, each followed by `asc` or `desc`. Functions and expressions are not allowed as arguments for the sort clause, except for the `weight()` and `random()` functions (the latter can only be used via SQL in the form of `ORDER BY random()`). However, you can use any expression in the SELECT list and sort by its alias.\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- response SQL -->\n\nCODE_BLOCK_2\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- response JSON -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n## Sorting via JSON\n\n<!-- example sorting 1 -->\n\n`\"sort\"` specifies an array where each element can be an attribute name or `_score` if you want to sort by match weights or `_random` if you want radnom match order. In that case, the sort order defaults to ascending for attributes and descending for `_score`.\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_5\n\n<!-- response JSON -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_13\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_14\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example sorting 2 -->\n\nYou can also specify the sort order explicitly:\n\n* `asc`: sort in ascending order\n\n* `desc`: sort in descending order\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- response JSON -->\n\nCODE_BLOCK_17\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_24\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_25\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n<!-- example sorting 3 -->\n\nYou can also use another syntax and specify the sort order via the `order` property:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_27\n\n<!-- response JSON -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_33\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_34\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_35\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_36\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n<!-- example sorting 4 -->\n\nSorting by MVA attributes is also supported in JSON queries. Sorting mode can be set via the `mode` property. The following modes are supported:\n\n* `min`: sort by minimum value\n\n* `max`: sort by maximum value\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_38\n\n<!-- response JSON -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_42\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_43\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_44\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_46\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_47\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n<!-- example sorting 5 -->\n\nWhen sorting on an attribute, match weight (score) calculation is disabled by default (no ranker is used). You can enable weight calculation by setting the `track_scores` property to `true`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_49\n\n<!-- response JSON -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_51\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_52\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_53\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_54\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_55\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_56\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_57\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_58\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n## Ranking overview",
    "translations": {
      "chinese": "# 排序和排名\n\n查询结果可以按全文排名权重、一个或多个属性或表达式进行排序。\n\n**全文**查询默认返回按排序匹配结果。如果未指定任何排序方式，结果将按相关性排序，相当于 SQL 格式中的 `ORDER BY weight() DESC`。\n\n**非全文**查询默认不进行任何排序。\n\n## 高级排序\n\n当您通过添加 SQL 格式的 `ORDER BY` 子句或通过 HTTP JSON 使用 `sort` 选项显式提供排序规则时，自动启用扩展模式。\n\n### 通过 SQL 排序\n\n通用语法：\n\nCODE_BLOCK_0\n\n<!--\n\n以下示例数据：\n\nDROP TABLE IF EXISTS test;\n\nCREATE TABLE test(a int, b int, f text);\n\nINSERT INTO test (a, b, f) VALUES\n\n(2, 3, 'document');\n\n-->\n\n<!-- 示例别名 -->\n\n在排序子句中，您可以使用最多 5 列的任意组合，每列后跟 `asc` 或 `desc`。除 `weight()` 和 `random()` 函数（后者只能以 `ORDER BY random()` 的形式在 SQL 中使用）外，不允许函数和表达式作为排序子句的参数。然而，您可以在 SELECT 列表中使用任何表达式，并按其别名排序。\n\n<!-- 请求 SQL -->\n\nCODE_BLOCK_1\n\n<!-- 响应 SQL -->\n\nCODE_BLOCK_2\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_3\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_4\n\n<!-- 结束 -->\n\n## 通过 JSON 排序\n\n<!-- 示例排序 1 -->\n\n`\"sort\"` 指定一个数组，其中每个元素可以是属性名称，若要按匹配权重排序则使用 `_score`，若要按随机匹配顺序排序则使用 `_random`。在这种情况下，属性默认按升序排序，`_score` 默认按降序排序。\n\n<!-- 介绍 -->\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_5\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_6\n\n<!-- 介绍 -->\n\n##### PHP：\n\n<!-- 请求 PHP -->\n\nCODE_BLOCK_7\n\n<!-- 介绍 -->\n\n##### Python：\n\n<!-- 请求 Python -->\n\nCODE_BLOCK_8\n\n<!-- 介绍 -->\n\n##### Python-asyncio：\n\n<!-- 请求 Python-asyncio -->\n\nCODE_BLOCK_9\n\n<!-- 介绍 -->\n\n##### Javascript：\n\n<!-- 请求 javascript -->\n\nCODE_BLOCK_10\n\n<!-- 介绍 -->\n\n##### java：\n\n<!-- 请求 Java -->\n\nCODE_BLOCK_11\n\n<!-- 介绍 -->\n\n##### C#：\n\n<!-- 请求 C# -->\n\nCODE_BLOCK_12\n\n<!-- 介绍 -->\n\n##### Rust：\n\n<!-- 请求 Rust -->\n\nCODE_BLOCK_13\n\n<!-- 介绍 -->\n\n##### Typescript：\n\n<!-- 请求 typescript -->\n\nCODE_BLOCK_14\n\n<!-- 介绍 -->\n\n##### Go：\n\n<!-- 请求 go -->\n\nCODE_BLOCK_15\n\n<!-- 结束 -->\n\n<!-- 示例排序 2 -->\n\n您也可以显式指定排序顺序：\n\n* `asc`：升序排序\n\n* `desc`：降序排序\n\n<!-- 介绍 -->\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_16\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_17\n\n<!-- 介绍 -->\n\n##### PHP：\n\n<!-- 请求 PHP -->\n\nCODE_BLOCK_18\n\n<!-- 介绍 -->\n\n##### Python：\n\n<!-- 请求 Python -->\n\nCODE_BLOCK_19\n\n<!-- 介绍 -->\n\n##### Python-asyncio：\n\n<!-- 请求 Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- 介绍 -->\n\n##### Javascript：\n\n<!-- 请求 javascript -->\n\nCODE_BLOCK_21\n\n<!-- 介绍 -->\n\n##### java：\n\n<!-- 请求 Java -->\n\nCODE_BLOCK_22\n\n<!-- 介绍 -->\n\n##### C#：\n\n<!-- 请求 C# -->\n\nCODE_BLOCK_23\n\n<!-- 介绍 -->\n\n##### Rust：\n\n<!-- 请求 Rust -->\n\nCODE_BLOCK_24\n\n<!-- 介绍 -->\n\n##### Typescript：\n\n<!-- 请求 typescript -->\n\nCODE_BLOCK_25\n\n<!-- 介绍 -->\n\n##### Go：\n\n<!-- 请求 go -->\n\nCODE_BLOCK_26\n\n<!-- 结束 -->\n\n<!-- 示例排序 3 -->\n\n您也可以使用另一种语法，通过 `order` 属性指定排序顺序：\n\n<!-- 介绍 -->\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_27\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_28\n\n<!-- 介绍 -->\n\n##### PHP：\n\n<!-- 请求 PHP -->\n\nCODE_BLOCK_29\n\n<!-- 介绍 -->\n\n##### Python：\n\n<!-- 请求 Python -->\n\nCODE_BLOCK_30\n\n<!-- 介绍 -->\n\n##### Python-asyncio：\n\n<!-- 请求 Python-asyncio -->\n\nCODE_BLOCK_31\n\n<!-- 介绍 -->\n\n##### Javascript：\n\n<!-- 请求 javascript -->\n\nCODE_BLOCK_32\n\n<!-- 介绍 -->\n\n##### java：\n\n<!-- 请求 Java -->\n\nCODE_BLOCK_33\n\n<!-- 介绍 -->\n\n##### C#：\n\n<!-- 请求 C# -->\n\nCODE_BLOCK_34\n\n<!-- 介绍 -->\n\n##### Rust：\n\n<!-- 请求 Rust -->\n\nCODE_BLOCK_35\n\n<!-- 介绍 -->\n\n##### Typescript：\n\n<!-- 请求 typescript -->\n\nCODE_BLOCK_36\n\n<!-- 介绍 -->\n\n##### Go：\n\n<!-- 请求 go -->\n\nCODE_BLOCK_37\n\n<!-- 结束 -->\n\n<!-- 示例排序 4 -->\n\n在 JSON 查询中也支持按 MVA 属性排序。排序模式可以通过 `mode` 属性设置。支持以下模式：\n\n* `min`：按最小值排序\n\n* `max`：按最大值排序\n\n<!-- 介绍 -->\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_38\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_39\n\n<!-- 介绍 -->\n\n##### PHP：\n\n<!-- 请求 PHP -->\n\nCODE_BLOCK_40\n\n<!-- 介绍 -->\n\n##### Python：\n\n<!-- 请求 Python -->\n\nCODE_BLOCK_41\n\n<!-- 介绍 -->\n\n##### Python-asyncio：\n\n<!-- 请求 Python-asyncio -->\n\nCODE_BLOCK_42\n\n<!-- 介绍 -->\n\n##### Javascript：\n\n<!-- 请求 javascript -->\n\nCODE_BLOCK_43\n\n<!-- 介绍 -->\n\n##### java：\n\n<!-- 请求 Java -->\n\nCODE_BLOCK_44\n\n<!-- 介绍 -->\n\n##### C#：\n\n<!-- 请求 C# -->\n\nCODE_BLOCK_45\n\n<!-- 介绍 -->\n\n##### Rust：\n\n<!-- 请求 Rust -->\n\nCODE_BLOCK_46\n\n<!-- 介绍 -->\n\n##### Typescript：\n\n<!-- 请求 typescript -->\n\nCODE_BLOCK_47\n\n<!-- 介绍 -->\n\n##### Go：\n\n<!-- 请求 go -->\n\nCODE_BLOCK_48\n\n<!-- 结束 -->\n\n<!-- 示例排序 5 -->\n\n在按属性排序时，默认禁用匹配权重（得分）计算（不使用排名器）。您可以通过将 `track_scores` 属性设置为 `true` 来启用权重计算：\n\n<!-- 介绍 -->\n\n<!-- 请求 JSON -->\n\nCODE_BLOCK_49\n\n<!-- 响应 JSON -->\n\nCODE_BLOCK_50\n\n<!-- 介绍 -->\n\n##### PHP：\n\n<!-- 请求 PHP -->\n\nCODE_BLOCK_51\n\n<!-- 介绍 -->\n\n##### Python：\n\n<!-- 请求 Python -->\n\nCODE_BLOCK_52\n\n<!-- 介绍 -->\n\n##### Python-asyncio：\n\n<!-- 请求 Python-asyncio -->\n\nCODE_BLOCK_53\n\n<!-- 介绍 -->\n\n##### Javascript：\n\n<!-- 请求 javascript -->\n\nCODE_BLOCK_54\n\n<!-- 介绍 -->\n\n##### java：\n\n<!-- 请求 Java -->\n\nCODE_BLOCK_55\n\n<!-- 介绍 -->\n\n##### C#：\n\n<!-- 请求 C# -->\n\nCODE_BLOCK_56\n\n<!-- 介绍 -->\n\n##### Rust：\n\n<!-- 请求 Rust -->\n\nCODE_BLOCK_57\n\n<!-- 介绍 -->\n\n##### Typescript：\n\n<!-- 请求 typescript -->\n\nCODE_BLOCK_58\n\n<!-- 介绍 -->\n\n##### Go：\n\n<!-- 请求 go -->\n\nCODE_BLOCK_59\n\n<!-- 结束 -->\n\n## 排名概览",
      "russian": "# Сортировка и ранжирование\n\nРезультаты запроса могут быть отсортированы по весу ранжирования полнотекстового поиска, одному или нескольким атрибутам или выражениям.\n\n**Полнотекстовые** запросы возвращают совпадения, отсортированные по умолчанию. Если ничего не указано, они сортируются по релевантности, что эквивалентно `ORDER BY weight() DESC` в SQL-формате.\n\n**Не полнотекстовые** запросы по умолчанию не выполняют никакой сортировки.\n\n## Расширенная сортировка\n\nРасширенный режим автоматически включается, когда вы явно указываете правила сортировки, добавляя клаузу `ORDER BY` в SQL-формате или используя опцию `sort` через HTTP JSON.\n\n### Сортировка через SQL\n\nОбщий синтаксис:\n\nCODE_BLOCK_0\n\n<!--\n\ndata for the following example:\n\nDROP TABLE IF EXISTS test;\n\nCREATE TABLE test(a int, b int, f text);\n\nINSERT INTO test (a, b, f) VALUES\n\n(2, 3, 'document');\n\n-->\n\n<!-- example alias -->\n\nВ клаузе сортировки вы можете использовать любую комбинацию до 5 колонок, каждая из которых может сопровождаться `asc` или `desc`. Функции и выражения не допускаются в качестве аргументов для клаузулы сортировки, за исключением функций `weight()` и `random()` (последняя может использоваться только через SQL в виде `ORDER BY random()`). Однако вы можете использовать любое выражение в списке SELECT и сортировать по его алиасу.\n\n<!-- request SQL -->\n\nCODE_BLOCK_1\n\n<!-- response SQL -->\n\nCODE_BLOCK_2\n\n<!-- request JSON -->\n\nCODE_BLOCK_3\n\n<!-- response JSON -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n## Сортировка через JSON\n\n<!-- example sorting 1 -->\n\n`\"sort\"` задаёт массив, где каждый элемент может быть именем атрибута или `_score`, если вы хотите сортировать по весам совпадений, или `_random`, если хотите случайный порядок совпадений. В этом случае порядок сортировки по умолчанию — по возрастанию для атрибутов и по убыванию для `_score`.\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_5\n\n<!-- response JSON -->\n\nCODE_BLOCK_6\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_7\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_8\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_9\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_10\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_11\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_12\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_13\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_14\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n<!-- example sorting 2 -->\n\nВы также можете явно указать порядок сортировки:\n\n* `asc`: сортировка по возрастанию\n\n* `desc`: сортировка по убыванию\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_16\n\n<!-- response JSON -->\n\nCODE_BLOCK_17\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_18\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_19\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_20\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_21\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_22\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_23\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_24\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_25\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n<!-- example sorting 3 -->\n\nВы также можете использовать другой синтаксис и указывать порядок сортировки через свойство `order`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_27\n\n<!-- response JSON -->\n\nCODE_BLOCK_28\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_29\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_30\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_31\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_32\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_33\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_34\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_35\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_36\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n<!-- example sorting 4 -->\n\nСортировка по атрибутам MVA также поддерживается в JSON-запросах. Режим сортировки может быть установлен через свойство `mode`. Поддерживаются следующие режимы:\n\n* `min`: сортировка по минимальному значению\n\n* `max`: сортировка по максимальному значению\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_38\n\n<!-- response JSON -->\n\nCODE_BLOCK_39\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_40\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_41\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_42\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_43\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_44\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_45\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_46\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_47\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n<!-- example sorting 5 -->\n\nПри сортировке по атрибуту вычисление веса совпадения (score) по умолчанию отключено (ранжировщик не используется). Вы можете включить вычисление веса, установив свойство `track_scores` в значение `true`:\n\n<!-- intro -->\n\n<!-- request JSON -->\n\nCODE_BLOCK_49\n\n<!-- response JSON -->\n\nCODE_BLOCK_50\n\n<!-- intro -->\n\n##### PHP:\n\n<!-- request PHP -->\n\nCODE_BLOCK_51\n\n<!-- intro -->\n\n##### Python:\n\n<!-- request Python -->\n\nCODE_BLOCK_52\n\n<!-- intro -->\n\n##### Python-asyncio:\n\n<!-- request Python-asyncio -->\n\nCODE_BLOCK_53\n\n<!-- intro -->\n\n##### Javascript:\n\n<!-- request javascript -->\n\nCODE_BLOCK_54\n\n<!-- intro -->\n\n##### java:\n\n<!-- request Java -->\n\nCODE_BLOCK_55\n\n<!-- intro -->\n\n##### C#:\n\n<!-- request C# -->\n\nCODE_BLOCK_56\n\n<!-- intro -->\n\n##### Rust:\n\n<!-- request Rust -->\n\nCODE_BLOCK_57\n\n<!-- intro -->\n\n##### Typescript:\n\n<!-- request typescript -->\n\nCODE_BLOCK_58\n\n<!-- intro -->\n\n##### Go:\n\n<!-- request go -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n## Обзор ранжирования"
    },
    "is_code_or_comment": false
  },
  "09903caed50baecf1eca5983b428856eb6af8bf7cd31f30a1a57c808c46612e8": {
    "original": "Ranking (also known as weighting) of search results can be defined as a process of computing a so-called relevance (weight) for every given matched document regards to a given query that matched it. So relevance is, in the end, just a number attached to every document that estimates how relevant the document is to the query. Search results can then be sorted based on this number and/or some additional parameters, so that the most sought-after results would appear higher on the results page.\n\nThere is no single standard one-size-fits-all way to rank any document in any scenario. Moreover, there can never be such a way, because relevance is *subjective*. As in, what seems relevant to you might not seem relevant to me. Hence, in general cases, it's not just hard to compute; it's theoretically impossible.\n\nSo ranking in Manticore is configurable. It has a notion of a so-called **ranker**. A ranker can formally be defined as a function that takes a document and a query as its input and produces a relevance value as output. In layman's terms, a ranker controls exactly how (using which specific algorithm) Manticore will assign weights to the documents.\n\n## Available built-in rankers\n\nManticore ships with several built-in rankers suited for different purposes. Many of them use two factors: phrase proximity (also known as LCS) and BM25. Phrase proximity works on keyword positions, while BM25 works on keyword frequencies. Essentially, the better the degree of phrase match between the document body and the query, the higher the phrase proximity (it maxes out when the document contains the entire query as a verbatim quote). And BM25 is higher when the document contains more rare words. We'll save the detailed discussion for later.\n\nThe currently implemented rankers are:\n\n* `proximity_bm25`, the default ranking mode that uses and combines both phrase proximity and BM25 ranking.\n\n* `bm25`, a statistical ranking mode that uses BM25 ranking only (similar to most other full-text engines). This mode is faster but may result in worse quality for queries containing more than one keyword.\n\n* `none`, a no-ranking mode. This mode is obviously the fastest. A weight of 1 is assigned to all matches. This is sometimes called boolean searching, which just matches the documents but does not rank them.\n\n* `wordcount`, ranking by the keyword occurrences count. This ranker computes the per-field keyword occurrence counts, then multiplies them by field weights, and sums the resulting values.\n\n* `proximity` returns the raw phrase proximity value as a result. This mode is internally used to emulate `SPH_MATCH_ALL` queries.\n\n* `matchany` returns rank as it was computed in `SPH_MATCH_ANY` mode earlier and is internally used to emulate `SPH_MATCH_ANY` queries.\n\n* `fieldmask` returns a 32-bit mask with the N-th bit corresponding to the N-th full-text field, numbering from 0. The bit will only be set when the respective field has any keyword occurrences satisfying the query.\n\n* `sph04` is generally based on the default 'proximity_bm25' ranker, but additionally boosts matches when they occur at the very beginning or the very end of a text field. Thus, if a field equals the exact query, `sph04` should rank it higher than a field that contains the exact query but is not equal to it. (For instance, when the query is \"Hyde Park\", a document titled \"Hyde Park\" should be ranked higher than one titled \"Hyde Park, London\" or \"The Hyde Park Cafe\".)\n\n* `expr` allows you to specify the ranking formula at runtime. It exposes several internal text factors and lets you define how the final weight should be computed from those factors. You can find more details about its syntax and a reference of available factors in a [subsection below](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors).\n\nThe ranker name is case-insensitive. Example:\n\nCODE_BLOCK_60\n\n## Quick summary of the ranking factors\n\n| Name                    | Level     | Type  | Summary                                                                                                            |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | query     | int   | maximum possible LCS value for the current query                                                                   |\n\n| bm25                    | document  | int   | quick estimate of BM25(1.2, 0)                                                                                     |\n\n| bm25a(k1, b)            | document  | int   | precise BM25() value with configurable K1, B constants and syntax support                                         |\n\n| bm25f(k1, b, {field=weight, ...}) | document | int   | precise BM25F() value with extra configurable field weights                                                       |\n\n| field_mask              | document  | int   | bit mask of matched fields                                                                                         |\n\n| query_word_count        | document  | int   | number of unique inclusive keywords in a query                                                                     |\n\n| doc_word_count          | document  | int   | number of unique keywords matched in the document                                                                  |\n\n| lcs                     | field     | int   | Longest Common Subsequence between query and document, in words                                                    |\n\n| user_weight             | field     | int   | user field weight                                                                                                  |\n\n| hit_count               | field     | int   | total number of keyword occurrences                                                                                |\n\n| word_count              | field     | int   | number of unique matched keywords                                                                                  |",
    "translations": {
      "chinese": "排名（也称为加权）搜索结果可以定义为一个过程，即针对与之匹配的给定查询，计算每个匹配文档的所谓相关性（权重）。因此，相关性最终只是附加到每个文档上的一个数字，用来估计该文档与查询的相关程度。然后可以基于这个数字和/或一些额外参数对搜索结果进行排序，从而使最受关注的结果出现在结果页面的更高处。\n\n没有一种单一的标准适用于任何场景中对任何文档进行排名的方式。更重要的是，也永远不会存在这样的方式，因为相关性是*主观的*。也就是说，对你而言看起来相关的内容可能对我来说并不相关。因此，在一般情况下，计算相关性不仅很难；从理论上讲是不可能的。\n\n所以 Manticore 中的排名是可配置的。它有一个所谓的**ranker**概念。ranker 可以正式定义为一个函数，它以文档和查询作为输入，输出一个相关性值。通俗来说，ranker 精确控制了 Manticore 将如何（使用哪种具体算法）为文档分配权重。\n\n## 可用的内置ranker\n\nManticore 提供了若干适用于不同目的的内置ranker。它们中的许多都使用两个因素：短语接近度（也称为 LCS）和 BM25。短语接近度基于关键字的位置，而 BM25 基于关键字的频率。基本上，文档正文与查询之间的短语匹配程度越高，短语接近度越高（当文档包含查询的完整逐字引用时，它达到最大值）。而当文档包含更多罕见词时，BM25 值会更高。详细讨论我们稍后再讲。\n\n当前实现的ranker包括：\n\n* `proximity_bm25`，默认排名模式，使用并结合了短语接近度和BM25排名。\n\n* `bm25`，一种统计排名模式，仅使用BM25排名（类似于大多数其他全文引擎）。此模式速度更快，但对于包含多个关键字的查询可能导致较差的质量。\n\n* `none`，无排名模式。显然这是最快的模式。所有匹配都分配权重为1。有时称为布尔检索，仅匹配文档但不对其进行排名。\n\n* `wordcount`，按关键字出现次数排名。该ranker计算每个字段的关键字出现次数，然后乘以字段权重，最后求和。\n\n* `proximity` 返回原始的短语接近度值。此模式内部用于模拟 `SPH_MATCH_ALL` 查询。\n\n* `matchany` 返回之前在 `SPH_MATCH_ANY` 模式下计算的排名，内部用于模拟 `SPH_MATCH_ANY` 查询。\n\n* `fieldmask` 返回一个32位掩码，第N位对应第N个全文字段，编号从0开始。只有当相应字段包含满足查询的关键字出现时，该位才会被设置。\n\n* `sph04` 一般基于默认的 `proximity_bm25` ranker，但额外提升当匹配发生在文本字段的开头或末尾时的权重。因此，如果字段等于精确查询，则 `sph04` 应该将它排在包含该查询但不完全相等的字段之前。（例如，当查询是“Hyde Park”时，标题为“Hyde Park”的文档应排在标题为“Hyde Park, London”或“The Hyde Park Cafe”的文档之前。）\n\n* `expr` 允许你在运行时指定排名公式。它暴露了几个内部文本因素，并让你定义如何根据这些因素计算最终权重。你可以在[下面的小节](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors)中找到关于其语法及可用因素的更多细节。\n\nranker 名称不区分大小写。示例：\n\nCODE_BLOCK_60\n\n## 排名因素快速总结\n\n| 名称                    | 级别      | 类型  | 简要说明                                                                                                        |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | 查询      | int   | 当前查询的最大可能 LCS 值                                                                                            |\n\n| bm25                    | 文档      | int   | BM25(1.2, 0) 的快速估计                                                                                              |\n\n| bm25a(k1, b)            | 文档      | int   | 使用可配置的 K1、B 常量和语法支持的精确 BM25() 值                                                                        |\n\n| bm25f(k1, b, {field=weight, ...}) | 文档 | int   | 带额外可配置字段权重的精确 BM25F() 值                                                                                 |\n\n| field_mask              | 文档      | int   | 匹配字段的位掩码                                                                                                     |\n\n| query_word_count        | 文档      | int   | 查询中唯一包含关键字的数量                                                                                             |\n\n| doc_word_count          | 文档      | int   | 文档中匹配的唯一关键字数量                                                                                             |\n\n| lcs                     | 字段      | int   | 查询和文档之间最长公共子序列（按词计）                                                                                 |\n\n| user_weight             | 字段      | int   | 用户字段权重                                                                                                        |\n\n| hit_count               | 字段      | int   | 关键字出现的总次数                                                                                                    |\n\n| word_count              | 字段      | int   | 匹配的唯一关键字数量                                                                                                  |",
      "russian": "Ранжирование (также известное как взвешивание) результатов поиска можно определить как процесс вычисления так называемой релевантности (веса) для каждого совпавшего документа относительно заданного запроса, который его совпал. Таким образом, релевантность — это, в конечном счёте, просто число, прикреплённое к каждому документу, которое оценивает, насколько документ релевантен запросу. Результаты поиска затем могут быть отсортированы на основе этого числа и/или некоторых дополнительных параметров, так что наиболее востребованные результаты будут отображены выше на странице результатов.\n\nНе существует единого универсального способа ранжирования любого документа в любом сценарии. Более того, такого способа не может быть в принципе, потому что релевантность является *субъективной*. То есть то, что кажется релевантным вам, может не показаться релевантным мне. Следовательно, в общем случае это не только трудно вычислить; это теоретически невозможно.\n\nПоэтому ранжирование в Manticore настраивается. В нём есть понятие так называемого **ранкера**. Ранкер можно формально определить как функцию, которая принимает документ и запрос на вход и выдаёт значение релевантности на выходе. Простыми словами, ранкер контролирует, как именно (с помощью какого конкретного алгоритма) Manticore присваивает веса документам.\n\n## Встроенные ранкеры\n\nManticore поставляется с несколькими встроенными ранкерами, подходящими для разных целей. Многие из них используют два фактора: близость фраз (также известную как LCS) и BM25. Близость фраз работает с позициями ключевых слов, тогда как BM25 — с частотами ключевых слов. По сути, чем лучше степень совпадения фразы между телом документа и запросом, тем выше близость фраз (она достигает максимума, когда документ содержит весь запрос дословно). BM25 выше, когда документ содержит более редкие слова. Подробное обсуждение будет позже.\n\nВ настоящее время реализованы следующие ранкеры:\n\n* `proximity_bm25` — режим ранжирования по умолчанию, который использует и сочетает близость фраз и ранжирование BM25.\n\n* `bm25` — статистический режим ранжирования, который использует только ранжирование BM25 (аналогично большинству других полнотекстовых движков). Этот режим быстрее, но может давать худшее качество для запросов, содержащих несколько ключевых слов.\n\n* `none` — режим без ранжирования. Этот режим, очевидно, самый быстрый. Всем совпадениям присваивается вес 1. Иногда это называется булевым поиском, который просто находит совпадения, но не ранжирует их.\n\n* `wordcount` — ранжирование по количеству вхождений ключевых слов. Этот ранкер вычисляет количество вхождений ключевых слов для каждого поля, затем умножает их на веса полей и суммирует полученные значения.\n\n* `proximity` возвращает исходное значение близости фраз как результат. Этот режим используется внутренне для эмуляции запросов `SPH_MATCH_ALL`.\n\n* `matchany` возвращает рейтинг, вычисленный в режиме `SPH_MATCH_ANY` ранее, и используется внутренне для эмуляции запросов `SPH_MATCH_ANY`.\n\n* `fieldmask` возвращает 32-битную маску, где N-й бит соответствует N-му полнотекстовому полю, нумерация с 0. Бит устанавливается только если в соответствующем поле есть вхождения ключевых слов, удовлетворяющих запросу.\n\n* `sph04` в основном основан на ранкере по умолчанию `proximity_bm25`, но дополнительно повышает рейтинг совпадений, когда они происходят в самом начале или самом конце текстового поля. Таким образом, если поле равно точному запросу, `sph04` ранжирует его выше, чем поле, которое содержит точный запрос, но не равно ему. (Например, если запрос \"Hyde Park\", документ с названием \"Hyde Park\" должен иметь рейтинг выше, чем \"Hyde Park, London\" или \"The Hyde Park Cafe\".)\n\n* `expr` позволяет задавать формулу ранжирования во время выполнения. Он предоставляет несколько внутренних текстовых факторов и позволяет определить, как из этих факторов вычислить итоговый вес. Более подробную информацию об его синтаксисе и список доступных факторов можно найти в [подразделе ниже](../Searching/Sorting_and_ranking.md#Quick-summary-of-the-ranking-factors).\n\nИмя ранкера не чувствительно к регистру. Пример:\n\nCODE_BLOCK_60\n\n## Краткое содержание факторов ранжирования\n\n| Имя                     | Уровень   | Тип   | Краткое описание                                                                                                   |\n\n| ----------------------- | --------- | ----- | ------------------------------------------------------------------------------------------------------------------ |\n\n| max_lcs                 | запрос    | int   | максимальное возможное значение LCS для текущего запроса                                                           |\n\n| bm25                    | документ  | int   | быстрая оценка BM25(1.2, 0)                                                                                        |\n\n| bm25a(k1, b)            | документ  | int   | точное значение BM25() с настраиваемыми константами K1, B и поддержкой синтаксиса                                 |\n\n| bm25f(k1, b, {field=weight, ...}) | документ | int   | точное значение BM25F() с дополнительной настраиваемой весовой шкалой для полей                                   |\n\n| field_mask              | документ  | int   | битовая маска совпавших полей                                                                                      |\n\n| query_word_count        | документ  | int   | количество уникальных включённых ключевых слов в запросе                                                          |\n\n| doc_word_count          | документ  | int   | количество уникальных ключевых слов, совпавших в документе                                                         |\n\n| lcs                     | поле      | int   | Наибольшая общая подпоследовательность между запросом и документом, в словах                                      |\n\n| user_weight             | поле      | int   | вес пользовательского поля                                                                                          |\n\n| hit_count               | поле      | int   | общее количество вхождений ключевых слов                                                                            |\n\n| word_count              | поле      | int   | количество уникальных совпавших ключевых слов                                                                       |"
    },
    "is_code_or_comment": false
  }
}
