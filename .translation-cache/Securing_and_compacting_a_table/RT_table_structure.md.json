{
  "3f3b446a06d9a5fc4f76245d6ead9d60f21067e6f77b7af37dffe07ee3a4fd07": {
    "original": "**Third, what about disk collection?**  If having many disk parts makes searching slower, what's the difference if I make them manually in the distributed table manner, or they're produced as disk parts (or, 'chunks') by an RT table? Well, in both cases, you can merge several tables into one. For example, you can merge hourly tables from yesterday and keep one 'daily' table for yesterday instead. With manual maintenance, you have to think about the schema and commands yourself. With an RT table, the server provides the [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) command, which does the same, but keeps you away from unnecessary internal details.\n\n**Fourth, if my \"document\" constitutes a 'mini-table' and I don't need it anymore, I can just throw it away. But if it is 'optimized', i.e. mixed together with tons of other documents, how can I undo or delete it?** Yes, indexed documents are 'mixed' together, and there is no easy way to delete one without rebuilding the whole table. And if for plain tables rebuilding or merging is just a normal way of maintenance, for a real-time table it keeps only the simplicity of manipulation, but not 'real-timeness'. To address the problem, Manticore uses a trick: when you delete a document, identified by document ID, the server just tracks the number. Together with other deleted documents, their IDs are saved in a so-called [kill-list](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md#Table-kill-list). When you search over the table, the server first retrieves all matching documents, and then throws out the documents that are found in the kill-list (that is the most basic description; in fact, internally it's more complex). The point is - for the sake of 'immediate' deletion, documents are not actually deleted, but are just marked as 'deleted'. They still occupy space in different table structures, being essentially garbage. Word statistics, which affect ranking, also aren't affected, meaning it works exactly as it is declared: we search among all documents, and then just hide ones marked as deleted from the final result. When a document is [replaced](../Data_creation_and_modification/Updating_documents/REPLACE.md), it means that it is killed in the old parts of the table and is inserted again in the freshest part. All consequences of 'hiding by killlist' are also in play in this case.\n\nWhen a rebuild of some part of a table happens, e.g., when some transactions (segments) of a RAM chunk are merged, or when a RAM chunk is converted into a disk chunk, or when two disk chunks are merged together, the server performs a comprehensive iteration over the affected parts and physically excludes deleted documents from all of them. That is, if they were in document lists of some words - they are wiped away. If it was a unique word - it gets removed completely.\n\nAs a summary: the deletion works in two phases:\n\n1. First, we mark documents as 'deleted' in real-time and suppress them in search results.\n\n2. During some operation with an RT table chunk, we finally physically wipe the deleted documents for good.\n\n**Fifth, if an RT table contains plain disk tables in its collection, can I just add my ready old disk table to it?** No. It's not possible to avoid unneeded complexity and prevent accidental corruption. However, if your RT table has just been created and contains no data, then you can [ATTACH TABLE](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Attaching_one_table_to_another.md) your disk table to it. Your old table will be moved inside the RT table and will become its part.\n\nAs a summary about the RT table structure: it is a cleverly organized collection of plain disk tables with a fast in-memory table, intended for real-time insertions and semi-real-time deletions of documents. The RT table has a common schema, common settings, and can be easily maintained without deep digging into details.\n\n<!-- proofread -->",
    "translations": {
      "chinese": "**第三，磁盘集合怎么办？** 如果有很多磁盘部分会使搜索变慢，那么我手动以分布式表的方式制作它们，或者它们由RT表生成的磁盘部分（或“块”）有什么区别呢？嗯，在这两种情况下，你都可以将多个表合并为一个。例如，你可以合并昨天的每小时表，并保留一个昨天的“每日”表。手动维护时，你必须自己考虑模式和命令。使用RT表，服务器提供了[OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE)命令，它做同样的事情，但让你远离不必要的内部细节。\n\n**第四，如果我的“文档”构成一个“迷你表”，我不再需要它了，我可以直接丢弃它。但如果它被“优化”了，即与大量其他文档混合在一起，我怎么撤销或删除它？** 是的，索引文档是“混合”在一起的，没有简单的方法删除其中一个而不重建整个表。对于普通表，重建或合并只是正常的维护方式，而对于实时表，它只保持了操作的简单性，但不是真正的“实时”。为了解决这个问题，Manticore使用了一个技巧：当你删除一个由文档ID标识的文档时，服务器只是跟踪这个编号。与其他已删除文档一起，它们的ID被保存在所谓的[kill-list](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md#Table-kill-list)中。当你搜索表时，服务器首先检索所有匹配的文档，然后剔除在kill-list中找到的文档（这是最基本的描述；实际上内部更复杂）。关键是——为了“即时”删除，文档实际上并未被删除，而只是被标记为“已删除”。它们仍然占据不同表结构中的空间，本质上是垃圾。影响排名的词统计也不受影响，这意味着它的工作方式正如声明的那样：我们在所有文档中搜索，然后仅从最终结果中隐藏标记为已删除的文档。当文档被[替换](../Data_creation_and_modification/Updating_documents/REPLACE.md)时，意味着它在表的旧部分被杀死，并在最新部分重新插入。“通过killlist隐藏”的所有后果在这种情况下也适用。\n\n当表的某个部分重建时，例如，当RAM块的一些事务（段）被合并，或者RAM块被转换为磁盘块，或者两个磁盘块被合并时，服务器会对受影响的部分进行全面迭代，并从所有部分物理排除已删除的文档。也就是说，如果它们在某些词的文档列表中——它们会被清除。如果是唯一词——它会被完全移除。\n\n总结：删除分两个阶段进行：\n\n1. 首先，我们在实时中将文档标记为“已删除”，并在搜索结果中抑制它们。\n\n2. 在对RT表块进行某些操作时，我们最终物理地彻底清除已删除的文档。\n\n**第五，如果RT表的集合中包含普通磁盘表，我能否直接将我准备好的旧磁盘表添加进去？** 不能。这样做无法避免不必要的复杂性，也无法防止意外损坏。然而，如果你的RT表刚创建且不包含数据，那么你可以[ATTACH TABLE](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Attaching_one_table_to_another.md)你的磁盘表到它。你的旧表将被移动到RT表内部，成为其一部分。\n\n关于RT表结构的总结：它是一个巧妙组织的普通磁盘表集合，配有一个快速的内存表，旨在实现文档的实时插入和半实时删除。RT表具有统一的模式、统一的设置，并且可以轻松维护，无需深入细节。\n\n<!-- proofread -->",
      "russian": "**Третье, как насчёт сбора дисков?** Если наличие множества частей диска замедляет поиск, в чём разница, если я создаю их вручную в виде распределённой таблицы, или они создаются как части диска (или «чанки») таблицей RT? В обоих случаях вы можете объединить несколько таблиц в одну. Например, можно объединить почасовые таблицы за вчерашний день и вместо этого сохранить одну «суточную» таблицу за вчера. При ручном обслуживании вам нужно самостоятельно продумывать схему и команды. С таблицей RT сервер предоставляет команду [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE), которая делает то же самое, но избавляет вас от ненужных внутренних деталей.\n\n**Четвёртое, если мой «документ» представляет собой «мини-таблицу» и он мне больше не нужен, я могу просто выбросить его. Но если он «оптимизирован», то есть смешан с множеством других документов, как я могу отменить или удалить его?** Да, индексированные документы «смешаны» вместе, и нет простого способа удалить один без перестройки всей таблицы. И если для обычных таблиц перестройка или слияние — это нормальный способ обслуживания, то для таблицы реального времени это сохраняет только простоту манипуляций, но не «реальное время». Чтобы решить эту проблему, Manticore использует хитрость: когда вы удаляете документ, идентифицированный по ID документа, сервер просто отслеживает этот номер. Вместе с другими удалёнными документами их ID сохраняются в так называемом [kill-list](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md#Table-kill-list). При поиске по таблице сервер сначала извлекает все подходящие документы, а затем исключает документы, найденные в kill-list (это самое базовое описание; на самом деле внутри всё сложнее). Суть в том, что ради «немедленного» удаления документы фактически не удаляются, а просто помечаются как «удалённые». Они всё ещё занимают место в различных структурах таблицы, по сути являясь мусором. Статистика слов, которая влияет на ранжирование, также не затрагивается, то есть работает именно так, как заявлено: мы ищем среди всех документов, а затем просто скрываем помеченные как удалённые из итогового результата. Когда документ [заменяется](../Data_creation_and_modification/Updating_documents/REPLACE.md), это означает, что он убивается в старых частях таблицы и вставляется заново в самую свежую часть. Все последствия «скрытия через killlist» также действуют в этом случае.\n\nКогда происходит перестройка какой-то части таблицы, например, когда сливаются некоторые транзакции (сегменты) RAM-чанка, или когда RAM-чанк конвертируется в дисковый чанк, или когда два дисковых чанка объединяются, сервер выполняет комплексную итерацию по затронутым частям и физически исключает удалённые документы из всех них. То есть, если они были в списках документов некоторых слов — они вычищаются. Если это было уникальное слово — оно удаляется полностью.\n\nВ итоге: удаление работает в два этапа:\n\n1. Сначала мы помечаем документы как «удалённые» в реальном времени и подавляем их в результатах поиска.\n\n2. Во время некоторой операции с чанком таблицы RT мы окончательно физически удаляем удалённые документы.\n\n**Пятое, если таблица RT содержит обычные дисковые таблицы в своей коллекции, могу ли я просто добавить в неё свою готовую старую дисковую таблицу?** Нет. Это невозможно, чтобы избежать ненужной сложности и предотвратить случайное повреждение. Однако, если ваша таблица RT только что создана и не содержит данных, вы можете [ATTACH TABLE](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Attaching_one_table_to_another.md) вашу дисковую таблицу к ней. Ваша старая таблица будет перемещена внутрь таблицы RT и станет её частью.\n\nВ итоге о структуре таблицы RT: это умно организованная коллекция обычных дисковых таблиц с быстрой таблицей в памяти, предназначенная для вставок в реальном времени и полуреального времени удаления документов. Таблица RT имеет общую схему, общие настройки и может легко обслуживаться без глубокого погружения в детали.\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "ec1a857dd80f6c0421a3e9976cc69208ae8da72bdb2b25f871034bcf43578a44": {
    "original": "# Real-time table structure\n\nA plain table can be created from an external source using a special tool called `indexer`, which reads a \"recipe\" from the configuration, connects to the data sources, pulls documents, and builds table files. This is a lengthy process. If your data changes, the table becomes outdated, and you need to rebuild it from the refreshed sources. If your data changes incrementally, such as a blog or newsfeed where old documents never change and only new ones are added, the rebuild will take more and more time, as you will need to process the archive sources again and again with each pass.\n\nOne way to deal with this problem is by using several tables instead of one solid table. For example, you can process sources produced in previous years and save the table. Then, take only sources from the current year and put them into a separate table, rebuilding it as often as necessary. You can then place both tables as parts of a distributed table and use it for querying. The point here is that each time you rebuild, you only process data from the last 12 months at most, and the table with older data remains untouched without needing to be rebuilt. You can go further and divide the last 12 months table into monthly, weekly, or daily tables, and so on.\n\nThis approach works, but you need to maintain your distributed table manually. That is, add new chunks, delete old ones, and keep the overall number of partial tables not too large (with too many tables, searching can become slower, and the OS usually limits the number of simultaneously opened files). To deal with this, you can manually merge several tables together by running [indexer --merge](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Merging_tables.md). However, that only solves the problem of having many tables, making maintenance more challenging. And even with 'per-hour' reindexing, you will most likely have a noticeable time gap between new data arriving in sources and rebuilding the table, which populates this data for searching.\n\nA real-time table is designed to solve this problem. It consists of two parts:\n\n1. A special RAM-based table (called RAM chunk) that contains portions of data arriving right now.\n\n2. A collection of plain tables called disk chunks that were built in the past.\n\nThis is very similar to a standard [distributed table](../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md), made from several local tables.\n\nYou don't need to build such a table by running `indexer`,  which reads a \"recipe\" from the config and tables data sources. Instead, the real-time table provides the ability to 'insert' new documents and 'replace' existing ones. When executing the 'insert' command, you push new documents to the server. It then builds a small table from the added documents and immediately brings it online. So, right after the 'insert' command completes, you can perform searches in all table parts, including the just-added documents.\n\nThe search server automatically maintains the table, so you don't have to worry about it. However, you might be interested in learning a few details about 'how it is maintained'.\n\n**First, since indexed data is stored in RAM - what about emergency power-off?** Will I lose my table then? Well, before completion, the server saves new data into a special 'binlog'. This consists of one or several files, living on your persistent storage, which incrementally grows as you add more and more changes. You can adjust the behavior regarding how often new queries (or transactions) are stored in the binlog, and how often the 'sync' command is executed over the binlog file to force the OS to actually save the data on a safe storage. The most paranoid approach is to flush and sync after every transaction. This is the slowest but also the safest method. The least expensive way is to switch off the binlog entirely. This is the fastest method, but you risk losing your indexed data. Intermediate variants, like flush/sync every second, are also provided.\n\nThe binlog is designed specifically for sequential saving of newly arriving transactions; it is not a table and cannot be searched over. It is merely an insurance policy to ensure that the server will not lose your data. If a sudden disruption occurs and everything crashes due to a software or hardware problem, the server will load the freshest available dump of the RAM chunk and then replay the binlog, repeating stored transactions. Ultimately, it will achieve the same state as it was in at the moment of the last change.\n\n**Second, what about limits?** What if I want to process, say, 10TB of data, but it just doesn't fit into RAM! RAM for a real-time table is limited and can be configured. When a certain amount of data is indexed, the server manages the RAM part of the table by merging together small transactions, keeping their number and overall size small. This process can sometimes cause delays during insertion, however. When merging no longer helps, and new insertions hit the [RAM limit](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_mem_limit), the server converts the RAM-based table into a plain table stored on disk (called a disk chunk). This table is added to the collection of tables in the second part of the RT table and becomes accessible online. The RAM is then flushed, and the space is deallocated.\n\nWhen the data from RAM is securely saved to disk, which occurs:\n\n* when the server saves the collected data as a disk table\n\n* or when it dumps the RAM part during a clean shutdown or by [manual flushing](../Securing_and_compacting_a_table/Flushing_RAM_chunk_to_disk.md#FLUSH-TABLE)\n\nthe binlog for that table is no longer necessary. So, it gets discarded. If all the tables are saved, the binlog will be deleted.",
    "translations": {
      "chinese": "# 实时表结构\n\n可以使用一个名为 `indexer` 的特殊工具从外部源创建一个普通表，该工具从配置中读取“配方”，连接到数据源，拉取文档，并构建表文件。这是一个耗时的过程。如果数据发生变化，表就会过时，需要从更新后的源重新构建。如果数据是增量变化的，比如博客或新闻源，旧文档永远不变，只添加新文档，那么重建将花费越来越多的时间，因为每次都需要反复处理归档源。\n\n解决这个问题的一种方法是使用多个表，而不是一个完整的表。例如，可以处理前几年产生的源并保存表。然后，只取当前年的源放入一个单独的表中，按需重建。然后可以将这两个表作为分布式表的部分放置，并用于查询。关键是每次重建时，最多只处理最近12个月的数据，旧数据的表保持不变，无需重建。还可以进一步将最近12个月的表划分为月表、周表或日表，等等。\n\n这种方法有效，但需要手动维护分布式表。也就是说，添加新的分片，删除旧的分片，并保持部分表的总数不过多（表太多时，搜索可能变慢，且操作系统通常限制同时打开的文件数）。为此，可以通过运行 [indexer --merge](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Merging_tables.md) 手动合并多个表。然而，这只解决了表数量过多的问题，使维护更具挑战性。即使是“每小时”重新索引，也很可能存在新数据到达源和重建表之间的明显时间差，而表用于搜索的数据就是在重建时填充的。\n\n实时表旨在解决这个问题。它由两部分组成：\n\n1. 一个特殊的基于内存的表（称为 RAM 分片），包含当前到达的数据部分。\n\n2. 一组普通表，称为磁盘分片，是过去构建的。\n\n这与标准的[分布式表](../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md)非常相似，由多个本地表组成。\n\n你不需要通过运行 `indexer` 来构建这样的表，`indexer` 会从配置读取“配方”和表数据源。相反，实时表提供了“插入”新文档和“替换”现有文档的能力。执行“插入”命令时，你将新文档推送到服务器。服务器从添加的文档构建一个小表，并立即上线。因此，在“插入”命令完成后，你可以在所有表部分中执行搜索，包括刚添加的文档。\n\n搜索服务器会自动维护表，因此你无需担心。但你可能想了解一些关于“它是如何维护的”的细节。\n\n**首先，既然索引数据存储在内存中——断电怎么办？** 我会丢失表吗？在完成之前，服务器会将新数据保存到一个特殊的“binlog”中。它由一个或多个文件组成，存储在持久存储上，随着你添加越来越多的更改而增大。你可以调整新查询（或事务）存储到 binlog 的频率，以及对 binlog 文件执行“同步”命令的频率，以强制操作系统将数据实际保存到安全存储。最谨慎的方法是每个事务后都刷新和同步。这是最慢但最安全的方法。最省资源的方法是完全关闭 binlog。这是最快的方法，但有丢失索引数据的风险。也提供了中间方案，比如每秒刷新/同步一次。\n\nbinlog 专门设计用于顺序保存新到达的事务；它不是表，不能被搜索。它只是一个保险策略，确保服务器不会丢失你的数据。如果发生突发中断，因软件或硬件问题崩溃，服务器将加载 RAM 分片的最新可用转储，然后重放 binlog，重复存储的事务。最终，它将达到最后一次更改时的相同状态。\n\n**其次，限制如何？** 如果我想处理，比如说，10TB 的数据，但它根本放不下内存怎么办！实时表的内存是有限的，可以配置。当索引到一定量的数据时，服务器通过合并小事务来管理内存部分，保持它们的数量和总体大小较小。但这个过程有时会导致插入时延迟。当合并不再有效，且新插入达到[内存限制](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_mem_limit)时，服务器会将基于内存的表转换为存储在磁盘上的普通表（称为磁盘分片）。该表被添加到实时表第二部分的表集合中，并可在线访问。然后内存被刷新，空间被释放。\n\n当内存中的数据安全保存到磁盘时，发生以下情况：\n\n* 服务器将收集的数据保存为磁盘表\n\n* 或在干净关闭时或通过[手动刷新](../Securing_and_compacting_a_table/Flushing_RAM_chunk_to_disk.md#FLUSH-TABLE)转储内存部分\n\n该表的 binlog 就不再需要，因此被丢弃。如果所有表都已保存，binlog 将被删除。",
      "russian": "# Структура таблицы в реальном времени\n\nОбычную таблицу можно создать из внешнего источника с помощью специального инструмента под названием `indexer`, который читает \"рецепт\" из конфигурации, подключается к источникам данных, извлекает документы и строит файлы таблицы. Это длительный процесс. Если ваши данные изменяются, таблица устаревает, и её нужно перестраивать из обновлённых источников. Если данные изменяются инкрементально, например, в блоге или новостной ленте, где старые документы не меняются, а добавляются только новые, перестройка будет занимать всё больше времени, так как вам придётся снова и снова обрабатывать архивные источники при каждом проходе.\n\nОдин из способов решения этой проблемы — использовать несколько таблиц вместо одной большой. Например, можно обработать источники, созданные в предыдущие годы, и сохранить таблицу. Затем взять только источники текущего года и поместить их в отдельную таблицу, перестраивая её так часто, как необходимо. После этого обе таблицы можно объединить в распределённую таблицу и использовать её для запросов. Суть в том, что при каждой перестройке вы обрабатываете данные не старше 12 месяцев, а таблица с более старыми данными остаётся без изменений и не требует перестройки. Можно пойти дальше и разделить таблицу за последние 12 месяцев на месячные, недельные или дневные таблицы и так далее.\n\nЭтот подход работает, но вам нужно вручную поддерживать распределённую таблицу. То есть добавлять новые части, удалять старые и следить, чтобы общее количество частичных таблиц не было слишком большим (при слишком большом количестве таблиц поиск может замедлиться, а ОС обычно ограничивает число одновременно открытых файлов). Для решения этой задачи можно вручную объединять несколько таблиц, запуская [indexer --merge](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Merging_tables.md). Однако это решает только проблему большого количества таблиц, усложняя обслуживание. И даже при переиндексации «по часам» у вас, скорее всего, будет заметный временной разрыв между появлением новых данных в источниках и перестройкой таблицы, которая делает эти данные доступными для поиска.\n\nТаблица в реальном времени создана для решения этой проблемы. Она состоит из двух частей:\n\n1. Специальной таблицы в оперативной памяти (называемой RAM chunk), которая содержит части данных, поступающих прямо сейчас.\n\n2. Набора обычных таблиц, называемых disk chunks, которые были построены ранее.\n\nЭто очень похоже на стандартную [распределённую таблицу](../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md), состоящую из нескольких локальных таблиц.\n\nВам не нужно строить такую таблицу, запуская `indexer`, который читает \"рецепт\" из конфигурации и источники данных таблиц. Вместо этого таблица в реальном времени предоставляет возможность «вставлять» новые документы и «заменять» существующие. При выполнении команды 'insert' вы отправляете новые документы на сервер. Он строит небольшую таблицу из добавленных документов и сразу же выводит её в онлайн. Таким образом, сразу после завершения команды 'insert' вы можете выполнять поиск во всех частях таблицы, включая только что добавленные документы.\n\nСервер поиска автоматически поддерживает таблицу, так что вам не нужно об этом беспокоиться. Однако вам может быть интересно узнать некоторые детали о том, «как она поддерживается».\n\n**Во-первых, поскольку индексированные данные хранятся в оперативной памяти — что будет при аварийном отключении питания?** Потеряю ли я тогда таблицу? Перед завершением сервер сохраняет новые данные в специальный «binlog». Это один или несколько файлов, находящихся на вашем постоянном хранилище, которые инкрементально растут по мере добавления изменений. Вы можете настроить поведение относительно того, как часто новые запросы (или транзакции) сохраняются в binlog и как часто выполняется команда 'sync' для binlog-файла, чтобы заставить ОС действительно сохранить данные на надёжном носителе. Самый параноидальный подход — сбрасывать и синхронизировать после каждой транзакции. Это самый медленный, но и самый безопасный метод. Самый дешёвый способ — полностью отключить binlog. Это самый быстрый метод, но вы рискуете потерять индексированные данные. Также предусмотрены промежуточные варианты, например, сброс/синхронизация каждую секунду.\n\nBinlog предназначен специально для последовательного сохранения новых транзакций; это не таблица и по нему нельзя выполнять поиск. Это всего лишь страховка, гарантирующая, что сервер не потеряет ваши данные. Если произойдёт внезапный сбой и всё упадёт из-за программной или аппаратной ошибки, сервер загрузит самый свежий доступный дамп RAM chunk и затем воспроизведёт binlog, повторяя сохранённые транзакции. В итоге он достигнет того же состояния, в котором находился в момент последнего изменения.\n\n**Во-вторых, как насчёт ограничений?** Что если я хочу обработать, скажем, 10 ТБ данных, но они просто не помещаются в оперативную память! Оперативная память для таблицы в реальном времени ограничена и может быть настроена. Когда индексируется определённый объём данных, сервер управляет RAM-частью таблицы, объединяя маленькие транзакции, чтобы их количество и общий размер оставались небольшими. Однако этот процесс иногда может вызывать задержки при вставке. Когда объединение уже не помогает, и новые вставки достигают [лимита RAM](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_mem_limit), сервер преобразует таблицу в оперативной памяти в обычную таблицу на диске (называемую disk chunk). Эта таблица добавляется в набор таблиц второй части RT-таблицы и становится доступной онлайн. Затем RAM очищается, и пространство освобождается.\n\nКогда данные из RAM надёжно сохранены на диск, что происходит:\n\n* когда сервер сохраняет собранные данные как дисковую таблицу\n\n* или когда он сбрасывает RAM-часть при корректном завершении работы или с помощью [ручного сброса](../Securing_and_compacting_a_table/Flushing_RAM_chunk_to_disk.md#FLUSH-TABLE)\n\nbinlog для этой таблицы больше не нужен. Поэтому он удаляется. Если все таблицы сохранены, binlog будет удалён."
    },
    "is_code_or_comment": false
  }
}
