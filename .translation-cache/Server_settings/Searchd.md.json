{
  "afc732cff412536b3ccb5e159dee2fac5f9d957041b911e2e7bdb37bdd47ad3e": {
    "original": "Alternatively, you can use the 'syslog' as the file name. In this case, the events will be sent to the syslog daemon. To use the syslog option, you need to configure Manticore with the `-–with-syslog` option during building.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\nLimits the amount of queries per batch. Optional, default is 32.\n\nMakes searchd perform a sanity check of the amount of queries submitted in a single batch when using [multi-queries](../Searching/Multi-queries.md). Set it to 0 to skip the check.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\nMaximum number of simultaneous client connections. Unlimited by default. That is usually noticeable only when using any kind of persistent connections, like cli mysql sessions or persistent remote connections from remote distributed tables. When the limit is exceeded you can still connect to the server using the [VIP connection](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection). VIP connections are not counted towards the limit.\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\nInstance-wide limit of threads one operation can use. By default, appropriate operations can occupy all CPU cores, leaving no room for other operations. For example, `call pq` against a considerably large percolate table can utilize all threads for tens of seconds. Setting `max_threads_per_query` to, say, half of [threads](../Server_settings/Searchd.md#threads) will ensure that you can run a couple of such `call pq` operations in parallel.\n\nYou can also set this setting as a session or a global variable during runtime.\n\nAdditionally, you can control the behavior on a per-query basis with the help of the [threads OPTION](../Searching/Options.md#threads).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\nMaximum allowed per-query filter count. This setting is only used for internal sanity checks and does not directly affect RAM usage or performance. Optional, the default is 256.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\nMaximum allowed per-filter values count. This setting is only used for internal sanity checks and does not directly affect RAM usage or performance. Optional, the default is 4096.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\nThe maximum number of files that the server is allowed to open is called the \"soft limit\". Note that serving large fragmented real-time tables may require this limit to be set high, as each disk chunk may occupy a dozen or more files. For example, a real-time table with 1000 chunks may require thousands of files to be opened simultaneously. If you encounter the error 'Too many open files' in the logs, try adjusting this option, as it may help resolve the issue.\n\nThere is also a \"hard limit\" that cannot be exceeded by the option. This limit is defined by the system and can be changed in the file `/etc/security/limits.conf` on Linux. Other operating systems may have different approaches, so consult your manuals for more information.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\nApart from direct numeric values, you can use the magic word 'max' to set the limit equal to the available current hard limit.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\nMaximum allowed network packet size. This setting limits both query packets from clients and response packets from remote agents in a distributed environment. Only used for internal sanity checks, it does not directly affect RAM usage or performance. Optional, the default is 128M.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\nA server version string to return via the MySQL protocol. Optional, the default is empty (returns the Manticore version).\n\nSeveral picky MySQL client libraries depend on a particular version number format used by MySQL, and moreover, sometimes choose a different execution path based on the reported version number (rather than the indicated capabilities flags). For instance, Python MySQLdb 1.2.2 throws an exception when the version number is not in X.Y.ZZ format; MySQL .NET connector 6.3.x fails internally on version numbers 1.x along with a certain combination of flags, etc. To work around that, you can use the `mysql_version_string` directive and have `searchd` report a different version to clients connecting over the MySQL protocol. (By default, it reports its own version.)\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### net_workers\n\nNumber of network threads, the default is 1.\n\nThis setting is useful for extremely high query rates when just one thread is not enough to manage all the incoming queries.\n\n### net_wait_tm\n\nControls the busy loop interval of the network thread. The default is -1, and it can be set to -1, 0, or a positive integer.",
    "translations": {
      "chinese": "或者，您可以使用 'syslog' 作为文件名。在这种情况下，事件将被发送到 syslog 守护进程。要使用 syslog 选项，您需要在构建时使用 `-–with-syslog` 选项配置 Manticore。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\n限制每批查询的数量。可选，默认值为 32。\n\n当使用 [多查询](../Searching/Multi-queries.md) 时，使 searchd 对单个批次中提交的查询数量进行合理性检查。设置为 0 可跳过检查。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\n最大同时客户端连接数。默认无限制。通常只有在使用任何类型的持久连接时才会注意到，比如 cli mysql 会话或来自远程分布式表的持久远程连接。当超过限制时，您仍然可以使用 [VIP 连接](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection) 连接服务器。VIP 连接不计入限制。\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\n单个操作可使用的线程实例范围限制。默认情况下，适当的操作可以占用所有 CPU 核心，不留给其他操作空间。例如，对相当大的 percolate 表执行 `call pq` 可能会利用所有线程持续数十秒。将 `max_threads_per_query` 设置为例如 [threads](../Server_settings/Searchd.md#threads) 的一半，将确保您可以并行运行几个这样的 `call pq` 操作。\n\n您也可以在运行时将此设置作为会话或全局变量设置。\n\n此外，您可以借助 [threads 选项](../Searching/Options.md#threads) 按查询控制行为。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\n每个查询允许的最大过滤器数量。此设置仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值为 256。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\n每个过滤器允许的最大值数量。此设置仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值为 4096。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\n服务器允许打开的最大文件数称为“软限制”。请注意，服务大型碎片化实时表可能需要将此限制设置得较高，因为每个磁盘块可能占用十几个或更多文件。例如，一个有 1000 个块的实时表可能需要同时打开数千个文件。如果您在日志中遇到“打开的文件过多”错误，请尝试调整此选项，这可能有助于解决问题。\n\n还有一个“硬限制”，该限制不能被此选项超越。此限制由系统定义，可在 Linux 的 `/etc/security/limits.conf` 文件中更改。其他操作系统可能有不同的方法，请查阅您的手册以获取更多信息。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\n除了直接的数字值，您还可以使用魔法词 'max' 将限制设置为当前可用的硬限制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\n允许的最大网络数据包大小。此设置限制来自客户端的查询包和分布式环境中远程代理的响应包。仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值为 128M。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\n通过 MySQL 协议返回的服务器版本字符串。可选，默认为空（返回 Manticore 版本）。\n\n一些挑剔的 MySQL 客户端库依赖于 MySQL 使用的特定版本号格式，而且有时会根据报告的版本号（而非指示的功能标志）选择不同的执行路径。例如，Python MySQLdb 1.2.2 在版本号不是 X.Y.ZZ 格式时会抛出异常；MySQL .NET 连接器 6.3.x 在版本号为 1.x 且某些标志组合时内部失败等。为了解决这个问题，您可以使用 `mysql_version_string` 指令，让 `searchd` 向通过 MySQL 协议连接的客户端报告不同的版本。（默认情况下，它报告自己的版本。）\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### net_workers\n\n网络线程数，默认值为 1。\n\n当查询率极高且单线程无法管理所有传入查询时，此设置非常有用。\n\n### net_wait_tm\n\n控制网络线程的忙循环间隔。默认值为 -1，可设置为 -1、0 或正整数。",
      "russian": "Alternatively, you can use the 'syslog' as the file name. In this case, the events will be sent to the syslog daemon. To use the syslog option, you need to configure Manticore with the `-–with-syslog` option during building.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_33\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\nОграничивает количество запросов в одном пакете. Необязательно, по умолчанию 32.\n\nЗаставляет searchd выполнять проверку разумности количества запросов, отправленных в одном пакете при использовании [мультизапросов](../Searching/Multi-queries.md). Установите в 0, чтобы пропустить проверку.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\nМаксимальное количество одновременных клиентских подключений. По умолчанию неограничено. Обычно это заметно только при использовании любых видов постоянных подключений, таких как cli mysql сессии или постоянные удалённые подключения из удалённых распределённых таблиц. При превышении лимита вы всё ещё можете подключиться к серверу, используя [VIP-подключение](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection). VIP-подключения не учитываются в лимит.\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\nГлобальное ограничение количества потоков, которые может использовать одна операция. По умолчанию соответствующие операции могут занимать все ядра CPU, не оставляя места для других операций. Например, `call pq` к достаточно большой таблице percolate может использовать все потоки в течение десятков секунд. Установка `max_threads_per_query` в, скажем, половину от значения [threads](../Server_settings/Searchd.md#threads) обеспечит возможность запуска нескольких таких операций `call pq` параллельно.\n\nВы также можете установить этот параметр как переменную сессии или глобальную переменную во время выполнения.\n\nКроме того, вы можете управлять поведением для каждого запроса с помощью опции [threads OPTION](../Searching/Options.md#threads).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\nМаксимально допустимое количество фильтров на запрос. Этот параметр используется только для внутренних проверок и не влияет напрямую на использование ОЗУ или производительность. Необязательно, по умолчанию 256.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\nМаксимально допустимое количество значений в фильтре. Этот параметр используется только для внутренних проверок и не влияет напрямую на использование ОЗУ или производительность. Необязательно, по умолчанию 4096.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\nМаксимальное количество файлов, которые сервер может открыть, называется \"мягким лимитом\". Обратите внимание, что обслуживание больших фрагментированных таблиц реального времени может требовать установки этого лимита на высоком уровне, так как каждый диск-чанк может занимать десятки и более файлов. Например, таблица реального времени с 1000 чанков может требовать открытия тысяч файлов одновременно. Если в логах появляется ошибка 'Too many open files', попробуйте изменить этот параметр, это может помочь решить проблему.\n\nСуществует также \"жёсткий лимит\", который нельзя превысить с помощью этой опции. Этот лимит определяется системой и может быть изменён в файле `/etc/security/limits.conf` на Linux. Другие операционные системы могут иметь другие подходы, поэтому обратитесь к документации для получения дополнительной информации.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\nПомимо прямых числовых значений, вы можете использовать магическое слово 'max', чтобы установить лимит равным текущему доступному жёсткому лимиту.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\nМаксимально допустимый размер сетевого пакета. Этот параметр ограничивает как пакеты запросов от клиентов, так и пакеты ответов от удалённых агентов в распределённой среде. Используется только для внутренних проверок и не влияет напрямую на использование ОЗУ или производительность. Необязательно, по умолчанию 128M.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\nСтрока версии сервера, возвращаемая через протокол MySQL. Необязательно, по умолчанию пусто (возвращает версию Manticore).\n\nНекоторые придирчивые библиотеки клиентов MySQL зависят от определённого формата номера версии, используемого MySQL, и более того, иногда выбирают другой путь выполнения на основе сообщаемого номера версии (а не на основе указанных флагов возможностей). Например, Python MySQLdb 1.2.2 выбрасывает исключение, если номер версии не в формате X.Y.ZZ; MySQL .NET connector 6.3.x внутренне падает на номерах версий 1.x вместе с определённой комбинацией флагов и т.д. Чтобы обойти это, вы можете использовать директиву `mysql_version_string` и заставить `searchd` сообщать другую версию клиентам, подключающимся по протоколу MySQL. (По умолчанию он сообщает свою собственную версию.)\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### net_workers\n\nКоличество сетевых потоков, по умолчанию 1.\n\nЭтот параметр полезен при чрезвычайно высоких скоростях запросов, когда одного потока недостаточно для обработки всех входящих запросов.\n\n### net_wait_tm\n\nУправляет интервалом busy loop сетевого потока. По умолчанию -1, может быть установлен в -1, 0 или положительное целое число."
    },
    "is_code_or_comment": false
  },
  "4e7a1b071c134b900d4e65d5b4eada9b8afb1ee3ecef9e7ddf0d194462fa1b47": {
    "original": "CODE_BLOCK_51\n\n<!-- end -->\n\nThere is an option, [SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time), that lets you limit the query time *and* get stable, repeatable results. Instead of regularly checking the actual current time while evaluating the query, which is indeterministic, it predicts the current running time using a simple linear model instead:\n\nCODE_BLOCK_52\n\nThe query is then terminated early when the `predicted_time` reaches a given limit.\n\nOf course, this is not a hard limit on the actual time spent (it is, however, a hard limit on the amount of *processing* work done), and a simple linear model is in no way an ideally precise one. So the wall clock time *may* be either below or over the target limit. However, the error margins are quite acceptable: for instance, in our experiments with a 100 msec target limit, the majority of the test queries fell into a 95 to 105 msec range, and *all* the queries were in an 80 to 120 msec range. Also, as a nice side effect, using the modeled query time instead of measuring the actual run time results in somewhat fewer gettimeofday() calls, too.\n\nNo two server makes and models are identical, so the `predicted_time_costs` directive lets you configure the costs for the model above. For convenience, they are integers, counted in nanoseconds. (The limit in max_predicted_time is counted in milliseconds, and having to specify cost values as 0.000128 ms instead of 128 ns is somewhat more error-prone.) It is not necessary to specify all four costs at once, as the missed ones will take the default values. However, we strongly suggest specifying all of them for readability.\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\nThe preopen_tables configuration directive specifies whether to forcibly preopen all tables on startup. The default value is 1, which means that all tables will be preopened regardless of the per-table [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) setting. If set to 0, the per-table settings can take effect, and they will default to 0.\n\nPre-opening tables can prevent races between search queries and rotations that can cause queries to fail occasionally. However, it also uses more file handles. In most scenarios, it is recommended to preopen tables.\n\nHere's an example configuration:\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_53\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\nThe pseudo_sharding configuration option enables parallelization of search queries to local plain and real-time tables, regardless of whether they are queried directly or through a distributed table. This feature will automatically parallelize queries to up to the number of threads specified in `searchd.threads` # of threads.\n\nNote that if your worker threads are already busy, because you have:\n\n* high query concurrency\n\n* physical sharding of any kind:\n\n  - distributed table of multiple plain/real-time tables\n\n  - real-time table consisting of too many disk chunks\n\nthen enabling pseudo_sharding may not provide any benefits and may even result in a slight decrease in throughput. If you prioritize higher throughput over lower latency, it's recommended to disable this option.\n\nEnabled by default.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_54\n\n<!-- end -->\n\n### replication_connect_timeout\n\nThe `replication_connect_timeout` directive defines the timeout for connecting to a remote node. By default, the value is assumed to be in milliseconds, but it can have [another suffix](../Server_settings/Special_suffixes.md). The default value is 1000 (1 second).\n\nWhen connecting to a remote node, Manticore will wait for this amount of time at most to complete the connection successfully. If the timeout is reached but the connection has not been established, and `retries` are enabled, a retry will be initiated.\n\n### replication_query_timeout\n\nThe `replication_query_timeout` sets the amount of time that searchd will wait for a remote node to complete a query. The default value is 3000 milliseconds (3 seconds), but can be `suffixed` to indicate a different unit of time.\n\nAfter establishing a connection, Manticore will wait for a maximum of `replication_query_timeout` for the remote node to complete. Note that this timeout is separate from the `replication_connect_timeout`, and the total possible delay caused by a remote node will be the sum of both values.\n\n### replication_retry_count\n\nThis setting is an integer that specifies how many times Manticore will attempt to connect and query a remote node during replication before reporting a fatal query error. The default value is 3.\n\n### replication_retry_delay\n\nThis setting is an integer in milliseconds (or [special_suffixes](../Server_settings/Special_suffixes.md)) that specifies the delay before Manticore retries querying a remote node in case of failure during replication. This value is only relevant when a non-zero value is specified. The default value is 500.\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\nThis configuration sets the maximum amount of RAM allocated for cached result sets in bytes. The default value is 16777216, which is equivalent to 16 megabytes. If the value is set to 0, the query cache is disabled. For more information about the query cache, please refer to the [query cache](../Searching/Query_cache.md) for details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### qcache_thresh_msec\n\nInteger, in milliseconds. The minimum wall time threshold for a query result to be cached. Defaults to 3000, or 3 seconds. 0 means cache everything. Refer to [query cache](../Searching/Query_cache.md) for details. This value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing '_msec'.\n\n### qcache_ttl_sec",
    "translations": {
      "chinese": "CODE_BLOCK_51\n\n<!-- end -->\n\n有一个选项，[SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time)，它允许你限制查询时间*并且*获得稳定、可重复的结果。它不是在评估查询时定期检查实际当前时间（这是不确定的），而是使用一个简单的线性模型来预测当前运行时间：\n\nCODE_BLOCK_52\n\n当`predicted_time`达到给定限制时，查询会被提前终止。\n\n当然，这并不是对实际花费时间的硬限制（但确实是对*处理*工作量的硬限制），而且简单的线性模型绝非理想的精确模型。因此，实际的墙钟时间*可能*低于或超过目标限制。不过误差范围是相当可接受的：例如，在我们以100毫秒为目标限制的实验中，大多数测试查询落在95到105毫秒范围内，*所有*查询都在80到120毫秒范围内。此外，作为一个不错的副作用，使用模型预测的查询时间而非测量实际运行时间，也减少了gettimeofday()调用的次数。\n\n没有两台服务器的品牌和型号是完全相同的，因此`predicted_time_costs`指令允许你配置上述模型的成本。为了方便，它们是以纳秒为单位的整数。（max_predicted_time中的限制以毫秒计，必须以0.000128毫秒而非128纳秒来指定成本值会更容易出错。）不必一次指定所有四个成本，缺失的将采用默认值。不过，我们强烈建议全部指定以提高可读性。\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\npreopen_tables配置指令指定是否在启动时强制预打开所有表。默认值为1，表示无论每个表的[preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings)设置如何，都会预打开所有表。如果设置为0，则每个表的设置生效，且默认值为0。\n\n预打开表可以防止搜索查询和轮换之间的竞争条件，避免查询偶尔失败。但它也会使用更多的文件句柄。在大多数场景下，建议预打开表。\n\n下面是一个示例配置：\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_53\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\npseudo_sharding配置选项启用对本地普通表和实时表的搜索查询并行化，无论是直接查询还是通过分布式表查询。此功能会自动将查询并行化到`searchd.threads`指定的线程数。\n\n请注意，如果你的工作线程已经很忙，因为你有：\n\n* 高查询并发\n\n* 任何形式的物理分片：\n\n  - 多个普通/实时表的分布式表\n\n  - 由过多磁盘块组成的实时表\n\n那么启用pseudo_sharding可能不会带来任何好处，甚至可能导致吞吐量略有下降。如果你优先考虑更高吞吐量而非更低延迟，建议禁用此选项。\n\n默认启用。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_54\n\n<!-- end -->\n\n### replication_connect_timeout\n\n`replication_connect_timeout`指令定义连接远程节点的超时时间。默认值假定为毫秒，但可以使用[其他后缀](../Server_settings/Special_suffixes.md)。默认值为1000（1秒）。\n\n连接远程节点时，Manticore最多等待此时间以成功完成连接。如果超时但连接未建立，且启用了`retries`，则会发起重试。\n\n### replication_query_timeout\n\n`replication_query_timeout`设置searchd等待远程节点完成查询的时间。默认值为3000毫秒（3秒），但可以使用后缀表示不同时间单位。\n\n建立连接后，Manticore将最多等待`replication_query_timeout`时间以完成远程节点的查询。注意此超时与`replication_connect_timeout`分开，远程节点可能导致的总延迟是两者之和。\n\n### replication_retry_count\n\n此设置为整数，指定Manticore在复制期间尝试连接和查询远程节点的次数，超过后报告致命查询错误。默认值为3。\n\n### replication_retry_delay\n\n此设置为以毫秒为单位的整数（或[特殊后缀](../Server_settings/Special_suffixes.md)），指定复制期间查询远程节点失败后重试前的延迟时间。仅当指定非零值时生效。默认值为500。\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\n此配置设置用于缓存结果集的最大RAM字节数。默认值为16777216，相当于16兆字节。如果设置为0，则禁用查询缓存。有关查询缓存的更多信息，请参阅[查询缓存](../Searching/Query_cache.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### qcache_thresh_msec\n\n整数，单位为毫秒。查询结果被缓存的最小墙钟时间阈值。默认值为3000，即3秒。0表示缓存所有。详情请参阅[查询缓存](../Searching/Query_cache.md)。此值也可以用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但请谨慎使用，避免与值名中包含的'_msec'混淆。\n\n### qcache_ttl_sec",
      "russian": "CODE_BLOCK_51\n\n<!-- end -->\n\nСуществует опция, [SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time), которая позволяет ограничить время выполнения запроса *и* получить стабильные, повторяемые результаты. Вместо того чтобы регулярно проверять текущее фактическое время во время выполнения запроса, что является неопределённым, она предсказывает текущее время выполнения с помощью простой линейной модели:\n\nCODE_BLOCK_52\n\nЗапрос затем прерывается досрочно, когда `predicted_time` достигает заданного предела.\n\nКонечно, это не жёсткое ограничение на фактическое затраченное время (однако это жёсткое ограничение на количество выполненной *обработки*), и простая линейная модель ни в коем случае не является идеально точной. Поэтому реальное время по часам *может* быть как ниже, так и выше целевого предела. Тем не менее, погрешности вполне приемлемы: например, в наших экспериментах с целевым лимитом 100 мс большинство тестовых запросов попадали в диапазон от 95 до 105 мс, и *все* запросы были в диапазоне от 80 до 120 мс. Также, в качестве приятного побочного эффекта, использование смоделированного времени запроса вместо измерения фактического времени выполнения приводит к некоторому уменьшению количества вызовов gettimeofday().\n\nНет двух одинаковых моделей и марок серверов, поэтому директива `predicted_time_costs` позволяет настроить затраты для вышеуказанной модели. Для удобства они заданы целыми числами, измеряемыми в наносекундах. (Лимит в max_predicted_time считается в миллисекундах, и указывать значения затрат как 0.000128 мс вместо 128 нс более подвержено ошибкам.) Не обязательно указывать все четыре значения затрат сразу, так как пропущенные будут иметь значения по умолчанию. Однако мы настоятельно рекомендуем указывать все для удобочитаемости.\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\nДиректива конфигурации preopen_tables указывает, следует ли принудительно предварительно открывать все таблицы при запуске. Значение по умолчанию — 1, что означает, что все таблицы будут предварительно открыты независимо от настройки [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) для каждой таблицы. Если установлено в 0, то могут применяться настройки для каждой таблицы, которые по умолчанию равны 0.\n\nПредварительное открытие таблиц может предотвратить гонки между поисковыми запросами и ротациями, которые могут иногда приводить к сбоям запросов. Однако это также использует больше дескрипторов файлов. В большинстве сценариев рекомендуется предварительно открывать таблицы.\n\nВот пример конфигурации:\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_53\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\nОпция конфигурации pseudo_sharding включает параллелизацию поисковых запросов к локальным plain и real-time таблицам, независимо от того, запрашиваются ли они напрямую или через распределённую таблицу. Эта функция автоматически параллелит запросы до количества потоков, указанного в `searchd.threads` # потоков.\n\nОбратите внимание, что если ваши рабочие потоки уже заняты, потому что у вас:\n\n* высокая конкуренция запросов\n\n* физическое шардинг любого типа:\n\n  - распределённая таблица из нескольких plain/real-time таблиц\n\n  - real-time таблица, состоящая из слишком большого количества дисковых чанков\n\nто включение pseudo_sharding может не дать никаких преимуществ и даже привести к небольшому снижению пропускной способности. Если вы отдаёте приоритет более высокой пропускной способности над меньшей задержкой, рекомендуется отключить эту опцию.\n\nВключено по умолчанию.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_54\n\n<!-- end -->\n\n### replication_connect_timeout\n\nДиректива `replication_connect_timeout` задаёт тайм-аут подключения к удалённому узлу. По умолчанию значение предполагается в миллисекундах, но может иметь [другой суффикс](../Server_settings/Special_suffixes.md). Значение по умолчанию — 1000 (1 секунда).\n\nПри подключении к удалённому узлу Manticore будет ждать не более этого времени для успешного завершения подключения. Если тайм-аут достигнут, но соединение не установлено, и включены `retries`, будет выполнена повторная попытка.\n\n### replication_query_timeout\n\n`replication_query_timeout` задаёт время, в течение которого searchd будет ждать завершения запроса от удалённого узла. Значение по умолчанию — 3000 миллисекунд (3 секунды), но может иметь `суффикс` для указания другой единицы времени.\n\nПосле установления соединения Manticore будет ждать максимум `replication_query_timeout` для завершения удалённым узлом. Обратите внимание, что этот тайм-аут отличается от `replication_connect_timeout`, и общая возможная задержка, вызванная удалённым узлом, будет суммой обоих значений.\n\n### replication_retry_count\n\nЭтот параметр — целое число, указывающее, сколько раз Manticore попытается подключиться и выполнить запрос к удалённому узлу во время репликации, прежде чем сообщить о фатальной ошибке запроса. Значение по умолчанию — 3.\n\n### replication_retry_delay\n\nЭтот параметр — целое число в миллисекундах (или [special_suffixes](../Server_settings/Special_suffixes.md)), задающее задержку перед повторной попыткой запроса к удалённому узлу в случае сбоя во время репликации. Это значение актуально только при ненулевом значении. Значение по умолчанию — 500.\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\nЭта конфигурация задаёт максимальный объём оперативной памяти, выделяемой для кэшированных наборов результатов в байтах. Значение по умолчанию — 16777216, что эквивалентно 16 мегабайтам. Если значение установлено в 0, кэш запросов отключается. Для получения дополнительной информации о кэше запросов смотрите [query cache](../Searching/Query_cache.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### qcache_thresh_msec\n\nЦелое число в миллисекундах. Минимальный порог времени выполнения запроса, при котором результат будет кэшироваться. По умолчанию 3000, или 3 секунды. 0 означает кэшировать всё. Подробнее см. [query cache](../Searching/Query_cache.md). Это значение также может быть выражено с помощью временных [special_suffixes](../Server_settings/Special_suffixes.md), но используйте их с осторожностью и не путайте с названием самого параметра, содержащим '_msec'.\n\n### qcache_ttl_sec"
    },
    "is_code_or_comment": false
  },
  "99215769287cf95bd2cbca40c8522fffb5af889edd385c5b0e1692964debcc03": {
    "original": "Legacy Sphinx protocol has 2 phases: handshake exchanging and data flow. The handshake consists of a packet of 4 bytes from the client, and a packet of 4 bytes from the daemon with only one purpose - the client determines that the remote is a real Sphinx daemon, the daemon determines that the remote is a real Sphinx client. The main dataflow is quite simple: let's both sides declare their handshakes, and the opposite check them. That exchange with short packets implies using special `TCP_NODELAY` flag, which switches off Nagle's TCP algorithm and declares that the TCP connection will be performed as a dialogue of small packages.\n\nHowever, it is not strictly defined who speaks first in this negotiation. Historically, all clients that use the binary API speak first: send handshake, then read 4 bytes from a daemon, then send a request and read an answer from the daemon.\n\nWhen we improved Sphinx protocol compatibility, we considered these things:\n\n1. Usually, master-agent communication is established from a known client to a known host on a known port. So, it is quite not possible that the endpoint will provide a wrong handshake. So, we may implicitly assume that both sides are valid and really speak in Sphinx proto.\n\n2. Given this assumption, we can 'glue' a handshake to the real request and send it in one packet. If the backend is a legacy Sphinx daemon, it will just read this glued packet as 4 bytes of a handshake, then request body. Since they both came in one packet, the backend socket has -1 RTT, and the frontend buffer still works despite that fact usual way.\n\n3. Continuing the assumption: since the 'query' packet is quite small, and the handshake is even smaller, let's send both in the initial 'SYN' TCP package using modern TFO (tcp-fast-open) technique. That is: we connect to a remote node with the glued handshake + body package. The daemon accepts the connection and immediately has both the handshake and the body in a socket buffer, as they came in the very first TCP 'SYN' packet. That eliminates another one RTT.\n\n4. Finally, teach the daemon to accept this improvement. Actually, from the application, it implies NOT to use `TCP_NODELAY`. And, from the system side, it implies to ensure that on the daemon side, accepting TFO is activated, and on the client side, sending TFO is also activated. By default, in modern systems, client TFO is already activated by default, so you only have to tune the server TFO for all things to work.\n\nAll these improvements without actually changing the protocol itself allowed us to eliminate 1.5 RTT of the TCP protocol from the connection. Which is, if the query and answer are capable of being placed in a single TCP package, decreases the whole binary API session from 3.5 RTT to 2 RTT - which makes network negotiation about 2 times faster.\n\nSo, all our improvements are stated around an initially undefined statement: 'who speaks first.' If a client speaks first, we may apply all these optimizations and effectively process connect + handshake + query in a single TFO package. Moreover, we can look at the beginning of the received package and determine a real protocol. That is why you can connect to one and the same port via API/http/https. If the daemon has to speak first, all these optimizations are impossible, and the multiprotocol is also impossible. That is why we have a dedicated port for MySQL and did not unify it with all the other protocols into a same port. Suddenly, among all clients, one was written implying that daemon should send a handshake first. That is - no possibility to all the described improvements. That is SphinxSE plugin for mysql/mariadb. So, specially for this single client we dedicated `sphinx` proto definition to work most legacy way. Namely: both sides activate `TCP_NODELAY` and exchange with small packages. The daemon sends its handshake on connect, then the client sends its, and then everything works usual way. That is not very optimal, but just works. If you use SphinxSE to connect to Manticore - you have to dedicate a listener with explicitly stated `sphinx` proto. For another clients - avoid to use this listener as it is slower. If you use another legacy Sphinx API clients - check first, if they are able to work with non-dedicated multiprotocol port. For master-agent linkage using the non-dedicated (multiprotocol) port and enabling client and server TFO works well and will definitely make working of network backend faster, especially if you have very light and fast queries.\n\n</details>\n\n### listen_tfo\n\nThis setting allows the TCP_FASTOPEN flag for all listeners. By default, it is managed by the system but may be explicitly switched off by setting it to '0'.\n\nFor general knowledge about the TCP Fast Open extension, please consult with [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open). In short, it allows the elimination of one TCP round-trip when establishing a connection.\n\nIn practice, using TFO in many situations may optimize client-agent network efficiency, as if [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) are in play, but without holding active connections, and also without limitation for the maximum num of connections.\n\nOn modern OS, TFO support is usually switched 'on' at the system level, but this is just a 'capability', not the rule. Linux (as the most progressive) has supported it since 2011, on kernels starting from 3.7 (for the server-side). Windows has supported it from some builds of Windows 10. Other operating systems (FreeBSD, MacOS) are also in the game.\n\nFor Linux system server checks variable `/proc/sys/net/ipv4/tcp_fastopen` and behaves according to it. Bit 0 manages client side, bit 1 rules listeners. By default, the system has this parameter set to 1, i.e., clients enabled, listeners disabled.\n\n### log\n\n<!-- example conf log -->\n\nThe log setting specifies the name of the log file where all `searchd` run time events will be logged. If not specified, the default name is 'searchd.log'.",
    "translations": {
      "chinese": "Legacy Sphinx 协议有两个阶段：握手交换和数据流。握手包括客户端发送的4字节数据包，以及守护进程发送的4字节数据包，唯一目的——客户端确定远程是一个真实的 Sphinx 守护进程，守护进程确定远程是一个真实的 Sphinx 客户端。主要数据流非常简单：双方都声明它们的握手，另一方进行验证。使用短包交换意味着使用特殊的 `TCP_NODELAY` 标志，该标志关闭 Nagle 的 TCP 算法，并声明 TCP 连接将作为小包对话进行。\n\n然而，谁先发言在此协商中并没有严格定义。历史上，所有使用二进制 API 的客户端都是先发言：先发送握手，然后读取守护进程的4字节，再发送请求并读取守护进程的响应。\n\n当我们改进 Sphinx 协议兼容性时，考虑了以下几点：\n\n1. 通常，主代理通信是从已知客户端到已知主机的已知端口建立的。因此，端点提供错误握手的可能性很小。所以，我们可以隐式假设双方都是有效的，并且确实使用 Sphinx 协议通信。\n\n2. 基于此假设，我们可以将握手“粘合”到真实请求中，并在一个数据包中发送。如果后端是传统的 Sphinx 守护进程，它会将这个粘合的数据包读取为4字节握手，然后是请求体。由于它们都在一个包中，后端套接字减少了1个往返时间（RTT），前端缓冲区仍然正常工作。\n\n3. 继续假设：由于“查询”包相当小，握手更小，我们可以使用现代的 TFO（tcp-fast-open）技术，在初始的 TCP “SYN” 包中发送握手和请求体。也就是说：我们用粘合的握手+请求体包连接远程节点。守护进程接受连接后，立即在套接字缓冲区中拥有握手和请求体，因为它们都在第一个 TCP “SYN” 包中。这消除了另一个 RTT。\n\n4. 最后，教守护进程接受此改进。实际上，从应用角度看，这意味着不使用 `TCP_NODELAY`。从系统角度看，这意味着确保守护进程端启用 TFO 接受，客户端启用 TFO 发送。现代系统中，客户端 TFO 默认已启用，因此只需调整服务器端 TFO 即可使所有功能正常。\n\n所有这些改进在不实际更改协议本身的情况下，允许我们从连接中消除 1.5 RTT 的 TCP 协议时间。如果查询和响应能够放入单个 TCP 包，则将整个二进制 API 会话从 3.5 RTT 降低到 2 RTT——这使网络协商速度提高约两倍。\n\n因此，我们所有的改进都基于一个最初未定义的声明：“谁先发言”。如果客户端先发言，我们可以应用所有这些优化，有效地在单个 TFO 包中处理连接 + 握手 + 查询。此外，我们可以查看接收包的开头，确定真实协议。这就是为什么你可以通过 API/http/https 连接到同一个端口。如果守护进程必须先发言，所有这些优化都不可能实现，多协议也不可能实现。这就是为什么我们为 MySQL 设置了专用端口，而没有将其与所有其他协议统一到同一端口。突然之间，在所有客户端中，有一个客户端是设计为守护进程先发送握手的。那就是 mysql/mariadb 的 SphinxSE 插件。因此，专门为这个单一客户端，我们专门定义了 `sphinx` 协议以最传统的方式工作。具体来说：双方都启用 `TCP_NODELAY` 并交换小包。守护进程在连接时发送握手，然后客户端发送握手，之后一切照常工作。这不是很优化，但能正常工作。如果你使用 SphinxSE 连接 Manticore——你必须专门为其指定一个明确声明为 `sphinx` 协议的监听器。对于其他客户端——避免使用此监听器，因为它较慢。如果你使用其他传统 Sphinx API 客户端——首先检查它们是否能在非专用多协议端口上工作。对于主代理链接，使用非专用（多协议）端口并启用客户端和服务器 TFO 工作良好，肯定会加快网络后端的工作速度，尤其是当你有非常轻量且快速的查询时。\n\n</details>\n\n### listen_tfo\n\n此设置允许为所有监听器启用 TCP_FASTOPEN 标志。默认情况下，由系统管理，但可以通过设置为 '0' 明确关闭。\n\n关于 TCP Fast Open 扩展的一般知识，请参考 [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open)。简而言之，它允许在建立连接时消除一次 TCP 往返。\n\n实际上，在许多情况下使用 TFO 可以优化客户端-代理的网络效率，就像 [持久代理](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) 一样，但无需保持活动连接，也没有最大连接数限制。\n\n在现代操作系统中，TFO 支持通常在系统级别默认开启，但这只是“能力”，而非规则。Linux（作为最先进的系统）自2011年起支持，内核版本从3.7开始（服务器端）。Windows 从某些 Windows 10 版本开始支持。其他操作系统（FreeBSD、MacOS）也支持。\n\n对于 Linux 系统，服务器检查变量 `/proc/sys/net/ipv4/tcp_fastopen` 并据此行为。第0位控制客户端，第1位控制监听器。默认系统设置为1，即客户端启用，监听器禁用。\n\n### log\n\n<!-- example conf log -->\n\nlog 设置指定日志文件名，所有 `searchd` 运行时事件将记录于此文件。如果未指定，默认文件名为 'searchd.log'。",
      "russian": "Legacy Sphinx protocol has 2 phases: handshake exchanging and data flow. The handshake consists of a packet of 4 bytes from the client, and a packet of 4 bytes from the daemon with only one purpose - the client determines that the remote is a real Sphinx daemon, the daemon determines that the remote is a real Sphinx client. The main dataflow is quite simple: let's both sides declare their handshakes, and the opposite check them. That exchange with short packets implies using special `TCP_NODELAY` flag, which switches off Nagle's TCP algorithm and declares that the TCP connection will be performed as a dialogue of small packages.\n\nHowever, it is not strictly defined who speaks first in this negotiation. Historically, all clients that use the binary API speak first: send handshake, then read 4 bytes from a daemon, then send a request and read an answer from the daemon.\n\nWhen we improved Sphinx protocol compatibility, we considered these things:\n\n1. Usually, master-agent communication is established from a known client to a known host on a known port. So, it is quite not possible that the endpoint will provide a wrong handshake. So, we may implicitly assume that both sides are valid and really speak in Sphinx proto.\n\n2. Given this assumption, we can 'glue' a handshake to the real request and send it in one packet. If the backend is a legacy Sphinx daemon, it will just read this glued packet as 4 bytes of a handshake, then request body. Since they both came in one packet, the backend socket has -1 RTT, and the frontend buffer still works despite that fact usual way.\n\n3. Continuing the assumption: since the 'query' packet is quite small, and the handshake is even smaller, let's send both in the initial 'SYN' TCP package using modern TFO (tcp-fast-open) technique. That is: we connect to a remote node with the glued handshake + body package. The daemon accepts the connection and immediately has both the handshake and the body in a socket buffer, as they came in the very first TCP 'SYN' packet. That eliminates another one RTT.\n\n4. Finally, teach the daemon to accept this improvement. Actually, from the application, it implies NOT to use `TCP_NODELAY`. And, from the system side, it implies to ensure that on the daemon side, accepting TFO is activated, and on the client side, sending TFO is also activated. By default, in modern systems, client TFO is already activated by default, so you only have to tune the server TFO for all things to work.\n\nAll these improvements without actually changing the protocol itself allowed us to eliminate 1.5 RTT of the TCP protocol from the connection. Which is, if the query and answer are capable of being placed in a single TCP package, decreases the whole binary API session from 3.5 RTT to 2 RTT - which makes network negotiation about 2 times faster.\n\nSo, all our improvements are stated around an initially undefined statement: 'who speaks first.' If a client speaks first, we may apply all these optimizations and effectively process connect + handshake + query in a single TFO package. Moreover, we can look at the beginning of the received package and determine a real protocol. That is why you can connect to one and the same port via API/http/https. If the daemon has to speak first, all these optimizations are impossible, and the multiprotocol is also impossible. That is why we have a dedicated port for MySQL and did not unify it with all the other protocols into a same port. Suddenly, among all clients, one was written implying that daemon should send a handshake first. That is - no possibility to all the described improvements. That is SphinxSE plugin for mysql/mariadb. So, specially for this single client we dedicated `sphinx` proto definition to work most legacy way. Namely: both sides activate `TCP_NODELAY` and exchange with small packages. The daemon sends its handshake on connect, then the client sends its, and then everything works usual way. That is not very optimal, but just works. If you use SphinxSE to connect to Manticore - you have to dedicate a listener with explicitly stated `sphinx` proto. For another clients - avoid to use this listener as it is slower. If you use another legacy Sphinx API clients - check first, if they are able to work with non-dedicated multiprotocol port. For master-agent linkage using the non-dedicated (multiprotocol) port and enabling client and server TFO works well and will definitely make working of network backend faster, especially if you have very light and fast queries.\n\n</details>\n\n### listen_tfo\n\nThis setting allows the TCP_FASTOPEN flag for all listeners. By default, it is managed by the system but may be explicitly switched off by setting it to '0'.\n\nFor general knowledge about the TCP Fast Open extension, please consult with [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open). In short, it allows the elimination of one TCP round-trip when establishing a connection.\n\nIn practice, using TFO in many situations may optimize client-agent network efficiency, as if [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) are in play, but without holding active connections, and also without limitation for the maximum num of connections.\n\nOn modern OS, TFO support is usually switched 'on' at the system level, but this is just a 'capability', not the rule. Linux (as the most progressive) has supported it since 2011, on kernels starting from 3.7 (for the server-side). Windows has supported it from some builds of Windows 10. Other operating systems (FreeBSD, MacOS) are also in the game.\n\nFor Linux system server checks variable `/proc/sys/net/ipv4/tcp_fastopen` and behaves according to it. Bit 0 manages client side, bit 1 rules listeners. By default, the system has this parameter set to 1, i.e., clients enabled, listeners disabled.\n\n### log\n\n<!-- example conf log -->\n\nThe log setting specifies the name of the log file where all `searchd` run time events will be logged. If not specified, the default name is 'searchd.log'."
    },
    "is_code_or_comment": false
  },
  "8ab3ec58cfb3adf69afa4e36640fff7f175c313aba1f05014ba5fedba5f394ac": {
    "original": "<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate.",
    "translations": {
      "russian": "<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate.",
      "chinese": "<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate."
    },
    "is_code_or_comment": true
  },
  "80c0b7b2323cc0285f09e07ffc4057b7c3f5272cdf9b285f149263cf9d88bf8f": {
    "original": "Binary logs are used for crash recovery of RT table data and for attribute updates of plain disk indices that would otherwise only be stored in RAM until flush. When logging is enabled, every transaction COMMIT-ted into an RT table is written into a log file. Logs are then automatically replayed on startup after an unclean shutdown, recovering the logged changes.\n\nThe `binlog_path` directive specifies the location of binary log files. It should only contain the path; `searchd` will create and unlink multiple `binlog.*` files in the directory as necessary (including binlog data, metadata, and lock files, etc).\n\nAn empty value disables binary logging, which improves performance but puts the RT table data at risk.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\nThis setting controls the default value for [boolean_simplify](../Searching/Options.md#boolean_simplify) search option. It is optional, with a default value of 1 (enabled).\n\nWhen set to 1, the server will automatically apply [boolean query optimization](../Searching/Full_text_matching/Boolean_optimization.md) to improve query performance. When set to 0, queries will be executed without optimization by default. This default can be overridden on a per-query basis using the corresponding search option `boolean_simplify`.\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\nThis setting determines the path to the Manticore Buddy binary. It is optional, with a default value being the build-time configured path, which varies across different operating systems. Typically, you don't need to modify this setting. However, it may be useful if you wish to run Manticore Buddy in debug mode, make changes to Manticore Buddy, or implement a new plugin. In the latter case, you can `git clone` Buddy from https://github.com/manticoresoftware/manticoresearch-buddy, add a new plugin to the directory `./plugins/`, and run `composer install --prefer-source` for easier development after you change the directory to the Buddy source.\n\nTo ensure you can run `composer`, your machine must have PHP 8.2 or higher installed with the following extensions:\n\nCODE_BLOCK_10\n\nYou can also opt for the special `manticore-executor-dev` version for Linux amd64 available in the releases, for example: https://github.com/manticoresoftware/executor/releases/tag/v1.0.13\n\nIf you go this route, remember to link the dev version of the manticore executor to `/usr/bin/php`.\n\nTo disable Manticore Buddy, set the value to empty as shown in the example.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\nThis setting determines the maximum time to wait between requests (in seconds or [special_suffixes](../Server_settings/Special_suffixes.md)) when using persistent connections. It is optional, with a default value of five minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\nServer libc locale. Optional, default is C.\n\nSpecifies the libc locale, affecting the libc-based collations. Refer to [collations](../Searching/Collations.md) section for the details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\nDefault server collation. Optional, default is libc_ci.\n\nSpecifies the default collation used for incoming requests. The collation can be overridden on a per-query basis. Refer to [collations](../Searching/Collations.md) section for the list of available collations and other details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\nWhen specified, this setting enables the [real-time mode](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29), which is an imperative way of managing data schema. The value should be a path to the directory where you want to store all your tables, binary logs, and everything else needed for the proper functioning of Manticore Search in this mode.\n\nIndexing of [plain tables](../Creating_a_table/Local_tables/Plain_table.md) is not allowed when the `data_dir` is specified. Read more about the difference between the RT mode and the plain mode in [this section](../Read_this_first.md#Real-time-table-vs-plain-table).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\nThe timeout for preventing auto-flushing a RAM chunk if there are no searches in the table. Optional, default is 30 seconds.\n\nThe time to check for searches before determining whether to auto-flush.\n\nAuto-flushing will occur only if there has been at least one search in the table within the last `diskchunk_flush_search_timeout` seconds. Works in conjunction with [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout). The corresponding [per-table setting](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) has a higher priority and will override this instance-wide default, providing more fine-grained control.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\nThe time in seconds to wait without a write before auto-flushing the RAM chunk to disk. Optional, default is 1 second.",
    "translations": {
      "chinese": "二进制日志用于RT表数据的崩溃恢复以及普通磁盘索引的属性更新，否则这些属性更新仅存储在RAM中直到刷新。启用日志记录时，每个提交到RT表的事务都会写入日志文件。在非正常关闭后启动时，日志会自动重放，恢复已记录的更改。\n\n`binlog_path` 指令指定二进制日志文件的位置。它应仅包含路径；`searchd` 会根据需要在该目录中创建和删除多个 `binlog.*` 文件（包括binlog数据、元数据和锁文件等）。\n\n空值禁用二进制日志记录，这会提升性能，但会使RT表数据面临风险。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\n此设置控制 [boolean_simplify](../Searching/Options.md#boolean_simplify) 搜索选项的默认值。该设置为可选，默认值为1（启用）。\n\n设置为1时，服务器将自动应用 [布尔查询优化](../Searching/Full_text_matching/Boolean_optimization.md) 以提升查询性能。设置为0时，查询默认不进行优化。此默认值可通过对应的搜索选项 `boolean_simplify` 在每个查询中覆盖。\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\n此设置确定Manticore Buddy二进制文件的路径。该设置为可选，默认值为构建时配置的路径，不同操作系统有所不同。通常不需要修改此设置。但如果您希望以调试模式运行Manticore Buddy、对其进行修改或实现新插件，则可能需要修改。后者情况下，您可以从 https://github.com/manticoresoftware/manticoresearch-buddy 克隆Buddy，向 `./plugins/` 目录添加新插件，并在切换到Buddy源码目录后运行 `composer install --prefer-source` 以便于开发。\n\n为确保能运行 `composer`，您的机器必须安装PHP 8.2或更高版本，并带有以下扩展：\n\nCODE_BLOCK_10\n\n您也可以选择发布中的Linux amd64专用版本 `manticore-executor-dev`，例如：https://github.com/manticoresoftware/executor/releases/tag/v1.0.13\n\n如果采用此方式，记得将manticore执行器的开发版本链接到 `/usr/bin/php`。\n\n要禁用Manticore Buddy，请将值设置为空，如示例所示。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\n此设置确定使用持久连接时请求之间的最大等待时间（以秒或 [special_suffixes](../Server_settings/Special_suffixes.md) 表示）。该设置为可选，默认值为五分钟。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\n服务器 libc 区域设置。可选，默认值为 C。\n\n指定 libc 区域，影响基于 libc 的排序规则。详情请参阅 [collations](../Searching/Collations.md) 部分。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\n默认服务器排序规则。可选，默认值为 libc_ci。\n\n指定用于传入请求的默认排序规则。排序规则可在每个查询中覆盖。可参阅 [collations](../Searching/Collations.md) 部分了解可用排序规则列表及其他详情。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\n指定此设置时，启用 [实时模式](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29)，这是一种命令式的数据模式管理方式。该值应为目录路径，用于存储所有表、二进制日志及运行Manticore Search所需的其他内容。\n\n指定 `data_dir` 时，不允许对 [普通表](../Creating_a_table/Local_tables/Plain_table.md) 进行索引。关于RT模式与普通模式的区别，请参阅 [本节](../Read_this_first.md#Real-time-table-vs-plain-table)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\n防止在表中无搜索时自动刷新RAM块的超时时间。可选，默认值为30秒。\n\n检查搜索的时间窗口，用于决定是否自动刷新。\n\n仅当在过去 `diskchunk_flush_search_timeout` 秒内表中至少有一次搜索时，才会自动刷新。此设置与 [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout) 配合使用。对应的 [每表设置](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) 优先级更高，会覆盖此实例级默认值，实现更细粒度控制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\n等待无写入操作的秒数，超过该时间后自动将RAM块刷新到磁盘。可选，默认值为1秒。",
      "russian": "Двоичные логи используются для восстановления данных таблицы RT после сбоев и для обновления атрибутов простых дисковых индексов, которые в противном случае хранились бы только в ОЗУ до сброса. Когда ведение логов включено, каждая транзакция, зафиксированная (COMMIT) в таблице RT, записывается в файл журнала. Логи затем автоматически воспроизводятся при запуске после некорректного завершения работы, восстанавливая записанные изменения.\n\nДиректива `binlog_path` указывает расположение файлов двоичных логов. Она должна содержать только путь; `searchd` будет создавать и удалять несколько файлов `binlog.*` в каталоге по мере необходимости (включая данные binlog, метаданные и файлы блокировок и т.д.).\n\nПустое значение отключает двоичное логирование, что улучшает производительность, но подвергает данные таблицы RT риску.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\nЭтот параметр управляет значением по умолчанию для опции поиска [boolean_simplify](../Searching/Options.md#boolean_simplify). Он необязателен, значение по умолчанию — 1 (включено).\n\nПри установке в 1 сервер автоматически применит [оптимизацию булевых запросов](../Searching/Full_text_matching/Boolean_optimization.md) для улучшения производительности запросов. При установке в 0 запросы будут выполняться без оптимизации по умолчанию. Это значение по умолчанию можно переопределить для каждого запроса с помощью соответствующей опции поиска `boolean_simplify`.\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\nЭтот параметр определяет путь к бинарному файлу Manticore Buddy. Он необязателен, значение по умолчанию — путь, настроенный во время сборки, который варьируется в зависимости от операционной системы. Обычно нет необходимости изменять этот параметр. Однако он может быть полезен, если вы хотите запустить Manticore Buddy в режиме отладки, внести изменения в Manticore Buddy или реализовать новый плагин. В последнем случае вы можете выполнить `git clone` Buddy с https://github.com/manticoresoftware/manticoresearch-buddy, добавить новый плагин в каталог `./plugins/` и запустить `composer install --prefer-source` для упрощения разработки после перехода в каталог исходников Buddy.\n\nДля возможности запуска `composer` на вашей машине должен быть установлен PHP версии 8.2 или выше с следующими расширениями:\n\nCODE_BLOCK_10\n\nВы также можете выбрать специальную версию `manticore-executor-dev` для Linux amd64, доступную в релизах, например: https://github.com/manticoresoftware/executor/releases/tag/v1.0.13\n\nЕсли вы выберете этот путь, не забудьте связать dev-версию исполнителя manticore с `/usr/bin/php`.\n\nЧтобы отключить Manticore Buddy, установите значение в пустое, как показано в примере.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\nЭтот параметр определяет максимальное время ожидания между запросами (в секундах или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)) при использовании постоянных соединений. Он необязателен, значение по умолчанию — пять минут.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_12\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\nЛокаль libc сервера. Необязательный параметр, по умолчанию C.\n\nОпределяет локаль libc, влияющую на сортировки, основанные на libc. Подробнее см. в разделе [collations](../Searching/Collations.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\nСортировка сервера по умолчанию. Необязательный параметр, по умолчанию libc_ci.\n\nОпределяет сортировку по умолчанию, используемую для входящих запросов. Сортировку можно переопределить для каждого запроса. Список доступных сортировок и другие детали см. в разделе [collations](../Searching/Collations.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\nПри указании этот параметр включает [режим реального времени](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29), который является императивным способом управления схемой данных. Значение должно быть путем к каталогу, в котором вы хотите хранить все ваши таблицы, двоичные логи и все остальное, необходимое для корректной работы Manticore Search в этом режиме.\n\nИндексация [простых таблиц](../Creating_a_table/Local_tables/Plain_table.md) не разрешена при указании `data_dir`. Подробнее о различиях между режимом RT и простым режимом читайте в [этом разделе](../Read_this_first.md#Real-time-table-vs-plain-table).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\nТаймаут для предотвращения автоматического сброса RAM-чанка, если в таблице нет поисковых запросов. Необязательный параметр, по умолчанию 30 секунд.\n\nВремя проверки наличия поисков перед решением о необходимости автоматического сброса.\n\nАвтоматический сброс произойдет только если в таблице был хотя бы один поиск за последние `diskchunk_flush_search_timeout` секунд. Работает совместно с [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout). Соответствующая [настройка на уровне таблицы](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) имеет более высокий приоритет и переопределит это значение по умолчанию, обеспечивая более тонкий контроль.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\nВремя в секундах ожидания без записи перед автоматическим сбросом RAM-чанка на диск. Необязательный параметр, по умолчанию 1 секунда."
    },
    "is_code_or_comment": false
  },
  "b384f31234f10043f0e32ca9ccd347241b2ab6b9e2d34bb15473e8aefbb8fe9c": {
    "original": "In cases where the server is configured as a pure master and just routes requests to agents, it is important to handle requests without delays and not allow the network thread to sleep. There is a busy loop for that. After an incoming request, the network thread uses CPU poll for `10 * net_wait_tm` milliseconds if `net_wait_tm` is a positive number or polls only with the CPU if `net_wait_tm` is `0`.  Also, the busy loop can be disabled with `net_wait_tm = -1` - in this case, the poller sets the timeout to the actual agent's timeouts on the system polling call.\n\n> **WARNING:** A CPU busy loop actually loads the CPU core, so setting this value to any non-default value will cause noticeable CPU usage even with an idle server.\n\n### net_throttle_accept\n\nDefines how many clients are accepted on each iteration of the network loop. Default is 0 (unlimited), which should be fine for most users. This is a fine-tuning option to control the throughput of the network loop in high load scenarios.\n\n### net_throttle_action\n\nDefines how many requests are processed on each iteration of the network loop. The default is 0 (unlimited), which should be fine for most users. This is a fine-tuning option to control the throughput of the network loop in high load scenarios.\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\nNetwork client request read/write timeout, in seconds (or  [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, the default is 5 seconds. `searchd` will forcibly close a client connection which fails to send a query or read a result within this timeout.\n\nNote also the [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet) parameter. This parameter alters the behavior of `network_timeout` from applying to the entire `query` or `result` to individual packets instead. Typically, a query/result fits within one or two packets. However, in cases where a large amount of data is required, this parameter can be invaluable in maintaining active operations.\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\nThis setting allows you to specify the network address of the node. By default, it is set to the replication [listen](../Server_settings/Searchd.md#listen) address. This is correct in most cases; however, there are situations where you have to specify it manually:\n\n* Node behind a firewall\n\n* Network address translation enabled (NAT)\n\n* Container deployments, such as Docker or cloud deployments\n\n* Clusters with nodes in more than one region\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\nThis setting determines whether to allow queries with only the [negation](../Searching/Full_text_matching/Operators.md#Negation-operator) full-text operator. Optional, the default is 0 (fail queries with only the NOT operator).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\nSets the default table compaction threshold. Read more here - [Number of optimized disk chunks](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). This setting can be overridden with the per-query option [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). It can also be changed dynamically via [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\nThis setting determines the maximum number of simultaneous persistent connections to remote [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md). Each time an agent defined under `agent_persistent` is connected, we try to reuse an existing connection (if any), or connect and save the connection for future use. However, in some cases, it makes sense to limit the number of such persistent connections. This directive defines the limit. It affects the number of connections to each agent's host across all distributed tables.\n\nIt is reasonable to set the value equal to or less than the [max_connections](../Server_settings/Searchd.md#max_connections) option in the agent's config.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file is a mandatory configuration option in Manticore search that specifies the path of the file where the process ID of the `searchd` server is stored.\n\nThe searchd process ID file is re-created and locked on startup, and contains the head server process ID while the server is running. It is unlinked on server shutdown.\n\nThe purpose of this file is to enable Manticore to perform various internal tasks, such as checking whether there is already a running instance of `searchd`, stopping `searchd`, and notifying it that it should rotate the tables. The file can also be used for external automation scripts.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\nCosts for the query time prediction model, in nanoseconds. Optional, the default is `doc=64, hit=48, skip=2048, match=64`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\nTerminating queries before completion based on their execution time (with the max query time setting) is a nice safety net, but it comes with an inherent drawback: indeterministic (unstable) results. That is, if you repeat the very same (complex) search query with a time limit several times, the time limit will be hit at different stages, and you will get *different* result sets.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_50\n\n<!-- request API -->",
    "translations": {
      "chinese": "在服务器配置为纯主服务器并仅将请求路由到代理的情况下，重要的是要无延迟地处理请求，不允许网络线程进入休眠状态。为此有一个忙循环。在收到请求后，如果 `net_wait_tm` 是正数，网络线程会使用 CPU 轮询 `10 * net_wait_tm` 毫秒；如果 `net_wait_tm` 是 `0`，则只用 CPU 轮询。 另外，可以通过设置 `net_wait_tm = -1` 来禁用忙循环——在这种情况下，轮询器会在系统轮询调用中将超时设置为实际代理的超时。\n\n> **警告：** CPU 忙循环实际上会占用 CPU 核心，因此将此值设置为任何非默认值都会导致即使服务器空闲时也会有明显的 CPU 使用率。\n\n### net_throttle_accept\n\n定义每次网络循环迭代中接受的客户端数量。默认值为 0（无限制），这对大多数用户来说是合适的。这是一个微调选项，用于在高负载场景下控制网络循环的吞吐量。\n\n### net_throttle_action\n\n定义每次网络循环迭代中处理的请求数量。默认值为 0（无限制），这对大多数用户来说是合适的。这是一个微调选项，用于在高负载场景下控制网络循环的吞吐量。\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\n网络客户端请求读写超时，单位为秒（或 [special_suffixes](../Server_settings/Special_suffixes.md)）。可选，默认值为 5 秒。`searchd` 会强制关闭在此超时内未能发送查询或读取结果的客户端连接。\n\n另请注意 [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet) 参数。该参数将 `network_timeout` 的行为从应用于整个 `query` 或 `result` 改为应用于单个数据包。通常，一个查询/结果包含一到两个数据包。然而，在需要大量数据的情况下，该参数对于保持操作活跃非常有用。\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\n此设置允许您指定节点的网络地址。默认情况下，它设置为复制的 [listen](../Server_settings/Searchd.md#listen) 地址。在大多数情况下这是正确的；但是，在某些情况下，您必须手动指定：\n\n* 节点位于防火墙后面\n\n* 启用了网络地址转换（NAT）\n\n* 容器部署，如 Docker 或云部署\n\n* 集群中节点分布在多个区域\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\n此设置决定是否允许仅包含 [否定](../Searching/Full_text_matching/Operators.md#Negation-operator) 全文操作符的查询。可选，默认值为 0（不允许仅含 NOT 操作符的查询）。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\n设置默认的表压缩阈值。详细信息请参见 - [优化的磁盘块数量](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks)。此设置可以被每个查询的选项 [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks) 覆盖。也可以通过 [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET) 动态更改。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\n此设置决定与远程 [持久代理](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) 的最大同时持久连接数。每次连接到 `agent_persistent` 下定义的代理时，我们会尝试重用现有连接（如果有），或者连接并保存该连接以供将来使用。然而，在某些情况下，限制此类持久连接的数量是合理的。此指令定义了该限制。它影响所有分布式表中与每个代理主机的连接数。\n\n合理的做法是将该值设置为代理配置中 [max_connections](../Server_settings/Searchd.md#max_connections) 选项的值或更小。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file 是 Manticore 搜索中的一个必需配置选项，指定存储 `searchd` 服务器进程 ID 的文件路径。\n\nsearchd 进程 ID 文件在启动时被重新创建并锁定，服务器运行时包含主服务器进程 ID。服务器关闭时该文件被删除。\n\n该文件的目的是使 Manticore 能执行各种内部任务，例如检查是否已有运行的 `searchd` 实例、停止 `searchd` 以及通知其应轮换表。该文件也可用于外部自动化脚本。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\n查询时间预测模型的成本，单位为纳秒。可选，默认值为 `doc=64, hit=48, skip=2048, match=64`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\n基于执行时间（使用最大查询时间设置）在查询完成前终止查询是一个不错的安全网，但它有一个固有缺点：结果不确定（不稳定）。也就是说，如果多次重复相同的（复杂）搜索查询并设置时间限制，时间限制会在不同阶段被触发，您将得到*不同*的结果集。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_50\n\n<!-- request API -->",
      "russian": "В случаях, когда сервер настроен как чистый мастер и просто маршрутизирует запросы к агентам, важно обрабатывать запросы без задержек и не допускать, чтобы сетевой поток засыпал. Для этого существует busy loop. После входящего запроса сетевой поток использует CPU poll в течение `10 * net_wait_tm` миллисекунд, если `net_wait_tm` положительное число, или опрашивает только с помощью CPU, если `net_wait_tm` равен `0`. Также busy loop можно отключить с помощью `net_wait_tm = -1` — в этом случае poller устанавливает таймауты, соответствующие фактическим таймаутам агента в системном вызове опроса.\n\n> **ВНИМАНИЕ:** Busy loop загружает ядро CPU, поэтому установка этого значения в любое не стандартное значение приведет к заметному использованию CPU даже при простое сервера.\n\n### net_throttle_accept\n\nОпределяет, сколько клиентов принимается на каждой итерации сетевого цикла. По умолчанию 0 (без ограничений), что подходит для большинства пользователей. Это опция тонкой настройки для контроля пропускной способности сетевого цикла в условиях высокой нагрузки.\n\n### net_throttle_action\n\nОпределяет, сколько запросов обрабатывается на каждой итерации сетевого цикла. По умолчанию 0 (без ограничений), что подходит для большинства пользователей. Это опция тонкой настройки для контроля пропускной способности сетевого цикла в условиях высокой нагрузки.\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\nТаймаут чтения/записи запроса клиента сети, в секундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Необязательно, по умолчанию 5 секунд. `searchd` принудительно закроет соединение клиента, если тот не отправит запрос или не прочитает результат в течение этого таймаута.\n\nОбратите внимание также на параметр [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet). Этот параметр изменяет поведение `network_timeout` с применения к всему `query` или `result` на применение к отдельным пакетам. Обычно запрос/результат помещается в один или два пакета. Однако в случаях, когда требуется большой объем данных, этот параметр может быть незаменим для поддержания активных операций.\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\nЭтот параметр позволяет указать сетевой адрес узла. По умолчанию он установлен в адрес репликации [listen](../Server_settings/Searchd.md#listen). Это правильно в большинстве случаев; однако бывают ситуации, когда его нужно указать вручную:\n\n* Узел за файрволом\n\n* Включен сетевой транслятор адресов (NAT)\n\n* Развертывания в контейнерах, таких как Docker или облачные развертывания\n\n* Кластеры с узлами в более чем одном регионе\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\nЭтот параметр определяет, разрешать ли запросы, содержащие только оператор [отрицания](../Searching/Full_text_matching/Operators.md#Negation-operator) полнотекстового поиска. Необязательно, по умолчанию 0 (запросы с только оператором NOT считаются ошибочными).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\nУстанавливает порог сжатия таблицы по умолчанию. Подробнее здесь — [Number of optimized disk chunks](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). Этот параметр можно переопределить с помощью опции на запрос [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). Также его можно динамически изменить через [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\nЭтот параметр определяет максимальное количество одновременных постоянных соединений с удалёнными [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md). Каждый раз, когда агент, определённый в `agent_persistent`, подключается, мы пытаемся повторно использовать существующее соединение (если оно есть) или подключиться и сохранить соединение для будущего использования. Однако в некоторых случаях имеет смысл ограничить количество таких постоянных соединений. Эта директива задаёт лимит. Она влияет на количество соединений с хостом каждого агента во всех распределённых таблицах.\n\nРекомендуется установить значение равным или меньше опции [max_connections](../Server_settings/Searchd.md#max_connections) в конфиге агента.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file — обязательный параметр конфигурации в Manticore search, который указывает путь к файлу, где хранится идентификатор процесса сервера `searchd`.\n\nФайл с идентификатором процесса searchd пересоздаётся и блокируется при запуске, и содержит идентификатор главного процесса сервера, пока сервер работает. При остановке сервера файл удаляется.\n\nНазначение этого файла — позволить Manticore выполнять различные внутренние задачи, такие как проверка, запущен ли уже экземпляр `searchd`, остановка `searchd` и уведомление о необходимости ротации таблиц. Файл также может использоваться внешними скриптами автоматизации.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\nЗатраты для модели предсказания времени выполнения запроса, в наносекундах. Необязательно, по умолчанию `doc=64, hit=48, skip=2048, match=64`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\nПрерывание запросов до их завершения на основе времени выполнения (с помощью настройки максимального времени запроса) — это хорошая страховка, но она имеет свой недостаток: неопределённые (нестабильные) результаты. То есть, если повторить один и тот же (сложный) поисковый запрос с ограничением по времени несколько раз, ограничение времени будет достигаться на разных этапах, и вы получите *разные* наборы результатов.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_50\n\n<!-- request API -->"
    },
    "is_code_or_comment": false
  },
  "33618c3984d292d8769e400f7edc40bf0c7b0ed4683ce73a5db433a9209d4082": {
    "original": "# Section \"Searchd\" in configuration\n\nThe below settings are to be used in the `searchd` section of the Manticore Search configuration file to control the server's behavior. Below is a summary of each setting:\n\n### access_plain_attrs\n\nThis setting sets instance-wide defaults for [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). It is optional, with a default value of `mmap_preread`.\n\nThe `access_plain_attrs` directive allows you to define the default value of [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) for all tables managed by this searchd instance. Per-table directives have higher priority and will override this instance-wide default, providing more fine-grained control.\n\n### access_blob_attrs\n\nThis setting sets instance-wide defaults for [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). It is optional, with a default value of `mmap_preread`.\n\nThe `access_blob_attrs` directive allows you to define the default value of [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) for all tables managed by this searchd instance. Per-table directives have higher priority and will override this instance-wide default, providing more fine-grained control.\n\n### access_doclists\n\nThis setting sets instance-wide defaults for [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). It is optional, with a default value of `file`.\n\nThe `access_doclists` directive allows you to define the default value of [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) for all tables managed by this searchd instance. Per-table directives have higher priority and will override this instance-wide default, providing more fine-grained control.\n\n### access_hitlists\n\nThis setting sets instance-wide defaults for [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). It is optional, with a default value of `file`.\n\nThe `access_hitlists` directive allows you to define the default value of [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) for all tables managed by this searchd instance. Per-table directives have higher priority and will override this instance-wide default, providing more fine-grained control.\n\n### access_dict\n\nThis setting sets instance-wide defaults for [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). It is optional, with a default value of `mmap_preread`.\n\nThe `access_dict` directive allows you to define the default value of [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) for all tables managed by this searchd instance. Per-table directives have higher priority and will override this instance-wide default, providing more fine-grained control.\n\n### agent_connect_timeout\n\nThis setting sets instance-wide defaults for the [agent_connect_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_connect_timeout) parameter.\n\n### agent_query_timeout\n\nThis setting sets instance-wide defaults for the [agent_query_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_query_timeout) parameter. It can be overridden on a per-query basis using the `OPTION agent_query_timeout=XXX` clause.\n\n### agent_retry_count\n\nThis setting is an integer that specifies how many times Manticore will attempt to connect and query remote agents through a distributed table before reporting a fatal query error. The default value is 0 (i.e., no retries). You can also set this value on a per-query basis using the `OPTION retry_count=XXX` clause. If a per-query option is provided, it will override the value specified in the configuration.\n\nNote that if you use [agent mirrors](../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors) in the definition of your distributed table, the server will select a different mirror for each connection attempt according to the chosen [ha_strategy](../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy). In this case, the `agent_retry_count` will be aggregated for all mirrors in a set.\n\nFor example, if you have 10 mirrors and set `agent_retry_count=5`, the server will retry up to 50 times, assuming an average of 5 tries for each of the 10 mirrors (with the `ha_strategy = roundrobin` option, this will be the case).\n\nHowever, the value provided as the `retry_count` option for the [agent](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent) serves as an absolute limit. In other words, the `[retry_count=2]` option in the agent definition always means a maximum of 2 attempts, regardless of whether you have specified 1 or 10 mirrors for the agent.\n\n### agent_retry_delay\n\nThis setting is an integer in milliseconds (or [special_suffixes](../Server_settings/Special_suffixes.md)) that specifies the delay before Manticore retries querying a remote agent in case of failure. This value is only relevant when a non-zero [agent_retry_count](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) or non-zero per-query `retry_count` is specified. The default value is 500. You can also set this value on a per-query basis using the `OPTION retry_delay=XXX` clause. If a per-query option is provided, it will override the value specified in the configuration.\n\n### attr_flush_period\n\n<!-- example conf attr_flush_period -->",
    "translations": {
      "chinese": "# 配置中的 \"Searchd\" 部分\n\n以下设置用于 Manticore Search 配置文件的 `searchd` 部分，以控制服务器的行为。以下是每个设置的摘要：\n\n### access_plain_attrs\n\n此设置为 [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 设置实例范围的默认值。此项为可选，默认值为 `mmap_preread`。\n\n`access_plain_attrs` 指令允许您为此 searchd 实例管理的所有表定义 [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 的默认值。每个表的指令优先级更高，会覆盖此实例范围的默认值，从而提供更细粒度的控制。\n\n### access_blob_attrs\n\n此设置为 [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 设置实例范围的默认值。此项为可选，默认值为 `mmap_preread`。\n\n`access_blob_attrs` 指令允许您为此 searchd 实例管理的所有表定义 [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 的默认值。每个表的指令优先级更高，会覆盖此实例范围的默认值，从而提供更细粒度的控制。\n\n### access_doclists\n\n此设置为 [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 设置实例范围的默认值。此项为可选，默认值为 `file`。\n\n`access_doclists` 指令允许您为此 searchd 实例管理的所有表定义 [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 的默认值。每个表的指令优先级更高，会覆盖此实例范围的默认值，从而提供更细粒度的控制。\n\n### access_hitlists\n\n此设置为 [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 设置实例范围的默认值。此项为可选，默认值为 `file`。\n\n`access_hitlists` 指令允许您为此 searchd 实例管理的所有表定义 [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 的默认值。每个表的指令优先级更高，会覆盖此实例范围的默认值，从而提供更细粒度的控制。\n\n### access_dict\n\n此设置为 [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 设置实例范围的默认值。此项为可选，默认值为 `mmap_preread`。\n\n`access_dict` 指令允许您为此 searchd 实例管理的所有表定义 [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) 的默认值。每个表的指令优先级更高，会覆盖此实例范围的默认值，从而提供更细粒度的控制。\n\n### agent_connect_timeout\n\n此设置为 [agent_connect_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_connect_timeout) 参数设置实例范围的默认值。\n\n### agent_query_timeout\n\n此设置为 [agent_query_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_query_timeout) 参数设置实例范围的默认值。可以通过 `OPTION agent_query_timeout=XXX` 子句在每个查询级别覆盖。\n\n### agent_retry_count\n\n此设置为整数，指定 Manticore 在报告致命查询错误之前，通过分布式表尝试连接和查询远程代理的次数。默认值为 0（即不重试）。您也可以通过 `OPTION retry_count=XXX` 子句在每个查询级别设置此值。如果提供了每查询选项，它将覆盖配置中指定的值。\n\n请注意，如果您在分布式表定义中使用了 [agent mirrors](../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors)，服务器将根据所选的 [ha_strategy](../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy) 为每次连接尝试选择不同的镜像。在这种情况下，`agent_retry_count` 将对集合中的所有镜像进行汇总。\n\n例如，如果您有 10 个镜像并设置 `agent_retry_count=5`，服务器将最多重试 50 次，假设每个镜像平均尝试 5 次（使用 `ha_strategy = roundrobin` 选项时即为如此）。\n\n然而，作为 [agent](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent) 的 `retry_count` 选项提供的值是绝对限制。换句话说，代理定义中的 `[retry_count=2]` 选项始终意味着最多尝试 2 次，无论您为代理指定了 1 个还是 10 个镜像。\n\n### agent_retry_delay\n\n此设置为以毫秒为单位的整数（或 [special_suffixes](../Server_settings/Special_suffixes.md)），指定 Manticore 在失败时重试查询远程代理之前的延迟时间。仅当指定非零的 [agent_retry_count](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) 或非零的每查询 `retry_count` 时，此值才有意义。默认值为 500。您也可以通过 `OPTION retry_delay=XXX` 子句在每个查询级别设置此值。如果提供了每查询选项，它将覆盖配置中指定的值。\n\n### attr_flush_period\n\n<!-- example conf attr_flush_period -->",
      "russian": "# Раздел \"Searchd\" в конфигурации\n\nНиже приведены настройки, которые используются в разделе `searchd` файла конфигурации Manticore Search для управления поведением сервера. Ниже приведено краткое описание каждой настройки:\n\n### access_plain_attrs\n\nЭта настройка задает значения по умолчанию для всего экземпляра для [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). Она является необязательной, значение по умолчанию — `mmap_preread`.\n\nДиректива `access_plain_attrs` позволяет определить значение по умолчанию для [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) для всех таблиц, управляемых этим экземпляром searchd. Директивы для отдельных таблиц имеют более высокий приоритет и переопределяют это значение по умолчанию, обеспечивая более тонкий контроль.\n\n### access_blob_attrs\n\nЭта настройка задает значения по умолчанию для всего экземпляра для [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). Она является необязательной, значение по умолчанию — `mmap_preread`.\n\nДиректива `access_blob_attrs` позволяет определить значение по умолчанию для [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) для всех таблиц, управляемых этим экземпляром searchd. Директивы для отдельных таблиц имеют более высокий приоритет и переопределяют это значение по умолчанию, обеспечивая более тонкий контроль.\n\n### access_doclists\n\nЭта настройка задает значения по умолчанию для всего экземпляра для [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). Она является необязательной, значение по умолчанию — `file`.\n\nДиректива `access_doclists` позволяет определить значение по умолчанию для [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) для всех таблиц, управляемых этим экземпляром searchd. Директивы для отдельных таблиц имеют более высокий приоритет и переопределяют это значение по умолчанию, обеспечивая более тонкий контроль.\n\n### access_hitlists\n\nЭта настройка задает значения по умолчанию для всего экземпляра для [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). Она является необязательной, значение по умолчанию — `file`.\n\nДиректива `access_hitlists` позволяет определить значение по умолчанию для [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) для всех таблиц, управляемых этим экземпляром searchd. Директивы для отдельных таблиц имеют более высокий приоритет и переопределяют это значение по умолчанию, обеспечивая более тонкий контроль.\n\n### access_dict\n\nЭта настройка задает значения по умолчанию для всего экземпляра для [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files). Она является необязательной, значение по умолчанию — `mmap_preread`.\n\nДиректива `access_dict` позволяет определить значение по умолчанию для [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) для всех таблиц, управляемых этим экземпляром searchd. Директивы для отдельных таблиц имеют более высокий приоритет и переопределяют это значение по умолчанию, обеспечивая более тонкий контроль.\n\n### agent_connect_timeout\n\nЭта настройка задает значения по умолчанию для всего экземпляра для параметра [agent_connect_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_connect_timeout).\n\n### agent_query_timeout\n\nЭта настройка задает значения по умолчанию для всего экземпляра для параметра [agent_query_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_query_timeout). Она может быть переопределена для каждого запроса с помощью клаузы `OPTION agent_query_timeout=XXX`.\n\n### agent_retry_count\n\nЭта настройка — целое число, которое указывает, сколько раз Manticore попытается подключиться и выполнить запрос к удалённым агентам через распределённую таблицу, прежде чем сообщить о фатальной ошибке запроса. Значение по умолчанию — 0 (т.е. без повторных попыток). Вы также можете задать это значение для каждого запроса с помощью клаузы `OPTION retry_count=XXX`. Если задана опция для конкретного запроса, она переопределит значение, указанное в конфигурации.\n\nОбратите внимание, что если вы используете [agent mirrors](../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors) в определении вашей распределённой таблицы, сервер будет выбирать другой зеркальный агент для каждой попытки подключения в соответствии с выбранной стратегией [ha_strategy](../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy). В этом случае `agent_retry_count` будет суммироваться для всех зеркал в наборе.\n\nНапример, если у вас 10 зеркал и установлено `agent_retry_count=5`, сервер будет пытаться до 50 раз, предполагая в среднем 5 попыток для каждого из 10 зеркал (при опции `ha_strategy = roundrobin` это будет так).\n\nОднако значение, указанное в опции `retry_count` для [агента](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent), служит абсолютным лимитом. Другими словами, опция `[retry_count=2]` в определении агента всегда означает максимум 2 попытки, независимо от того, указали ли вы 1 или 10 зеркал для агента.\n\n### agent_retry_delay\n\nЭта настройка — целое число в миллисекундах (или [special_suffixes](../Server_settings/Special_suffixes.md)), которое задает задержку перед повторной попыткой запроса к удалённому агенту в случае сбоя. Это значение актуально только при ненулевом [agent_retry_count](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) или ненулевом значении `retry_count` для конкретного запроса. Значение по умолчанию — 500. Вы также можете задать это значение для каждого запроса с помощью клаузы `OPTION retry_delay=XXX`. Если задана опция для конкретного запроса, она переопределит значение, указанное в конфигурации.\n\n### attr_flush_period\n\n<!-- example conf attr_flush_period -->"
    },
    "is_code_or_comment": false
  },
  "b49fc10755008e718201eb759b35259b273d016cec03758b65553f24847ed806": {
    "original": "If no write occurs in the RAM chunk within `diskchunk_flush_write_timeout` seconds, the chunk will be flushed to disk. Works in conjunction with [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout). To disable auto-flush, set `diskchunk_flush_write_timeout = -1` explicitly in your configuration. The corresponding [per-table setting](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout) has a higher priority and will override this instance-wide default, providing more fine-grained control.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\nThis setting specifies the maximum size of document blocks from document storage that are held in memory. It is optional, with a default value of 16m (16 megabytes).\n\nWhen `stored_fields` is used, document blocks are read from disk and uncompressed. Since every block typically holds several documents, it may be reused when processing the next document. For this purpose, the block is held in a server-wide cache. The cache holds uncompressed blocks.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\nDefault attribute storage engine used when creating tables in RT mode. Can be `rowwise` (default) or `columnar`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\nThis setting determines the maximum number of expanded keywords for a single wildcard. It is optional, with a default value of 0 (no limit).\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords (think of matching `a*` against the entire Oxford dictionary). This directive allows you to limit the impact of such expansions. Setting `expansion_limit = N` restricts expansions to no more than N of the most frequent matching keywords (per each wildcard in the query).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\nThis setting determines the maximum number of documents in the expanded keyword that allows merging all such keywords together. It is optional, with a default value of 32.\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords. This directive allows you to increase the limit of how many keywords will merge together to speed up matching but uses more memory in the search.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\nThis setting determines the maximum number of hits in the expanded keyword that allows merging all such keywords together. It is optional, with a default value of 256.\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords. This directive allows you to increase the limit of how many keywords will merge together to speed up matching but uses more memory in the search.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\nThis setting controls the maximum number of alternative phrase variants generated due to `OR` operators inside `PHRASE`, `PROXIMITY`, and `QUORUM` operators. It is optional, with a default value of 1024.\n\nWhen using the `|` (OR) operator inside phrase-like operator, the total number of expanded combinations may grow exponentially depending on the number of alternatives specified. This setting helps prevent excessive query expansion by capping the number of permutations considered during query processing.\n\nIf the number of generated variants exceeds this limit, the query will either:\n\n- fail with an error (default behavior)\n\n- return partial results with a warning, if `expansion_phrase_warning` is enabled\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\nThis setting controls the behavior when the query expansion limit defined by `expansion_phrase_limit` is exceeded.\n\nBy default, the query will fail with an error message. When `expansion_phrase_warning` is set to 1, the search continues using a partial transformation of the phrase (up to the configured limit), and the server returns a warning message to the user along with the result set. This allows queries that are too complex for full expansion to still return partial results without complete failure.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### grouping_in_utc\n\nThis setting specifies whether timed grouping in API and SQL will be calculated in the local timezone or in UTC. It is optional, with a default value of 0 (meaning 'local timezone').",
    "translations": {
      "chinese": "如果在 `diskchunk_flush_write_timeout` 秒内没有对 RAM 块进行写操作，该块将被刷新到磁盘。此设置与 [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout) 配合使用。要禁用自动刷新，请在配置中显式设置 `diskchunk_flush_write_timeout = -1`。对应的[每表设置](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout)优先级更高，会覆盖此实例范围的默认值，提供更细粒度的控制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\n此设置指定文档存储中保存在内存中的文档块的最大大小。此项为可选，默认值为 16m（16 兆字节）。\n\n当使用 `stored_fields` 时，文档块会从磁盘读取并解压缩。由于每个块通常包含多个文档，因此在处理下一个文档时可能会重用该块。为此，块会保存在服务器范围的缓存中。缓存保存的是未压缩的块。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\n创建 RT 模式表时使用的默认属性存储引擎。可以是 `rowwise`（默认）或 `columnar`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\n此设置确定单个通配符展开的最大关键字数量。此项为可选，默认值为 0（无限制）。\n\n在对启用了 `dict = keywords` 的表执行子串搜索时，单个通配符可能会导致成千上万甚至数百万个匹配关键字（例如匹配整个牛津词典中的 `a*`）。此指令允许您限制此类展开的影响。设置 `expansion_limit = N` 限制每个查询中每个通配符的展开不超过 N 个最频繁匹配的关键字。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\n此设置确定允许合并所有此类关键字的展开关键字中的最大文档数。此项为可选，默认值为 32。\n\n在对启用了 `dict = keywords` 的表执行子串搜索时，单个通配符可能会导致成千上万甚至数百万个匹配关键字。此指令允许您增加合并关键字的数量限制，以加快匹配速度，但会在搜索时使用更多内存。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\n此设置确定允许合并所有此类关键字的展开关键字中的最大命中数。此项为可选，默认值为 256。\n\n在对启用了 `dict = keywords` 的表执行子串搜索时，单个通配符可能会导致成千上万甚至数百万个匹配关键字。此指令允许您增加合并关键字的数量限制，以加快匹配速度，但会在搜索时使用更多内存。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\n此设置控制由于 `PHRASE`、`PROXIMITY` 和 `QUORUM` 操作符内的 `OR` 操作符生成的替代短语变体的最大数量。此项为可选，默认值为 1024。\n\n当在类似短语的操作符内使用 `|`（OR）操作符时，展开的组合总数可能会根据指定的备选项数量呈指数增长。此设置通过限制查询处理期间考虑的排列数，帮助防止过度的查询展开。\n\n如果生成的变体数量超过此限制，查询将：\n\n- 失败并返回错误（默认行为）\n\n- 如果启用了 `expansion_phrase_warning`，则返回带有警告的部分结果\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\n此设置控制当查询展开限制 `expansion_phrase_limit` 被超出时的行为。\n\n默认情况下，查询将失败并返回错误信息。当 `expansion_phrase_warning` 设置为 1 时，搜索将继续使用短语的部分转换（最多到配置的限制），服务器会向用户返回带有警告信息的结果集。这允许对于过于复杂无法完全展开的查询，仍能返回部分结果而不会完全失败。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### grouping_in_utc\n\n此设置指定 API 和 SQL 中的时间分组是按本地时区还是 UTC 计算。此项为可选，默认值为 0（表示“本地时区”）。",
      "russian": "Если в течение `diskchunk_flush_write_timeout` секунд в RAM-чанк не происходит запись, чанк будет сброшен на диск. Работает совместно с [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout). Чтобы отключить авто-сброс, явно установите `diskchunk_flush_write_timeout = -1` в вашей конфигурации. Соответствующая [настройка для каждой таблицы](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout) имеет более высокий приоритет и переопределит это значение по умолчанию для всего экземпляра, обеспечивая более тонкий контроль.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\nЭта настройка задает максимальный размер блоков документов из хранилища документов, которые удерживаются в памяти. Опционально, значение по умолчанию — 16m (16 мегабайт).\n\nКогда используется `stored_fields`, блоки документов читаются с диска и распаковываются. Поскольку каждый блок обычно содержит несколько документов, он может быть повторно использован при обработке следующего документа. Для этой цели блок удерживается в кэше на уровне сервера. Кэш хранит распакованные блоки.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\nДвижок хранения атрибутов по умолчанию, используемый при создании таблиц в режиме RT. Может быть `rowwise` (по умолчанию) или `columnar`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\nЭта настройка определяет максимальное количество расширенных ключевых слов для одного подстановочного знака. Опционально, значение по умолчанию — 0 (без ограничений).\n\nПри выполнении поиска подстрок в таблицах с включенным `dict = keywords` один подстановочный знак может привести к тысячам или даже миллионам совпадающих ключевых слов (например, сопоставление `a*` со всем словарем Оксфорда). Эта директива позволяет ограничить влияние таких расширений. Установка `expansion_limit = N` ограничивает расширения не более чем N наиболее частыми совпадающими ключевыми словами (для каждого подстановочного знака в запросе).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\nЭта настройка определяет максимальное количество документов в расширенном ключевом слове, при котором возможно объединение всех таких ключевых слов вместе. Опционально, значение по умолчанию — 32.\n\nПри выполнении поиска подстрок в таблицах с включенным `dict = keywords` один подстановочный знак может привести к тысячам или даже миллионам совпадающих ключевых слов. Эта директива позволяет увеличить лимит количества ключевых слов, которые будут объединены для ускорения сопоставления, но при этом используется больше памяти в поиске.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\nЭта настройка определяет максимальное количество попаданий в расширенном ключевом слове, при котором возможно объединение всех таких ключевых слов вместе. Опционально, значение по умолчанию — 256.\n\nПри выполнении поиска подстрок в таблицах с включенным `dict = keywords` один подстановочный знак может привести к тысячам или даже миллионам совпадающих ключевых слов. Эта директива позволяет увеличить лимит количества ключевых слов, которые будут объединены для ускорения сопоставления, но при этом используется больше памяти в поиске.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\nЭта настройка контролирует максимальное количество альтернативных вариантов фраз, сгенерированных из-за операторов `OR` внутри операторов `PHRASE`, `PROXIMITY` и `QUORUM`. Опционально, значение по умолчанию — 1024.\n\nПри использовании оператора `|` (OR) внутри операторов, похожих на фразы, общее количество расширенных комбинаций может расти экспоненциально в зависимости от количества указанных альтернатив. Эта настройка помогает предотвратить чрезмерное расширение запроса, ограничивая количество перестановок, рассматриваемых при обработке запроса.\n\nЕсли количество сгенерированных вариантов превышает этот лимит, запрос либо:\n\n- завершится с ошибкой (поведение по умолчанию)\n\n- вернет частичные результаты с предупреждением, если включен `expansion_phrase_warning`\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\nЭта настройка контролирует поведение при превышении лимита расширения запроса, определенного `expansion_phrase_limit`.\n\nПо умолчанию запрос завершится с сообщением об ошибке. При установке `expansion_phrase_warning` в 1 поиск продолжается с использованием частичной трансформации фразы (до настроенного лимита), и сервер возвращает пользователю предупреждающее сообщение вместе с результатами. Это позволяет запросам, слишком сложным для полного расширения, возвращать частичные результаты без полного сбоя.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### grouping_in_utc\n\nЭта настройка определяет, будет ли группировка по времени в API и SQL рассчитываться в локальном часовом поясе или в UTC. Опционально, значение по умолчанию — 0 (означает «локальный часовой пояс»)."
    },
    "is_code_or_comment": false
  },
  "559d082d37650fc3b0d81393bd97427cf4db98a7603a7fb12ac9be1c81c7c062": {
    "original": "If there are only a few unique JOIN ON conditions, reusing the results can be more efficient than repeatedly executing queries on the right table. To enable this, the result sets are stored in a cache.\n\nThis option allows you to configure the size of this cache. The default value is `20 MB`, and setting this option to 0 disables caching.\n\nNote that each thread maintains its own cache, so you should account for the number of threads executing queries when estimating total memory usage.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nThe listen_backlog setting determines the length of the TCP listen backlog for incoming connections. This is particularly relevant for Windows builds that process requests one by one. When the connection queue reaches its limit, new incoming connections will be refused.\n\nFor non-Windows builds, the default value should work fine, and there is usually no need to adjust this setting.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\nA server version string to return to Kibana or OpenSearch Dashboards. Optional — by default, it's set `7.6.0`.\n\nSome versions of Kibana and OpenSearch Dashboards expect the server to report a specific version number, and might behave differently depending on it. To workaround such issues, you can use this setting, which makes Manticore report a custom version to Kibana or OpenSearch Dashboards.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\nThis setting lets you specify an IP address and port, or Unix-domain socket path, that Manticore will accept connections on.\n\nThe general syntax for `listen` is:\n\nCODE_BLOCK_31\n\nYou can specify:\n\n* either an IP address (or hostname) and a port number\n\n* or just a port number\n\n* or a Unix socket path (not supported on Windows)\n\n* or an IP address and port range\n\nIf you specify a port number but not an address, `searchd` will listen on all network interfaces. Unix path is identified by a leading slash. Port range can be set only for the replication protocol.\n\nYou can also specify a protocol handler (listener) to be used for connections on this socket. The listeners are:\n\n* **Not specified** - Manticore will accept connections at this port from:\n\n  - other Manticore agents (i.e., a remote distributed table)\n\n  - clients via HTTP and HTTPS\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/). **Ensure you have a listener of this kind (or an `http` listener, as mentioned below) to avoid limitations in Manticore functionality.**\n\n* `mysql` MySQL protocol for connections from MySQL clients. Note:\n\n  - Compressed protocol is also supported.\n\n  - If [SSL](../Security/SSL.md#SSL) is enabled, you can make an encrypted connection.\n\n* `replication` - replication protocol used for nodes communication. More details can be found in the [replication](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md) section. You can specify multiple replication listeners, but they must all listen on the same IP; only the ports can be different. When you define a replication listener with a port range (e.g., `listen = 192.168.0.1:9320-9328:replication`), Manticore doesn't immediately start listening on these ports. Instead, it will take random free ports from the specified range only when you start using replication. At least 2 ports are required in the range for replication to work properly.\n\n* `http` - same as **Not specified**. Manticore will accept connections at this port from remote agents and clients via HTTP and HTTPS.\n\n* `https` - HTTPS protocol. Manticore will accept **only** HTTPS connections at this port. More details can be found in section [SSL](../Security/SSL.md).\n\n* `sphinx` - legacy binary protocol. Used to serve connections from remote [SphinxSE](../Extensions/SphinxSE.md) clients. Some Sphinx API clients implementations (an example is the Java one) require the explicit declaration of the listener.\n\nAdding suffix `_vip` to client protocols (that is, all except `replication`, for instance `mysql_vip` or `http_vip` or just `_vip`) forces creating a dedicated thread for the connection to bypass different limitations. That's useful for node maintenance in case of severe overload when the server would either stall or not let you connect via a regular port otherwise.\n\nSuffix `_readonly` sets [read-only mode](../Security/Read_only.md) for the listener and limits it to accept only read queries.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\nThere can be multiple `listen` directives. `searchd` will listen for client connections on all specified ports and sockets. The default config provided in Manticore packages defines listening on ports:\n\n* `9308` and `9312` for connections from remote agents and non-MySQL based clients\n\n* and on port `9306` for MySQL connections.\n\nIf you don't specify any `listen` in the configuration at all, Manticore will wait for connections on:\n\n* `127.0.0.1:9306` for MySQL clients\n\n* `127.0.0.1:9312`  for HTTP/HTTPS and connections from other Manticore nodes and clients based on the Manticore binary API.\n\n#### Listening on privileged ports\n\nBy default, Linux won't allow you to let Manticore listen on a port below 1024 (e.g. `listen = 127.0.0.1:80:http` or `listen = 127.0.0.1:443:https`) unless you run searchd under root. If you still want to be able to start Manticore, so it listens on ports < 1024 under a non-root user, consider doing one of the following (either of these should work):\n\n* Run the command `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* Add `AmbientCapabilities=CAP_NET_BIND_SERVICE` to Manticore's systemd unit and reload the daemon (`systemctl daemon-reload`).\n\n#### Technical details about Sphinx API protocol and TFO\n\n<details>",
    "translations": {
      "chinese": "如果只有少数几个唯一的 JOIN ON 条件，重用结果集比反复执行右表查询更高效。为此，结果集会被存储在缓存中。\n\n此选项允许您配置该缓存的大小。默认值为 `20 MB`，将此选项设置为 0 则禁用缓存。\n\n请注意，每个线程维护自己的缓存，因此在估算总内存使用时应考虑执行查询的线程数。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nlisten_backlog 设置决定了 TCP 监听队列的长度，用于传入连接。这对于逐个处理请求的 Windows 版本尤为重要。当连接队列达到限制时，新传入的连接将被拒绝。\n\n对于非 Windows 版本，默认值通常适用，通常无需调整此设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\n返回给 Kibana 或 OpenSearch Dashboards 的服务器版本字符串。可选 — 默认设置为 `7.6.0`。\n\n某些版本的 Kibana 和 OpenSearch Dashboards 期望服务器报告特定的版本号，且可能根据版本号表现不同。为解决此类问题，您可以使用此设置，使 Manticore 向 Kibana 或 OpenSearch Dashboards 报告自定义版本。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\n此设置允许您指定 Manticore 接受连接的 IP 地址和端口，或 Unix 域套接字路径。\n\n`listen` 的通用语法为：\n\nCODE_BLOCK_31\n\n您可以指定：\n\n* IP 地址（或主机名）和端口号\n\n* 或仅端口号\n\n* 或 Unix 套接字路径（Windows 不支持）\n\n* 或 IP 地址和端口范围\n\n如果指定端口号但未指定地址，`searchd` 将监听所有网络接口。Unix 路径以斜杠开头。端口范围仅可用于复制协议。\n\n您还可以为此套接字上的连接指定协议处理程序（监听器）。监听器包括：\n\n* **未指定** - Manticore 将在此端口接受来自：\n\n  - 其他 Manticore 代理（即远程分布式表）\n\n  - 通过 HTTP 和 HTTPS 的客户端\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/)。**确保您有此类监听器（或下文提到的 `http` 监听器），以避免 Manticore 功能受限。**\n\n* `mysql` MySQL 协议，用于 MySQL 客户端连接。注意：\n\n  - 也支持压缩协议。\n\n  - 如果启用了 [SSL](../Security/SSL.md#SSL)，可以建立加密连接。\n\n* `replication` - 用于节点通信的复制协议。更多细节见 [复制](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md) 部分。您可以指定多个复制监听器，但它们必须监听同一 IP，端口可以不同。当您定义带端口范围的复制监听器（例如 `listen = 192.168.0.1:9320-9328:replication`）时，Manticore 不会立即开始监听这些端口。只有在开始使用复制时，才会从指定范围中随机选择空闲端口。复制正常工作至少需要范围内有 2 个端口。\n\n* `http` - 与 **未指定** 相同。Manticore 将在此端口接受来自远程代理和通过 HTTP、HTTPS 的客户端连接。\n\n* `https` - HTTPS 协议。Manticore 仅在此端口接受 HTTPS 连接。更多细节见 [SSL](../Security/SSL.md) 部分。\n\n* `sphinx` - 传统二进制协议。用于服务来自远程 [SphinxSE](../Extensions/SphinxSE.md) 客户端的连接。一些 Sphinx API 客户端实现（例如 Java 版本）需要显式声明监听器。\n\n在客户端协议后添加后缀 `_vip`（即除 `replication` 外的所有协议，如 `mysql_vip`、`http_vip` 或仅 `_vip`）会强制为连接创建专用线程，以绕过各种限制。这在服务器严重过载时进行节点维护非常有用，否则服务器可能会停滞或无法通过常规端口连接。\n\n后缀 `_readonly` 为监听器设置[只读模式](../Security/Read_only.md)，限制其仅接受读取查询。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\n可以有多个 `listen` 指令。`searchd` 会在所有指定的端口和套接字上监听客户端连接。Manticore 软件包中提供的默认配置定义了监听端口：\n\n* `9308` 和 `9312`，用于来自远程代理和非 MySQL 客户端的连接\n\n* 以及端口 `9306`，用于 MySQL 连接。\n\n如果配置中完全未指定任何 `listen`，Manticore 将等待以下连接：\n\n* `127.0.0.1:9306`，用于 MySQL 客户端\n\n* `127.0.0.1:9312`，用于 HTTP/HTTPS 以及来自其他 Manticore 节点和基于 Manticore 二进制 API 的客户端的连接。\n\n#### 监听特权端口\n\n默认情况下，Linux 不允许 Manticore 监听 1024 以下的端口（例如 `listen = 127.0.0.1:80:http` 或 `listen = 127.0.0.1:443:https`），除非以 root 用户运行 searchd。如果您仍希望在非 root 用户下启动 Manticore 并监听 <1024 端口，请考虑以下任一方法（任一方法均可）：\n\n* 运行命令 `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* 在 Manticore 的 systemd 单元中添加 `AmbientCapabilities=CAP_NET_BIND_SERVICE` 并重新加载守护进程（`systemctl daemon-reload`）。\n\n#### 关于 Sphinx API 协议和 TFO 的技术细节\n\n<details>",
      "russian": "Если существует всего несколько уникальных условий JOIN ON, повторное использование результатов может быть более эффективным, чем многократное выполнение запросов к правой таблице. Для этого наборы результатов сохраняются в кэше.\n\nЭтот параметр позволяет настроить размер этого кэша. Значение по умолчанию — `20 MB`, а установка этого параметра в 0 отключает кэширование.\n\nОбратите внимание, что каждый поток поддерживает свой собственный кэш, поэтому при оценке общего использования памяти следует учитывать количество потоков, выполняющих запросы.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nПараметр listen_backlog определяет длину очереди TCP listen backlog для входящих соединений. Это особенно актуально для сборок под Windows, которые обрабатывают запросы по одному. Когда очередь соединений достигает предела, новые входящие соединения будут отклоняться.\n\nДля сборок не под Windows значение по умолчанию обычно подходит, и обычно нет необходимости настраивать этот параметр.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\nСтрока версии сервера, возвращаемая Kibana или OpenSearch Dashboards. Необязательно — по умолчанию установлено `7.6.0`.\n\nНекоторые версии Kibana и OpenSearch Dashboards ожидают, что сервер будет сообщать конкретный номер версии, и могут вести себя по-разному в зависимости от него. Чтобы обойти такие проблемы, вы можете использовать этот параметр, который заставляет Manticore сообщать Kibana или OpenSearch Dashboards пользовательскую версию.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\nЭтот параметр позволяет указать IP-адрес и порт или путь к Unix-доменному сокету, на которых Manticore будет принимать соединения.\n\nОбщий синтаксис для `listen`:\n\nCODE_BLOCK_31\n\nВы можете указать:\n\n* либо IP-адрес (или имя хоста) и номер порта\n\n* либо только номер порта\n\n* либо путь к Unix-сокету (не поддерживается в Windows)\n\n* либо IP-адрес и диапазон портов\n\nЕсли вы указываете номер порта, но не адрес, `searchd` будет слушать на всех сетевых интерфейсах. Путь Unix определяется ведущим слэшем. Диапазон портов можно задать только для протокола репликации.\n\nВы также можете указать обработчик протокола (listener), который будет использоваться для соединений на этом сокете. Слушатели:\n\n* **Не указан** — Manticore будет принимать соединения на этом порту от:\n\n  - других агентов Manticore (например, удалённой распределённой таблицы)\n\n  - клиентов через HTTP и HTTPS\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/). **Убедитесь, что у вас есть слушатель такого типа (или `http` слушатель, как указано ниже), чтобы избежать ограничений в функциональности Manticore.**\n\n* `mysql` — протокол MySQL для соединений от клиентов MySQL. Обратите внимание:\n\n  - Поддерживается также сжатый протокол.\n\n  - Если включён [SSL](../Security/SSL.md#SSL), можно установить зашифрованное соединение.\n\n* `replication` — протокол репликации, используемый для связи узлов. Подробнее см. в разделе [репликация](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md). Можно указать несколько слушателей репликации, но они все должны слушать на одном IP; различаться могут только порты. При определении слушателя репликации с диапазоном портов (например, `listen = 192.168.0.1:9320-9328:replication`) Manticore не начинает слушать эти порты сразу. Вместо этого он будет брать случайные свободные порты из указанного диапазона только при начале использования репликации. Для корректной работы репликации в диапазоне должно быть не менее 2 портов.\n\n* `http` — то же, что и **Не указан**. Manticore будет принимать соединения на этом порту от удалённых агентов и клиентов через HTTP и HTTPS.\n\n* `https` — протокол HTTPS. Manticore будет принимать **только** HTTPS-соединения на этом порту. Подробнее см. в разделе [SSL](../Security/SSL.md).\n\n* `sphinx` — устаревший бинарный протокол. Используется для обслуживания соединений от удалённых клиентов [SphinxSE](../Extensions/SphinxSE.md). Некоторые реализации клиентов Sphinx API (например, Java) требуют явного указания слушателя.\n\nДобавление суффикса `_vip` к протоколам клиентов (то есть ко всем, кроме `replication`, например `mysql_vip` или `http_vip` или просто `_vip`) заставляет создавать выделенный поток для соединения, чтобы обойти различные ограничения. Это полезно для обслуживания узла в случае сильной перегрузки, когда сервер в противном случае либо зависнет, либо не позволит подключиться через обычный порт.\n\nСуффикс `_readonly` устанавливает [режим только для чтения](../Security/Read_only.md) для слушателя и ограничивает его приём только запросами на чтение.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\nМожет быть несколько директив `listen`. `searchd` будет слушать клиентские соединения на всех указанных портах и сокетах. Конфигурация по умолчанию, поставляемая в пакетах Manticore, определяет прослушивание на портах:\n\n* `9308` и `9312` для соединений от удалённых агентов и клиентов, не основанных на MySQL\n\n* и на порту `9306` для MySQL-соединений.\n\nЕсли вы вообще не укажете `listen` в конфигурации, Manticore будет ждать соединений на:\n\n* `127.0.0.1:9306` для клиентов MySQL\n\n* `127.0.0.1:9312` для HTTP/HTTPS и соединений от других узлов Manticore и клиентов, основанных на бинарном API Manticore.\n\n#### Прослушивание привилегированных портов\n\nПо умолчанию Linux не позволит Manticore слушать порт ниже 1024 (например, `listen = 127.0.0.1:80:http` или `listen = 127.0.0.1:443:https`), если вы не запускаете searchd от root. Если вы всё же хотите запускать Manticore, чтобы он слушал порты < 1024 под обычным пользователем, рассмотрите один из следующих вариантов (любой из них должен работать):\n\n* Выполните команду `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* Добавьте `AmbientCapabilities=CAP_NET_BIND_SERVICE` в systemd-юнит Manticore и перезагрузите демон (`systemctl daemon-reload`).\n\n#### Технические детали о протоколе Sphinx API и TFO\n\n<details>"
    },
    "is_code_or_comment": false
  },
  "e14734b6253e703daf18486ef25360a13bc83861a539c9ccd2965af85be728c3": {
    "original": "When using [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) to modify document attributes in real-time, the changes are first written to an in-memory copy of the attributes. These updates occur in a memory-mapped file, meaning the OS decides when to write the changes to disk. Upon normal shutdown of `searchd` (triggered by a `SIGTERM` signal), all changes are forced to be written to disk.\n\nYou can also instruct `searchd` to periodically write these changes back to disk to prevent data loss. The interval between these flushes is determined by `attr_flush_period`, specified in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)).\n\nBy default, the value is 0, which disables periodic flushing. However, flushing will still occur during a normal shutdown.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\nThis setting controls the automatic [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) process for table compaction.\n\nBy default table compaction occurs automatically. You can modify this behavior with the `auto_optimize` setting:\n\n* 0 to disable automatic table compaction (you can still call `OPTIMIZE` manually)\n\n* 1 to explicitly enable it\n\n* to enable it while multiplying the optimization threshold by 2.\n\nBy default, OPTIMIZE runs until the number of disk chunks is less than or equal to the number of logical CPU cores multiplied by 2.\n\nHowever, if the table has attributes with KNN indexes, this threshold is different. In this case, it is set to the number of physical CPU cores divided by 2 to improve KNN search performance.\n\nNote that toggling `auto_optimize` on or off doesn't prevent you from running [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) manually.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore supports the automatic creation of tables that don't yet exist but are specified in INSERT statements. This feature is enabled by default. To disable it, set `auto_schema = 0` explicitly in your configuration. To re-enable it, set `auto_schema = 1` or remove the `auto_schema` setting from the configuration.\n\nKeep in mind that the `/bulk` HTTP endpoint does not support automatic table creation.\n\n> NOTE: The [auto schema functionality](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) requires [Manticore Buddy](../Installation/Manticore_Buddy.md). If it doesn't work, make sure Buddy is installed.\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Enable -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\nThis setting controls the binary log transaction flush/sync mode. It is optional, with a default value of 2 (flush every transaction, sync every second).\n\nThe directive determines how frequently the binary log will be flushed to the OS and synced to disk. There are three supported modes:\n\n*  0, flush and sync every second. This offers the best performance, but up to 1 second worth of committed transactions can be lost in the event of a server crash or an OS/hardware crash.\n\n*  1, flush and sync every transaction. This mode provides the worst performance but guarantees that every committed transaction's data is saved.\n\n*  2, flush every transaction, sync every second. This mode delivers good performance and ensures that every committed transaction is saved in case of a server crash. However, in the event of an OS/hardware crash, up to 1 second worth of committed transactions can be lost.\n\nFor those familiar with MySQL and InnoDB, this directive is similar to `innodb_flush_log_at_trx_commit`. In most cases, the default hybrid mode 2 provides a nice balance of speed and safety, with full RT table data protection against server crashes and some protection against hardware ones.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_5\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\nThis setting controls how binary log files are managed. It is optional, with a default value of 0 (separate file for each table).\n\nYou can choose between two ways to manage binary log files:\n\n* Separate file for each table (default, `0`): Each table saves its changes in its own log file. This setup is good if you have many tables that get updated at different times. It allows tables to be updated without waiting for others. Also, if there is a problem with one table's log file, it does not affect the others.\n\n* Single file for all tables (`1`): All tables use the same binary log file. This method makes it easier to handle files because there are fewer of them. However, this could keep files longer than needed if one table still needs to save its updates. This setting might also slow things down if many tables need to update at the same time because all changes have to wait to be written to one file.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->\n\nThis setting controls the maximum binary log file size. It is optional, with a default value of 256 MB.\n\nA new binlog file will be forcibly opened once the current binlog file reaches this size limit. This results in a finer granularity of logs and can lead to more efficient binlog disk usage under certain borderline workloads. A value of 0 indicates that the binlog file should not be reopened based on size.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\nThis setting determines the path for binary log (also known as transaction log) files. It is optional, with a default value of the build-time configured data directory (e.g., `/var/lib/manticore/data/binlog.*` in Linux).",
    "translations": {
      "chinese": "当使用 [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) 实时修改文档属性时，变更首先写入属性的内存副本。这些更新发生在内存映射文件中，意味着操作系统决定何时将更改写入磁盘。在 `searchd` 正常关闭时（由 `SIGTERM` 信号触发），所有更改都会被强制写入磁盘。\n\n您也可以指示 `searchd` 定期将这些更改写回磁盘以防止数据丢失。刷新间隔由 `attr_flush_period` 决定，单位为秒（或 [special_suffixes](../Server_settings/Special_suffixes.md)）。\n\n默认值为 0，表示禁用定期刷新。但在正常关闭时仍会进行刷新。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\n此设置控制表压缩的自动 [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) 过程。\n\n默认情况下，表压缩会自动进行。您可以通过 `auto_optimize` 设置修改此行为：\n\n* 0 禁用自动表压缩（您仍然可以手动调用 `OPTIMIZE`）\n\n* 1 显式启用自动表压缩\n\n* 启用自动表压缩并将优化阈值乘以 2。\n\n默认情况下，OPTIMIZE 会运行直到磁盘块数小于或等于逻辑 CPU 核心数乘以 2。\n\n但是，如果表具有带 KNN 索引的属性，则阈值不同。在这种情况下，阈值设置为物理 CPU 核心数除以 2，以提升 KNN 搜索性能。\n\n请注意，切换 `auto_optimize` 开关不会阻止您手动运行 [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore 支持自动创建尚不存在但在 INSERT 语句中指定的表。此功能默认启用。要禁用它，请在配置中显式设置 `auto_schema = 0`。要重新启用，请设置 `auto_schema = 1` 或从配置中移除 `auto_schema` 设置。\n\n请注意，`/bulk` HTTP 端点不支持自动创建表。\n\n> 注意：[自动 schema 功能](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) 需要 [Manticore Buddy](../Installation/Manticore_Buddy.md)。如果功能无法使用，请确保 Buddy 已安装。\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Enable -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\n此设置控制二进制日志事务的刷新/同步模式。为可选项，默认值为 2（每个事务刷新，每秒同步一次）。\n\n该指令决定二进制日志刷新到操作系统和同步到磁盘的频率。支持三种模式：\n\n*  0，每秒刷新和同步一次。性能最佳，但在服务器崩溃或操作系统/硬件崩溃时，最多可能丢失 1 秒内的已提交事务。\n\n*  1，每个事务刷新和同步一次。性能最差，但保证每个已提交事务的数据都被保存。\n\n*  2，每个事务刷新，每秒同步一次。性能良好，确保服务器崩溃时每个已提交事务都被保存。但在操作系统/硬件崩溃时，最多可能丢失 1 秒内的已提交事务。\n\n对于熟悉 MySQL 和 InnoDB 的用户，此指令类似于 `innodb_flush_log_at_trx_commit`。在大多数情况下，默认的混合模式 2 在速度和安全性之间提供了良好平衡，完全保护 RT 表数据免受服务器崩溃影响，并对硬件崩溃提供一定保护。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_5\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\n此设置控制二进制日志文件的管理方式。为可选项，默认值为 0（每个表单独文件）。\n\n您可以选择两种管理二进制日志文件的方式：\n\n* 每个表单独文件（默认，`0`）：每个表将其更改保存到自己的日志文件中。此设置适合有许多表且更新时间不同的情况。它允许表独立更新，无需等待其他表。如果某个表的日志文件出现问题，也不会影响其他表。\n\n* 所有表共用一个文件（`1`）：所有表使用同一个二进制日志文件。此方法便于文件管理，因为文件数量较少。但如果某个表仍需保存更新，文件可能会被保留时间较长。如果许多表同时需要更新，可能会导致性能下降，因为所有更改必须等待写入同一个文件。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->\n\n此设置控制二进制日志文件的最大大小。为可选项，默认值为 256 MB。\n\n当当前二进制日志文件达到此大小限制时，将强制打开一个新的日志文件。这带来了更细粒度的日志划分，并且在某些边界工作负载下可以更高效地使用二进制日志磁盘空间。值为 0 表示不基于大小重新打开日志文件。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\n此设置确定二进制日志（也称为事务日志）文件的路径。为可选项，默认值为构建时配置的数据目录（例如 Linux 下的 `/var/lib/manticore/data/binlog.*`）。",
      "russian": "При использовании [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) для изменения атрибутов документа в реальном времени, изменения сначала записываются в копию атрибутов в памяти. Эти обновления происходят в файле с отображением в память, что означает, что ОС решает, когда записывать изменения на диск. При нормальном завершении работы `searchd` (инициируемом сигналом `SIGTERM`) все изменения принудительно записываются на диск.\n\nВы также можете указать `searchd` периодически записывать эти изменения на диск, чтобы предотвратить потерю данных. Интервал между этими сбросами определяется параметром `attr_flush_period`, указанным в секундах (или [special_suffixes](../Server_settings/Special_suffixes.md)).\n\nПо умолчанию значение равно 0, что отключает периодический сброс. Однако сброс все равно происходит при нормальном завершении работы.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\nЭтот параметр управляет автоматическим процессом [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) для сжатия таблицы.\n\nПо умолчанию сжатие таблицы происходит автоматически. Вы можете изменить это поведение с помощью параметра `auto_optimize`:\n\n* 0 — отключить автоматическое сжатие таблицы (вы все еще можете вызвать `OPTIMIZE` вручную)\n\n* 1 — явно включить его\n\n* включить с умножением порога оптимизации на 2.\n\nПо умолчанию OPTIMIZE выполняется до тех пор, пока количество дисковых чанков не станет меньше или равно количеству логических ядер CPU, умноженному на 2.\n\nОднако, если в таблице есть атрибуты с KNN индексами, этот порог отличается. В этом случае он устанавливается равным количеству физических ядер CPU, деленному на 2, для улучшения производительности KNN поиска.\n\nОбратите внимание, что переключение `auto_optimize` в положение вкл/выкл не мешает вам запускать [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) вручную.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore поддерживает автоматическое создание таблиц, которые еще не существуют, но указаны в операторах INSERT. Эта функция включена по умолчанию. Чтобы отключить её, явно установите `auto_schema = 0` в вашей конфигурации. Чтобы снова включить, установите `auto_schema = 1` или удалите параметр `auto_schema` из конфигурации.\n\nИмейте в виду, что HTTP-эндпоинт `/bulk` не поддерживает автоматическое создание таблиц.\n\n> ПРИМЕЧАНИЕ: [Функциональность авто-схемы](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если она не работает, убедитесь, что Buddy установлен.\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Enable -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\nЭтот параметр управляет режимом сброса/синхронизации транзакций бинарного лога. Он необязателен, значение по умолчанию — 2 (сброс каждой транзакции, синхронизация каждую секунду).\n\nДиректива определяет, как часто бинарный лог будет сбрасываться в ОС и синхронизироваться на диск. Поддерживаются три режима:\n\n*  0 — сброс и синхронизация каждую секунду. Это обеспечивает лучшую производительность, но при сбое сервера или ОС/аппаратном сбое можно потерять до 1 секунды подтвержденных транзакций.\n\n*  1 — сброс и синхронизация каждой транзакции. Этот режим обеспечивает худшую производительность, но гарантирует сохранение данных каждой подтвержденной транзакции.\n\n*  2 — сброс каждой транзакции, синхронизация каждую секунду. Этот режим обеспечивает хорошую производительность и гарантирует сохранение каждой подтвержденной транзакции при сбое сервера. Однако при сбое ОС/аппаратном сбое можно потерять до 1 секунды подтвержденных транзакций.\n\nДля тех, кто знаком с MySQL и InnoDB, эта директива похожа на `innodb_flush_log_at_trx_commit`. В большинстве случаев режим 2 по умолчанию обеспечивает хороший баланс скорости и безопасности, с полной защитой данных RT таблиц от сбоев сервера и частичной защитой от аппаратных сбоев.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_5\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\nЭтот параметр управляет тем, как управляются файлы бинарного лога. Он необязателен, значение по умолчанию — 0 (отдельный файл для каждой таблицы).\n\nВы можете выбрать один из двух способов управления файлами бинарного лога:\n\n* Отдельный файл для каждой таблицы (по умолчанию, `0`): каждая таблица сохраняет свои изменения в собственном лог-файле. Эта настройка хороша, если у вас много таблиц, которые обновляются в разное время. Это позволяет обновлять таблицы без ожидания других. Также, если возникает проблема с лог-файлом одной таблицы, это не влияет на другие.\n\n* Один файл для всех таблиц (`1`): все таблицы используют один и тот же файл бинарного лога. Этот метод упрощает управление файлами, так как их меньше. Однако это может привести к тому, что файлы будут храниться дольше, если одна таблица все еще должна сохранить свои обновления. Эта настройка также может замедлить работу, если много таблиц нужно обновить одновременно, так как все изменения должны ждать записи в один файл.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->\n\nЭтот параметр управляет максимальным размером файла бинарного лога. Он необязателен, значение по умолчанию — 256 МБ.\n\nНовый файл binlog будет принудительно открыт, как только текущий файл достигнет этого предела размера. Это приводит к более мелкой гранулярности логов и может привести к более эффективному использованию диска binlog при определенных пограничных нагрузках. Значение 0 означает, что файл binlog не должен переоткрываться по размеру.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\nЭтот параметр определяет путь для файлов бинарного лога (также известного как журнал транзакций). Он необязателен, значение по умолчанию — каталог данных, настроенный во время сборки (например, `/var/lib/manticore/data/binlog.*` в Linux)."
    },
    "is_code_or_comment": false
  },
  "ebb7d5744a2c9ab7c6c40b594edd83834f89db0e68b32314c4076c12fd6649ec": {
    "original": "By default, all 'group by time' expressions (like group by day, week, month, and year in API, also group by day, month, year, yearmonth, yearmonthday in SQL) are done using local time. For example, if you have documents with attributes timed `13:00 utc` and `15:00 utc`, in the case of grouping, they both will fall into facility groups according to your local timezone setting. If you live in `utc`, it will be one day, but if you live in `utc+10`, then these documents will be matched into different `group by day` facility groups (since 13:00 utc in UTC+10 timezone is 23:00 local time, but 15:00 is 01:00 of the next day). Sometimes such behavior is unacceptable, and it is desirable to make time grouping not dependent on timezone. You can run the server with a defined global TZ environment variable, but it will affect not only grouping but also timestamping in the logs, which may be undesirable as well. Switching 'on' this option (either in config or using [SET global](../Server_settings/Setting_variables_online.md#SET) statement in SQL) will cause all time grouping expressions to be calculated in UTC, leaving the rest of time-depentend functions (i.e. logging of the server) in local TZ.\n\n### timezone\n\nThis setting specifies the timezone to be used by date/time-related functions. By default, the local timezone is used, but you can specify a different timezone in IANA format (e.g., `Europe/Amsterdam`).\n\nNote that this setting has no impact on logging, which always operates in the local timezone.\n\nAlso, note that if `grouping_in_utc` is used, the 'group by time' function will still use UTC, while other date/time-related functions will use the specified timezone. Overall, it is not recommended to mix `grouping_in_utc` and `timezone`.\n\nYou can configure this option either in the config or by using the [SET global](../Server_settings/Setting_variables_online.md#SET) statement in SQL.\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\nThis setting specifies the agent mirror statistics window size, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). It is optional, with a default value of 60 seconds.\n\nFor a distributed table with agent mirrors in it (see more in [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md),  the master tracks several different per-mirror counters. These counters are then used for failover and balancing (the master picks the best mirror to use based on the counters). Counters are accumulated in blocks of `ha_period_karma` seconds.\n\nAfter beginning a new block, the master may still use the accumulated values from the previous one until the new one is half full. As a result, any previous history stops affecting the mirror choice after 1.5 times ha_period_karma seconds at most.\n\nEven though at most two blocks are used for mirror selection, up to 15 last blocks are stored for instrumentation purposes. These blocks can be inspected using the [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS) statement.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\nThis setting configures the interval between agent mirror pings, in milliseconds (or [special_suffixes](../Server_settings/Special_suffixes.md)).  It is optional, with a default value of 1000 milliseconds.\n\nFor a distributed table with agent mirrors in it (see more in [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)),  the master sends all mirrors a ping command during idle periods. This is to track the current agent status (alive or dead, network roundtrip, etc). The interval between such pings is defined by this directive. To disable pings, set ha_ping_interval to 0.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### hostname_lookup\n\nThe `hostname_lookup` option defines the strategy for renewing hostnames. By default, the IP addresses of agent host names are cached at server start to avoid excessive access to DNS. However, in some cases, the IP can change dynamically (e.g. cloud hosting) and it may be desirable to not cache the IPs. Setting this option to `request` disables the caching and queries the DNS for each query. The IP addresses can also be manually renewed using the `FLUSH HOSTNAMES` command.\n\n### jobs_queue_size\n\nThe jobs_queue_size setting defines how many \"jobs\" can be in the queue at the same time. It is unlimited by default.\n\nIn most cases, a \"job\" means one query to a single local table (plain table or a disk chunk of a real-time table). For example, if you have a distributed table consisting of 2 local tables or a real-time table with 2 disk chunks, a search query to either of them will mostly put 2 jobs in the queue. Then, the thread pool (whose size is defined by [threads](../Server_settings/Searchd.md#threads) will process them. However, in some cases, if the query is too complex, more jobs can be created. Changing this setting is recommended when [max_connections](../Server_settings/Searchd.md#max_connections) and [threads](../Server_settings/Searchd.md#threads) are not enough to find a balance between the desired performance.\n\n### join_batch_size\n\nTable joins work by accumulating a batch of matches, which are the results of the query executed on the left table. This batch is then processed as a single query on the right table.\n\nThis option allows you to adjust the batch size. The default value is `1000`, and setting this option to `0` disables batching.\n\nA larger batch size may improve performance; however, for some queries, it can lead to excessive memory consumption.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### join_cache_size\n\nEach query executed on the right table is defined by specific JOIN ON conditions, which determine the result set retrieved from the right table.",
    "translations": {
      "chinese": "默认情况下，所有“按时间分组”表达式（如 API 中的按天、周、月和年分组，以及 SQL 中的按天、月、年、年月、年月日分组）均使用本地时间进行。例如，如果您有属性时间为 `13:00 utc` 和 `15:00 utc` 的文档，在分组时，它们都会根据您的本地时区设置归入相应的设施组。如果您所在时区为 `utc`，则它们属于同一天，但如果您所在时区为 `utc+10`，则这些文档会被匹配到不同的“按天分组”设施组（因为 UTC+10 时区的 13:00 utc 是本地时间 23:00，而 15:00 是第二天的 01:00）。有时这种行为是不可接受的，且希望使时间分组不依赖于时区。您可以通过设置全局 TZ 环境变量来运行服务器，但这不仅会影响分组，还会影响日志中的时间戳，这可能也是不希望的。开启此选项（无论是在配置中还是使用 SQL 中的 [SET global](../Server_settings/Setting_variables_online.md#SET) 语句）将使所有时间分组表达式以 UTC 计算，而其他依赖时间的函数（例如服务器日志记录）仍使用本地时区。\n\n### timezone\n\n此设置指定日期/时间相关函数使用的时区。默认情况下，使用本地时区，但您可以指定 IANA 格式的其他时区（例如，`Europe/Amsterdam`）。\n\n请注意，此设置不会影响日志记录，日志始终使用本地时区。\n\n另外，请注意，如果使用了 `grouping_in_utc`，则“按时间分组”函数仍将使用 UTC，而其他日期/时间相关函数将使用指定的时区。总体而言，不建议混合使用 `grouping_in_utc` 和 `timezone`。\n\n您可以在配置中设置此选项，或通过 SQL 中的 [SET global](../Server_settings/Setting_variables_online.md#SET) 语句进行配置。\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\n此设置指定代理镜像统计窗口大小，单位为秒（或 [special_suffixes](../Server_settings/Special_suffixes.md)）。此项为可选，默认值为 60 秒。\n\n对于包含代理镜像的分布式表（详见 [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)），主节点跟踪多个不同的每镜像计数器。这些计数器随后用于故障转移和平衡（主节点根据计数器选择最佳镜像）。计数器以 `ha_period_karma` 秒为块进行累积。\n\n开始新块后，主节点可能仍会使用前一个块的累积值，直到新块填充到一半。因此，任何之前的历史最多在 1.5 倍 ha_period_karma 秒后停止影响镜像选择。\n\n尽管最多使用两个块进行镜像选择，但最多存储最近 15 个块以供监控使用。可以使用 [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS) 语句查看这些块。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\n此设置配置代理镜像之间的 ping 间隔，单位为毫秒（或 [special_suffixes](../Server_settings/Special_suffixes.md)）。此项为可选，默认值为 1000 毫秒。\n\n对于包含代理镜像的分布式表（详见 [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)），主节点在空闲期间向所有镜像发送 ping 命令，以跟踪当前代理状态（存活或死亡、网络往返时间等）。此指令定义了 ping 之间的间隔。要禁用 ping，请将 ha_ping_interval 设置为 0。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### hostname_lookup\n\n`hostname_lookup` 选项定义了主机名更新策略。默认情况下，代理主机名的 IP 地址在服务器启动时缓存，以避免频繁访问 DNS。但在某些情况下，IP 可能动态变化（例如云托管），此时可能希望不缓存 IP。将此选项设置为 `request` 会禁用缓存，并在每次查询时查询 DNS。IP 地址也可以通过 `FLUSH HOSTNAMES` 命令手动更新。\n\n### jobs_queue_size\n\njobs_queue_size 设置定义了队列中可以同时存在多少“作业”。默认情况下无限制。\n\n在大多数情况下，“作业”指的是对单个本地表（普通表或实时表的磁盘分片）的一次查询。例如，如果您有一个由 2 个本地表组成的分布式表，或一个有 2 个磁盘分片的实时表，对它们的搜索查询通常会在队列中放入 2 个作业。然后，线程池（其大小由 [threads](../Server_settings/Searchd.md#threads) 定义）处理这些作业。但在某些情况下，如果查询过于复杂，可能会创建更多作业。当 [max_connections](../Server_settings/Searchd.md#max_connections) 和 [threads](../Server_settings/Searchd.md#threads) 无法平衡所需性能时，建议调整此设置。\n\n### join_batch_size\n\n表连接通过累积一批匹配项来工作，这些匹配项是对左表执行查询的结果。然后将此批次作为单个查询在右表上处理。\n\n此选项允许您调整批次大小。默认值为 `1000`，将此选项设置为 `0` 可禁用批处理。\n\n较大的批次大小可能提升性能；但对于某些查询，可能导致内存消耗过大。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### join_cache_size\n\n对右表执行的每个查询由特定的 JOIN ON 条件定义，这些条件决定了从右表检索的结果集。",
      "russian": "По умолчанию все выражения 'group by time' (например, group by day, week, month и year в API, а также group by day, month, year, yearmonth, yearmonthday в SQL) выполняются с использованием локального времени. Например, если у вас есть документы с атрибутами времени `13:00 utc` и `15:00 utc`, при группировке они оба попадут в группы по объектам в соответствии с вашей локальной настройкой часового пояса. Если вы живёте в `utc`, это будет один день, но если вы живёте в `utc+10`, то эти документы будут отнесены к разным группам `group by day` (поскольку 13:00 utc в часовом поясе UTC+10 — это 23:00 местного времени, а 15:00 — это 01:00 следующего дня). Иногда такое поведение неприемлемо, и желательно сделать группировку времени независимой от часового пояса. Вы можете запустить сервер с определённой глобальной переменной окружения TZ, но это повлияет не только на группировку, но и на отметки времени в логах, что также может быть нежелательно. Включение этой опции (либо в конфиге, либо с помощью оператора [SET global](../Server_settings/Setting_variables_online.md#SET) в SQL) приведёт к тому, что все выражения группировки времени будут вычисляться в UTC, при этом остальные функции, зависящие от времени (например, логирование сервера), останутся в локальном часовом поясе.\n\n### timezone\n\nЭтот параметр задаёт часовой пояс, который будет использоваться функциями, связанными с датой и временем. По умолчанию используется локальный часовой пояс, но вы можете указать другой часовой пояс в формате IANA (например, `Europe/Amsterdam`).\n\nОбратите внимание, что этот параметр не влияет на логирование, которое всегда работает в локальном часовом поясе.\n\nТакже обратите внимание, что если используется `grouping_in_utc`, функция 'group by time' всё равно будет использовать UTC, в то время как другие функции, связанные с датой и временем, будут использовать указанный часовой пояс. В целом не рекомендуется смешивать `grouping_in_utc` и `timezone`.\n\nВы можете настроить эту опцию либо в конфиге, либо с помощью оператора [SET global](../Server_settings/Setting_variables_online.md#SET) в SQL.\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\nЭтот параметр задаёт размер окна статистики зеркал агентов в секундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Он необязателен, значение по умолчанию — 60 секунд.\n\nДля распределённой таблицы с зеркалами агентов (подробнее см. в [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)) мастер отслеживает несколько различных счётчиков для каждого зеркала. Эти счётчики затем используются для переключения и балансировки (мастер выбирает лучшее зеркало на основе счётчиков). Счётчики накапливаются блоками по `ha_period_karma` секунд.\n\nПосле начала нового блока мастер может продолжать использовать накопленные значения из предыдущего блока, пока новый блок не заполнится наполовину. В результате, любая предыдущая история перестаёт влиять на выбор зеркала максимум через 1.5 раза `ha_period_karma` секунд.\n\nХотя для выбора зеркала используется максимум два блока, до 15 последних блоков сохраняются для целей инструментирования. Эти блоки можно просмотреть с помощью оператора [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\nЭтот параметр задаёт интервал между пингами зеркал агентов в миллисекундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Он необязателен, значение по умолчанию — 1000 миллисекунд.\n\nДля распределённой таблицы с зеркалами агентов (подробнее см. в [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)) мастер отправляет всем зеркалам команду пинга в периоды простоя. Это необходимо для отслеживания текущего статуса агента (жив или мёртв, время сетевого отклика и т.д.). Интервал между такими пингами определяется этой директивой. Чтобы отключить пинги, установите ha_ping_interval в 0.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### hostname_lookup\n\nОпция `hostname_lookup` определяет стратегию обновления имён хостов. По умолчанию IP-адреса имён хостов агентов кэшируются при запуске сервера, чтобы избежать чрезмерных обращений к DNS. Однако в некоторых случаях IP может динамически меняться (например, в облачном хостинге), и может быть желательно не кэшировать IP. Установка этой опции в значение `request` отключает кэширование и выполняет запросы к DNS при каждом запросе. IP-адреса также можно обновить вручную с помощью команды `FLUSH HOSTNAMES`.\n\n### jobs_queue_size\n\nПараметр jobs_queue_size определяет, сколько \"заданий\" может находиться в очереди одновременно. По умолчанию ограничений нет.\n\nВ большинстве случаев \"задание\" означает один запрос к одной локальной таблице (обычной таблице или дисковому чанку таблицы реального времени). Например, если у вас есть распределённая таблица, состоящая из 2 локальных таблиц, или таблица реального времени с 2 дисковыми чанками, поисковый запрос к любой из них обычно создаст 2 задания в очереди. Затем пул потоков (размер которого задаётся параметром [threads](../Server_settings/Searchd.md#threads)) обрабатывает их. Однако в некоторых случаях, если запрос слишком сложный, может создаваться больше заданий. Рекомендуется изменять этот параметр, когда [max_connections](../Server_settings/Searchd.md#max_connections) и [threads](../Server_settings/Searchd.md#threads) недостаточны для достижения баланса между желаемой производительностью.\n\n### join_batch_size\n\nОбъединения таблиц работают путём накопления партии совпадений, которые являются результатами запроса, выполненного по левой таблице. Эта партия затем обрабатывается как единый запрос к правой таблице.\n\nЭта опция позволяет настроить размер партии. Значение по умолчанию — `1000`, установка этого параметра в `0` отключает пакетную обработку.\n\nБольший размер партии может улучшить производительность; однако для некоторых запросов это может привести к чрезмерному потреблению памяти.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### join_cache_size\n\nКаждый запрос, выполняемый по правой таблице, определяется конкретными условиями JOIN ON, которые определяют набор результатов, извлекаемых из правой таблицы."
    },
    "is_code_or_comment": false
  },
  "ef5014b780f504762bef6884b27637cf255f3963b85ff2460e2e98e140bddd17": {
    "original": "Integer, in seconds. The expiration period for a cached result set. Defaults to 60, or 1 minute. The minimum possible value is 1 second. Refer to [query cache](../Searching/Query_cache.md) for details. This value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing '_sec'.\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\nQuery log format. Optional, allowed values are `plain` and `sphinxql`, default is `sphinxql`.\n\nThe `sphinxql` mode logs valid SQL statements. The `plain` mode logs queries in a plain text format (mostly suitable for purely full-text use cases). This directive allows you to switch between the two formats on search server startup. The log format can also be altered on the fly, using `SET GLOBAL query_log_format=sphinxql` syntax. Refer to [Query logging](../Logging/Query_logging.md) for more details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### query_log_min_msec\n\nLimit (in milliseconds) that prevents the query from being written to the query log. Optional, default is 0 (all queries are written to the query log). This directive specifies that only queries with execution times that exceed the specified limit will be logged (this value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing `_msec`).\n\n### query_log\n\n<!-- example conf query_log -->\n\nQuery log file name. Optional, default is empty (do not log queries). All search queries (such as SELECT ... but not INSERT/REPLACE/UPDATE queries) will be logged in this file. The format is described in [Query logging](../Logging/Query_logging.md). In case of 'plain' format, you can use 'syslog' as the path to the log file. In this case, all search queries will be sent to the syslog daemon with `LOG_INFO` priority, prefixed with '[query]' instead of timestamp. To use the syslog option, Manticore must be configured with  `-–with-syslog` on building.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nThe query_log_mode directive allows you to set a different permission for the searchd and query log files. By default, these log files are created with 600 permission, meaning that only the user under which the server runs and root users can read the log files.\n\nThis directive can be handy if you want to allow other users to read the log files, for example, monitoring solutions running on non-root users.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nThe read_buffer_docs directive controls the per-keyword read buffer size for document lists. For every keyword occurrence in every search query, there are two associated read buffers: one for the document list and one for the hit list. This setting lets you control the document list buffer size.\n\nA larger buffer size might increase per-query RAM use, but it could possibly decrease I/O time. It makes sense to set larger values for slow storage, but for storage capable of high IOPS, experimenting should be done in the low values area.\n\nThe default value is 256K, and the minimal value is 8K. You may also set [read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs) on a per-table basis, which will override anything set on the server's config level.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nThe read_buffer_hits directive specifies the per-keyword read buffer size for hit lists in search queries. By default, the size is 256K and the minimum value is 8K. For every keyword occurrence in a search query, there are two associated read buffers, one for the document list and one for the hit list. Increasing the buffer size can increase per-query RAM use but decrease I/O time. For slow storage, larger buffer sizes make sense, while for storage capable of high IOPS, experimenting should be done in the low values area.\n\nThis setting can also be specified on a per-table basis using the read_buffer_hits option in [read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits) which will override the server-level setting.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\nUnhinted read size. Optional, default is 32K, minimal 1K\n\nWhen querying, some reads know in advance exactly how much data is there to be read, but some currently do not. Most prominently, hit list size is not currently known in advance. This setting lets you control how much data to read in such cases. It impacts hit list I/O time, reducing it for lists larger than unhinted read size, but raising it for smaller lists. It does **not** affect RAM usage because the read buffer will already be allocated. So it should not be greater than read_buffer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\nRefines the behavior of networking timeouts (such as `network_timeout` and `agent_query_timeout`).\n\nWhen set to 0, timeouts limit the maximum time for sending the entire request/query.\n\nWhen set to 1 (default), timeouts limit the maximum time between network activities.",
    "translations": {
      "chinese": "整数，单位为秒。缓存结果集的过期时间。默认值为60秒，即1分钟。最小可能值为1秒。详情请参阅[查询缓存](../Searching/Query_cache.md)。该值也可以用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但请谨慎使用，不要与值本身包含的“_sec”混淆。\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\n查询日志格式。可选，允许的值为`plain`和`sphinxql`，默认是`sphinxql`。\n\n`sphinxql`模式记录有效的SQL语句。`plain`模式以纯文本格式记录查询（主要适用于纯全文搜索场景）。此指令允许您在搜索服务器启动时切换这两种格式。日志格式也可以动态更改，使用`SET GLOBAL query_log_format=sphinxql`语法。详情请参阅[查询日志](../Logging/Query_logging.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### query_log_min_msec\n\n限制（以毫秒为单位），防止查询被写入查询日志。可选，默认值为0（所有查询都会写入查询日志）。此指令指定只有执行时间超过指定限制的查询才会被记录（该值也可以用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但请谨慎使用，不要与值本身包含的“_msec”混淆）。\n\n### query_log\n\n<!-- example conf query_log -->\n\n查询日志文件名。可选，默认为空（不记录查询）。所有搜索查询（如SELECT ...，但不包括INSERT/REPLACE/UPDATE查询）都会记录在此文件中。格式详见[查询日志](../Logging/Query_logging.md)。在“plain”格式下，可以使用“syslog”作为日志文件路径。在这种情况下，所有搜索查询将以`LOG_INFO`优先级发送到syslog守护进程，前缀为“[query]”而非时间戳。要使用syslog选项，Manticore必须在构建时配置`-–with-syslog`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nquery_log_mode指令允许您为searchd和查询日志文件设置不同的权限。默认情况下，这些日志文件的权限为600，意味着只有运行服务器的用户和root用户可以读取日志文件。\n\n如果您想允许其他用户读取日志文件，例如运行在非root用户下的监控解决方案，此指令非常有用。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nread_buffer_docs指令控制文档列表的每个关键字读取缓冲区大小。对于每个搜索查询中的每个关键字出现，有两个相关的读取缓冲区：一个用于文档列表，一个用于命中列表。此设置允许您控制文档列表缓冲区大小。\n\n较大的缓冲区大小可能会增加每个查询的RAM使用，但可能减少I/O时间。对于慢速存储，设置较大值是合理的，但对于能够提供高IOPS的存储，应在较低值区域进行实验。\n\n默认值为256K，最小值为8K。您也可以在每个表级别设置[read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs)，这将覆盖服务器配置级别的设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nread_buffer_hits指令指定搜索查询中命中列表的每个关键字读取缓冲区大小。默认大小为256K，最小值为8K。对于搜索查询中的每个关键字出现，有两个相关的读取缓冲区，一个用于文档列表，一个用于命中列表。增加缓冲区大小可以增加每个查询的RAM使用，但减少I/O时间。对于慢速存储，较大的缓冲区大小是合理的，而对于能够提供高IOPS的存储，应在较低值区域进行实验。\n\n此设置也可以通过在每个表级别使用read_buffer_hits选项在[read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits)中指定，这将覆盖服务器级别的设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\n未提示读取大小。可选，默认值为32K，最小值为1K。\n\n在查询时，有些读取操作事先知道确切的数据量，但有些则不知道。最明显的是，命中列表大小目前无法预先知道。此设置允许您控制在这种情况下读取的数据量。它影响命中列表的I/O时间，对于大于未提示读取大小的列表减少I/O时间，但对于较小的列表则增加I/O时间。它**不**影响RAM使用，因为读取缓冲区已经分配。因此，它不应大于read_buffer。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\n细化网络超时（如`network_timeout`和`agent_query_timeout`）的行为。\n\n设置为0时，超时限制发送整个请求/查询的最大时间。\n\n设置为1（默认）时，超时限制网络活动之间的最大时间。",
      "russian": "Целое число, в секундах. Период истечения срока действия для кэшированного набора результатов. По умолчанию 60, или 1 минута. Минимально возможное значение — 1 секунда. Подробности см. в разделе [query cache](../Searching/Query_cache.md). Это значение также может быть выражено с помощью временных [special_suffixes](../Server_settings/Special_suffixes.md), но используйте это с осторожностью и не путайте с названием самого значения, содержащим '_sec'.\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\nФормат журнала запросов. Необязательно, допустимые значения — `plain` и `sphinxql`, по умолчанию `sphinxql`.\n\nРежим `sphinxql` записывает действительные SQL-запросы. Режим `plain` записывает запросы в простом текстовом формате (в основном подходит для чисто полнотекстовых случаев использования). Эта директива позволяет переключаться между двумя форматами при запуске поискового сервера. Формат журнала также можно изменить на лету, используя синтаксис `SET GLOBAL query_log_format=sphinxql`. Подробности см. в разделе [Query logging](../Logging/Query_logging.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### query_log_min_msec\n\nЛимит (в миллисекундах), который предотвращает запись запроса в журнал запросов. Необязательно, по умолчанию 0 (все запросы записываются в журнал запросов). Эта директива указывает, что в журнал будут записываться только запросы с временем выполнения, превышающим указанный лимит (это значение также может быть выражено с помощью временных [special_suffixes](../Server_settings/Special_suffixes.md), но используйте это с осторожностью и не путайте с названием самого значения, содержащим `_msec`).\n\n### query_log\n\n<!-- example conf query_log -->\n\nИмя файла журнала запросов. Необязательно, по умолчанию пусто (не вести журнал запросов). Все поисковые запросы (например, SELECT ... но не INSERT/REPLACE/UPDATE запросы) будут записываться в этот файл. Формат описан в разделе [Query logging](../Logging/Query_logging.md). В случае формата 'plain' можно использовать 'syslog' в качестве пути к файлу журнала. В этом случае все поисковые запросы будут отправлены демону syslog с приоритетом `LOG_INFO`, с префиксом '[query]' вместо временной метки. Для использования опции syslog Manticore должен быть собран с опцией `-–with-syslog`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nДиректива query_log_mode позволяет установить разные права доступа для файлов журнала searchd и журнала запросов. По умолчанию эти файлы журнала создаются с правами 600, что означает, что читать их могут только пользователь, под которым запущен сервер, и пользователи root.\n\nЭта директива может быть полезна, если вы хотите разрешить другим пользователям читать файлы журнала, например, решениям для мониторинга, работающим под не-root пользователями.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nДиректива read_buffer_docs управляет размером буфера чтения на ключевое слово для списков документов. Для каждого вхождения ключевого слова в каждом поисковом запросе существует два связанных буфера чтения: один для списка документов и один для списка попаданий. Эта настройка позволяет контролировать размер буфера списка документов.\n\nБольший размер буфера может увеличить использование ОЗУ на запрос, но возможно уменьшит время ввода-вывода. Имеет смысл устанавливать большие значения для медленных хранилищ, но для хранилищ с высокой производительностью IOPS следует экспериментировать с малыми значениями.\n\nЗначение по умолчанию — 256K, минимальное значение — 8K. Вы также можете установить [read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs) для каждой таблицы отдельно, что переопределит настройки на уровне сервера.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nДиректива read_buffer_hits задает размер буфера чтения на ключевое слово для списков попаданий в поисковых запросах. По умолчанию размер 256K, минимальное значение 8K. Для каждого вхождения ключевого слова в поисковом запросе существует два связанных буфера чтения: один для списка документов и один для списка попаданий. Увеличение размера буфера может увеличить использование ОЗУ на запрос, но уменьшить время ввода-вывода. Для медленных хранилищ имеет смысл использовать большие размеры буфера, а для хранилищ с высокой производительностью IOPS следует экспериментировать с малыми значениями.\n\nЭта настройка также может быть задана для каждой таблицы отдельно с помощью опции read_buffer_hits в [read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits), что переопределит настройку на уровне сервера.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\nРазмер чтения без подсказок. Необязательно, по умолчанию 32K, минимальное 1K\n\nПри выполнении запросов некоторые чтения заранее точно знают, сколько данных нужно прочитать, а некоторые — нет. Наиболее заметно, что размер списка попаданий в настоящее время заранее не известен. Эта настройка позволяет контролировать, сколько данных читать в таких случаях. Она влияет на время ввода-вывода списка попаданий, уменьшая его для списков, больших, чем размер чтения без подсказок, но увеличивая для меньших списков. Она **не** влияет на использование ОЗУ, так как буфер чтения уже будет выделен. Поэтому она не должна быть больше, чем read_buffer.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\nУточняет поведение сетевых таймаутов (таких как `network_timeout` и `agent_query_timeout`).\n\nЕсли установлено в 0, таймауты ограничивают максимальное время отправки всего запроса/запроса.\n\nЕсли установлено в 1 (по умолчанию), таймауты ограничивают максимальное время между сетевой активностью."
    },
    "is_code_or_comment": false
  },
  "dc7fb23aa2436d011e59da5fd7bd28a1cdef301c523dc571322493a4bdf66fcc": {
    "original": "With replication, a node may need to send a large file (for example, 100GB) to another node. Assume the network can transfer data at 1GB/s, with a series of packets of 4-5MB each. To transfer the entire file, you would need 100 seconds. A default timeout of 5 seconds would only allow the transfer of 5GB before the connection is dropped. Increasing the timeout could be a workaround, but it is not scalable (for instance, the next file might be 150GB, leading to failure again). However, with the default `reset_network_timeout_on_packet` set to 1, the timeout is applied not to the entire transfer but to individual packets. As long as the transfer is in progress (and data is actually being received over the network during the timeout period), it is kept alive. If the transfer gets stuck, such that a timeout occurs between packets, it will be dropped.\n\nNote that if you set up a distributed table, each node — both master and agents — should be tuned. On the master side, `agent_query_timeout` is affected; on agents, `network_timeout` is relevant.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nRT tables RAM chunk flush check period, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 10 hours.\n\nActively updated RT tables that fully fit in RAM chunks can still result in ever-growing binlogs, impacting disk use and crash recovery time. With this directive, the search server performs periodic flush checks, and eligible RAM chunks can be saved, enabling consequential binlog cleanup. See [Binary logging](../Logging/Binary_logging.md) for more details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nA maximum number of I/O operations (per second) that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).\n\nThis directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. It is guaranteed that all RT optimization activities will not generate more disk IOPS (I/Os per second) than the configured limit. Limiting rt_merge_iops can reduce search performance degradation caused by merging.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nA maximum size of an I/O operation that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).\n\nThis directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. I/Os larger than this limit will be broken down into two or more I/Os, which will then be accounted for as separate I/Os with regards to the [rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops) limit. Thus, it is guaranteed that all optimization activities will not generate more than (rt_merge_iops * rt_merge_maxiosize) bytes of disk I/O per second.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\nPrevents `searchd` stalls while rotating tables with huge amounts of data to precache. Optional, default is 1 (enable seamless rotation). On Windows systems, seamless rotation is disabled by default.\n\nTables may contain some data that needs to be precached in RAM. At the moment, `.spa`, `.spb`, `.spi`, and `.spm` files are fully precached (they contain attribute data, blob attribute data, keyword table, and killed row map, respectively.) Without seamless rotate, rotating a table tries to use as little RAM as possible and works as follows:\n\n1. New queries are temporarily rejected (with \"retry\" error code);\n\n2. `searchd` waits for all currently running queries to finish;\n\n3. The old table is deallocated, and its files are renamed;\n\n4. New table files are renamed, and required RAM is allocated;\n\n5. New table attribute and dictionary data are preloaded to RAM;\n\n6. `searchd` resumes serving queries from the new table.\n\nHowever, if there's a lot of attribute or dictionary data, then the preloading step could take a noticeable amount of time - up to several minutes in the case of preloading 1-5+ GB files.\n\nWith seamless rotate enabled, rotation works as follows:\n\n1. New table RAM storage is allocated;\n\n2. New table attribute and dictionary data are asynchronously preloaded to RAM;\n\n3. On success, the old table is deallocated, and both tables' files are renamed;\n\n4. On failure, the new table is deallocated;\n\n5. At any given moment, queries are served either from the old or new table copy.\n\nSeamless rotate comes at the cost of higher peak memory usage during the rotation (because both old and new copies of `.spa/.spb/.spi/.spm` data need to be in RAM while preloading the new copy). Average usage remains the same.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\nThis option specifies the size of the block cache used by secondary indexes. It is optional, with a default of 8 MB. When secondary indexes work with filters that contain many values (e.g., IN() filters), they read and process metadata blocks for these values.\n\nIn joined queries, this process is repeated for each batch of rows from the left table, and each batch may reread the same metadata within a single joined query. This can severely affect performance. The metadata block cache keeps these blocks in memory so they\n\ncan be reused by subsequent batches.\n\nThe cache is only used in joined queries and has no effect on non-joined queries. Note that the cache size limit applies per attribute and per secondary index. Each attribute within each disk chunk operates within this limit. In the worst case, the total memory\n\nusage can be estimated by multiplying the limit by the number of disk chunks and the number of attributes used in joined queries.\n\nSetting `secondary_index_block_cache = 0` disables the cache.\n\n<!-- intro -->\n\n##### Example:",
    "translations": {
      "chinese": "通过复制，节点可能需要将一个大文件（例如，100GB）发送到另一个节点。假设网络传输速率为1GB/s，数据包大小为4-5MB。传输整个文件需要100秒。默认的5秒超时只允许传输5GB数据，之后连接会被断开。增加超时可以作为一种解决方法，但这不可扩展（例如，下一个文件可能是150GB，仍会导致失败）。然而，默认情况下 `reset_network_timeout_on_packet` 设置为1，超时应用于单个数据包而非整个传输。只要传输正在进行中（且在超时期间网络上实际接收到了数据），连接就会保持活跃。如果传输卡住，导致数据包之间发生超时，则连接会被断开。\n\n请注意，如果设置了分布式表，主节点和代理节点都应进行调优。主节点影响的是 `agent_query_timeout`；代理节点则相关于 `network_timeout`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nRT表RAM块刷新检查周期，单位为秒（或[special_suffixes](../Server_settings/Special_suffixes.md)）。可选，默认值为10小时。\n\n完全适合RAM块的主动更新RT表仍可能导致binlog不断增长，影响磁盘使用和崩溃恢复时间。通过此指令，搜索服务器执行周期性刷新检查，符合条件的RAM块可以被保存，从而实现后续binlog清理。详情见[二进制日志](../Logging/Binary_logging.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nRT块合并线程允许启动的最大I/O操作数（每秒）。可选，默认值为0（无限制）。\n\n此指令允许限制由 `OPTIMIZE` 语句引起的I/O影响。保证所有RT优化活动产生的磁盘IOPS（每秒I/O次数）不会超过配置的限制。限制rt_merge_iops可以减少合并导致的搜索性能下降。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nRT块合并线程允许启动的最大I/O操作大小。可选，默认值为0（无限制）。\n\n此指令允许限制由 `OPTIMIZE` 语句引起的I/O影响。超过此限制的I/O操作将被拆分成两个或更多I/O操作，这些操作将作为独立I/O计入[rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops)限制。因此，保证所有优化活动每秒产生的磁盘I/O不超过 (rt_merge_iops * rt_merge_maxiosize) 字节。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\n防止在旋转包含大量数据以进行预缓存的表时，`searchd` 停顿。可选，默认值为1（启用无缝旋转）。在Windows系统上，默认禁用无缝旋转。\n\n表可能包含需要预缓存到RAM中的数据。目前，`.spa`、`.spb`、`.spi` 和 `.spm` 文件会被完全预缓存（它们分别包含属性数据、blob属性数据、关键字表和已删除行映射）。无无缝旋转时，旋转表尽量少用RAM，流程如下：\n\n1. 临时拒绝新查询（返回“重试”错误码）；\n\n2. `searchd` 等待所有正在运行的查询完成；\n\n3. 旧表被释放，其文件被重命名；\n\n4. 新表文件被重命名，分配所需RAM；\n\n5. 新表属性和字典数据预加载到RAM；\n\n6. `searchd` 恢复从新表服务查询。\n\n但如果属性或字典数据量大，预加载步骤可能耗时显著——预加载1-5GB以上文件时可能需要几分钟。\n\n启用无缝旋转后，旋转流程如下：\n\n1. 分配新表RAM存储；\n\n2. 异步预加载新表属性和字典数据到RAM；\n\n3. 成功时，释放旧表，重命名两个表的文件；\n\n4. 失败时，释放新表；\n\n5. 任何时刻，查询要么从旧表，要么从新表副本服务。\n\n无缝旋转代价是旋转期间峰值内存使用增加（因为预加载新副本时，旧副本和新副本的 `.spa/.spb/.spi/.spm` 数据都需在RAM中）。平均使用量保持不变。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\n此选项指定二级索引使用的块缓存大小。可选，默认8MB。当二级索引处理包含大量值的过滤器（例如IN()过滤器）时，会读取并处理这些值的元数据块。\n\n在连接查询中，这一过程会对左表的每个批次重复执行，每个批次可能在单个连接查询内重复读取相同元数据。这会严重影响性能。元数据块缓存将这些块保存在内存中，以便后续批次重用。\n\n缓存仅在连接查询中使用，对非连接查询无影响。注意，缓存大小限制是针对每个属性和每个二级索引的。每个磁盘块中的每个属性都在此限制内运行。最坏情况下，总内存使用量可估算为限制乘以磁盘块数和连接查询中使用的属性数。\n\n设置 `secondary_index_block_cache = 0` 可禁用缓存。\n\n<!-- intro -->\n\n##### 示例：",
      "russian": "При репликации узлу может потребоваться отправить большой файл (например, 100 ГБ) другому узлу. Предположим, что сеть может передавать данные со скоростью 1 ГБ/с, с серией пакетов по 4-5 МБ каждый. Для передачи всего файла потребуется 100 секунд. Таймаут по умолчанию в 5 секунд позволит передать только 5 ГБ, после чего соединение будет разорвано. Увеличение таймаута могло бы быть обходным решением, но это не масштабируемо (например, следующий файл может быть 150 ГБ, что снова приведет к сбою). Однако при установленном по умолчанию `reset_network_timeout_on_packet` в 1 таймаут применяется не ко всей передаче, а к отдельным пакетам. Пока передача продолжается (и данные действительно принимаются по сети в течение периода таймаута), соединение поддерживается. Если передача застревает, и таймаут происходит между пакетами, соединение будет разорвано.\n\nОбратите внимание, что если вы настраиваете распределенную таблицу, каждый узел — как мастер, так и агенты — должен быть настроен. На стороне мастера влияет `agent_query_timeout`; на агентах — `network_timeout`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nПериод проверки сброса чанков RAM RT-таблиц, в секундах (или [special_suffixes](../Server_settings/Special_suffixes.md)). Необязательно, по умолчанию 10 часов.\n\nАктивно обновляемые RT-таблицы, полностью помещающиеся в чанки RAM, могут приводить к постоянно растущим бинлогам, что влияет на использование диска и время восстановления после сбоев. С помощью этой директивы поисковый сервер выполняет периодические проверки сброса, и подходящие чанки RAM могут быть сохранены, что позволяет последующую очистку бинлогов. Подробнее см. в разделе [Binary logging](../Logging/Binary_logging.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nМаксимальное количество операций ввода-вывода (в секунду), которые поток слияния чанков RT может начать. Необязательно, по умолчанию 0 (без ограничений).\n\nЭта директива позволяет ограничить влияние операций ввода-вывода, возникающих из-за операторов `OPTIMIZE`. Гарантируется, что все операции оптимизации RT не будут генерировать больше дисковых IOPS (операций ввода-вывода в секунду), чем заданный лимит. Ограничение rt_merge_iops может уменьшить деградацию производительности поиска, вызванную слиянием.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nМаксимальный размер операции ввода-вывода, которую поток слияния чанков RT может начать. Необязательно, по умолчанию 0 (без ограничений).\n\nЭта директива позволяет ограничить влияние операций ввода-вывода, возникающих из-за операторов `OPTIMIZE`. Операции ввода-вывода, превышающие этот лимит, будут разбиты на две или более операций, которые затем будут учитываться как отдельные операции в рамках лимита [rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops). Таким образом, гарантируется, что все операции оптимизации не будут генерировать более (rt_merge_iops * rt_merge_maxiosize) байт дискового ввода-вывода в секунду.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\nПредотвращает зависания `searchd` при ротации таблиц с огромным объемом данных для предварительного кэширования. Необязательно, по умолчанию 1 (включена бесшовная ротация). В системах Windows бесшовная ротация по умолчанию отключена.\n\nТаблицы могут содержать данные, которые необходимо предварительно кэшировать в RAM. В настоящее время файлы `.spa`, `.spb`, `.spi` и `.spm` полностью предварительно кэшируются (они содержат данные атрибутов, данные блоб-атрибутов, таблицу ключевых слов и карту удаленных строк соответственно). Без бесшовной ротации ротация таблицы старается использовать как можно меньше RAM и работает следующим образом:\n\n1. Новые запросы временно отклоняются (с кодом ошибки \"retry\");\n\n2. `searchd` ожидает завершения всех текущих запросов;\n\n3. Старая таблица освобождается, и ее файлы переименовываются;\n\n4. Файлы новой таблицы переименовываются, и выделяется необходимая RAM;\n\n5. Данные атрибутов и словаря новой таблицы предварительно загружаются в RAM;\n\n6. `searchd` возобновляет обслуживание запросов из новой таблицы.\n\nОднако если данных атрибутов или словаря много, этап предварительной загрузки может занять заметное время — до нескольких минут при загрузке файлов размером 1-5+ ГБ.\n\nПри включенной бесшовной ротации ротация работает следующим образом:\n\n1. Выделяется RAM для хранения новой таблицы;\n\n2. Данные атрибутов и словаря новой таблицы асинхронно предварительно загружаются в RAM;\n\n3. При успешной загрузке старая таблица освобождается, и файлы обеих таблиц переименовываются;\n\n4. При неудаче новая таблица освобождается;\n\n5. В любой момент запросы обслуживаются либо из старой, либо из новой копии таблицы.\n\nБесшовная ротация требует большего пикового использования памяти во время ротации (поскольку обе копии данных `.spa/.spb/.spi/.spm` — старая и новая — должны находиться в RAM во время предварительной загрузки новой копии). Среднее использование памяти остается прежним.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\nЭтот параметр задает размер кэша блоков, используемого вторичными индексами. Необязательно, по умолчанию 8 МБ. Когда вторичные индексы работают с фильтрами, содержащими много значений (например, фильтры IN()), они читают и обрабатывают метаданные блоков для этих значений.\n\nВ объединенных запросах этот процесс повторяется для каждой партии строк из левой таблицы, и каждая партия может повторно читать одни и те же метаданные в рамках одного объединенного запроса. Это может значительно повлиять на производительность. Кэш метаданных блоков хранит эти блоки в памяти, чтобы они\n\nмогли быть повторно использованы последующими партиями.\n\nКэш используется только в объединенных запросах и не влияет на не объединенные запросы. Обратите внимание, что ограничение размера кэша применяется на каждый атрибут и на каждый вторичный индекс. Каждый атрибут в каждом дисковом чанке работает в рамках этого ограничения. В худшем случае общее использование памяти\n\nможно оценить, умножив ограничение на количество дисковых чанков и количество атрибутов, используемых в объединенных запросах.\n\nУстановка `secondary_index_block_cache = 0` отключает кэш.\n\n<!-- intro -->\n\n##### Пример:"
    },
    "is_code_or_comment": false
  },
  "0f41ec5ecb6fa7274b87673619ab0b118a7d8e25d11ffd101dbe860b11c05fed": {
    "original": "The server uses the CA file to verify the signature on the certificate. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\nPath to the server's SSL certificate. Optional, default is empty.\n\nThe server uses this certificate as a self-signed public key to encrypt HTTP traffic over SSL. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nPath to the SSL certificate key. Optional, default is empty.\n\nThe server uses this private key to encrypt HTTP traffic over SSL. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\nMax common subtree document cache size, per-query. Optional, default is 0 (disabled).\n\nThis setting limits the RAM usage of a common subtree optimizer (see  [multi-queries](../Searching/Multi-queries.md)). At most, this much RAM will be spent to cache document entries for each query. Setting the limit to 0 disables the optimizer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\nMax common subtree hit cache size, per-query. Optional, default is 0 (disabled).\n\nThis setting limits the RAM usage of a common subtree optimizer (see [multi-queries](../Searching/Multi-queries.md)). At most, this much RAM will be spent to cache keyword occurrences (hits) for each query. Setting the limit to 0 disables the optimizer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nNumber of working threads (or, size of thread pool) for the Manticore daemon. Manticore creates this number of OS threads on start, and they perform all jobs inside the daemon, such as executing queries, creating snippets, etc. Some operations may be split into sub-tasks and executed in parallel, for example:\n\n* Search in a real-time table\n\n* Search in a distributed table consisting of local tables\n\n* Percolate query call\n\n* and others\n\nBy default, it's set to the number of CPU cores on the server. Manticore creates the threads on start and keeps them until it's stopped. Each sub-task can use one of the threads when it needs it. When the sub-task finishes, it releases the thread so another sub-task can use it.\n\nIn the case of intensive I/O type of load, it might make sense to set the value higher than the number of CPU cores.\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\nMaximum stack size for a job (coroutine, one search query may cause multiple jobs/coroutines). Optional, default is 128K.\n\nEach job has its own stack of 128K. When you run a query, it's checked for how much stack it requires. If the default 128K is enough, it's just processed. If it needs more, another job with an increased stack is scheduled, which continues processing. The maximum size of such an advanced stack is limited by this setting.\n\nSetting the value to a reasonably high rate will help with processing very deep queries without implying that overall RAM consumption will grow too high. For example, setting it to 1G does not imply that every new job will take 1G of RAM, but if we see that it requires, let's say, 100M stack, we just allocate 100M for the job. Other jobs at the same time will be running with their default 128K stack. The same way, we can run even more complex queries that need 500M. And only if we **see** internally that the job requires more than 1G of stack, we will fail and report about too low thread_stack.\n\nHowever, in practice, even a query which needs 16M of stack is often too complex for parsing and consumes too much time and resources to be processed. So, the daemon will process it, but limiting such queries by the `thread_stack` setting looks quite reasonable.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\nDetermines whether to unlink `.old` table copies on successful rotation. Optional, default is 1 (do unlink).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\nThreaded server watchdog. Optional, default is 1 (watchdog enabled).\n\nWhen a Manticore query crashes, it can take down the entire server. With the watchdog feature enabled, `searchd` also maintains a separate lightweight process that monitors the main server process and automatically restarts it in case of abnormal termination. The watchdog is enabled by default.\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n<!-- proofread -->",
    "translations": {
      "chinese": "服务器使用 CA 文件来验证证书上的签名。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\n服务器 SSL 证书的路径。可选，默认值为空。\n\n服务器使用此证书作为自签名公钥，通过 SSL 加密 HTTP 流量。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nSSL 证书密钥的路径。可选，默认值为空。\n\n服务器使用此私钥通过 SSL 加密 HTTP 流量。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\n每个查询的最大公共子树文档缓存大小。可选，默认值为 0（禁用）。\n\n此设置限制公共子树优化器的内存使用（参见 [multi-queries](../Searching/Multi-queries.md)）。最多将使用这么多内存来缓存每个查询的文档条目。将限制设置为 0 会禁用优化器。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\n每个查询的最大公共子树命中缓存大小。可选，默认值为 0（禁用）。\n\n此设置限制公共子树优化器的内存使用（参见 [multi-queries](../Searching/Multi-queries.md)）。最多将使用这么多内存来缓存每个查询的关键字出现（命中）。将限制设置为 0 会禁用优化器。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nManticore 守护进程的工作线程数（或线程池大小）。Manticore 启动时创建此数量的操作系统线程，这些线程执行守护进程内的所有任务，如执行查询、创建摘要等。一些操作可能被拆分为子任务并行执行，例如：\n\n* 在实时表中搜索\n\n* 在由本地表组成的分布式表中搜索\n\n* 轮询查询调用\n\n* 以及其他\n\n默认情况下，线程数设置为服务器的 CPU 核心数。Manticore 启动时创建线程并保持运行直到停止。每个子任务在需要时可以使用其中一个线程。子任务完成后释放线程，供其他子任务使用。\n\n在密集 I/O 类型负载的情况下，设置的线程数高于 CPU 核心数可能更合理。\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\n作业的最大栈大小（协程，一个搜索查询可能导致多个作业/协程）。可选，默认值为 128K。\n\n每个作业有自己的 128K 栈。运行查询时，会检查所需的栈大小。如果默认的 128K 足够，则直接处理。如果需要更多，则调度另一个具有更大栈的作业继续处理。此设置限制了此类扩展栈的最大大小。\n\n将此值设置为合理较高的数值，有助于处理非常深的查询，而不会导致整体内存消耗过高。例如，设置为 1G 并不意味着每个新作业都会占用 1G 内存，而是如果发现作业需要 100M 栈，则只分配 100M。其他作业同时使用默认的 128K 栈。以此类推，我们可以运行需要 500M 的更复杂查询。只有当内部检测到作业需要超过 1G 栈时，才会失败并报告 thread_stack 设置过低。\n\n然而，实际上，即使是需要 16M 栈的查询通常也过于复杂，解析耗时且资源消耗大。因此，守护进程会处理它，但通过 `thread_stack` 设置限制此类查询是合理的。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\n确定是否在成功轮换后取消链接 `.old` 表副本。可选，默认值为 1（执行取消链接）。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\n线程化服务器看门狗。可选，默认值为 1（启用看门狗）。\n\n当 Manticore 查询崩溃时，可能导致整个服务器宕机。启用看门狗功能后，`searchd` 还维护一个独立的轻量级进程，监控主服务器进程，并在异常终止时自动重启。看门狗默认启用。\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n<!-- proofread -->",
      "russian": "Сервер использует файл CA для проверки подписи на сертификате. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\nПуть к SSL-сертификату сервера. Необязательно, по умолчанию пусто.\n\nСервер использует этот сертификат как самоподписанный открытый ключ для шифрования HTTP-трафика по SSL. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nПуть к ключу SSL-сертификата. Необязательно, по умолчанию пусто.\n\nСервер использует этот приватный ключ для шифрования HTTP-трафика по SSL. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\nМаксимальный размер кеша документов общего поддерева, на запрос. Необязательно, по умолчанию 0 (отключено).\n\nЭта настройка ограничивает использование ОЗУ оптимизатором общего поддерева (см. [multi-queries](../Searching/Multi-queries.md)). Максимум столько ОЗУ будет потрачено на кеширование записей документов для каждого запроса. Установка лимита в 0 отключает оптимизатор.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\nМаксимальный размер кеша попаданий общего поддерева, на запрос. Необязательно, по умолчанию 0 (отключено).\n\nЭта настройка ограничивает использование ОЗУ оптимизатором общего поддерева (см. [multi-queries](../Searching/Multi-queries.md)). Максимум столько ОЗУ будет потрачено на кеширование вхождений ключевых слов (попаданий) для каждого запроса. Установка лимита в 0 отключает оптимизатор.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nКоличество рабочих потоков (или размер пула потоков) для демона Manticore. Manticore создаёт такое количество потоков ОС при запуске, и они выполняют все задачи внутри демона, такие как выполнение запросов, создание сниппетов и т.д. Некоторые операции могут быть разбиты на подзадачи и выполняться параллельно, например:\n\n* Поиск в таблице реального времени\n\n* Поиск в распределённой таблице, состоящей из локальных таблиц\n\n* Вызов перколяции запроса\n\n* и другие\n\nПо умолчанию установлено количество ядер CPU на сервере. Manticore создаёт потоки при запуске и держит их до остановки. Каждая подзадача может использовать один из потоков, когда это необходимо. Когда подзадача завершается, она освобождает поток, чтобы другая подзадача могла его использовать.\n\nВ случае интенсивной нагрузки типа I/O может иметь смысл установить значение выше количества ядер CPU.\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\nМаксимальный размер стека для задачи (корутина, один поисковый запрос может вызвать несколько задач/корутин). Необязательно, по умолчанию 128K.\n\nКаждая задача имеет свой собственный стек размером 128K. При запуске запроса проверяется, сколько стека он требует. Если стандартных 128K достаточно, запрос просто обрабатывается. Если требуется больше, планируется другая задача с увеличенным стеком, которая продолжает обработку. Максимальный размер такого расширенного стека ограничен этой настройкой.\n\nУстановка значения на разумно высоком уровне поможет обрабатывать очень глубокие запросы без значительного увеличения общего потребления ОЗУ. Например, установка 1G не означает, что каждая новая задача будет занимать 1G ОЗУ, но если мы видим, что требуется, скажем, 100M стека, мы выделяем 100M для задачи. Другие задачи в это время будут работать со стандартным стеком 128K. Аналогично, можно запускать ещё более сложные запросы, которым нужен стек в 500M. И только если мы **увидим** внутренне, что задача требует более 1G стека, мы завершимся с ошибкой и сообщим о слишком низком thread_stack.\n\nОднако на практике даже запрос, требующий 16M стека, часто слишком сложен для парсинга и потребляет слишком много времени и ресурсов для обработки. Поэтому демон обработает его, но ограничение таких запросов настройкой `thread_stack` выглядит вполне разумным.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\nОпределяет, следует ли удалять копии таблиц с расширением `.old` после успешной ротации. Необязательно, по умолчанию 1 (удалять).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\nПоточный сторож сервера. Необязательно, по умолчанию 1 (сторож включён).\n\nКогда запрос Manticore аварийно завершается, он может привести к падению всего сервера. При включённой функции сторожа `searchd` также поддерживает отдельный лёгкий процесс, который следит за основным процессом сервера и автоматически перезапускает его в случае ненормального завершения. Сторож включён по умолчанию.\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "54fb31d383eaa135960cb99666e1457f57fe7ea3296c11219e0d264053c91ce0": {
    "original": "Alternatively, you can use the 'syslog' as the file name. In this case, the events will be sent to the syslog daemon. To use the syslog option, you need to configure Manticore with the `-–with-syslog` option during building.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\nLimits the amount of queries per batch. Optional, default is 32.\n\nMakes searchd perform a sanity check of the amount of queries submitted in a single batch when using [multi-queries](../Searching/Multi-queries.md). Set it to 0 to skip the check.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\nMaximum number of simultaneous client connections. Unlimited by default. That is usually noticeable only when using any kind of persistent connections, like cli mysql sessions or persistent remote connections from remote distributed tables. When the limit is exceeded you can still connect to the server using the [VIP connection](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection). VIP connections are not counted towards the limit.\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\nInstance-wide limit of threads one operation can use. By default, appropriate operations can occupy all CPU cores, leaving no room for other operations. For example, `call pq` against a considerably large percolate table can utilize all threads for tens of seconds. Setting `max_threads_per_query` to, say, half of [threads](../Server_settings/Searchd.md#threads) will ensure that you can run a couple of such `call pq` operations in parallel.\n\nYou can also set this setting as a session or a global variable during runtime.\n\nAdditionally, you can control the behavior on a per-query basis with the help of the [threads OPTION](../Searching/Options.md#threads).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\nMaximum allowed per-query filter count. This setting is only used for internal sanity checks and does not directly affect RAM usage or performance. Optional, the default is 256.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\nMaximum allowed per-filter values count. This setting is only used for internal sanity checks and does not directly affect RAM usage or performance. Optional, the default is 4096.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\nThe maximum number of files that the server is allowed to open is called the \"soft limit\". Note that serving large fragmented real-time tables may require this limit to be set high, as each disk chunk may occupy a dozen or more files. For example, a real-time table with 1000 chunks may require thousands of files to be opened simultaneously. If you encounter the error 'Too many open files' in the logs, try adjusting this option, as it may help resolve the issue.\n\nThere is also a \"hard limit\" that cannot be exceeded by the option. This limit is defined by the system and can be changed in the file `/etc/security/limits.conf` on Linux. Other operating systems may have different approaches, so consult your manuals for more information.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\nApart from direct numeric values, you can use the magic word 'max' to set the limit equal to the available current hard limit.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\nMaximum allowed network packet size. This setting limits both query packets from clients and response packets from remote agents in a distributed environment. Only used for internal sanity checks, it does not directly affect RAM usage or performance. Optional, the default is 128M.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\nA server version string to return via the MySQL protocol. Optional, the default is empty (returns the Manticore version).\n\nSeveral picky MySQL client libraries depend on a particular version number format used by MySQL, and moreover, sometimes choose a different execution path based on the reported version number (rather than the indicated capabilities flags). For instance, Python MySQLdb 1.2.2 throws an exception when the version number is not in X.Y.ZZ format; MySQL .NET connector 6.3.x fails internally on version numbers 1.x along with a certain combination of flags, etc. To work around that, you can use the `mysql_version_string` directive and have `searchd` report a different version to clients connecting over the MySQL protocol. (By default, it reports its own version.)\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### net_workers\n\nNumber of network threads, the default is 1.\n\nThis setting is useful for extremely high query rates when just one thread is not enough to manage all the incoming queries.\n\n### net_wait_tm\n\nControls the busy loop interval of the network thread. The default is -1, and it can be set to -1, 0, or a positive integer.",
    "translations": {
      "chinese": "或者，您也可以使用 'syslog' 作为文件名。在这种情况下，事件将发送到 syslog 守护进程。要使用 syslog 选项，您需要在构建过程中使用 `-–with-syslog` 选项配置 Manticore。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\n限制每个批次的查询数量。可选，默认值是 32。\n\n使 searchd 在使用[多查询](../Searching/Multi-queries.md)时，对单个批次中提交的查询数量进行合理性检查。将其设置为 0 可以跳过该检查。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\n最大同时客户端连接数。默认无限制。通常只有在使用任何类型的持久连接时才会注意到，比如 cli mysql 会话或来自远程分布式表的持久远程连接。当超过限制时，您仍然可以使用[VIP 连接](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection)连接服务器。VIP 连接不计入连接数限制。\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\n单个操作可使用的线程实例级限制。默认情况下，适当的操作可以占用所有 CPU 核心，不给其他操作留空间。例如，对相当大的实时表进行 `call pq` 可能会利用所有线程数持续数十秒。将 `max_threads_per_query` 设置为比如[threads](../Server_settings/Searchd.md#threads)的一半，可以确保可以并行运行几个这样的 `call pq` 操作。\n\n您也可以在运行时将此设置作为会话或全局变量进行设置。\n\n此外，您还可以借助[threads 选项](../Searching/Options.md#threads)，对单个查询的行为进行控制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\n每查询允许的最大过滤器数量。此设置仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值为 256。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\n每个过滤器允许的最大值数量。此设置仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值是 4096。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\n服务器允许打开的最大文件数称为“软限制”。请注意，服务大型碎片化实时表可能需要将此限制设置得较高，因为每个磁盘块可能占用十几个或更多文件。例如，一个拥有 1000 个块的实时表可能需要同时打开数千个文件。如果日志中出现 “Too many open files” 错误，请尝试调整此选项，可能有助于解决问题。\n\n此外还有一个无法被选项超越的“硬限制”。此限制由系统定义，可以在 Linux 系统的 `/etc/security/limits.conf` 文件中更改。其他操作系统可能有不同的方式，请参考您的手册获取更多信息。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\n除了直接的数值外，您还可以使用魔法字 'max' 将限制设置为当前可用的硬限制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\n允许的最大网络数据包大小。此设置限制来自客户端的查询包以及分布式环境中远程代理的响应包。仅用于内部合理性检查，不直接影响内存使用或性能。可选，默认值为 128M。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\n通过 MySQL 协议返回的服务器版本字符串。可选，默认为空（返回 Manticore 版本）。\n\n一些挑剔的 MySQL 客户端库依赖于 MySQL 使用的特定版本号格式，而且有时基于报告的版本号（而不是能力标志）选择不同的执行路径。例如，Python MySQLdb 1.2.2 如果版本号不是 X.Y.ZZ 格式会抛出异常；MySQL .NET connector 6.3.x 在版本号为 1.x 并且有某些标志组合时内部分失败，等等。为了解决这个问题，您可以使用 `mysql_version_string` 指令，让 `searchd` 向通过 MySQL 协议连接的客户端报告不同的版本。（默认情况下，它报告自身版本。）\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### net_workers\n\n网络线程数，默认是 1。\n\n此设置在极高查询率下非常有用，当单个线程不足以处理所有传入查询时。\n\n### net_wait_tm\n\n控制网络线程的忙等待循环间隔。默认是 -1，可以设置为 -1、0 或正整数。",
      "russian": "Или вы можете использовать 'syslog' в качестве имени файла. В этом случае события будут отправляться демонской службе syslog. Чтобы использовать опцию syslog, необходимо настроить Manticore с опцией `-–with-syslog` при сборке.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_35\n\n<!-- end -->\n\n### max_batch_queries\n\n<!-- example conf max_batch_queries -->\n\nОграничивает количество запросов в одном пакете. Опционально, по умолчанию 32.\n\nЗаставляет searchd выполнять проверку количества запросов, отправленных в одном пакете при использовании [мультизапросов](../Searching/Multi-queries.md). Установите значение 0, чтобы пропустить проверку.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_36\n\n<!-- end -->\n\n### max_connections\n\n<!-- example max_connections -->\n\nМаксимальное количество одновременных подключений клиентов. По умолчанию не ограничено. Обычно это заметно только при использовании любых видов постоянных соединений, например, CLI-сессий mysql или постоянных удалённых соединений для распределённых таблиц. При превышении лимита вы всё ещё сможете подключиться к серверу используя [VIP соединение](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection). VIP соединения не учитываются в лимит.\n\n<!-- request Example -->\n\nCODE_BLOCK_37\n\n<!-- end -->\n\n### max_threads_per_query\n\n<!-- example max_threads_per_query -->\n\nГлобальный лимит на количество потоков, используемых одной операцией. По умолчанию соответствующие операции могут занимать все ядра CPU, не оставляя ресурсов для других операций. Например, `call pq` для достаточно крупной таблицы percolate может использовать все потоки в течение десятков секунд. Установка `max_threads_per_query` в, скажем, половину значения [threads](../Server_settings/Searchd.md#threads) обеспечит возможность параллельного запуска пары таких операций `call pq`.\n\nТакже можно установить эту настройку как переменную сессии или глобальную переменную во время выполнения.\n\nКроме того, поведение можно контролировать для каждого запроса индивидуально с помощью [OPTION threads](../Searching/Options.md#threads).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_38\n\n<!-- end -->\n\n### max_filters\n\n<!-- example conf max_filters -->\n\nМаксимально допустимое количество фильтров на запрос. Эта настройка используется только для внутренних проверок корректности и не влияет напрямую на использование RAM или производительность. Опционально, по умолчанию 256.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_39\n\n<!-- end -->\n\n### max_filter_values\n\n<!-- example conf max_filter_values -->\n\nМаксимально допустимое количество значений в одном фильтре. Эта настройка используется только для внутренних проверок корректности и не влияет напрямую на использование RAM или производительность. Опционально, по умолчанию 4096.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_40\n\n<!-- end -->\n\n### max_open_files\n\n<!-- example conf max_open_files -->\n\nМаксимальное количество открытых файлов сервером называется \"мягким лимитом\". Учтите, что обслуживание больших фрагментированных таблиц реального времени может требовать высокого значения этого лимита, так как каждый диск-чанк может занимать десятки или более файлов. Например, таблица реального времени с 1000 чанками может требовать открытия тысяч файлов одновременно. Если в логах встречается ошибка 'Too many open files', попробуйте настроить эту опцию — это может помочь решить проблему.\n\nТакже существует \"жёсткий лимит\", который нельзя превысить с помощью опции. Этот лимит определяется системой и может быть изменён в файле `/etc/security/limits.conf` на Linux. Другие операционные системы могут иметь другие механизмы, ознакомьтесь с их документацией.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_41\n\n<!-- end -->\n\n<!-- example conf max_open_files max -->\n\nПомимо числовых значений, можно использовать магическое слово 'max' для установки лимита равным доступному текущему жёсткому лимиту.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_42\n\n<!-- end -->\n\n### max_packet_size\n\n<!-- example conf max_packet_size -->\n\nМаксимально допустимый размер сетевого пакета. Эта настройка ограничивает размер как запросов от клиентов, так и ответов от удалённых агентов в распределённой среде. Используется только для внутренних проверок корректности и не влияет напрямую на использование RAM или производительность. Опционально, по умолчанию 128M.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_43\n\n<!-- end -->\n\n### mysql_version_string\n\n<!-- example conf mysql_version_string -->\n\nСтрока версии сервера для возврата через MySQL протокол. Опционально, по умолчанию пуста (возвращает версию Manticore).\n\nНекоторые капризные библиотеки клиентов MySQL зависят от конкретного формата номера версии MySQL и иногда выбирают разные пути выполнения на основе указанного номера версии (а не флагов возможностей). Например, Python MySQLdb 1.2.2 выбрасывает исключение, если версия не в формате X.Y.ZZ; MySQL .NET connector 6.3.x внутренне ошибается на версиях 1.x с определённой комбинацией флагов и т.д. Чтобы обойти это, можно использовать директиву `mysql_version_string` и заставить `searchd` сообщать другую версию клиентам, подключающимся по MySQL протоколу (по умолчанию сообщает свою собственную версию).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_44\n\n<!-- end -->\n\n### net_workers\n\nКоличество сетевых потоков, по умолчанию 1.\n\nЭта настройка полезна при экстремально высоких скоростях запросов, когда одного потока недостаточно для обработки всего входящего трафика.\n\n### net_wait_tm\n\nУправляет интервалом цикла занятости сетевого потока. По умолчанию -1, может принимать значения -1, 0 или положительное целое число."
    },
    "is_code_or_comment": false
  },
  "e0d886637653ad90abdcf97bbb38af9c7f30919c8c90b8efd222fdd2c7038888": {
    "original": "This setting controls the maximum binary log file size. It is optional, with a default value of 256 MB.\n\nA new binlog file will be forcibly opened once the current binlog file reaches this size limit. This results in a finer granularity of logs and can lead to more efficient binlog disk usage under certain borderline workloads. A value of 0 indicates that the binlog file should not be reopened based on size.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\nThis setting determines the path for binary log (also known as transaction log) files. It is optional, with a default value of the build-time configured data directory (e.g., `/var/lib/manticore/data/binlog.*` in Linux).\n\nBinary logs are used for crash recovery of RT table data and for attribute updates of plain disk indices that would otherwise only be stored in RAM until flush. When logging is enabled, every transaction COMMIT-ted into an RT table is written into a log file. Logs are then automatically replayed on startup after an unclean shutdown, recovering the logged changes.\n\nThe `binlog_path` directive specifies the location of binary log files. It should only contain the path; `searchd` will create and unlink multiple `binlog.*` files in the directory as necessary (including binlog data, metadata, and lock files, etc).\n\nAn empty value disables binary logging, which improves performance but puts the RT table data at risk.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\nThis setting controls the default value for [boolean_simplify](../Searching/Options.md#boolean_simplify) search option. It is optional, with a default value of 1 (enabled).\n\nWhen set to 1, the server will automatically apply [boolean query optimization](../Searching/Full_text_matching/Boolean_optimization.md) to improve query performance. When set to 0, queries will be executed without optimization by default. This default can be overridden on a per-query basis using the corresponding search option `boolean_simplify`.\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\nThis setting determines the path to the Manticore Buddy binary. It is optional, with a default value being the build-time configured path, which varies across different operating systems. Typically, you don't need to modify this setting. However, it may be useful if you wish to run Manticore Buddy in debug mode, make changes to Manticore Buddy, or implement a new plugin. In the latter case, you can `git clone` Buddy from https://github.com/manticoresoftware/manticoresearch-buddy, add a new plugin to the directory `./plugins/`, and run `composer install --prefer-source` for easier development after you change the directory to the Buddy source.\n\nTo ensure you can run `composer`, your machine must have PHP 8.2 or higher installed with the following extensions:\n\nCODE_BLOCK_12\n\nYou can also opt for the special `manticore-executor-dev` version for Linux amd64 available in the releases, for example: https://github.com/manticoresoftware/executor/releases/tag/v1.0.13\n\nIf you go this route, remember to link the dev version of the manticore executor to `/usr/bin/php`.\n\nTo disable Manticore Buddy, set the value to empty as shown in the example.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\nThis setting determines the maximum time to wait between requests (in seconds or [special_suffixes](../Server_settings/Special_suffixes.md)) when using persistent connections. It is optional, with a default value of five minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\nServer libc locale. Optional, default is C.\n\nSpecifies the libc locale, affecting the libc-based collations. Refer to [collations](../Searching/Collations.md) section for the details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\nDefault server collation. Optional, default is libc_ci.\n\nSpecifies the default collation used for incoming requests. The collation can be overridden on a per-query basis. Refer to [collations](../Searching/Collations.md) section for the list of available collations and other details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\nWhen specified, this setting enables the [real-time mode](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29), which is an imperative way of managing data schema. The value should be a path to the directory where you want to store all your tables, binary logs, and everything else needed for the proper functioning of Manticore Search in this mode.\n\nIndexing of [plain tables](../Creating_a_table/Local_tables/Plain_table.md) is not allowed when the `data_dir` is specified. Read more about the difference between the RT mode and the plain mode in [this section](../Read_this_first.md#Real-time-table-vs-plain-table).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\nThe timeout for preventing auto-flushing a RAM chunk if there are no searches in the table. Optional, default is 30 seconds.\n\nThe time to check for searches before determining whether to auto-flush.",
    "translations": {
      "chinese": "此设置控制最大二进制日志文件大小。此设置为可选，默认值为256 MB。\n\n一旦当前binlog文件达到此大小限制，将强制打开一个新的binlog文件。这导致日志的粒度更细，并且在某些边界工作负载下可以实现更高效的binlog磁盘使用。值为0表示不应基于大小重新打开binlog文件。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\n此设置决定二进制日志（也称为事务日志）文件的路径。此设置为可选，默认值为构建时配置的数据目录（例如Linux中的`/var/lib/manticore/data/binlog.*`）。\n\n二进制日志用于RT表数据的崩溃恢复以及普通磁盘索引的属性更新，这些属性更新否则仅存储在RAM中直到刷新。启用日志记录时，每个提交到RT表的事务都会写入日志文件。在非正常关闭后启动时，日志会自动重播以恢复记录的更改。\n\n`binlog_path`指令指定二进制日志文件的位置。它应仅包含路径；`searchd`将在该目录中根据需要创建和删除多个`binlog.*`文件（包括binlog数据、元数据和锁文件等）。\n\n空值禁用二进制日志记录，这提高性能但会使RT表数据面临风险。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\n此设置控制[boolean_simplify](../Searching/Options.md#boolean_simplify)搜索选项的默认值。此设置为可选，默认值为1（启用）。\n\n设置为1时，服务器将自动应用[布尔查询优化](../Searching/Full_text_matching/Boolean_optimization.md)以提升查询性能。设置为0时，查询默认不经过优化。此默认值可通过相应的搜索选项`boolean_simplify`按查询覆盖。\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\n此设置决定Manticore Buddy二进制文件的路径。此设置为可选，默认值为构建时配置的路径，不同操作系统间有所差异。通常情况下无需修改此设置。然而，如果您希望以调试模式运行Manticore Buddy，修改Manticore Buddy，或实现新的插件，此设置将非常有用。在后两种情况下，您可以从https://github.com/manticoresoftware/manticoresearch-buddy克隆Buddy，将新插件添加到`./plugins/`目录中，并切换到Buddy源目录后运行`composer install --prefer-source`以便于开发。\n\n为确保可以运行`composer`，机器必须安装PHP 8.2或更高版本，并启用以下扩展：\n\nCODE_BLOCK_12\n\n您还可以选择针对Linux amd64的特殊版本`manticore-executor-dev`，可在发布页面例如：https://github.com/manticoresoftware/executor/releases/tag/v1.0.13 下载。\n\n如果选择此方案，请记得将manticore executor的开发版链接到`/usr/bin/php`。\n\n若要禁用Manticore Buddy，请将值设置为空，如示例所示。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\n此设置决定在使用持久连接时请求之间的最大等待时间（单位为秒或[special_suffixes](../Server_settings/Special_suffixes.md)）。此设置为可选，默认值为五分钟。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\n服务器libc语言环境。可选，默认是C。\n\n指定libc语言环境，影响基于libc的排序规则。详情请参阅[排序规则](../Searching/Collations.md)部分。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\n默认服务器排序规则。可选，默认是libc_ci。\n\n指定用于传入请求的默认排序规则。排序规则可以在每个查询中覆盖。详情请参阅[排序规则](../Searching/Collations.md)部分中的可用排序规则及其他信息。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\n指定此设置时，将启用[实时模式](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29)，这是一种管理数据架构的命令式方式。该值应为存储所有表、二进制日志及其他确保Manticore Search在此模式下正常运行所需内容的目录路径。\n\n当指定`data_dir`时，不允许对[普通表](../Creating_a_table/Local_tables/Plain_table.md)进行索引。关于实时模式与普通模式的区别，请阅读[此部分](../Read_this_first.md#Real-time-table-vs-plain-table)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\n如果表中无搜索请求，防止RAM区块自动刷新超时时间。可选，默认是30秒。\n\n判断是否自动刷新的搜索检查时间。",
      "russian": "Этот параметр контролирует максимальный размер бинарного лог-файла. Он является необязательным и имеет значение по умолчанию 256 МБ.\n\nНовый binlog-файл будет принудительно открыт, как только текущий binlog-файл достигнет этого лимита размера. Это приводит к более мелкой гранулярности логов и может привести к более эффективному использованию диска binlog в некоторых пограничных нагрузках. Значение 0 указывает, что binlog-файл не должен переоткрываться по размеру.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_9\n\n<!-- end -->\n\n### binlog_path\n\n<!-- example conf binlog_path -->\n\nЭтот параметр определяет путь к файлам бинарного лога (также известного как транзакционный лог). Он является необязательным и по умолчанию равен каталогу данных, настроенному при сборке (например, `/var/lib/manticore/data/binlog.*` в Linux).\n\nБинарные логи используются для восстановления данных таблиц RT после сбоев и для обновления атрибутов простых дисковых индексов, которые в противном случае сохранялись бы только в оперативной памяти до сброса. Когда ведение логов включено, каждая транзакция, зафиксированная COMMIT в таблице RT, записывается в лог-файл. Логи автоматически воспроизводятся при запуске после некорректного завершения работы, восстанавливая залогированные изменения.\n\nДиректива `binlog_path` указывает расположение файлов бинарного лога. Она должна содержать только путь; `searchd` будет создавать и удалять несколько файлов `binlog.*` в директории по мере необходимости (включая данные binlog, метаданные и блокировки и т.д.).\n\nПустое значение отключает ведение бинарного лога, что улучшает производительность, но подвергает данные таблицы RT риску.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_10\n\n<!-- end -->\n\n### boolean_simplify\n\n<!-- example conf boolean_simplify -->\n\nЭтот параметр управляет значением по умолчанию для опции поиска [boolean_simplify](../Searching/Options.md#boolean_simplify). Он необязательный, по умолчанию равен 1 (включено).\n\nПри значении 1 сервер автоматически применит [оптимизацию булевого запроса](../Searching/Full_text_matching/Boolean_optimization.md) для улучшения производительности поиска. При значении 0 запросы будут выполняться без оптимизации по умолчанию. Это значение по умолчанию можно изменить для каждого запроса с помощью соответствующей опции поиска `boolean_simplify`.\n\n<!-- request Example -->\n\nCODE_BLOCK_11\n\n<!-- end -->\n\n### buddy_path\n\n<!-- example conf buddy_path -->\n\nЭтот параметр определяет путь к исполняемому файлу Manticore Buddy. Он является необязательным и по умолчанию установлен в путь, определённый при сборке, который различается в разных операционных системах. Обычно изменять этот параметр не нужно. Однако это может быть полезно, если вы хотите запустить Manticore Buddy в режиме отладки, внести изменения в Manticore Buddy или реализовать новый плагин. В последнем случае вы можете `git clone` Buddy из https://github.com/manticoresoftware/manticoresearch-buddy, добавить новый плагин в каталог `./plugins/`, и запустить `composer install --prefer-source` для упрощения разработки после перехода в директорию исходников Buddy.\n\nДля запуска `composer` на вашей машине должен быть установлен PHP 8.2 или выше с следующими расширениями:\n\nCODE_BLOCK_12\n\nВы также можете воспользоваться специальной версией `manticore-executor-dev` для Linux amd64, доступной в релизах, например: https://github.com/manticoresoftware/executor/releases/tag/v1.0.13\n\nЕсли вы пойдёте этим путём, не забудьте связать dev-версию manticore executor с `/usr/bin/php`.\n\nЧтобы отключить Manticore Buddy, задайте пустое значение, как показано в примере.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_13\n\n<!-- end -->\n\n### client_timeout\n\n<!-- example conf client_timeout -->\n\nЭтот параметр определяет максимальное время ожидания между запросами (в секундах или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)) при использовании постоянных соединений. Он необязательный, значение по умолчанию — пять минут.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_14\n\n<!-- end -->\n\n### collation_libc_locale\n\n<!-- example conf collation_libc_locale -->\n\nЛокаль libc сервера. Опционально, по умолчанию C.\n\nЗадает локаль libc, влияющую на колляции на основе libc. Подробнее см. в разделе [collations](../Searching/Collations.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_15\n\n<!-- end -->\n\n### collation_server\n\n<!-- example conf collation_server -->\n\nКолляция сервера по умолчанию. Опционально, по умолчанию libc_ci.\n\nОпределяет колляцию по умолчанию для входящих запросов. Колляция может быть переопределена для каждого запроса. Ознакомьтесь с разделом [collations](../Searching/Collations.md) для списка доступных колляций и других подробностей.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_16\n\n<!-- end -->\n\n### data_dir\n\n<!-- example conf data_dir -->\n\nЕсли указан, этот параметр включает [режим реального времени](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29), который представляет собой императивный способ управления схемой данных. Значение должно быть путем к каталогу, где вы хотите хранить все свои таблицы, бинарные логи и все остальное, необходимое для правильной работы Manticore Search в этом режиме.\n\nИндексация [простых таблиц](../Creating_a_table/Local_tables/Plain_table.md) запрещена при указании `data_dir`. Подробнее о различиях между режимом RT и простым режимом читайте в [этом разделе](../Read_this_first.md#Real-time-table-vs-plain-table).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_17\n\n<!-- end -->\n\n### diskchunk_flush_search_timeout\n\n<!-- example conf diskchunk_flush_search_timeout -->\n\nТаймаут для предотвращения автоматического сброса RAM-куска, если в таблице нет поисков. Необязательный параметр, значение по умолчанию 30 секунд.\n\nВремя проверки поисков перед решением об авто-сбросе."
    },
    "is_code_or_comment": false
  },
  "7ac145191dcf52e135b16d95e79845669f4eb31412093bf8485a42f1152889c2": {
    "original": "Auto-flushing will occur only if there has been at least one search in the table within the last `diskchunk_flush_search_timeout` seconds. Works in conjunction with [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout). The corresponding [per-table setting](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) has a higher priority and will override this instance-wide default, providing more fine-grained control.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\nThe time in seconds to wait without a write before auto-flushing the RAM chunk to disk. Optional, default is 1 second.\n\nIf no write occurs in the RAM chunk within `diskchunk_flush_write_timeout` seconds, the chunk will be flushed to disk. Works in conjunction with [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout). To disable auto-flush, set `diskchunk_flush_write_timeout = -1` explicitly in your configuration. The corresponding [per-table setting](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout) has a higher priority and will override this instance-wide default, providing more fine-grained control.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\nThis setting specifies the maximum size of document blocks from document storage that are held in memory. It is optional, with a default value of 16m (16 megabytes).\n\nWhen `stored_fields` is used, document blocks are read from disk and uncompressed. Since every block typically holds several documents, it may be reused when processing the next document. For this purpose, the block is held in a server-wide cache. The cache holds uncompressed blocks.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\nDefault attribute storage engine used when creating tables in RT mode. Can be `rowwise` (default) or `columnar`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\nThis setting determines the maximum number of expanded keywords for a single wildcard. It is optional, with a default value of 0 (no limit).\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords (think of matching `a*` against the entire Oxford dictionary). This directive allows you to limit the impact of such expansions. Setting `expansion_limit = N` restricts expansions to no more than N of the most frequent matching keywords (per each wildcard in the query).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\nThis setting determines the maximum number of documents in the expanded keyword that allows merging all such keywords together. It is optional, with a default value of 32.\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords. This directive allows you to increase the limit of how many keywords will merge together to speed up matching but uses more memory in the search.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\nThis setting determines the maximum number of hits in the expanded keyword that allows merging all such keywords together. It is optional, with a default value of 256.\n\nWhen performing substring searches against tables built with `dict = keywords` enabled, a single wildcard may potentially result in thousands or even millions of matched keywords. This directive allows you to increase the limit of how many keywords will merge together to speed up matching but uses more memory in the search.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\nThis setting controls the maximum number of alternative phrase variants generated due to `OR` operators inside `PHRASE`, `PROXIMITY`, and `QUORUM` operators. It is optional, with a default value of 1024.\n\nWhen using the `|` (OR) operator inside phrase-like operator, the total number of expanded combinations may grow exponentially depending on the number of alternatives specified. This setting helps prevent excessive query expansion by capping the number of permutations considered during query processing.\n\nIf the number of generated variants exceeds this limit, the query will either:\n\n- fail with an error (default behavior)\n\n- return partial results with a warning, if `expansion_phrase_warning` is enabled\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\nThis setting controls the behavior when the query expansion limit defined by `expansion_phrase_limit` is exceeded.\n\nBy default, the query will fail with an error message. When `expansion_phrase_warning` is set to 1, the search continues using a partial transformation of the phrase (up to the configured limit), and the server returns a warning message to the user along with the result set. This allows queries that are too complex for full expansion to still return partial results without complete failure.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### grouping_in_utc",
    "translations": {
      "chinese": "自动刷新仅在表中最近 `diskchunk_flush_search_timeout` 秒内至少有一次查询时发生。与 [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout) 结合使用。对应的[每表设置](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout)优先级更高，会覆盖此实例级默认设置，提供更精细的控制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\n在写入超时且无写操作时，等待的秒数，之后自动将RAM块刷新到磁盘。可选，默认值为1秒。\n\n如果在 `diskchunk_flush_write_timeout` 秒内 RAM 块没有写操作，则该块将被刷新到磁盘。与 [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout) 配合使用。若要禁用自动刷新，请在配置中显式设置 `diskchunk_flush_write_timeout = -1`。对应的[每表设置](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout)优先级更高，会覆盖此实例级默认设置，提供更细粒度的控制。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\n此设置指定了文档存储中文档块在内存中保留的最大大小。可选，默认值为16m（16兆字节）。\n\n当使用 `stored_fields` 时，文档块从磁盘读取并解压缩。由于每个块通常包含多个文档，因此在处理下一个文档时可能重用该块。为此，块被保存在服务器范围的缓存中。缓存保存的是解压缩的块。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\n创建RT模式表时使用的默认属性存储引擎。可为 `rowwise`（默认）或 `columnar`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\n此设置确定单个通配符可扩展的最大关键词数量。可选，默认值为0（无限制）。\n\n在对启用了 `dict = keywords` 的表进行子字符串搜索时，单个通配符可能匹配数千甚至数百万个关键词（比如匹配整个牛津词典中的 `a*`）。此指令允许限制这类扩展的影响。设置 `expansion_limit = N` 限制扩展结果不超过每个通配符的N个最常见匹配关键词。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\n此设置确定允许合并所有扩展关键词的最大文档数量。可选，默认值为32。\n\n在对启用了 `dict = keywords` 的表进行子字符串搜索时，单个通配符可能匹配成千上万甚至上百万的关键词。此指令允许增加合并关键词的限制，以加快匹配速度，但这会增加搜索使用的内存。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\n此设置确定允许合并所有扩展关键词的最大命中次数。可选，默认值为256。\n\n在对启用了 `dict = keywords` 的表进行子字符串搜索时，单个通配符可能匹配成千上万甚至上百万个关键词。此指令允许增加合并关键词的限制，以加快匹配速度，但会增加搜索时的内存消耗。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\n此设置控制由于 `PHRASE`、`PROXIMITY` 和 `QUORUM` 操作符内部的 `OR` 操作符所生成的最大替代短语变体数。可选，默认值为1024。\n\n当在类似短语的操作符内使用 `|`（OR）操作符时，展开的组合总数可能随着指定的候选项数量呈指数增长。此设置有助于限制查询扩展，防止过度扩展，通过限制查询处理时考虑的排列数量。\n\n如果生成的变体数量超过此限制，查询将：\n\n- 报错失败（默认行为）\n\n- 如果启用了 `expansion_phrase_warning`，则返回带有警告的部分结果\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\n此设置控制当查询扩展限制 `expansion_phrase_limit` 被超出时的处理行为。\n\n默认情况下，查询将失败并显示错误信息。设置 `expansion_phrase_warning = 1` 后，搜索将继续使用短语的部分转换（最多到配置的限制），并向用户返回带有警告信息的结果集。这允许对过于复杂而不能完全扩展的查询返回部分结果，而不完全失败。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### grouping_in_utc",
      "russian": "Автоматическая очистка произойдет только в том случае, если в таблице был хотя бы один поиск за последние `diskchunk_flush_search_timeout` секунд. Работает в связке с [diskchunk_flush_write_timeout](../Server_settings/Searchd.md#diskchunk_flush_write_timeout). Соответствующая [настройка для каждой таблицы](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) имеет более высокий приоритет и переопределит это значение по умолчанию для всего инстанса, обеспечивая более точный контроль.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_18\n\n<!-- end -->\n\n### diskchunk_flush_write_timeout\n\n<!-- example conf diskchunk_flush_write_timeout -->\n\nВремя в секундах ожидания без записи перед автоматической очисткой RAM-чункa на диск. Необязательно, по умолчанию 1 секунда.\n\nЕсли в RAM-чункe не происходит запись в течение `diskchunk_flush_write_timeout` секунд, чанк будет сброшен на диск. Работает в связке с [diskchunk_flush_search_timeout](../Server_settings/Searchd.md#diskchunk_flush_search_timeout). Чтобы отключить автоочистку, явно укажите `diskchunk_flush_write_timeout = -1` в вашей конфигурации. Соответствующая [настройка для каждой таблицы](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout) имеет более высокий приоритет и переопределит это значение по умолчанию для всего инстанса, обеспечивая более точный контроль.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_19\n\n<!-- end -->\n\n### docstore_cache_size\n\n<!-- example conf docstore_cache_size -->\n\nЭта настройка определяет максимальный размер блоков документов из хранилища документов, которые хранятся в памяти. Необязательно, значение по умолчанию — 16m (16 мегабайт).\n\nКогда используется `stored_fields`, блоки документов считываются с диска и распаковываются. Поскольку каждый блок обычно содержит несколько документов, он может быть повторно использован при обработке следующего документа. Для этой цели блок хранится в кешe на уровне сервера. В кеше хранятся распакованные блоки.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_20\n\n<!-- end -->\n\n### engine\n\n<!-- example conf engine -->\n\nДвижок хранения атрибутов по умолчанию, используемый при создании таблиц в режиме RT. Может быть `rowwise` (по умолчанию) или `columnar`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_21\n\n<!-- end -->\n\n### expansion_limit\n\n<!-- example conf expansion_limit -->\n\nЭта настройка определяет максимальное количество развернутых ключевых слов для одного подстановочного знака. Необязательно, значение по умолчанию 0 (без ограничения).\n\nПри выполнении поиска подстрок в таблицах, построенных с включенным `dict = keywords`, один подстановочный знак может потенциально привести к тысячам или даже миллионам совпадающих ключевых слов (подумайте о сопоставлении `a*` со всем словарем Оксфорда). Эта директива позволяет ограничить влияние таких расширений. Установка `expansion_limit = N` ограничивает расширения не более чем N наиболее частыми совпадающими ключевыми словами (для каждого подстановочного знака в запросе).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_22\n\n<!-- end -->\n\n### expansion_merge_threshold_docs\n\n<!-- example conf expansion_merge_threshold_docs -->\n\nЭта настройка определяет максимальное количество документов в развернутом ключевом слове, при котором допускается объединение всех таких ключевых слов. Необязательно, значение по умолчанию 32.\n\nПри выполнении поиска подстрок в таблицах, построенных с включенным `dict = keywords`, один подстановочный знак может потенциально привести к тысячам или даже миллионам совпадающих ключевых слов. Эта директива позволяет увеличить предел количества ключевых слов, которые будут объединены вместе для ускорения сопоставления, но при этом использует больше памяти в процессе поиска.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_23\n\n<!-- end -->\n\n### expansion_merge_threshold_hits\n\n<!-- example conf expansion_merge_threshold_hits -->\n\nЭта настройка определяет максимальное количество попаданий (hits) в развернутом ключевом слове, при котором допускается объединение всех таких ключевых слов. Необязательно, значение по умолчанию 256.\n\nПри выполнении поиска подстрок в таблицах, построенных с включенным `dict = keywords`, один подстановочный знак может потенциально привести к тысячам или даже миллионам совпадающих ключевых слов. Эта директива позволяет увеличить предел количества ключевых слов, которые будут объединены вместе для ускорения сопоставления, но при этом использует больше памяти в процессе поиска.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_24\n\n<!-- end -->\n\n### expansion_phrase_limit\n\n<!-- example conf expansion_phrase_limit -->\n\nЭта настройка контролирует максимальное количество альтернативных вариантов фраз, генерируемых из-за операторов `OR` внутри операторов `PHRASE`, `PROXIMITY` и `QUORUM`. Необязательно, значение по умолчанию 1024.\n\nПри использовании оператора `|` (OR) внутри операторов, похожих на фразы, общее количество расширенных комбинаций может расти экспоненциально в зависимости от количества указанных альтернатив. Эта настройка помогает предотвратить чрезмерное расширение запроса, ограничивая количество перестановок, рассматриваемых при обработке запроса.\n\nЕсли количество сгенерированных вариантов превышает этот предел, запрос:\n\n- будет завершен с ошибкой (поведение по умолчанию)\n\n- вернет частичные результаты с предупреждением, если включен `expansion_phrase_warning`\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_25\n\n<!-- end -->\n\n### expansion_phrase_warning\n\n<!-- example conf expansion_phrase_warning -->\n\nЭта настройка контролирует поведение при превышении лимита расширения запроса, определенного параметром `expansion_phrase_limit`.\n\nПо умолчанию запрос завершится с сообщением об ошибке. При установке `expansion_phrase_warning` в 1 поиск продолжается с использованием частичной трансформации фразы (до настроенного предела), и сервер возвращает пользователю предупреждение вместе с набором результатов. Это позволяет запросам, которые слишком сложны для полного расширения, по-прежнему возвращать частичные результаты без полного отказа.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_26\n\n<!-- end -->\n\n### grouping_in_utc"
    },
    "is_code_or_comment": false
  },
  "298042e77f0ee24ac565db4778ecac5121c077e842b9b60e47ef8c496552310b": {
    "original": "<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate.",
    "translations": {
      "chinese": "<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate.",
      "russian": "<!-- request Example -->\n\nCODE_BLOCK_69\n\n<!-- end -->\n\n### secondary_indexes\n\n<!-- example conf secondary_indexes -->\n\nThis option enables/disables the use of secondary indexes for search queries. It is optional, and the default is 1 (enabled). Note that you don't need to enable it for indexing as it is always enabled as long as the [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) is installed. The latter is also required for using the indexes when searching. There are three modes available:\n\n* `0`: Disable the use of secondary indexes on search. They can be enabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `1`: Enable the use of secondary indexes on search. They can be disabled for individual queries using [analyzer hints](../Searching/Options.md#Query-optimizer-hints)\n\n* `force`: Same as enable, but any errors during the loading of secondary indexes will be reported, and the whole index will not be loaded into the daemon.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_70\n\n<!-- end -->\n\n### server_id\n\n<!-- example conf server_id -->\n\nInteger number that serves as a server identifier used as a seed to generate a unique short UUID for nodes that are part of a replication cluster. The server_id must be unique across the nodes of a cluster and in the range from 0 to 127. If server_id is not set, it is calculated as a hash of the MAC address and the path to the PID file or a random number will be used as a seed for the short UUID.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_71\n\n<!-- end -->\n\n### shutdown_timeout\n\n<!-- example conf shutdown_timeout -->\n\n`searchd --stopwait` waiting time, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 60 seconds.\n\nWhen you run `searchd --stopwait` your server needs to perform some activities before stopping, such as finishing queries, flushing RT RAM chunks, flushing attributes, and updating the binlog. These tasks require some time. `searchd --stopwait` will wait up to `shutdown_time` seconds for the server to finish its jobs. The suitable time depends on your table size and load.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_72\n\n<!-- end -->\n\n### shutdown_token\n\nSHA1 hash of the password required to invoke the 'shutdown' command from a VIP Manticore SQL connection. Without it,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' subcommand will never cause the server to stop. Note that such simple hashing should not be considered strong protection, as we don't use a salted hash or any kind of modern hash function. It is intended as a fool-proof measure for housekeeping daemons in a local network.\n\n### snippets_file_prefix\n\n<!-- example conf snippets_file_prefix -->\n\nA prefix to prepend to the local file names when generating snippets. Optional, default is the current working folder.\n\nThis prefix can be used in distributed snippets generation along with `load_files` or `load_files_scattered` options.\n\nNote that this is a prefix and **not** a path! This means that if a prefix is set to \"server1\" and the request refers to \"file23\", `searchd` will attempt to open \"server1file23\" (all of that without quotes). So, if you need it to be a path, you have to include the trailing slash.\n\nAfter constructing the final file path, the server unwinds all relative dirs and compares the final result with the value of `snippet_file_prefix`. If the result does not begin with the prefix, such a file will be rejected with an error message.\n\nFor example, if you set it to `/mnt/data` and someone calls snippet generation with the file `../../../etc/passwd` as the source, they will get the error message:\n\n`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`\n\ninstead of the content of the file.\n\nAlso, with a non-set parameter and reading `/etc/passwd`, it will actually read /daemon/working/folder/etc/passwd since the default for the parameter is the server's working folder.\n\nNote also that this is a local option; it does not affect the agents in any way. So you can safely set a prefix on a master server. The requests routed to the agents will not be affected by the master's setting. They will, however, be affected by the agent's own settings.\n\nThis might be useful, for instance, when the document storage locations (whether local storage or NAS mountpoints) are inconsistent across the servers.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_73\n\n<!-- end -->\n\n> **WARNING:** If you still want to access files from the FS root, you have to explicitly set `snippets_file_prefix` to empty value (by `snippets_file_prefix=` line), or to root (by `snippets_file_prefix=/`).\n\n### sphinxql_state\n\n<!-- example conf sphinxql_state -->\n\nPath to a file where the current SQL state will be serialized.\n\nOn server startup, this file gets replayed. On eligible state changes (e.g., SET GLOBAL), this file gets rewritten automatically. This can prevent a hard-to-diagnose problem: If you load UDF functions but Manticore crashes, when it gets (automatically) restarted, your UDF and global variables will no longer be available. Using persistent state helps ensure a graceful recovery with no such surprises.\n\n`sphinxql_state` cannot be used to execute arbitrary commands, such as `CREATE TABLE`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_74\n\n<!-- end -->\n\n### sphinxql_timeout\n\n<!-- example conf sphinxql_timeout -->\n\nMaximum time to wait between requests (in seconds, or [special_suffixes](../Server_settings/Special_suffixes.md)) when using the SQL interface. Optional, default is 15 minutes.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_75\n\n<!-- end -->\n\n### ssl_ca\n\n<!-- example conf ssl_ca -->\n\nPath to the SSL Certificate Authority (CA) certificate file (also known as root certificate). Optional, default is empty. When not empty, the certificate in `ssl_cert` should be signed by this root certificate."
    },
    "is_code_or_comment": true
  },
  "2dbb154fcd1010d6b5b4d6660b03a5d784679aee080eab1d6fde3783e771416e": {
    "original": "Integer, in seconds. The expiration period for a cached result set. Defaults to 60, or 1 minute. The minimum possible value is 1 second. Refer to [query cache](../Searching/Query_cache.md) for details. This value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing '_sec'.\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\nQuery log format. Optional, allowed values are `plain` and `sphinxql`, default is `sphinxql`.\n\nThe `sphinxql` mode logs valid SQL statements. The `plain` mode logs queries in a plain text format (mostly suitable for purely full-text use cases). This directive allows you to switch between the two formats on search server startup. The log format can also be altered on the fly, using `SET GLOBAL query_log_format=sphinxql` syntax. Refer to [Query logging](../Logging/Query_logging.md) for more details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### query_log_min_msec\n\nLimit (in milliseconds) that prevents the query from being written to the query log. Optional, default is 0 (all queries are written to the query log). This directive specifies that only queries with execution times that exceed the specified limit will be logged (this value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing `_msec`).\n\n### query_log\n\n<!-- example conf query_log -->\n\nQuery log file name. Optional, default is empty (do not log queries). All search queries (such as SELECT ... but not INSERT/REPLACE/UPDATE queries) will be logged in this file. The format is described in [Query logging](../Logging/Query_logging.md). In case of 'plain' format, you can use 'syslog' as the path to the log file. In this case, all search queries will be sent to the syslog daemon with `LOG_INFO` priority, prefixed with '[query]' instead of timestamp. To use the syslog option, Manticore must be configured with  `-–with-syslog` on building.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nThe query_log_mode directive allows you to set a different permission for the searchd and query log files. By default, these log files are created with 600 permission, meaning that only the user under which the server runs and root users can read the log files.\n\nThis directive can be handy if you want to allow other users to read the log files, for example, monitoring solutions running on non-root users.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nThe read_buffer_docs directive controls the per-keyword read buffer size for document lists. For every keyword occurrence in every search query, there are two associated read buffers: one for the document list and one for the hit list. This setting lets you control the document list buffer size.\n\nA larger buffer size might increase per-query RAM use, but it could possibly decrease I/O time. It makes sense to set larger values for slow storage, but for storage capable of high IOPS, experimenting should be done in the low values area.\n\nThe default value is 256K, and the minimal value is 8K. You may also set [read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs) on a per-table basis, which will override anything set on the server's config level.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nThe read_buffer_hits directive specifies the per-keyword read buffer size for hit lists in search queries. By default, the size is 256K and the minimum value is 8K. For every keyword occurrence in a search query, there are two associated read buffers, one for the document list and one for the hit list. Increasing the buffer size can increase per-query RAM use but decrease I/O time. For slow storage, larger buffer sizes make sense, while for storage capable of high IOPS, experimenting should be done in the low values area.\n\nThis setting can also be specified on a per-table basis using the read_buffer_hits option in [read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits) which will override the server-level setting.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\nUnhinted read size. Optional, default is 32K, minimal 1K\n\nWhen querying, some reads know in advance exactly how much data is there to be read, but some currently do not. Most prominently, hit list size is not currently known in advance. This setting lets you control how much data to read in such cases. It impacts hit list I/O time, reducing it for lists larger than unhinted read size, but raising it for smaller lists. It does **not** affect RAM usage because the read buffer will already be allocated. So it should not be greater than read_buffer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\nRefines the behavior of networking timeouts (such as `network_timeout` and `agent_query_timeout`).\n\nWhen set to 0, timeouts limit the maximum time for sending the entire request/query.\n\nWhen set to 1 (default), timeouts limit the maximum time between network activities.",
    "translations": {
      "chinese": "整数，单位为秒。缓存结果集的过期时间。默认值为60秒，即1分钟。最小值为1秒。详情请参考[查询缓存](../Searching/Query_cache.md)。该值也可以用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但使用时需小心，不要与包含“_sec”的值名混淆。\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\n查询日志格式。可选，允许的值为`plain`和`sphinxql`，默认值为`sphinxql`。\n\n`sphinxql`模式记录有效的SQL语句。`plain`模式以纯文本格式记录查询（主要适用于纯全文搜索场景）。该指令允许您在搜索服务器启动时切换两种格式。日志格式也可以动态修改，使用`SET GLOBAL query_log_format=sphinxql`语法。详情请参阅[查询日志](../Logging/Query_logging.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### query_log_min_msec\n\n限制（毫秒），防止查询被写入查询日志。可选，默认值为0（所有查询均写入查询日志）。该指令指定仅执行时间超过指定限制的查询将被记录（该值也可用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但使用时需小心，不要与包含`_msec`的值名混淆）。\n\n### query_log\n\n<!-- example conf query_log -->\n\n查询日志文件名。可选，默认值为空（不记录查询）。所有搜索查询（如SELECT ...，但不包括INSERT/REPLACE/UPDATE查询）将记录在此文件中。格式详见[查询日志](../Logging/Query_logging.md)。采用“plain”格式时，可以使用“syslog”作为日志文件路径。在此情况下，所有搜索查询将使用`LOG_INFO`优先级发送到syslog守护进程，前缀为“[query]”而非时间戳。要使用syslog选项，构建Manticore时必须配置`-–with-syslog`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nquery_log_mode指令允许您为searchd和查询日志文件设置不同的权限。默认情况下，这些日志文件以600权限创建，意味着只有运行服务器的用户和root用户可以读取日志文件。\n\n如果您想允许其他用户读取日志文件（例如，运行在非root用户下的监控解决方案），此指令非常有用。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nread_buffer_docs指令控制每个关键字用于文档列表读取缓冲区的大小。每个搜索查询中的每个关键字出现都会关联两个读取缓冲区：一个用于文档列表，一个用于命中列表。该设置让您控制文档列表缓冲区的大小。\n\n较大的缓冲区可能增加每个查询的内存使用，但可能减少I/O时间。对于慢速存储，设置较大值是合理的，对于支持高IOPS的存储，应在较低值范围内进行实验。\n\n默认值为256K，最小值为8K。您还可以为每个表设置[read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs)，覆盖服务器配置级别的设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nread_buffer_hits指令指定搜索查询中每个关键字用于命中列表的读取缓冲区大小。默认大小为256K，最小值为8K。每个搜索查询的每个关键字都有两个关联的读取缓冲区，一个用于文档列表，一个用于命中列表。增加缓冲区大小可增加每个查询的内存使用，但减少I/O时间。对慢速存储，较大缓冲区更合理，对高IOPS存储，应在较低值范围进行实验。\n\n该设置也可通过每个表级别的read_buffer_hits选项指定，详见[read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits)，可覆盖服务器级别的设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\n未提示的读取大小。可选，默认值为32K，最小为1K。\n\n查询时，有些读取能够提前知道需要读取的数据量，但有些则不能，最明显的是命中列表大小目前无法预先知道。该设置允许您控制在此类情况下读取的数据量。它影响命中列表的I/O时间，对大于未提示读取大小的列表可以降低时间，但会增加较小列表的时间。它**不影响**内存使用，因为读取缓冲区已经分配。因此，不应大于read_buffer。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\n细化网络超时行为（如`network_timeout`和`agent_query_timeout`）。\n\n设置为0时，超时限制整个请求/查询的最大发送时间。\n\n设置为1（默认）时，超时限制网络活动之间的最大时间。",
      "russian": "Целое число, в секундах. Период истечения срока для кэшированного результата запроса. По умолчанию 60, или 1 минута. Минимальное возможное значение — 1 секунда. Смотрите подробности в разделе [кэш запросов](../Searching/Query_cache.md). Это значение также может быть выражено с использованием временных [специальных_суффиксов](../Server_settings/Special_suffixes.md), но используйте его осторожно и не путайте с названием самого значения, содержащим '_sec'.\n\n### query_log_format\n\n<!-- example conf query_log_format -->\n\nФормат журнала запросов. Опционально, допустимые значения — `plain` и `sphinxql`, по умолчанию `sphinxql`.\n\nРежим `sphinxql` логирует валидные SQL-запросы. Режим `plain` логирует запросы в текстовом формате (в основном подходит для чисто полнотекстовых случаев использования). Эта директива позволяет переключаться между двумя форматами при запуске поискового сервера. Формат журнала также можно изменять на лету, используя синтаксис `SET GLOBAL query_log_format=sphinxql`. Подробнее смотрите в разделе [Ведение журнала запросов](../Logging/Query_logging.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_58\n\n<!-- end -->\n\n### query_log_min_msec\n\nОграничение (в миллисекундах), которое предотвращает запись запроса в журнал запросов. Опционально, по умолчанию 0 (все запросы записываются в журнал запросов). Эта директива задаёт, что только запросы с временем выполнения, превышающим указанный порог, будут записываться в журнал (это значение также может быть выражено с использованием временных [специальных_суффиксов](../Server_settings/Special_suffixes.md), но используйте с осторожностью и не путайте с названием самого значения, содержащим `_msec`).\n\n### query_log\n\n<!-- example conf query_log -->\n\nИмя файла журнала запросов. Опционально, по умолчанию пусто (запросы не логируются). Все поисковые запросы (например, SELECT ... но не INSERT/REPLACE/UPDATE) будут записываться в этот файл. Формат описан в разделе [Ведение журнала запросов](../Logging/Query_logging.md). В случае формата 'plain' можно использовать 'syslog' в качестве пути к файлу журнала. В этом случае все поисковые запросы будут отправляться демону syslog с приоритетом `LOG_INFO`, с префиксом '[query]' вместо временной метки. Для использования опции syslog, Manticore должен быть скомпилирован с параметром `-–with-syslog`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_59\n\n<!-- end -->\n\n### query_log_mode\n\n<!-- example conf query_log_mode -->\n\nДиректива query_log_mode позволяет установить различные права доступа для файлов searchd и журнала запросов. По умолчанию эти журналы создаются с правами 600, что означает, что только пользователь, под которым запущен сервер, и root могут читать эти файлы.\n\nЭта директива может быть полезна, если вы хотите разрешить другим пользователям читать журналы, например, решениям мониторинга, запущенным под не-root пользователями.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_60\n\n<!-- end -->\n\n### read_buffer_docs\n\n<!-- example conf read_buffer_docs -->\n\nДиректива read_buffer_docs контролирует размер буфера чтения на ключевое слово для списков документов. Для каждого вхождения ключевого слова в запросе есть два связанных буфера чтения: один для списка документов и один для списка попаданий. Этот параметр позволяет контролировать размер буфера списка документов.\n\nУвеличенный размер буфера может повысить использование оперативной памяти на запрос, но потенциально снизить время ввода-вывода. Логично задавать большие значения для медленных хранилищ, а для хранилищ с высокой производительностью IOPS стоит экспериментировать с низкими значениями.\n\nЗначение по умолчанию 256K, минимальное — 8K. Также можно задавать [read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs) на уровне каждой таблицы, что переопределит настройки на уровне сервера.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_61\n\n<!-- end -->\n\n### read_buffer_hits\n\n<!-- example conf read_buffer_hits -->\n\nДиректива read_buffer_hits задаёт размер буфера чтения на ключевое слово для списков попаданий в поисковых запросах. По умолчанию размер 256K, минимальное значение 8K. Для каждого вхождения ключевого слова в запросе есть два связанных буфера чтения: один для списка документов и один для списка попаданий. Увеличение размера буфера может повысить использование ОЗУ на запрос, но снизить время ввода-вывода. Для медленных хранилищ логично использовать большие размеры буферов, а для хранилищ с высокой производительностью IOPS стоит экспериментировать с низкими значениями.\n\nЭтот параметр также можно указать на уровне каждой таблицы через опцию [read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits), что переопределит настройку на уровне сервера.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_62\n\n<!-- end -->\n\n### read_unhinted\n\n<!-- example conf read_unhinted -->\n\nРазмер неуказанного чтения. Опционально, по умолчанию 32K, минимальное 1K.\n\nПри выполнении запроса некоторые чтения заранее точно знают, сколько данных нужно считать, а некоторые — нет. Особенно это касается размера списка попаданий, который сейчас не известен заранее. Этот параметр позволяет контролировать, сколько данных читать в таких случаях. Он влияет на время ввода-вывода для списков попаданий, уменьшая его для списков, больших чем размер неуказанного чтения, но увеличивая для меньших списков. Он **не** влияет на использование оперативной памяти, так как буфер чтения уже будет выделен. Поэтому не должен быть больше, чем read_buffer.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_63\n\n<!-- end -->\n\n### reset_network_timeout_on_packet\n\n<!-- example conf reset_network_timeout_on_packet -->\n\nУточняет поведение сетевых таймаутов (например, `network_timeout` и `agent_query_timeout`).\n\nПри значении 0 таймауты ограничивают максимальное время отправки всего запроса/запроса.\n\nПри значении 1 (по умолчанию) таймауты ограничивают максимальное время между сетевой активностью."
    },
    "is_code_or_comment": false
  },
  "301c0a74082ac43c410660033e9ee7b7cc60354d5685654be864f20afa88fb7f": {
    "original": "CODE_BLOCK_53\n\n<!-- end -->\n\nThere is an option, [SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time), that lets you limit the query time *and* get stable, repeatable results. Instead of regularly checking the actual current time while evaluating the query, which is indeterministic, it predicts the current running time using a simple linear model instead:\n\nCODE_BLOCK_54\n\nThe query is then terminated early when the `predicted_time` reaches a given limit.\n\nOf course, this is not a hard limit on the actual time spent (it is, however, a hard limit on the amount of *processing* work done), and a simple linear model is in no way an ideally precise one. So the wall clock time *may* be either below or over the target limit. However, the error margins are quite acceptable: for instance, in our experiments with a 100 msec target limit, the majority of the test queries fell into a 95 to 105 msec range, and *all* the queries were in an 80 to 120 msec range. Also, as a nice side effect, using the modeled query time instead of measuring the actual run time results in somewhat fewer gettimeofday() calls, too.\n\nNo two server makes and models are identical, so the `predicted_time_costs` directive lets you configure the costs for the model above. For convenience, they are integers, counted in nanoseconds. (The limit in max_predicted_time is counted in milliseconds, and having to specify cost values as 0.000128 ms instead of 128 ns is somewhat more error-prone.) It is not necessary to specify all four costs at once, as the missed ones will take the default values. However, we strongly suggest specifying all of them for readability.\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\nThe preopen_tables configuration directive specifies whether to forcibly preopen all tables on startup. The default value is 1, which means that all tables will be preopened regardless of the per-table [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) setting. If set to 0, the per-table settings can take effect, and they will default to 0.\n\nPre-opening tables can prevent races between search queries and rotations that can cause queries to fail occasionally. However, it also uses more file handles. In most scenarios, it is recommended to preopen tables.\n\nHere's an example configuration:\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\nThe pseudo_sharding configuration option enables parallelization of search queries to local plain and real-time tables, regardless of whether they are queried directly or through a distributed table. This feature will automatically parallelize queries to up to the number of threads specified in `searchd.threads` # of threads.\n\nNote that if your worker threads are already busy, because you have:\n\n* high query concurrency\n\n* physical sharding of any kind:\n\n  - distributed table of multiple plain/real-time tables\n\n  - real-time table consisting of too many disk chunks\n\nthen enabling pseudo_sharding may not provide any benefits and may even result in a slight decrease in throughput. If you prioritize higher throughput over lower latency, it's recommended to disable this option.\n\nEnabled by default.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### replication_connect_timeout\n\nThe `replication_connect_timeout` directive defines the timeout for connecting to a remote node. By default, the value is assumed to be in milliseconds, but it can have [another suffix](../Server_settings/Special_suffixes.md). The default value is 1000 (1 second).\n\nWhen connecting to a remote node, Manticore will wait for this amount of time at most to complete the connection successfully. If the timeout is reached but the connection has not been established, and `retries` are enabled, a retry will be initiated.\n\n### replication_query_timeout\n\nThe `replication_query_timeout` sets the amount of time that searchd will wait for a remote node to complete a query. The default value is 3000 milliseconds (3 seconds), but can be `suffixed` to indicate a different unit of time.\n\nAfter establishing a connection, Manticore will wait for a maximum of `replication_query_timeout` for the remote node to complete. Note that this timeout is separate from the `replication_connect_timeout`, and the total possible delay caused by a remote node will be the sum of both values.\n\n### replication_retry_count\n\nThis setting is an integer that specifies how many times Manticore will attempt to connect and query a remote node during replication before reporting a fatal query error. The default value is 3.\n\n### replication_retry_delay\n\nThis setting is an integer in milliseconds (or [special_suffixes](../Server_settings/Special_suffixes.md)) that specifies the delay before Manticore retries querying a remote node in case of failure during replication. This value is only relevant when a non-zero value is specified. The default value is 500.\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\nThis configuration sets the maximum amount of RAM allocated for cached result sets in bytes. The default value is 16777216, which is equivalent to 16 megabytes. If the value is set to 0, the query cache is disabled. For more information about the query cache, please refer to the [query cache](../Searching/Query_cache.md) for details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### qcache_thresh_msec\n\nInteger, in milliseconds. The minimum wall time threshold for a query result to be cached. Defaults to 3000, or 3 seconds. 0 means cache everything. Refer to [query cache](../Searching/Query_cache.md) for details. This value also may be expressed with time [special_suffixes](../Server_settings/Special_suffixes.md), but use it with care and don't confuse yourself with the name of the value itself, containing '_msec'.\n\n### qcache_ttl_sec",
    "translations": {
      "chinese": "CODE_BLOCK_53\n\n<!-- end -->\n\n有一个选项，[SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time)，它允许你限制查询时间*并且*获得稳定、可重复的结果。它不是在评估查询时定期检查实际当前时间（这是不确定的），而是使用一个简单的线性模型来预测当前运行时间：\n\nCODE_BLOCK_54\n\n当 `predicted_time` 达到给定限制时，查询会被提前终止。\n\n当然，这并不是对实际花费时间的硬限制（但确实是对*处理*工作量的硬限制），而且简单的线性模型绝不是理想的精确模型。所以实时时钟时间*可能*低于或超过目标限制。然而，误差范围相当可以接受：例如，在我们以100毫秒为目标限制的实验中，大多数测试查询在95到105毫秒范围内，且*所有*查询都在80到120毫秒范围内。此外，作为一个额外的好处，使用建模的查询时间代替测量的实际运行时间，也减少了部分 gettimeofday() 调用。\n\n没有两个服务器的制造商和型号是完全相同的，所以 `predicted_time_costs` 指令允许你配置上述模型的成本。为方便起见，它们是以纳秒为单位的整数。（max_predicted_time 中的限制以毫秒计，必须将成本值指定为 0.000128 毫秒而非128纳秒会更易出错。）不必一次指定所有四个成本，未指定的将采用默认值。但是，我们强烈建议全部指定以便于阅读。\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\npreopen_tables 配置指令指定是否在启动时强制预打开所有表。默认值是1，意味着无论单表的 [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) 设置如何，都会预打开所有表。如果设置为0，则单表设置生效，默认为0。\n\n预打开表可以防止搜索查询和轮换之间的竞争条件导致查询偶尔失败。然而，这也会使用更多的文件句柄。在大多数场景下，建议预打开表。\n\n下面是一个配置示例：\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\npseudo_sharding 配置选项开启对本地普通表和实时表搜索查询的并行化，无论它们是直接查询还是通过分布式表查询。此功能将自动将查询并行化至 `searchd.threads` 指定的线程数。\n\n请注意，如果你的工作线程已经繁忙，因为你有：\n\n* 高查询并发\n\n* 任何形式的物理分片：\n\n  - 多个普通/实时表组成的分布式表\n\n  - 由过多磁盘块组成的实时表\n\n那么启用 pseudo_sharding 可能不会带来任何好处，甚至可能导致吞吐量略有下降。如果你优先考虑更高的吞吐量而非更低的延迟，建议禁用此选项。\n\n默认启用。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### replication_connect_timeout\n\n`replication_connect_timeout` 指令定义连接远程节点的超时时间。默认单位为毫秒，但可以使用[其他后缀](../Server_settings/Special_suffixes.md)。默认值为1000（1秒）。\n\n连接远程节点时，Manticore 最多等待此时间以成功建立连接。如果超时且连接未建立，且启用 `retries`，则会重试。\n\n### replication_query_timeout\n\n`replication_query_timeout` 设置 searchd 等待远程节点完成查询的时间。默认值是3000毫秒（3秒），也可以添加后缀指定不同时间单位。\n\n建立连接后，Manticore 会等待最多 `replication_query_timeout` 时间以获得远程节点的结果。注意，该超时与 `replication_connect_timeout` 分开，总延迟可能为两者之和。\n\n### replication_retry_count\n\n此设置为整数，指定 Manticore 在复制期间尝试连接和查询远程节点的次数上限，超过则报告致命错误。默认值为3。\n\n### replication_retry_delay\n\n此设置为整数，单位为毫秒（或[特殊后缀](../Server_settings/Special_suffixes.md)），指定在复制失败时重试查询远程节点之前的延迟时间。当指定非零值时生效。默认值为500。\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\n此配置设置用于缓存结果集的最大RAM量，单位为字节。默认值为16777216，即16兆字节。如果设置为0，则禁用查询缓存。更多查询缓存信息请参阅 [query cache](../Searching/Query_cache.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### qcache_thresh_msec\n\n整数，单位为毫秒。查询结果进入缓存的最小壁钟时间阈值。默认为3000，即3秒。0 表示缓存所有。详情请参阅[查询缓存](../Searching/Query_cache.md)。该值也可用时间[特殊后缀](../Server_settings/Special_suffixes.md)表示，但使用时需小心，避免和名称中含有 '_msec' 混淆。\n\n### qcache_ttl_sec",
      "russian": "CODE_BLOCK_53\n\n<!-- end -->\n\nСуществует опция, [SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time), которая позволяет ограничить время запроса *и* получить стабильные, воспроизводимые результаты. Вместо того, чтобы регулярно проверять фактическое текущее время во время выполнения запроса, что является неопределённым, она предсказывает текущее время выполнения с помощью простой линейной модели:\n\nCODE_BLOCK_54\n\nЗапрос при этом завершается досрочно, когда `predicted_time` достигает заданного лимита.\n\nРазумеется, это не жёсткое ограничение по фактическому времени выполнения (однако жёсткое ограничение по объёму *обработанной* работы), и простая линейная модель отнюдь не является идеально точной. Поэтому фактическое время на часах *может* быть как ниже, так и выше целевого лимита. Тем не менее, погрешности вполне приемлемы: например, в наших экспериментах с целевым лимитом 100 мс большинство тестовых запросов попадало в диапазон 95–105 мс, и *все* запросы были в диапазоне 80–120 мс. Кроме того, как приятный побочный эффект, использование смоделированного времени запроса вместо измерения фактического ведёт к уменьшению количества вызовов gettimeofday().\n\nНет двух одинаковых моделей и марок серверов, поэтому директива `predicted_time_costs` позволяет вам настроить стоимости для приведённой выше модели. Для удобства они задаются целыми числами в наносекундах. (Лимит в max_predicted_time задаётся в миллисекундах, и указывать значения стоимости как 0.000128 мс вместо 128 нс более подвержено ошибкам.) Задавать все четыре стоимости одновременно не обязательно, пропущенные возьмут значения по умолчанию. Однако мы настоятельно рекомендуем установить все для лучшей читаемости.\n\n### preopen_tables\n\n<!-- example conf preopen_tables -->\n\nДиректива конфигурации preopen_tables задаёт, нужно ли принудительно предварительно открывать все таблицы при запуске. Значение по умолчанию — 1, что означает предварительное открытие всех таблиц независимо от настройки [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) для каждой таблицы. Если установить 0, будут действовать настройки для отдельных таблиц, которые по умолчанию равны 0.\n\nПредварительное открытие таблиц помогает предотвратить гонки между поисковыми запросами и ротациями, которые могут изредка приводить к сбоям запросов. Однако это также увеличивает количество открытых файловых дескрипторов. В большинстве случаев рекомендуется использовать предварительное открытие таблиц.\n\nПример конфигурации:\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_55\n\n<!-- end -->\n\n### pseudo_sharding\n\n<!-- example conf pseudo_sharding -->\n\nОпция конфигурации pseudo_sharding включает параллелизацию поисковых запросов к локальным обычным и реальным таблицам, независимо от того, запрашиваются ли они напрямую или через распределённую таблицу. Эта функция автоматически параллелит запросы до числа потоков `searchd.threads`.\n\nОбратите внимание, что если ваши рабочие потоки уже заняты из-за:\n\n* высокой конкуренции запросов\n\n* любого физического шардирования:\n\n  - распределённая таблица из нескольких обычных/реальных таблиц\n\n  - реальная таблица, состоящая из слишком большого количества дисковых чанков\n\nто включение pseudo_sharding может не дать выгоды и даже слегка снизить пропускную способность. Если вы предпочитаете большую пропускную способность ценой большей задержки, рекомендуется отключить эту опцию.\n\nПо умолчанию включено.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_56\n\n<!-- end -->\n\n### replication_connect_timeout\n\nДиректива `replication_connect_timeout` задаёт таймаут подключения к удалённому узлу. По умолчанию значение предполагается в миллисекундах, но может иметь [другой суффикс](../Server_settings/Special_suffixes.md). Значение по умолчанию — 1000 (1 секунда).\n\nПри подключении к удалённому узлу Manticore будет ждать успешного соединения не более указанного времени. Если время истекает, а соединение не установлено, и включены `retries`, выполняется повторная попытка.\n\n### replication_query_timeout\n\n`replication_query_timeout` задаёт время ожидания ответа удалённого узла на выполнение запроса. Значение по умолчанию — 3000 миллисекунд (3 секунды), может иметь `суффикс` для указания другой единицы времени.\n\nПосле установления соединения Manticore будет ждать ответ удалённого узла не более `replication_query_timeout`. Обратите внимание, что этот таймаут отличается от `replication_connect_timeout`, и общая возможная задержка со стороны удалённого узла будет суммой обоих значений.\n\n### replication_retry_count\n\nДанный параметр — целое число, задающее количество попыток подключения и запроса к удалённому узлу в процессе репликации до сообщения о фатальной ошибке запроса. Значение по умолчанию — 3.\n\n### replication_retry_delay\n\nЭтот параметр — целое число в миллисекундах (или с [специальным суффиксом](../Server_settings/Special_suffixes.md)), задаёт задержку перед повторной попыткой запроса к удалённому узлу при сбое в репликации. Значение актуально только при ненулевом значении. Значение по умолчанию — 500.\n\n### qcache_max_bytes\n\n<!-- example conf qcache_max_bytes -->\n\nЭта конфигурация задаёт максимальный объём ОЗУ, выделенный под кешированные наборы результатов, в байтах. Значение по умолчанию — 16777216, что эквивалентно 16 мегабайтам. Если значение равно 0, кеш запросов отключен. Подробнее о кеше запросов смотрите в разделе [query cache](../Searching/Query_cache.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_57\n\n<!-- end -->\n\n### qcache_thresh_msec\n\nЦелое число в миллисекундах. Минимальный порог времени ответа для кеширования результата запроса. По умолчанию — 3000 (3 секунды). 0 означает кешировать все. Подробности смотрите в [query cache](../Searching/Query_cache.md). Значение может задаваться и со [специальным суффиксом времени](../Server_settings/Special_suffixes.md), но используйте это аккуратно, чтобы не запутаться с именем параметра, содержащим '_msec'.\n\n### qcache_ttl_sec"
    },
    "is_code_or_comment": false
  },
  "a4a65daef423f6d339bdfdbc67f9c8ffdf00d5ab74dfd88723f0a43ed58485d6": {
    "original": "#### Technical details about Sphinx API protocol and TFO\n\n<details>\n\nLegacy Sphinx protocol has 2 phases: handshake exchanging and data flow. The handshake consists of a packet of 4 bytes from the client, and a packet of 4 bytes from the daemon with only one purpose - the client determines that the remote is a real Sphinx daemon, the daemon determines that the remote is a real Sphinx client. The main dataflow is quite simple: let's both sides declare their handshakes, and the opposite check them. That exchange with short packets implies using special `TCP_NODELAY` flag, which switches off Nagle's TCP algorithm and declares that the TCP connection will be performed as a dialogue of small packages.\n\nHowever, it is not strictly defined who speaks first in this negotiation. Historically, all clients that use the binary API speak first: send handshake, then read 4 bytes from a daemon, then send a request and read an answer from the daemon.\n\nWhen we improved Sphinx protocol compatibility, we considered these things:\n\n1. Usually, master-agent communication is established from a known client to a known host on a known port. So, it is quite not possible that the endpoint will provide a wrong handshake. So, we may implicitly assume that both sides are valid and really speak in Sphinx proto.\n\n2. Given this assumption, we can 'glue' a handshake to the real request and send it in one packet. If the backend is a legacy Sphinx daemon, it will just read this glued packet as 4 bytes of a handshake, then request body. Since they both came in one packet, the backend socket has -1 RTT, and the frontend buffer still works despite that fact usual way.\n\n3. Continuing the assumption: since the 'query' packet is quite small, and the handshake is even smaller, let's send both in the initial 'SYN' TCP package using modern TFO (tcp-fast-open) technique. That is: we connect to a remote node with the glued handshake + body package. The daemon accepts the connection and immediately has both the handshake and the body in a socket buffer, as they came in the very first TCP 'SYN' packet. That eliminates another one RTT.\n\n4. Finally, teach the daemon to accept this improvement. Actually, from the application, it implies NOT to use `TCP_NODELAY`. And, from the system side, it implies to ensure that on the daemon side, accepting TFO is activated, and on the client side, sending TFO is also activated. By default, in modern systems, client TFO is already activated by default, so you only have to tune the server TFO for all things to work.\n\nAll these improvements without actually changing the protocol itself allowed us to eliminate 1.5 RTT of the TCP protocol from the connection. Which is, if the query and answer are capable of being placed in a single TCP package, decreases the whole binary API session from 3.5 RTT to 2 RTT - which makes network negotiation about 2 times faster.\n\nSo, all our improvements are stated around an initially undefined statement: 'who speaks first.' If a client speaks first, we may apply all these optimizations and effectively process connect + handshake + query in a single TFO package. Moreover, we can look at the beginning of the received package and determine a real protocol. That is why you can connect to one and the same port via API/http/https. If the daemon has to speak first, all these optimizations are impossible, and the multiprotocol is also impossible. That is why we have a dedicated port for MySQL and did not unify it with all the other protocols into a same port. Suddenly, among all clients, one was written implying that daemon should send a handshake first. That is - no possibility to all the described improvements. That is SphinxSE plugin for mysql/mariadb. So, specially for this single client we dedicated `sphinx` proto definition to work most legacy way. Namely: both sides activate `TCP_NODELAY` and exchange with small packages. The daemon sends its handshake on connect, then the client sends its, and then everything works usual way. That is not very optimal, but just works. If you use SphinxSE to connect to Manticore - you have to dedicate a listener with explicitly stated `sphinx` proto. For another clients - avoid to use this listener as it is slower. If you use another legacy Sphinx API clients - check first, if they are able to work with non-dedicated multiprotocol port. For master-agent linkage using the non-dedicated (multiprotocol) port and enabling client and server TFO works well and will definitely make working of network backend faster, especially if you have very light and fast queries.\n\n</details>\n\n### listen_tfo\n\nThis setting allows the TCP_FASTOPEN flag for all listeners. By default, it is managed by the system but may be explicitly switched off by setting it to '0'.\n\nFor general knowledge about the TCP Fast Open extension, please consult with [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open). In short, it allows the elimination of one TCP round-trip when establishing a connection.\n\nIn practice, using TFO in many situations may optimize client-agent network efficiency, as if [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) are in play, but without holding active connections, and also without limitation for the maximum num of connections.\n\nOn modern OS, TFO support is usually switched 'on' at the system level, but this is just a 'capability', not the rule. Linux (as the most progressive) has supported it since 2011, on kernels starting from 3.7 (for the server-side). Windows has supported it from some builds of Windows 10. Other operating systems (FreeBSD, MacOS) are also in the game.\n\nFor Linux system server checks variable `/proc/sys/net/ipv4/tcp_fastopen` and behaves according to it. Bit 0 manages client side, bit 1 rules listeners. By default, the system has this parameter set to 1, i.e., clients enabled, listeners disabled.\n\n### log\n\n<!-- example conf log -->\n\nThe log setting specifies the name of the log file where all `searchd` run time events will be logged. If not specified, the default name is 'searchd.log'.",
    "translations": {
      "chinese": "#### 关于 Sphinx API 协议和 TFO 的技术细节\n\n<details>\n\n传统的 Sphinx 协议有两个阶段：握手交换和数据流。握手由客户端发送的4字节数据包和守护进程发送的4字节数据包组成，唯一目的——客户端确定远程是一个真实的 Sphinx 守护进程，守护进程确定远程是一个真实的 Sphinx 客户端。主要的数据流非常简单：双方都声明自己的握手包，对方校验它们。用短包交换意味着使用特殊的 `TCP_NODELAY` 标志，它关闭了 Nagle 的 TCP 算法，并声明 TCP 连接将以小包对话的方式执行。\n\n但是，协议中并没有严格定义谁先发言。历史上，所有使用二进制 API 的客户端都会先说话：发送握手，接着读取守护进程返回的4字节，再发送请求并读取守护进程的回答。\n\n当我们改进 Sphinx 协议兼容性时，考虑了以下几个方面：\n\n1. 通常主代理通信由已知客户端连接到已知主机上的已知端口。因此，终端提供错误握手的可能性很低。因此，我们可以隐含假设双方都是有效且确实是用 Sphinx 协议通信。\n\n2. 基于此假设，我们可以将握手“粘合”到真实请求中，并将其作为一个包发送。如果后端是传统 Sphinx 守护进程，它会先读取这4字节的握手然后读取请求体。由于它们都在一个包中，后端套接字节省了1个 RTT，而前端缓冲区依然照常工作。\n\n3. 延续此假设：由于“查询”包非常小，握手包更小，让我们使用现代的 TFO（tcp-fast-open）技术，在初始的 'SYN' TCP 包中发送两者。即：连接远程节点时，以粘合的握手加请求体包进行连接。守护进程接受连接时，这两部分数据已立刻到达套接字缓冲区，就像它们在第一个 TCP 'SYN' 包里一样，消除了又一个 RTT。\n\n4. 最后，教会守护进程支持此改进。实际上，这意味着应用层不使用 `TCP_NODELAY`。系统层面要确保守护进程端启用 TFO 的接受，客户端同时启用 TFO 的发送。现代系统默认客户端 TFO 已启用，只需调试服务端的 TFO 即可正常工作。\n\n所有这些改进，在不改变协议本身的前提下，使我们消除了 TCP 连接中的1.5个 RTT。如果查询和回答能够放入一个 TCP 包，则整个二进制 API 会话从3.5个 RTT减少到2个 RTT——网络协商速度提升了一倍。\n\n所有改进都基于最初未定义的命题：“谁先说话？”如果客户端先说话，我们就可以应用这些优化，在单个 TFO 包中高效完成连接＋握手＋查询。此外，我们可以查看接收包的开头判断实际协议。这就是为什么同一个端口可以通过 API/http/https 多种方式连接。如果守护进程必须先说话，所有这些优化都无法实现，多协议也无法支持。这就是为什么 MySQL 有专用端口而不统一到其他协议端口。某客户端要求守护进程先发送握手——不可能做上述优化，那就是 MySQL/MariaDB 的 SphinxSE 插件。针对它，我们专门设立了 `sphinx` 协议定义，最大程度以传统方式工作。即双方启用 `TCP_NODELAY`，以小包交换，守护进程连接时先发握手，然后客户端发握手，然后以常规方式工作。这种方式不够优化，但能正常工作。若用 SphinxSE 连接 Manticore，需专门监听并显式用 `sphinx` 协议；其他客户端则尽量避免使用此监听器，因为速度较慢。若用其他传统 Sphinx API 客户端，需先确认它们是否支持非专用多协议端口。对于主-agent 链接，使用非专用（多协议）端口及同时启用客户端和服务器的 TFO 表现良好，能显著提升网络后端速度，特别是在查询轻量快速时效果明显。\n\n</details>\n\n### listen_tfo\n\n此设置允许为所有监听器启用 TCP_FASTOPEN 标志。默认由系统管理，但可显式设置为 '0' 关闭。\n\n有关 TCP Fast Open 扩展的一般知识，请参阅 [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open)。简而言之，它允许建立连接时省去一个 TCP 往返。\n\n实际上，在许多情况下，使用 TFO 可优化客户端与代理间的网络效率，就像使用 [持久代理](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) 一样，但不保持活动连接，并且没有连接数最大限制。\n\n在现代操作系统中，TFO 支持通常默认启用，但这只是“能力”而非规则。Linux（作为最先进系统）从2011年起支持此功能，内核自3.7开始支持服务器端。Windows 在 Windows 10 的某些版本支持。其他操作系统（FreeBSD，MacOS）也在支持中。\n\nLinux 系统服务器查看变量 `/proc/sys/net/ipv4/tcp_fastopen` 并据此行为。第0位控制客户端，第1位控制监听器。默认系统设置是1，代表客户端启用，监听器禁用。\n\n### log\n\n<!-- example conf log -->\n\nlog 设置指明了所有 `searchd` 运行时事件的日志文件名。如果未指定，默认名称是 'searchd.log'。",
      "russian": "#### Технические детали протокола Sphinx API и TFO\n\n<details>\n\nУстаревший протокол Sphinx состоит из 2 этапов: обмен рукопожатиями и передача данных. Рукопожатие представляет собой пакет из 4 байт от клиента и пакет из 4 байт от демона с единственной целью — клиент определяет, что удалённый узел является настоящим демоном Sphinx, демон определяет, что удалённый узел — это настоящий клиент Sphinx. Основной поток данных достаточно простой: обе стороны объявляют свои рукопожатия, и противоположная сторона их проверяет. Такой обмен короткими пакетами предполагает использование специального флага `TCP_NODELAY`, который отключает алгоритм Нагла в TCP и указывает, что TCP-соединение будет выполняться как диалог маленьких пакетов.\n\nОднако не было строго определено, кто начинает первым в этом обмене. Исторически все клиенты, использующие бинарный API, начинают первыми: отправляют рукопожатие, затем читают 4 байта от демона, затем отправляют запрос и читают ответ от демона.\n\nКогда мы улучшали совместимость протокола Sphinx, мы учитывали следующие моменты:\n\n1. Обычно связь мастер-агента устанавливается от известного клиента к известному хосту на известный порт. Поэтому маловероятно, что конечная точка предоставит неправильное рукопожатие. Следовательно, мы можем неявно предполагать, что обе стороны валидны и действительно говорят на протоколе Sphinx.\n\n2. Исходя из этого предположения, мы можем «склеить» рукопожатие с реальным запросом и отправить в одном пакете. Если бэкенд — устаревший демон Sphinx, он просто прочитает этот склеенный пакет сначала как 4 байта рукопожатия, затем тело запроса. Поскольку всё пришло в одном пакете, у сокета бэкенда есть -1 RTT, а буфер фронтенда всё равно работает как обычно.\n\n3. Продолжая предположение: поскольку пакет «запроса» достаточно мал, а рукопожатие ещё меньше, давайте отправим их оба в начальном TCP-пакете «SYN» с помощью современной техники TFO (tcp-fast-open). То есть мы подключаемся к удалённому узлу, отправляя склеенный пакет рукопожатия + тело запроса. Демон принимает соединение и сразу имеет и рукопожатие, и тело запроса в буфере сокета, так как они пришли в самом первом TCP-пакете «SYN». Это устраняет ещё один RTT.\n\n4. Наконец, научить демон принимать это улучшение. Фактически это означает, что на уровне приложения НЕ используется `TCP_NODELAY`. А со стороны системы нужно обеспечить, чтобы на стороне демона была активирована поддержка TFO для приёма, а на стороне клиента — для отправки. По умолчанию в современных системах клиентский TFO уже активирован, поэтому вам нужно лишь настроить серверный TFO для правильной работы.\n\nВсе эти улучшения без изменения самого протокола позволили нам сократить 1.5 RTT TCP-протокола при соединении. Если запрос и ответ могут помещаться в один TCP-пакет, это уменьшает всю сессию бинарного API с 3.5 RTT до 2 RTT — что делает сетевой обмен примерно вдвое быстрее.\n\nТаким образом, все наши улучшения основаны на изначально неопределённом моменте: «кто говорит первым». Если клиент говорит первым, мы можем применить все эти оптимизации и эффективно обработать подключение + рукопожатие + запрос в одном TFO-пакете. Более того, мы можем взглянуть в начало полученного пакета и определить реальный протокол. Вот почему вы можете подключаться к одному и тому же порту через API/http/https. Если же демон должен говорить первым, все эти оптимизации невозможны, а мультипротокол тоже невозможен. Поэтому у нас есть выделенный порт для MySQL, который мы не объединили с другими протоколами на одном порту. Вдруг среди всех клиентов нашёлся один, написанный с предположением, что демон должен первым отправлять рукопожатие. Это — плагин SphinxSE для mysql/mariadb. Для этого единственного клиента мы выделили определение протокола `sphinx`, чтобы работать максимально наследуемым способом. А именно: обе стороны активируют `TCP_NODELAY` и обмениваются маленькими пакетами. Демон отправляет своё рукопожатие при подключении, затем клиент отправляет своё, и дальше всё работает обычно. Это не очень оптимально, но просто работает. Если вы используете SphinxSE для подключения к Manticore — вам нужно выделить слушателя с явно указанным протоколом `sphinx`. Для других клиентов избегайте использовать этот слушатель, так как он медленнее. Если у вас есть другие устаревшие клиенты Sphinx API — сначала проверьте, могут ли они работать без выделенного мультипротокольного порта. Для связки мастер-агент использование мультипротокольного порта с включённым TFO клиента и сервера работает хорошо и однозначно ускорит работу сетевого бэкенда, особенно если ваши запросы лёгкие и быстрые.\n\n</details>\n\n### listen_tfo\n\nЭтот параметр позволяет включить флаг TCP_FASTOPEN для всех слушателей. По умолчанию управление осуществляется системой, но его можно явно отключить установкой значения '0'.\n\nДля общего понимания расширения TCP Fast Open, пожалуйста, обратитесь к [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open). Кратко: оно позволяет устранить один раунд TCP при установлении соединения.\n\nНа практике использование TFO во многих случаях может оптимизировать эффективность сети клиент-агент, как при использовании [постоянных агентов](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md), но без удержания активных соединений и без ограничений на максимальное число соединений.\n\nНа современных ОС поддержка TFO обычно включена на уровне системы, но это лишь «возможность», а не правило. Linux (как наиболее прогрессивный) поддерживает его с 2011 года на ядрах начиная с 3.7 (сервера). Windows поддерживает его с некоторых сборок Windows 10. Другие ОС (FreeBSD, MacOS) тоже в игре.\n\nНа Linux сервер проверяет переменную `/proc/sys/net/ipv4/tcp_fastopen` и действует согласно её значению. Бит 0 управляет клиентской стороной, бит 1 — слушателями. По умолчанию системное значение равно 1, т.е. клиенты включены, слушатели отключены.\n\n### log\n\n<!-- example conf log -->\n\nПараметр log указывает имя файла журнала, куда будут записываться все события выполнения `searchd`. Если не указан, используется имя по умолчанию 'searchd.log'."
    },
    "is_code_or_comment": false
  },
  "2943ccf2fc8a7646e00da46a5f1753abd8014a1d682e60774a0c4977be08a674": {
    "original": "When using [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) to modify document attributes in real-time, the changes are first written to an in-memory copy of the attributes. These updates occur in a memory-mapped file, meaning the OS decides when to write the changes to disk. Upon normal shutdown of `searchd` (triggered by a `SIGTERM` signal), all changes are forced to be written to disk.\n\nYou can also instruct `searchd` to periodically write these changes back to disk to prevent data loss. The interval between these flushes is determined by `attr_flush_period`, specified in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)).\n\nBy default, the value is 0, which disables periodic flushing. However, flushing will still occur during a normal shutdown.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\nThis setting controls the automatic [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) process for table compaction.\n\nBy default table compaction occurs automatically. You can modify this behavior with the `auto_optimize` setting:\n\n* 0 to disable automatic table compaction (you can still call `OPTIMIZE` manually)\n\n* 1 to explicitly enable it\n\n* to enable it while multiplying the optimization threshold by 2.\n\nBy default, OPTIMIZE runs until the number of disk chunks is less than or equal to the number of logical CPU cores multiplied by 2.\n\nHowever, if the table has attributes with KNN indexes, this threshold is different. In this case, it is set to the number of physical CPU cores divided by 2 to improve KNN search performance.\n\nNote that toggling `auto_optimize` on or off doesn't prevent you from running [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) manually.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### parallel_chunk_merges\n\n<!-- example conf parallel_chunk_merges -->\n\nThis setting controls how many disk chunk merge jobs the server is allowed to run in parallel during [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) for real-time tables.\n\nThis affects only disk chunk merging (compaction), not query parallelism.\n\nSet it to `1` to disable parallel chunk merging (merge jobs will run one-by-one). Higher values may speed up compaction on systems with fast storage, but will increase concurrent disk I/O.\n\nDefault is `max(1, min(2, threads/2))`.\n\nThis value can be changed at runtime using `SET GLOBAL parallel_chunk_merges = N` and inspected via `SHOW VARIABLES`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Increase -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore supports the automatic creation of tables that don't yet exist but are specified in INSERT statements. This feature is enabled by default. To disable it, set `auto_schema = 0` explicitly in your configuration. To re-enable it, set `auto_schema = 1` or remove the `auto_schema` setting from the configuration.\n\nKeep in mind that the `/bulk` HTTP endpoint does not support automatic table creation.\n\n> NOTE: The [auto schema functionality](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) requires [Manticore Buddy](../Installation/Manticore_Buddy.md). If it doesn't work, make sure Buddy is installed.\n\n<!-- request Disable -->\n\nCODE_BLOCK_5\n\n<!-- request Enable -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\nThis setting controls the binary log transaction flush/sync mode. It is optional, with a default value of 2 (flush every transaction, sync every second).\n\nThe directive determines how frequently the binary log will be flushed to the OS and synced to disk. There are three supported modes:\n\n*  0, flush and sync every second. This offers the best performance, but up to 1 second worth of committed transactions can be lost in the event of a server crash or an OS/hardware crash.\n\n*  1, flush and sync every transaction. This mode provides the worst performance but guarantees that every committed transaction's data is saved.\n\n*  2, flush every transaction, sync every second. This mode delivers good performance and ensures that every committed transaction is saved in case of a server crash. However, in the event of an OS/hardware crash, up to 1 second worth of committed transactions can be lost.\n\nFor those familiar with MySQL and InnoDB, this directive is similar to `innodb_flush_log_at_trx_commit`. In most cases, the default hybrid mode 2 provides a nice balance of speed and safety, with full RT table data protection against server crashes and some protection against hardware ones.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\nThis setting controls how binary log files are managed. It is optional, with a default value of 0 (separate file for each table).\n\nYou can choose between two ways to manage binary log files:\n\n* Separate file for each table (default, `0`): Each table saves its changes in its own log file. This setup is good if you have many tables that get updated at different times. It allows tables to be updated without waiting for others. Also, if there is a problem with one table's log file, it does not affect the others.\n\n* Single file for all tables (`1`): All tables use the same binary log file. This method makes it easier to handle files because there are fewer of them. However, this could keep files longer than needed if one table still needs to save its updates. This setting might also slow things down if many tables need to update at the same time because all changes have to wait to be written to one file.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->",
    "translations": {
      "chinese": "在使用 [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) 实时修改文档属性时，更改首先写入到属性的内存副本中。这些更新发生在内存映射文件中，意味着操作系统决定何时将更改写入磁盘。在正常关闭 `searchd`（由 `SIGTERM` 信号触发）时，所有更改都会被强制写入磁盘。\n\n您还可以指示 `searchd` 定期将这些更改写回磁盘以防止数据丢失。两次刷新之间的间隔由 `attr_flush_period` 决定，单位为秒（或 [special_suffixes](../Server_settings/Special_suffixes.md)）。\n\n默认值为 0，表示禁用周期性刷新。但在正常关闭期间仍会进行刷新。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\n此设置控制表压缩的自动 [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) 过程。\n\n默认情况下，表压缩会自动执行。您可以通过 `auto_optimize` 设置修改此行为：\n\n* 0 禁用自动表压缩（您仍然可以手动调用 `OPTIMIZE`）\n\n* 1 明确启用自动压缩\n\n* 在启用的同时将优化阈值乘以 2。\n\n默认情况下，OPTIMIZE 会运行，直到磁盘块数量小于或等于逻辑 CPU 核心数乘以 2。\n\n但是，如果表具有带 KNN 索引的属性，则此阈值不同。在这种情况下，阈值设置为物理 CPU 核心数除以 2，以提高 KNN 搜索性能。\n\n请注意，打开或关闭 `auto_optimize` 并不会阻止您手动运行 [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### parallel_chunk_merges\n\n<!-- example conf parallel_chunk_merges -->\n\n此设置控制服务器在 [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) 实时表时允许并行运行的磁盘块合并作业数量。\n\n这只影响磁盘块合并（压缩），不影响查询并行度。\n\n设置为 `1` 可禁用并行块合并（合并作业将逐个运行）。在具有高速存储的系统上，较高的值可能加速压缩，但会增加并发磁盘 I/O。\n\n默认值为 `max(1, min(2, threads/2))`。\n\n此值可通过运行时命令 `SET GLOBAL parallel_chunk_merges = N` 更改，并通过 `SHOW VARIABLES` 查看。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Increase -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore 支持自动创建尚不存在但在 INSERT 语句中指定的表。此功能默认启用。要禁用它，请在配置中显式设置 `auto_schema = 0`。要重新启用，设置 `auto_schema = 1` 或从配置中删除该设置。\n\n请注意，`/bulk` HTTP 端点不支持自动创建表。\n\n> 注意：[自动模式功能](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) 需要 [Manticore Buddy](../Installation/Manticore_Buddy.md)。如果不起作用，请确保 Buddy 已安装。\n\n<!-- request Disable -->\n\nCODE_BLOCK_5\n\n<!-- request Enable -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\n此设置控制二进制日志事务的刷新/同步模式。可选，默认值为 2（每个事务刷新，每秒同步一次）。\n\n该指令决定二进制日志刷新到操作系统及同步到磁盘的频率。支持三种模式：\n\n*  0，每秒刷新和同步一次。性能最佳，但在服务器崩溃或操作系统/硬件故障时，最多可能丢失 1 秒内的已提交事务。\n\n*  1，每个事务都刷新和同步一次。性能最差，但可保证每个已提交事务的数据都被保存。\n\n*  2，每个事务刷新，每秒同步一次。性能良好，在服务器崩溃情况下确保所有已提交事务数据被保存，但在操作系统/硬件故障时，最多可能丢失 1 秒内的已提交事务。\n\n对于熟悉 MySQL 和 InnoDB 的用户，此指令类似于 `innodb_flush_log_at_trx_commit`。通常，默认的混合模式 2 在速度和安全之间提供良好平衡，能充分保护实时表数据免受服务器崩溃影响，并对硬件故障提供一定保护。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\n此设置控制二进制日志文件的管理方式。可选，默认值为 0（每个表单独文件）。\n\n您可以在两种二进制日志文件管理方式之间选择：\n\n* 每个表单独一个文件（默认，`0`）：每个表将其更改保存到自己的日志文件中。如果您有许多在不同时间更新的表，此设置很好。它允许表独立更新，无需等待其他表。此外，一个表的日志文件出现问题不会影响其他表。\n\n* 所有表共用一个文件（`1`）：所有表使用相同的二进制日志文件。此方法使文件管理更简单，因为文件更少。但如果某个表仍需保存更新，文件可能保持时间较长。如果许多表同时需要更新，这可能降低性能，因为所有更改必须等待写入同一个文件。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->",
      "russian": "При использовании [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) для изменения атрибутов документа в реальном времени, изменения сначала записываются во внутреннюю копию атрибутов в памяти. Эти обновления происходят в памяти с отображением файла, то есть ОС решает, когда записывать изменения на диск. При нормальном завершении работы `searchd` (инициируется сигналом `SIGTERM`), все изменения принудительно записываются на диск.\n\nВы также можете настроить `searchd` на периодическую запись этих изменений на диск, чтобы предотвратить потерю данных. Интервал между этими сбросами определяется параметром `attr_flush_period`, задаваемым в секундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)).\n\nПо умолчанию значение равно 0, что отключает периодическую запись. Однако сброс всё равно происходит при нормальном завершении.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_0\n\n<!-- end -->\n\n### auto_optimize\n\n<!-- example conf auto_optimize -->\n\nЭтот параметр управляет автоматическим процессом [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) для сжатия таблицы.\n\nПо умолчанию сжатие таблицы происходит автоматически. Вы можете изменить это поведение с помощью параметра `auto_optimize`:\n\n* 0 — отключить автоматическое сжатие таблицы (вы всё ещё можете вызвать `OPTIMIZE` вручную)\n\n* 1 — явно включить его\n\n* включить с умножением порога оптимизации на 2.\n\nПо умолчанию OPTIMIZE выполняется до тех пор, пока количество дисковых чанков не станет меньше или равно числу логических ядер CPU, умноженному на 2.\n\nОднако, если у таблицы есть атрибуты с KNN индексами, этот порог изменяется. В этом случае он равен числу физических ядер CPU, делённому на 2, чтобы улучшить производительность поиска KNN.\n\nОбратите внимание, что включение или отключение `auto_optimize` не препятствует выполнению [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) вручную.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Disable -->\n\nCODE_BLOCK_1\n\n<!-- request Throttle -->\n\nCODE_BLOCK_2\n\n<!-- end -->\n\n### parallel_chunk_merges\n\n<!-- example conf parallel_chunk_merges -->\n\nЭтот параметр управляет количеством заданий слияния дисковых чанков, которые сервер может запускать параллельно во время [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) для таблиц в реальном времени.\n\nЭто влияет только на слияние дисковых чанков (сжатие), а не на параллелизм запросов.\n\nУстановите значение в `1`, чтобы отключить параллельное слияние чанков (задания будут выполняться последовательно). Более высокие значения могут ускорить сжатие на системах с быстрым хранилищем, но увеличат конкурентный ввод-вывод диска.\n\nПо умолчанию `max(1, min(2, threads/2))`.\n\nЭто значение можно изменить во время работы с помощью `SET GLOBAL parallel_chunk_merges = N` и просмотреть через `SHOW VARIABLES`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Disable -->\n\nCODE_BLOCK_3\n\n<!-- request Increase -->\n\nCODE_BLOCK_4\n\n<!-- end -->\n\n### auto_schema\n\n<!-- example conf auto_schema -->\n\nManticore поддерживает автоматическое создание таблиц, которые ещё не существуют, но указаны в инструкциях INSERT. Эта функция включена по умолчанию. Чтобы отключить её, явно установите `auto_schema = 0` в конфигурации. Чтобы включить обратно, установите `auto_schema = 1` или удалите настройку `auto_schema` из конфигурации.\n\nИмейте в виду, что HTTP endpoint `/bulk` не поддерживает автоматическое создание таблиц.\n\n> ПРИМЕЧАНИЕ: [Функция авто-схемы](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если она не работает, убедитесь, что Buddy установлен.\n\n<!-- request Disable -->\n\nCODE_BLOCK_5\n\n<!-- request Enable -->\n\nCODE_BLOCK_6\n\n<!-- end -->\n\n### binlog_flush\n\n<!-- example conf binlog_flush -->\n\nЭтот параметр управляет режимом сброса/синхронизации бинарного лога транзакций. Он опционален, значение по умолчанию — 2 (сброс после каждой транзакции, синхронизация каждую секунду).\n\nДиректива определяет, как часто бинарный лог будет сбрасываться в ОС и синхронизироваться с диском. Поддерживаются три режима:\n\n*  0 — сброс и синхронизация каждую секунду. Обеспечивает лучшую производительность, но при сбое сервера или ОС/оборудования можно потерять до 1 секунды коммитов.\n\n*  1 — сброс и синхронизация после каждой транзакции. Режим с худшей производительностью, но гарантирующий сохранность данных каждой коммитнутой транзакции.\n\n*  2 — сброс после каждой транзакции, синхронизация каждую секунду. Обеспечивает хорошую производительность и сохранность каждой коммитнутой транзакции при сбое сервера. Однако при сбое ОС/оборудования можно потерять до 1 секунды коммитов.\n\nДля тех, кто знаком с MySQL и InnoDB, эта директива подобна `innodb_flush_log_at_trx_commit`. В большинстве случаев режим 2 по умолчанию даёт хороший баланс скорости и безопасности, с полной защитой данных таблиц RT от сбоев сервера и некоторой защитой от сбоев оборудования.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_7\n\n<!-- end -->\n\n### binlog_common\n\n<!-- example conf binlog_common -->\n\nЭтот параметр управляет управлением файлами бинарного лога. Он опционален, значение по умолчанию 0 (отдельный файл для каждой таблицы).\n\nВы можете выбрать один из двух способов управления файлами бинарного лога:\n\n* Отдельный файл для каждой таблицы (по умолчанию, `0`): Каждая таблица сохраняет свои изменения в собственном лог-файле. Такой подход хорош, если у вас много таблиц, обновляющихся в разное время. Он позволяет обновлять таблицы без ожиданий других. Также, если возникает проблема с лог-файлом одной таблицы, это не влияет на остальные.\n\n* Единый файл для всех таблиц (`1`): Все таблицы используют один общий файл бинарного лога. Такой метод упрощает управление файлами, потому что их меньше. Однако это может привести к тому, что файл дольше не будет удалён, если хотя бы одна таблица продолжает сохранять изменения. Эта настройка также может снизить производительность, если много таблиц обновляются одновременно, так как все изменения должны записываться в один файл.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_8\n\n<!-- end -->\n\n### binlog_max_log_size\n\n<!-- example conf binlog_max_log_size -->"
    },
    "is_code_or_comment": false
  },
  "ba9b79dcfccb1b1c485ec945b38cb8238eec2c1f86701ce3a513ec12ce3ed619": {
    "original": "In cases where the server is configured as a pure master and just routes requests to agents, it is important to handle requests without delays and not allow the network thread to sleep. There is a busy loop for that. After an incoming request, the network thread uses CPU poll for `10 * net_wait_tm` milliseconds if `net_wait_tm` is a positive number or polls only with the CPU if `net_wait_tm` is `0`.  Also, the busy loop can be disabled with `net_wait_tm = -1` - in this case, the poller sets the timeout to the actual agent's timeouts on the system polling call.\n\n> **WARNING:** A CPU busy loop actually loads the CPU core, so setting this value to any non-default value will cause noticeable CPU usage even with an idle server.\n\n### net_throttle_accept\n\nDefines how many clients are accepted on each iteration of the network loop. Default is 0 (unlimited), which should be fine for most users. This is a fine-tuning option to control the throughput of the network loop in high load scenarios.\n\n### net_throttle_action\n\nDefines how many requests are processed on each iteration of the network loop. The default is 0 (unlimited), which should be fine for most users. This is a fine-tuning option to control the throughput of the network loop in high load scenarios.\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\nNetwork client request read/write timeout, in seconds (or  [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, the default is 5 seconds. `searchd` will forcibly close a client connection which fails to send a query or read a result within this timeout.\n\nNote also the [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet) parameter. This parameter alters the behavior of `network_timeout` from applying to the entire `query` or `result` to individual packets instead. Typically, a query/result fits within one or two packets. However, in cases where a large amount of data is required, this parameter can be invaluable in maintaining active operations.\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\nThis setting allows you to specify the network address of the node. By default, it is set to the replication [listen](../Server_settings/Searchd.md#listen) address. This is correct in most cases; however, there are situations where you have to specify it manually:\n\n* Node behind a firewall\n\n* Network address translation enabled (NAT)\n\n* Container deployments, such as Docker or cloud deployments\n\n* Clusters with nodes in more than one region\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\nThis setting determines whether to allow queries with only the [negation](../Searching/Full_text_matching/Operators.md#Negation-operator) full-text operator. Optional, the default is 0 (fail queries with only the NOT operator).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\nSets the default table compaction threshold. Read more here - [Number of optimized disk chunks](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). This setting can be overridden with the per-query option [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). It can also be changed dynamically via [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\nThis setting determines the maximum number of simultaneous persistent connections to remote [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md). Each time an agent defined under `agent_persistent` is connected, we try to reuse an existing connection (if any), or connect and save the connection for future use. However, in some cases, it makes sense to limit the number of such persistent connections. This directive defines the limit. It affects the number of connections to each agent's host across all distributed tables.\n\nIt is reasonable to set the value equal to or less than the [max_connections](../Server_settings/Searchd.md#max_connections) option in the agent's config.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file is a mandatory configuration option in Manticore search that specifies the path of the file where the process ID of the `searchd` server is stored.\n\nThe searchd process ID file is re-created and locked on startup, and contains the head server process ID while the server is running. It is unlinked on server shutdown.\n\nThe purpose of this file is to enable Manticore to perform various internal tasks, such as checking whether there is already a running instance of `searchd`, stopping `searchd`, and notifying it that it should rotate the tables. The file can also be used for external automation scripts.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_50\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\nCosts for the query time prediction model, in nanoseconds. Optional, the default is `doc=64, hit=48, skip=2048, match=64`.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\nTerminating queries before completion based on their execution time (with the max query time setting) is a nice safety net, but it comes with an inherent drawback: indeterministic (unstable) results. That is, if you repeat the very same (complex) search query with a time limit several times, the time limit will be hit at different stages, and you will get *different* result sets.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\n<!-- request API -->",
    "translations": {
      "chinese": "在服务器被配置为纯主服务器并且仅将请求路由到代理的情况下，重要的是能无延迟地处理请求，并且不允许网络线程进入休眠状态。为此，存在一个忙循环。在收到请求后，如果 `net_wait_tm` 为正数，网络线程会使用 CPU 轮询 `10 * net_wait_tm` 毫秒；如果 `net_wait_tm` 为 `0`，则仅用 CPU 进行轮询。同时，可以通过将 `net_wait_tm = -1` 来禁用忙循环 —— 在这种情况下，轮询器在系统轮询调用时将超时设置为实际代理的超时时间。\n\n> **警告：** CPU 忙循环实际上会使 CPU 核心处于高负载，因此将此值设置为任何非默认值都会导致即使在服务器空闲时也能观察到明显的 CPU 使用率。\n\n### net_throttle_accept\n\n定义每次网络循环迭代接受多少客户端连接。默认值为 0（无限制），对大多数用户来说已经足够。这个选项是用于在高负载场景下对网络循环吞吐量进行微调的手段。\n\n### net_throttle_action\n\n定义每次网络循环迭代处理多少请求。默认值为 0（无限制），对大多数用户来说已经足够。这个选项是用于在高负载场景下对网络循环吞吐量进行微调的手段。\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\n网络客户端请求读写超时时间，单位为秒（或使用 [特殊后缀](../Server_settings/Special_suffixes.md)）。此参数为可选，默认值为 5 秒。`searchd` 将强制关闭在此超时内未能发送查询或读取结果的客户端连接。\n\n另请注意 [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet) 参数。该参数将 `network_timeout` 的行为从应用于整个 `query` 或 `result` 变更为仅应用于单个数据包。通常，一个查询或结果会包含一个或两个数据包，但在需要大量数据的情况下，这个参数对维持活动操作十分有用。\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\n此设置允许您指定节点的网络地址。默认情况下，它被设置为复制的 [listen](../Server_settings/Searchd.md#listen) 地址。在大多数情况下这是正确的；然而，在以下场景中，您需要手动指定：\n\n* 节点位于防火墙后面\n\n* 启用了网络地址转换（NAT）\n\n* 容器部署，比如 Docker 或云部署\n\n* 集群中的节点分布在多个区域\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\n此设置确定是否允许仅包含[否定](../Searching/Full_text_matching/Operators.md#Negation-operator)全文操作符的查询。此参数为可选，默认值为 0（拒绝仅包含 NOT 操作符的查询）。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\n设置默认的表压缩阈值。详细信息请参阅 - [已优化磁盘块数量](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks)。该设置可以通过每个查询选项 [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks) 覆盖。也可以通过 [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET) 动态修改。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\n此设置确定远程 [持久代理](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)的最大同时持久连接数。每次连接 `agent_persistent` 下定义的代理时，我们都会尝试重用现有连接（如果有），或者建立新连接并保存以供将来使用。不过，在某些情况下，限制持久连接数量是有意义的。该指令定义了该限制。它影响所有分布式表中每个代理主机的连接数。\n\n合理的做法是将该值设置为不高于代理配置中的 [max_connections](../Server_settings/Searchd.md#max_connections) 选项。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file 是 Manticore search 中的一个必填配置选项，指定存储 `searchd` 服务器进程 ID 的文件路径。\n\nsearchd 进程 ID 文件在启动时被重新创建并锁定，服务器运行时包含主进程的进程 ID。服务器关闭时该文件会被删除。\n\n该文件的目的是让 Manticore 执行各种内部任务，例如检查是否已有 `searchd` 进程在运行、停止 `searchd` 以及通知它应当旋转表。该文件也可用于外部自动化脚本。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_50\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\n查询时间预测模型的成本，单位为纳秒。选填，默认值为 `doc=64, hit=48, skip=2048, match=64`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\n基于执行时间（使用最大查询时间设置）在查询完成前终止查询是一种不错的保护措施，但它有一个固有缺点：结果具有不确定性（不稳定）。也就是说，如果对完全相同（复杂）的带有时间限制的搜索查询重复多次，时间限制会在不同阶段被触发，因而得到 *不同* 的结果集。\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\n<!-- request API -->",
      "russian": "В случаях, когда сервер настроен как чистый мастер и просто маршрутизирует запросы к агентам, важно обрабатывать запросы без задержек и не допускать сон сетевого потока. Для этого существует busy loop. После входящего запроса сетевой поток использует CPU poll в течение `10 * net_wait_tm` миллисекунд, если `net_wait_tm` положительное число, или опрашивает только CPU, если `net_wait_tm` равен `0`. Также busy loop можно отключить с помощью `net_wait_tm = -1` — в этом случае poller устанавливает тайм-аут равным фактическим тайм-аутам агента при системном вызове poll.\n\n> **ПРЕДУПРЕЖДЕНИЕ:** Цикл занятости CPU фактически загружает ядро процессора, поэтому установка этого значения в отличное от значения по умолчанию приведет к заметному использованию CPU даже при простое сервера.\n\n### net_throttle_accept\n\nОпределяет, сколько клиентов принимается на каждой итерации сетевого цикла. По умолчанию 0 (без ограничений), что подходит для большинства пользователей. Это настройка тонкой настройки для контроля пропускной способности сетевого цикла при высокой нагрузке.\n\n### net_throttle_action\n\nОпределяет, сколько запросов обрабатывается на каждой итерации сетевого цикла. По умолчанию 0 (без ограничений), что подходит для большинства пользователей. Это настройка тонкой настройки для контроля пропускной способности сетевого цикла при высокой нагрузке.\n\n### network_timeout\n\n<!-- example conf network_timeout -->\n\nТайм-аут чтения/записи клиентского запроса в сети, в секундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Необязательно, по умолчанию 5 секунд. `searchd` принудительно закрывает клиентское соединение, которое не успевает отправить запрос или получить результат в течение этого тайм-аута.\n\nОбратите также внимание на параметр [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet). Этот параметр изменяет поведение `network_timeout` — он применяется не к всему запросу или результату, а к отдельным пакетам. Обычно запрос/результат помещается в один или два пакета. Однако в случаях, когда требуется большой объем данных, этот параметр может оказаться бесценным для поддержания активных операций.\n\n<!-- request Example -->\n\nCODE_BLOCK_45\n\n<!-- end -->\n\n### node_address\n\n<!-- example conf node_address -->\n\nЭтот параметр позволяет указать сетевой адрес узла. По умолчанию он установлен в адрес [listen](../Server_settings/Searchd.md#listen) для репликации. В большинстве случаев это правильно; однако бывают ситуации, когда необходимо указать его вручную:\n\n* Узел за файрволом\n\n* Включен сетевой трансляции адресов (NAT)\n\n* Развертывания в контейнерах, таких как Docker или облачные развертывания\n\n* Кластеры с узлами в нескольких регионах\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_46\n\n<!-- end -->\n\n### not_terms_only_allowed\n\n<!-- example conf not_terms_only_allowed -->\n\nЭтот параметр определяет, разрешать ли запросы с использованием только оператора отрицания [negation](../Searching/Full_text_matching/Operators.md#Negation-operator) полнотекстового поиска. Необязательно, по умолчанию 0 (запросы, содержащие только оператор NOT, отклоняются).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_47\n\n<!-- end -->\n\n### optimize_cutoff\n\n<!-- example conf optimize_cutoff -->\n\nУстанавливает порог слияния таблиц по умолчанию. Подробнее см. здесь — [Число оптимизированных дисковых чанков](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). Этот параметр можно переопределить с помощью опции запроса [cutoff](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks). Также его можно изменить динамически через [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_48\n\n<!-- end -->\n\n### persistent_connections_limit\n\n<!-- example conf persistent_connections_limit -->\n\nЭтот параметр определяет максимальное количество одновременных постоянных соединений с удалёнными [persistent agents](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md). Каждый раз, когда устанавливается соединение с агентом, определённым в `agent_persistent`, пытаемся переиспользовать существующее соединение (если оно есть) или установить и сохранить новое соединение для будущего использования. Однако иногда разумно ограничить количество таких постоянных соединений. Эта директива определяет такой лимит. Она влияет на количество соединений с хостом каждого агента по всем распределённым таблицам.\n\nЛогично установить значение равным или меньше опции [max_connections](../Server_settings/Searchd.md#max_connections) в конфиге агента.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_49\n\n<!-- end -->\n\n### pid_file\n\n<!-- example conf pid_file -->\n\npid_file — обязательный параметр конфигурации в Manticore search, который указывает путь к файлу, где хранится идентификатор процесса (PID) сервера `searchd`.\n\nФайл с PID процесса searchd пересоздаётся и блокируется при запуске, содержит PID главного процесса сервера, пока сервер работает. При остановке сервера файл удаляется.\n\nЦель этого файла — позволить Manticore выполнять различные внутренние задачи, такие как проверка, запущен ли уже экземпляр `searchd`, остановка `searchd` и уведомление о необходимости ротации таблиц. Файл также может использоваться внешними скриптами автоматизации.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_50\n\n<!-- end -->\n\n### predicted_time_costs\n\n<!-- example conf predicted_time_costs -->\n\nЗатраты для модели предсказания времени выполнения запроса, в наносекундах. Необязательно, по умолчанию `doc=64, hit=48, skip=2048, match=64`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_51\n\n<!-- end -->\n\n<!-- example conf predicted_time_costs 1 -->\n\nПринудительное завершение запросов до их выполнения на основании максимального времени запроса — хорошая страховка, но у неё есть существенный недостаток: недетерминированные (нестабильные) результаты. То есть, если повторить один и тот же (сложный) поисковый запрос с ограничением по времени несколько раз, лимит времени будет достигнут на разных этапах, и вы получите *разные* наборы результатов.\n\n<!-- intro -->\n\n##### SQL:\n\n<!-- request SQL -->\n\nCODE_BLOCK_52\n\n<!-- request API -->"
    },
    "is_code_or_comment": false
  },
  "5f27a8a4a0a54e98ba04ef8fbaf6eb0b472d162ba38f2b0f125860c99c798976": {
    "original": "This setting specifies whether timed grouping in API and SQL will be calculated in the local timezone or in UTC. It is optional, with a default value of 0 (meaning 'local timezone').\n\nBy default, all 'group by time' expressions (like group by day, week, month, and year in API, also group by day, month, year, yearmonth, yearmonthday in SQL) are done using local time. For example, if you have documents with attributes timed `13:00 utc` and `15:00 utc`, in the case of grouping, they both will fall into facility groups according to your local timezone setting. If you live in `utc`, it will be one day, but if you live in `utc+10`, then these documents will be matched into different `group by day` facility groups (since 13:00 utc in UTC+10 timezone is 23:00 local time, but 15:00 is 01:00 of the next day). Sometimes such behavior is unacceptable, and it is desirable to make time grouping not dependent on timezone. You can run the server with a defined global TZ environment variable, but it will affect not only grouping but also timestamping in the logs, which may be undesirable as well. Switching 'on' this option (either in config or using [SET global](../Server_settings/Setting_variables_online.md#SET) statement in SQL) will cause all time grouping expressions to be calculated in UTC, leaving the rest of time-depentend functions (i.e. logging of the server) in local TZ.\n\n### timezone\n\nThis setting specifies the timezone to be used by date/time-related functions. By default, the local timezone is used, but you can specify a different timezone in IANA format (e.g., `Europe/Amsterdam`).\n\nNote that this setting has no impact on logging, which always operates in the local timezone.\n\nAlso, note that if `grouping_in_utc` is used, the 'group by time' function will still use UTC, while other date/time-related functions will use the specified timezone. Overall, it is not recommended to mix `grouping_in_utc` and `timezone`.\n\nYou can configure this option either in the config or by using the [SET global](../Server_settings/Setting_variables_online.md#SET) statement in SQL.\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\nThis setting specifies the agent mirror statistics window size, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). It is optional, with a default value of 60 seconds.\n\nFor a distributed table with agent mirrors in it (see more in [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md),  the master tracks several different per-mirror counters. These counters are then used for failover and balancing (the master picks the best mirror to use based on the counters). Counters are accumulated in blocks of `ha_period_karma` seconds.\n\nAfter beginning a new block, the master may still use the accumulated values from the previous one until the new one is half full. As a result, any previous history stops affecting the mirror choice after 1.5 times ha_period_karma seconds at most.\n\nEven though at most two blocks are used for mirror selection, up to 15 last blocks are stored for instrumentation purposes. These blocks can be inspected using the [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS) statement.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\nThis setting configures the interval between agent mirror pings, in milliseconds (or [special_suffixes](../Server_settings/Special_suffixes.md)).  It is optional, with a default value of 1000 milliseconds.\n\nFor a distributed table with agent mirrors in it (see more in [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)),  the master sends all mirrors a ping command during idle periods. This is to track the current agent status (alive or dead, network roundtrip, etc). The interval between such pings is defined by this directive. To disable pings, set ha_ping_interval to 0.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### hostname_lookup\n\nThe `hostname_lookup` option defines the strategy for renewing hostnames. By default, the IP addresses of agent host names are cached at server start to avoid excessive access to DNS. However, in some cases, the IP can change dynamically (e.g. cloud hosting) and it may be desirable to not cache the IPs. Setting this option to `request` disables the caching and queries the DNS for each query. The IP addresses can also be manually renewed using the `FLUSH HOSTNAMES` command.\n\n### jobs_queue_size\n\nThe jobs_queue_size setting defines how many \"jobs\" can be in the queue at the same time. It is unlimited by default.\n\nIn most cases, a \"job\" means one query to a single local table (plain table or a disk chunk of a real-time table). For example, if you have a distributed table consisting of 2 local tables or a real-time table with 2 disk chunks, a search query to either of them will mostly put 2 jobs in the queue. Then, the thread pool (whose size is defined by [threads](../Server_settings/Searchd.md#threads) will process them. However, in some cases, if the query is too complex, more jobs can be created. Changing this setting is recommended when [max_connections](../Server_settings/Searchd.md#max_connections) and [threads](../Server_settings/Searchd.md#threads) are not enough to find a balance between the desired performance.\n\n### join_batch_size\n\nTable joins work by accumulating a batch of matches, which are the results of the query executed on the left table. This batch is then processed as a single query on the right table.\n\nThis option allows you to adjust the batch size. The default value is `1000`, and setting this option to `0` disables batching.\n\nA larger batch size may improve performance; however, for some queries, it can lead to excessive memory consumption.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### join_cache_size",
    "translations": {
      "chinese": "此设置指定API和SQL中的定时分组是按本地时区计算还是按UTC计算。该设置是可选的，默认值为0（表示“本地时区”）。\n\n默认情况下，所有“按时间分组”表达式（如API中的按天、周、月和年分组，SQL中的按天、月、年、年月、年月日分组）均使用本地时间进行。例如，如果您有属性时间为`13:00 utc`和`15:00 utc`的文档，在分组时，它们都将根据本地时区设置归入相应的分组。如果您位于`utc`时区，则它们属于同一天，但如果您位于`utc+10`，则这些文档将被匹配到不同的“按天分组”群组（因为UTC+10时区的13:00 utc是本地时间23:00，而15:00 utc是第二天01:00）。有时这种行为不可接受，且希望时间分组不依赖时区。您可以通过设置全局TZ环境变量运行服务器，但这不仅影响分组，还会影响日志中的时间戳，这可能也是不希望的。启用此选项（无论是在配置中还是使用SQL中的[SET global](../Server_settings/Setting_variables_online.md#SET)语句）将使所有时间分组表达式按UTC计算，而其他时间相关功能（如服务器日志记录）仍使用本地时区。\n\n### timezone\n\n此设置指定日期/时间相关函数使用的时区。默认情况下使用本地时区，但您可以指定IANA格式的其他时区（例如`Europe/Amsterdam`）。\n\n请注意，该设置不影响日志记录，日志始终使用本地时区。\n\n还要注意，如果使用了`grouping_in_utc`，则“按时间分组”功能仍使用UTC，而其他日期/时间相关函数将使用指定的时区。总体来说，不建议混用`grouping_in_utc`和`timezone`。\n\n您可以在配置文件中设置此选项，或使用SQL中的[SET global](../Server_settings/Setting_variables_online.md#SET)语句进行配置。\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\n此设置指定代理镜像统计的时间窗口大小，单位为秒（或[special_suffixes](../Server_settings/Special_suffixes.md)）。该设置是可选的，默认值为60秒。\n\n对于含有代理镜像的分布式表（详情参见[agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)），主节点跟踪每个镜像的多个不同计数器。这些计数器用于故障切换和平衡（主节点基于计数器选择最佳镜像）。计数器累积的时间块大小为`ha_period_karma`秒。\n\n在开始新时间块后，主节点可能仍使用之前时间块的累计值，直到新时间块达到一半容量。因此，以前的历史数据最多在1.5倍ha_period_karma秒后不再影响镜像选择。\n\n尽管镜像选择最多使用两个时间块，但会存储最多15个最近时间块以供监控使用。可使用[SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS)语句查看这些时间块。\n\n<!-- intro -->\n\n##### 例子：\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\n此设置配置代理镜像之间ping命令的间隔，单位为毫秒（或[special_suffixes](../Server_settings/Special_suffixes.md)）。该设置是可选的，默认值为1000毫秒。\n\n对于含有代理镜像的分布式表（详情参见[agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)），主节点会在空闲时向所有镜像发送ping命令，以跟踪代理当前状态（是否存活，网络往返时间等）。ping命令的间隔由此指令定义。若要禁用ping，将ha_ping_interval设置为0。\n\n<!-- intro -->\n\n##### 例子：\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### hostname_lookup\n\n`hostname_lookup`选项定义主机名更新策略。默认情况下，服务器启动时会缓存代理主机名的IP地址，以避免过度访问DNS。然而，在某些情况下，IP可能动态变化（例如云托管），此时可能希望不缓存IP。将此设置为`request`可禁用缓存，每次查询都请求DNS。也可以使用`FLUSH HOSTNAMES`命令手动更新IP地址。\n\n### jobs_queue_size\n\njobs_queue_size设置定义队列中可同时存在的“作业”数量。默认情况下没有限制。\n\n在大多数情况下，一个“作业”意味着对单个本地表（普通表或实时表的磁盘分区）的一次查询。例如，如果您有一个由2个本地表组成的分布式表，或一个具有2个磁盘分区的实时表，对它们的搜索查询通常会在队列中放入2个作业。然后，线程池（大小由[threads](../Server_settings/Searchd.md#threads)定义）处理这些作业。但在某些情况下，如果查询过于复杂，可能生成更多作业。当[ max_connections](../Server_settings/Searchd.md#max_connections)和[threads](../Server_settings/Searchd.md#threads)不足以达到性能平衡时，建议调整此设置。\n\n### join_batch_size\n\n表连接的工作方式是累计一批匹配项，这些匹配项是针对左表执行查询所得的结果。然后，这批结果作为单次查询发送到右表进行处理。\n\n此选项允许您调整批处理大小。默认值为`1000`，将此选项设置为`0`即可禁用批处理。\n\n较大的批处理大小可能提升性能；但对于某些查询，可能导致内存消耗过大。\n\n<!-- intro -->\n\n##### 例子：\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### join_cache_size",
      "russian": "Этот параметр указывает, будет ли временное группирование в API и SQL рассчитываться в локальном часовом поясе или в UTC. Он необязателен, по умолчанию имеет значение 0 (что означает «локальный часовой пояс»).\n\nПо умолчанию все выражения 'group by time' (такие как группировка по дню, неделе, месяцу и году в API, а также группировка по дню, месяцу, году, yearmonth, yearmonthday в SQL) выполняются с использованием локального времени. Например, если у вас есть документы с атрибутами времени `13:00 utc` и `15:00 utc`, в случае группировки они оба попадут в группы facility согласно настройке локального часового пояса. Если вы находитесь в `utc`, это будет один день, но если вы находитесь в `utc+10`, то эти документы будут сопоставлены с разными группами facility по дню (поскольку 13:00 utc в часовом поясе UTC+10 это 23:00 местного времени, а 15:00 — это 01:00 следующего дня). Иногда такое поведение неприемлемо, и желательно сделать групировку по времени независимой от часового пояса. Вы можете запустить сервер с установленной глобальной переменной окружения TZ, но это повлияет не только на группировку, но и на отметки времени в логах, что тоже может быть нежелательно. Включение этой опции (либо в конфиге, либо с использованием оператора [SET global](../Server_settings/Setting_variables_online.md#SET) в SQL) приведёт к вычислению всех выражений группировки времени в UTC, оставляя остальные функции, зависящие от времени (например, логирование сервера), в локальном часовом поясе.\n\n### timezone\n\nЭтот параметр задаёт часовой пояс, используемый функциями, связанными с датой и временем. По умолчанию используется локальный часовой пояс, но вы можете указать другой часовой пояс в формате IANA (например, `Europe/Amsterdam`).\n\nОбратите внимание, что этот параметр не влияет на логирование, которое всегда работает в локальном часовом поясе.\n\nТакже учтите, что если используется `grouping_in_utc`, функция 'group by time' всё равно будет использовать UTC, в то время как другие функции, связанные с датой и временем, будут использовать указанный часовой пояс. В целом не рекомендуется смешивать `grouping_in_utc` и `timezone`.\n\nВы можете настроить эту опцию либо в конфиге, либо с помощью оператора [SET global](../Server_settings/Setting_variables_online.md#SET) в SQL.\n\n### ha_period_karma\n\n<!-- example conf ha_period_karma -->\n\nЭтот параметр задаёт размер окна статистики зеркал агента в секундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Он необязателен, по умолчанию имеет значение 60 секунд.\n\nДля распределённой таблицы с зеркалами агента (подробнее см. в разделе [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)) мастер отслеживает несколько различных счётчиков на каждое зеркало. Эти счётчики затем используются для переключения отказа и балансировки (мастер выбирает лучшее зеркало на основе счётчиков). Счётчики накапливаются блоками длительностью `ha_period_karma` секунд.\n\nПосле начала нового блока мастер может ещё использовать накопленные значения из предыдущего блока, пока новый блок не будет заполнен наполовину. В результате любое предыдущее состояние перестаёт влиять на выбор зеркала спустя максимум 1.5 раза `ha_period_karma` секунд.\n\nХотя для выбора зеркала используется максимум два блока, до 15 последних блоков хранится для целей инструментирования. Эти блоки можно просмотреть с помощью оператора [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_27\n\n<!-- end -->\n\n### ha_ping_interval\n\n<!-- example conf ha_ping_interval -->\n\nЭтот параметр задаёт интервал между пингами зеркал агента в миллисекундах (или с использованием [special_suffixes](../Server_settings/Special_suffixes.md)). Он необязателен, по умолчанию имеет значение 1000 миллисекунд.\n\nДля распределённой таблицы с зеркалами агента (подробнее см. в разделе [agent](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)) мастер отправляет всем зеркалам команду пинга в периоды простоя. Это нужно для отслеживания текущего статуса агента (жив или мёртв, время сетевого отклика и т.д.). Интервал между такими пингами задаётся этой директивой. Чтобы отключить пинги, установите `ha_ping_interval` в 0.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_28\n\n<!-- end -->\n\n### hostname_lookup\n\nОпция `hostname_lookup` определяет стратегию обновления имён хостов. По умолчанию IP-адреса имён агентов кэшируются при запуске сервера, чтобы избежать избыточного обращения к DNS. Однако в некоторых случаях IP может динамически меняться (например, в облачном хостинге), и может быть желательно не кэшировать IP. Установка этой опции в значение `request` отключает кэширование и выполняет DNS-запрос при каждом запросе. IP-адреса также можно обновлять вручную с помощью команды `FLUSH HOSTNAMES`.\n\n### jobs_queue_size\n\nПараметр jobs_queue_size определяет, сколько «заданий» может одновременно находиться в очереди. По умолчанию она не ограничена.\n\nВ большинстве случаев «задание» означает один запрос к одной локальной таблице (обычной таблице или дисковому чанку таблицы в реальном времени). Например, если у вас есть распределённая таблица, состоящая из 2 локальных таблиц, или таблица в реальном времени с 2 дисковыми чанками, поисковый запрос к любой из них создаст в очереди примерно 2 задания. Затем пул потоков (размер которого задаётся параметром [threads](../Server_settings/Searchd.md#threads)) обработает их. Однако в некоторых случаях, если запрос слишком сложный, может быть создано больше заданий. Рекомендуется менять этот параметр, если [max_connections](../Server_settings/Searchd.md#max_connections) и [threads](../Server_settings/Searchd.md#threads) не хватает для достижения баланса между производительностью и нагрузкой.\n\n### join_batch_size\n\nОбъединение таблиц работает путём накопления батча совпадений — результатов запроса, выполненного в левой таблице. Этот батч затем обрабатывается как единый запрос к правой таблице.\n\nЭта опция позволяет регулировать размер батча. Значение по умолчанию — `1000`, установка в `0` отключает батчинг.\n\nБольший размер батча может улучшить производительность; однако для некоторых запросов это может привести к чрезмерному потреблению памяти.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_29\n\n<!-- end -->\n\n### join_cache_size"
    },
    "is_code_or_comment": false
  },
  "b474813dd7b5a9c24079428def1e9841c21e83844c268a83f2abe615a43d4907": {
    "original": "Each query executed on the right table is defined by specific JOIN ON conditions, which determine the result set retrieved from the right table.\n\nIf there are only a few unique JOIN ON conditions, reusing the results can be more efficient than repeatedly executing queries on the right table. To enable this, the result sets are stored in a cache.\n\nThis option allows you to configure the size of this cache. The default value is `20 MB`, and setting this option to 0 disables caching.\n\nNote that each thread maintains its own cache, so you should account for the number of threads executing queries when estimating total memory usage.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nThe listen_backlog setting determines the length of the TCP listen backlog for incoming connections. This is particularly relevant for Windows builds that process requests one by one. When the connection queue reaches its limit, new incoming connections will be refused.\n\nFor non-Windows builds, the default value should work fine, and there is usually no need to adjust this setting.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\nA server version string to return to Kibana or OpenSearch Dashboards. Optional — by default, it's set `7.6.0`.\n\nSome versions of Kibana and OpenSearch Dashboards expect the server to report a specific version number, and might behave differently depending on it. To workaround such issues, you can use this setting, which makes Manticore report a custom version to Kibana or OpenSearch Dashboards.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\nThis setting lets you specify an IP address and port, or Unix-domain socket path, that Manticore will accept connections on.\n\nThe general syntax for `listen` is:\n\nCODE_BLOCK_33\n\nYou can specify:\n\n* either an IP address (or hostname) and a port number\n\n* or just a port number\n\n* or a Unix socket path (not supported on Windows)\n\n* or an IP address and port range\n\nIf you specify a port number but not an address, `searchd` will listen on all network interfaces. Unix path is identified by a leading slash. Port range can be set only for the replication protocol.\n\nYou can also specify a protocol handler (listener) to be used for connections on this socket. The listeners are:\n\n* **Not specified** - Manticore will accept connections at this port from:\n\n  - other Manticore agents (i.e., a remote distributed table)\n\n  - clients via HTTP and HTTPS\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/). **Ensure you have a listener of this kind (or an `http` listener, as mentioned below) to avoid limitations in Manticore functionality.**\n\n* `mysql` MySQL protocol for connections from MySQL clients. Note:\n\n  - Compressed protocol is also supported.\n\n  - If [SSL](../Security/SSL.md#SSL) is enabled, you can make an encrypted connection.\n\n* `replication` - replication protocol used for nodes communication. More details can be found in the [replication](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md) section. You can specify multiple replication listeners, but they must all listen on the same IP; only the ports can be different. When you define a replication listener with a port range (e.g., `listen = 192.168.0.1:9320-9328:replication`), Manticore doesn't immediately start listening on these ports. Instead, it will take random free ports from the specified range only when you start using replication. At least 2 ports are required in the range for replication to work properly.\n\n* `http` - same as **Not specified**. Manticore will accept connections at this port from remote agents and clients via HTTP and HTTPS.\n\n* `https` - HTTPS protocol. Manticore will accept **only** HTTPS connections at this port. More details can be found in section [SSL](../Security/SSL.md).\n\n* `sphinx` - legacy binary protocol. Used to serve connections from remote [SphinxSE](../Extensions/SphinxSE.md) clients. Some Sphinx API clients implementations (an example is the Java one) require the explicit declaration of the listener.\n\nAdding suffix `_vip` to client protocols (that is, all except `replication`, for instance `mysql_vip` or `http_vip` or just `_vip`) forces creating a dedicated thread for the connection to bypass different limitations. That's useful for node maintenance in case of severe overload when the server would either stall or not let you connect via a regular port otherwise.\n\nSuffix `_readonly` sets [read-only mode](../Security/Read_only.md) for the listener and limits it to accept only read queries.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\nThere can be multiple `listen` directives. `searchd` will listen for client connections on all specified ports and sockets. The default config provided in Manticore packages defines listening on ports:\n\n* `9308` and `9312` for connections from remote agents and non-MySQL based clients\n\n* and on port `9306` for MySQL connections.\n\nIf you don't specify any `listen` in the configuration at all, Manticore will wait for connections on:\n\n* `127.0.0.1:9306` for MySQL clients\n\n* `127.0.0.1:9312`  for HTTP/HTTPS and connections from other Manticore nodes and clients based on the Manticore binary API.\n\n#### Listening on privileged ports\n\nBy default, Linux won't allow you to let Manticore listen on a port below 1024 (e.g. `listen = 127.0.0.1:80:http` or `listen = 127.0.0.1:443:https`) unless you run searchd under root. If you still want to be able to start Manticore, so it listens on ports < 1024 under a non-root user, consider doing one of the following (either of these should work):\n\n* Run the command `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* Add `AmbientCapabilities=CAP_NET_BIND_SERVICE` to Manticore's systemd unit and reload the daemon (`systemctl daemon-reload`).",
    "translations": {
      "chinese": "右表上执行的每个查询由特定的 JOIN ON 条件定义，这些条件决定了从右表检索的结果集。\n\n如果只有少数唯一的 JOIN ON 条件，重用结果集通常比重复执行右表查询更高效。为实现此目的，结果集被存储在缓存中。\n\n此选项允许您配置该缓存的大小。默认值为 `20 MB`，将此选项设置为 0 则禁用缓存。\n\n请注意，每个线程维护其自己的缓存，因此在估计总内存使用时应考虑执行查询的线程数。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nlisten_backlog 设置决定了用于传入连接的 TCP 监听队列的长度。这对于逐个处理请求的 Windows 版本尤其相关。当连接队列达到其限制时，新的传入连接将被拒绝。\n\n对于非 Windows 版本，默认值通常工作良好，通常无需调整此设置。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\n返回给 Kibana 或 OpenSearch Dashboards 的服务器版本字符串。可选——默认值为 `7.6.0`。\n\n某些版本的 Kibana 和 OpenSearch Dashboards 期望服务器报告特定的版本号，可能会据此表现不同。为了解决此类问题，可以使用此设置，使 Manticore 向 Kibana 或 OpenSearch Dashboards 报告自定义版本。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\n此设置允许您指定 Manticore 接受连接的 IP 地址和端口，或 Unix 域套接字路径。\n\n`listen` 的通用语法是：\n\nCODE_BLOCK_33\n\n您可以指定：\n\n* IP 地址（或主机名）和端口号\n\n* 或仅端口号\n\n* 或 Unix 套接字路径（Windows 上不支持）\n\n* 或 IP 地址和端口范围\n\n如果您指定了端口号但未指定地址，`searchd` 将监听所有网络接口。Unix 路径通过前导斜杠识别。端口范围仅可用于复制协议。\n\n您还可以为此套接字上的连接指定协议处理器（监听器）。监听器为：\n\n* **未指定** - Manticore 将在此端口接受来自：\n\n  - 其他 Manticore 代理（即远程分布式表）\n\n  - 通过 HTTP 和 HTTPS 的客户端\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/)。**确保您有此类监听器（或下面提到的 `http` 监听器），以避免 Manticore 功能受限。**\n\n* `mysql` - 用于来自 MySQL 客户端连接的 MySQL 协议。注意：\n\n  - 也支持压缩协议。\n\n  - 如果启用 [SSL](../Security/SSL.md#SSL)，可以建立加密连接。\n\n* `replication` - 用于节点通信的复制协议。更多详情见 [复制](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md) 章节。可以指定多个复制监听器，但它们必须监听相同 IP；只有端口可以不同。当您定义带端口范围的复制监听器（例如 `listen = 192.168.0.1:9320-9328:replication`）时，Manticore 不会立即开始监听这些端口。只有在开始使用复制时，才会从指定范围内随机选择空闲端口。复制正常工作至少需要 2 个端口。\n\n* `http` - 与 **未指定** 相同。Manticore 将接受来自远程代理和通过 HTTP 及 HTTPS 的客户端连接。\n\n* `https` - HTTPS 协议。Manticore 只接受此端口上的 HTTPS 连接。详情参见 [SSL](../Security/SSL.md) 章节。\n\n* `sphinx` - 传统二进制协议。用于服务远程 [SphinxSE](../Extensions/SphinxSE.md) 客户端连接。一些 Sphinx API 客户端实现（例如 Java 版）需要显式声明监听器。\n\n向客户端协议（即除 `replication` 外的所有协议，例如 `mysql_vip`、`http_vip` 或仅 `_vip`）添加后缀 `_vip` 会强制为连接创建专用线程，以绕过各种限制。在服务器严重过载并可能停顿或无法通过普通端口连接时，这对节点维护非常有用。\n\n后缀 `_readonly` 为监听器设置[只读模式](../Security/Read_only.md)，并限制其仅接受读查询。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\n可以有多个 `listen` 指令。`searchd` 将在所有指定的端口和套接字上监听客户端连接。Manticore 软件包提供的默认配置在以下端口监听：\n\n* `9308` 和 `9312`，用于远程代理和非 MySQL 客户端的连接\n\n* 以及端口 `9306`，用于 MySQL 连接。\n\n如果您在配置中完全未指定任何 `listen`，Manticore 将等待以下连接：\n\n* `127.0.0.1:9306` 的 MySQL 客户端连接\n\n* `127.0.0.1:9312` 的 HTTP/HTTPS 连接以及来自其他 Manticore 节点和基于 Manticore 二进制 API 的客户端的连接\n\n#### 监听特权端口\n\n默认情况下，Linux 不允许 Manticore 监听 1024 以下的端口（例如 `listen = 127.0.0.1:80:http` 或 `listen = 127.0.0.1:443:https`），除非以 root 用户身份运行 searchd。如果您仍希望在非 root 用户下启动 Manticore 监听 1024 以下端口，考虑执行以下任一操作（任一操作均可）：\n\n* 运行命令 `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* 向 Manticore 的 systemd 单元添加 `AmbientCapabilities=CAP_NET_BIND_SERVICE` 并重新加载守护进程（`systemctl daemon-reload`）。",
      "russian": "Каждый запрос, выполняемый по правой таблице, определяется конкретными условиями JOIN ON, которые определяют извлекаемый из правой таблицы набор результатов.\n\nЕсли уникальных условий JOIN ON немного, повторное использование результатов может быть более эффективным, чем многократное выполнение запросов к правой таблице. Для этого наборы результатов сохраняются в кеше.\n\nЭта опция позволяет настроить размер этого кеша. Значение по умолчанию — `20 MB`, а установка значения 0 отключает кеширование.\n\nОбратите внимание, что каждый поток поддерживает свой собственный кеш, поэтому при оценке общего потребления памяти следует учитывать количество потоков, выполняющих запросы.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_30\n\n<!-- end -->\n\n### listen_backlog\n\n<!-- example conf listen_backlog -->\n\nПараметр listen_backlog определяет длину очереди TCP для входящих соединений. Особенно актуально для сборок под Windows, которые обрабатывают запросы по одному. Когда очередь соединений достигает предела, новые входящие соединения отклоняются.\n\nДля не-Windows сборок значение по умолчанию обычно подходит, и нет необходимости изменять эту настройку.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_31\n\n<!-- end -->\n\n### kibana_version_string\n\n<!-- example conf kibana_version_string -->\n\nСтрока версии сервера, возвращаемая Kibana или OpenSearch Dashboards. Опционально — по умолчанию установлено значение `7.6.0`.\n\nНекоторые версии Kibana и OpenSearch Dashboards ожидают, что сервер будет возвращать конкретный номер версии, и могут вести себя по-разному в зависимости от этого. Чтобы обойти такие проблемы, вы можете использовать эту настройку, которая заставляет Manticore сообщать Kibana или OpenSearch Dashboards кастомную версию.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_32\n\n<!-- end -->\n\n### listen\n\n<!-- example conf listen -->\n\nЭта настройка позволяет указать IP-адрес и порт или путь к Unix-доменному сокету, на которых Manticore будет принимать соединения.\n\nОбщий синтаксис для `listen`:\n\nCODE_BLOCK_33\n\nВы можете указать:\n\n* либо IP-адрес (или имя хоста) и номер порта\n\n* либо только номер порта\n\n* либо путь к Unix-сокету (не поддерживается на Windows)\n\n* либо IP-адрес и диапазон портов\n\nЕсли указан только номер порта без адреса, `searchd` будет слушать все сетевые интерфейсы. Путь Unix-сокета определяется ведущим слэшем. Диапазон портов можно задать только для протокола репликации.\n\nТакже можно указать обработчик протокола (listener), который будет использоваться для соединений на этом сокете. Листенеры:\n\n* **Не указан** — Manticore принимает соединения на этом порту от:\n\n  - других агентов Manticore (например, удалённой распределённой таблицы)\n\n  - клиентов через HTTP и HTTPS\n\n  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/). **Убедитесь, что у вас есть листенер этого типа (или `http` листенер, как указано ниже), чтобы избежать ограничений функциональности Manticore.**\n\n* `mysql` — протокол MySQL для соединений от MySQL клиентов. Замечания:\n\n  - Также поддерживается сжатый протокол.\n\n  - Если включён [SSL](../Security/SSL.md#SSL), можно установить зашифрованное соединение.\n\n* `replication` — протокол репликации для коммуникации между узлами. Подробнее см. в разделе [репликация](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md). Можно указать несколько replication-листенеров, но все должны слушать на одном IP; разными могут быть только порты. Если задать replication-листенер с диапазоном портов (например, `listen = 192.168.0.1:9320-9328:replication`), Manticore не начнёт слушать порты сразу. Вместо этого будут взяты случайные свободные порты из диапазона только при начале использования репликации. Для правильной работы репликации требуется минимум 2 порта в диапазоне.\n\n* `http` — то же, что и **Не указан**. Manticore будет принимать соединения на этом порту от удалённых агентов и клиентов через HTTP и HTTPS.\n\n* `https` — протокол HTTPS. Manticore принимает **только** HTTPS соединения на этом порту. Подробнее в разделе [SSL](../Security/SSL.md).\n\n* `sphinx` — устаревший бинарный протокол. Используется для обслуживания соединений от удалённых клиентов [SphinxSE](../Extensions/SphinxSE.md). Некоторые реализации клиентов API Sphinx (например, Java) требуют явного объявления листенера.\n\nДобавление суффикса `_vip` к клиентским протоколам (всем, кроме `replication`, например `mysql_vip` или `http_vip` или просто `_vip`) заставляет создавать выделенный поток для соединения, чтобы обойти ограничения. Полезно для обслуживания узла при сильной нагрузке, когда сервер мог бы либо зависнуть, либо не позволить подключиться через обычный порт.\n\nСуффикс `_readonly` устанавливает [режим только для чтения](../Security/Read_only.md) для листенера и ограничивает его приём только чтением запросов.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_34\n\n<!-- end -->\n\nМожно указать несколько директив `listen`. `searchd` будет слушать клиентские соединения на всех указанных портах и сокетах. Конфигурация по умолчанию, предлагаемая в пакетах Manticore, задаёт прослушивание портов:\n\n* `9308` и `9312` для соединений от удалённых агентов и клиентов, не использующих MySQL\n\n* и порта `9306` для MySQL соединений.\n\nЕсли в конфигурации не указать ни одного `listen`, Manticore будет ожидать соединения на:\n\n* `127.0.0.1:9306` для MySQL клиентов\n\n* `127.0.0.1:9312` для HTTP/HTTPS и соединений от других узлов Manticore и клиентов, использующих бинарный API Manticore.\n\n#### Прослушивание привилегированных портов\n\nПо умолчанию Linux не позволит запускать Manticore с прослушиванием порта ниже 1024 (например, `listen = 127.0.0.1:80:http` или `listen = 127.0.0.1:443:https`), если запускать `searchd` не от root. Если хотите, чтобы Manticore слушал порты ниже 1024 под непользовательским пользователем, рассмотрите следующие варианты (любой из них должен сработать):\n\n* Выполните команду `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd`\n\n* Добавьте `AmbientCapabilities=CAP_NET_BIND_SERVICE` в systemd юнит Manticore и перезагрузите демон (`systemctl daemon-reload`)."
    },
    "is_code_or_comment": false
  },
  "5c68dfe8d67481b2de2f8b9efc2752f8ced2798ca92bb61b151c6a1a6e328ca3": {
    "original": "The server uses the CA file to verify the signature on the certificate. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\nPath to the server's SSL certificate. Optional, default is empty.\n\nThe server uses this certificate as a self-signed public key to encrypt HTTP traffic over SSL. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nPath to the SSL certificate key. Optional, default is empty.\n\nThe server uses this private key to encrypt HTTP traffic over SSL. The file must be in PEM format.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\nMax common subtree document cache size, per-query. Optional, default is 0 (disabled).\n\nThis setting limits the RAM usage of a common subtree optimizer (see  [multi-queries](../Searching/Multi-queries.md)). At most, this much RAM will be spent to cache document entries for each query. Setting the limit to 0 disables the optimizer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\nMax common subtree hit cache size, per-query. Optional, default is 0 (disabled).\n\nThis setting limits the RAM usage of a common subtree optimizer (see [multi-queries](../Searching/Multi-queries.md)). At most, this much RAM will be spent to cache keyword occurrences (hits) for each query. Setting the limit to 0 disables the optimizer.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nNumber of working threads (or, size of thread pool) for the Manticore daemon. Manticore creates this number of OS threads on start, and they perform all jobs inside the daemon, such as executing queries, creating snippets, etc. Some operations may be split into sub-tasks and executed in parallel, for example:\n\n* Search in a real-time table\n\n* Search in a distributed table consisting of local tables\n\n* Percolate query call\n\n* and others\n\nBy default, it's set to the number of CPU cores on the server. Manticore creates the threads on start and keeps them until it's stopped. Each sub-task can use one of the threads when it needs it. When the sub-task finishes, it releases the thread so another sub-task can use it.\n\nIn the case of intensive I/O type of load, it might make sense to set the value higher than the number of CPU cores.\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\nMaximum stack size for a job (coroutine, one search query may cause multiple jobs/coroutines). Optional, default is 128K.\n\nEach job has its own stack of 128K. When you run a query, it's checked for how much stack it requires. If the default 128K is enough, it's just processed. If it needs more, another job with an increased stack is scheduled, which continues processing. The maximum size of such an advanced stack is limited by this setting.\n\nSetting the value to a reasonably high rate will help with processing very deep queries without implying that overall RAM consumption will grow too high. For example, setting it to 1G does not imply that every new job will take 1G of RAM, but if we see that it requires, let's say, 100M stack, we just allocate 100M for the job. Other jobs at the same time will be running with their default 128K stack. The same way, we can run even more complex queries that need 500M. And only if we **see** internally that the job requires more than 1G of stack, we will fail and report about too low thread_stack.\n\nHowever, in practice, even a query which needs 16M of stack is often too complex for parsing and consumes too much time and resources to be processed. So, the daemon will process it, but limiting such queries by the `thread_stack` setting looks quite reasonable.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\nDetermines whether to unlink `.old` table copies on successful rotation. Optional, default is 1 (do unlink).\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_83\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\nThreaded server watchdog. Optional, default is 1 (watchdog enabled).\n\nWhen a Manticore query crashes, it can take down the entire server. With the watchdog feature enabled, `searchd` also maintains a separate lightweight process that monitors the main server process and automatically restarts it in case of abnormal termination. The watchdog is enabled by default.\n\n<!-- request Example -->\n\nCODE_BLOCK_84\n\n<!-- end -->\n\n<!-- proofread -->",
    "translations": {
      "chinese": "服务器使用 CA 文件来验证证书上的签名。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\n服务器 SSL 证书的路径。可选，默认值为空。\n\n服务器使用此证书作为自签名公钥，通过 SSL 加密 HTTP 流量。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nSSL 证书密钥的路径。可选，默认值为空。\n\n服务器使用此私钥通过 SSL 加密 HTTP 流量。该文件必须是 PEM 格式。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\n每查询最大公共子树文档缓存大小。可选，默认值为 0（禁用）。\n\n此设置限制公共子树优化器的 RAM 使用（参见 [multi-queries](../Searching/Multi-queries.md)）。每个查询最多消耗这么多 RAM 用于缓存文档条目。将此限制设置为 0 会禁用该优化器。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\n每查询最大公共子树命中缓存大小。可选，默认值为 0（禁用）。\n\n此设置限制公共子树优化器的 RAM 使用（参见 [multi-queries](../Searching/Multi-queries.md)）。每个查询最多消耗这么多 RAM 用于缓存关键字出现位置（命中）。将此限制设置为 0 会禁用该优化器。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nManticore 守护进程的工作线程数（或线程池大小）。Manticore 启动时会创建这么多操作系统线程，它们执行守护进程内的所有任务，例如执行查询、生成摘要等。有些操作可以拆分为子任务并行执行，例如：\n\n* 在实时表中搜索\n\n* 在由本地表组成的分布式表中搜索\n\n* 继续调用 Percolate 查询\n\n* 以及其他操作\n\n默认情况下，线程数设置为服务器 CPU 核心数。Manticore 启动时创建线程并保持直到停止。每个子任务需要时可以使用一个线程，子任务完成后释放线程供其他子任务使用。\n\n在高强度 I/O 负载情况下，将此值设置高于 CPU 核心数可能更合理。\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\n作业的最大栈大小（协程，一个搜索查询可能产生多个作业/协程）。可选，默认值为 128K。\n\n每个作业拥有其自己的 128K 栈。运行查询时，会判断其所需栈大小。如果默认的 128K 足够，则直接处理；如果需要更大栈，则调度另一个具有增大栈的作业继续处理。此类扩展栈的最大大小受此设置限制。\n\n合理设置较大的此值可以帮助处理非常深层的查询，而不至于整体 RAM 占用大幅增加。例如，设置为 1G 不意味着每个新作业都占用 1G RAM，而是如果某作业需要 100M 栈，就只为该作业分配 100M。其他作业同时运行时仍使用默认 128K 栈。同理，能处理更复杂需 500M 栈的查询。只有当内部检测到作业需求超过 1G 栈时，才会失败并报告 thread_stack 过小。\n\n实际上，需要 16M 栈的查询通常过于复杂，解析时耗费大量时间和资源。守护进程会处理该查询，但通过 `thread_stack` 设置限制此类查询是合理的。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\n确定成功旋转后是否解除 `.old` 表复制的链接。可选，默认值为 1（解除链接）。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_83\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\n线程化服务器看门狗。可选，默认值为 1（启用看门狗）。\n\n当 Manticore 查询崩溃时，可能导致整个服务器宕机。启用看门狗功能后，`searchd` 会维护一个轻量级独立进程，监控主服务器进程并在异常终止时自动重启服务器。看门狗默认启用。\n\n<!-- request Example -->\n\nCODE_BLOCK_84\n\n<!-- end -->\n\n<!-- proofread -->",
      "russian": "Сервер использует файл CA для проверки подписи на сертификате. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_76\n\n<!-- end -->\n\n### ssl_cert\n\n<!-- example conf ssl_cert -->\n\nПуть к SSL-сертификату сервера. Опционально, по умолчанию пусто.\n\nСервер использует этот сертификат как самоподписанный открытый ключ для шифрования HTTP-трафика через SSL. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_77\n\n<!-- end -->\n\n### ssl_key\n\n<!-- example conf ssl_key -->\n\nПуть к ключу SSL-сертификата. Опционально, по умолчанию пусто.\n\nСервер использует этот приватный ключ для шифрования HTTP-трафика через SSL. Файл должен быть в формате PEM.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_78\n\n<!-- end -->\n\n### subtree_docs_cache\n\n<!-- example conf subtree_docs_cache -->\n\nМаксимальный размер кеша документов общего поддерева на запрос. Опционально, по умолчанию 0 (отключено).\n\nЭтот параметр ограничивает использование оперативной памяти оптимизатором общего поддерева (см. [multi-queries](../Searching/Multi-queries.md)). Максимум столько ОЗУ будет потрачено на кеширование записей документов для каждого запроса. Установка лимита в 0 отключает оптимизатор.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_79\n\n<!-- end -->\n\n### subtree_hits_cache\n\n<!-- example conf subtree_hits_cache -->\n\nМаксимальный размер кеша вхождений общего поддерева на запрос. Опционально, по умолчанию 0 (отключено).\n\nЭтот параметр ограничивает использование оперативной памяти оптимизатором общего поддерева (см. [multi-queries](../Searching/Multi-queries.md)). Максимум столько ОЗУ будет потрачено на кеширование вхождений ключевых слов (hits) для каждого запроса. Установка лимита в 0 отключает оптимизатор.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_80\n\n<!-- end -->\n\n### threads\n\n<!-- example threads -->\n\nКоличество рабочих потоков (или размер пула потоков) для демона Manticore. Manticore создаёт такое количество потоков ОС при запуске, и они выполняют все задачи внутри демона, такие как выполнение запросов, создание сниппетов и т.д. Некоторые операции могут быть разбиты на подзадачи и выполнены параллельно, например:\n\n* Поиск в таблице реального времени\n\n* Поиск в распределённой таблице, состоящей из локальных таблиц\n\n* Вызов перколирования запроса\n\n* и другие\n\nПо умолчанию установлено количество потоков равное количеству ядер процессора на сервере. Manticore создаёт потоки при запуске и удерживает их до остановки. Каждая подзадача может использовать один из потоков, когда это нужно. Когда подзадача завершается, поток освобождается для использования другой подзадачей.\n\nВ случае интенсивной нагрузки типа ввода-вывода может иметь смысл установить значение выше количества ядер процессора.\n\n<!-- request Example -->\n\nCODE_BLOCK_81\n\n<!-- end -->\n\n### thread_stack\n\n<!-- example conf thread_stack -->\n\nМаксимальный размер стека для задачи (корутина, один поисковый запрос может создавать несколько задач/корутин). Опционально, по умолчанию 128K.\n\nУ каждой задачи собственный стек размером 128K. При выполнении запроса проверяется, сколько стека он требует. Если 128K достаточно, задача просто обрабатывается. Если требуется больше, планируется другая задача с увеличенным стеком, которая продолжает обработку. Максимальный размер такого увеличенного стека ограничен этим параметром.\n\nУстановка значения на разумно высоком уровне поможет при обработке очень глубоких запросов без значительного увеличения общего потребления ОЗУ. Например, установка 1G не означает, что каждая новая задача будет занимать 1G ОЗУ, а лишь то, что если нужно, например, 100M стека, выделяется именно 100M для задачи. Другие задачи одновременно выполняются с их стандартным стеком 128K. Таким же образом можно выполнять более сложные запросы, требующие 500M. И только если **видим** внутренне, что задача требует стека более 1G, будет ошибка и сообщение о слишком маленьком параметре thread_stack.\n\nТем не менее на практике даже запросы, требующие 16M стека, часто слишком сложны для парсинга и занимают слишком много времени и ресурсов для обработки. Поэтому демон обработает их, но ограничение таких запросов параметром `thread_stack` выглядит вполне разумным.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_82\n\n<!-- end -->\n\n### unlink_old\n\n<!-- example conf unlink_old -->\n\nОпределяет, следует ли удалять (unlink) копии таблиц с расширением `.old` после успешного ротации. Опционально, по умолчанию 1 (удалять).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_83\n\n<!-- end -->\n\n### watchdog\n\n<!-- example conf watchdog -->\n\nПоточечный сторож сервера. Опционально, по умолчанию 1 (сторож включён).\n\nКогда запрос Manticore аварийно завершает работу, он может привести к падению всего сервера. При включённой функции сторожа `searchd` поддерживает отдельный лёгкий процесс, который следит за основным процессом сервера и автоматически перезапускает его в случае аномального завершения. Сторож включен по умолчанию.\n\n<!-- request Example -->\n\nCODE_BLOCK_84\n\n<!-- end -->\n\n<!-- proofread -->"
    },
    "is_code_or_comment": false
  },
  "0617db7f01259fabd61158829095384b26810023b1959332100851bf2587c5b1": {
    "original": "With replication, a node may need to send a large file (for example, 100GB) to another node. Assume the network can transfer data at 1GB/s, with a series of packets of 4-5MB each. To transfer the entire file, you would need 100 seconds. A default timeout of 5 seconds would only allow the transfer of 5GB before the connection is dropped. Increasing the timeout could be a workaround, but it is not scalable (for instance, the next file might be 150GB, leading to failure again). However, with the default `reset_network_timeout_on_packet` set to 1, the timeout is applied not to the entire transfer but to individual packets. As long as the transfer is in progress (and data is actually being received over the network during the timeout period), it is kept alive. If the transfer gets stuck, such that a timeout occurs between packets, it will be dropped.\n\nNote that if you set up a distributed table, each node — both master and agents — should be tuned. On the master side, `agent_query_timeout` is affected; on agents, `network_timeout` is relevant.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nRT tables RAM chunk flush check period, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 10 hours.\n\nActively updated RT tables that fully fit in RAM chunks can still result in ever-growing binlogs, impacting disk use and crash recovery time. With this directive, the search server performs periodic flush checks, and eligible RAM chunks can be saved, enabling consequential binlog cleanup. See [Binary logging](../Logging/Binary_logging.md) for more details.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nA maximum number of I/O operations (per second) that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).\n\nThis directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. It is guaranteed that all RT optimization activities will not generate more disk IOPS (I/Os per second) than the configured limit. Limiting rt_merge_iops can reduce search performance degradation caused by merging.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nA maximum size of an I/O operation that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).\n\nThis directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. I/Os larger than this limit will be broken down into two or more I/Os, which will then be accounted for as separate I/Os with regards to the [rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops) limit. Thus, it is guaranteed that all optimization activities will not generate more than (rt_merge_iops * rt_merge_maxiosize) bytes of disk I/O per second.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\nPrevents `searchd` stalls while rotating tables with huge amounts of data to precache. Optional, default is 1 (enable seamless rotation). On Windows systems, seamless rotation is disabled by default.\n\nTables may contain some data that needs to be precached in RAM. At the moment, `.spa`, `.spb`, `.spi`, and `.spm` files are fully precached (they contain attribute data, blob attribute data, keyword table, and killed row map, respectively.) Without seamless rotate, rotating a table tries to use as little RAM as possible and works as follows:\n\n1. New queries are temporarily rejected (with \"retry\" error code);\n\n2. `searchd` waits for all currently running queries to finish;\n\n3. The old table is deallocated, and its files are renamed;\n\n4. New table files are renamed, and required RAM is allocated;\n\n5. New table attribute and dictionary data are preloaded to RAM;\n\n6. `searchd` resumes serving queries from the new table.\n\nHowever, if there's a lot of attribute or dictionary data, then the preloading step could take a noticeable amount of time - up to several minutes in the case of preloading 1-5+ GB files.\n\nWith seamless rotate enabled, rotation works as follows:\n\n1. New table RAM storage is allocated;\n\n2. New table attribute and dictionary data are asynchronously preloaded to RAM;\n\n3. On success, the old table is deallocated, and both tables' files are renamed;\n\n4. On failure, the new table is deallocated;\n\n5. At any given moment, queries are served either from the old or new table copy.\n\nSeamless rotate comes at the cost of higher peak memory usage during the rotation (because both old and new copies of `.spa/.spb/.spi/.spm` data need to be in RAM while preloading the new copy). Average usage remains the same.\n\n<!-- intro -->\n\n##### Example:\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\nThis option specifies the size of the block cache used by secondary indexes. It is optional, with a default of 8 MB. When secondary indexes work with filters that contain many values (e.g., IN() filters), they read and process metadata blocks for these values.\n\nIn joined queries, this process is repeated for each batch of rows from the left table, and each batch may reread the same metadata within a single joined query. This can severely affect performance. The metadata block cache keeps these blocks in memory so they\n\ncan be reused by subsequent batches.\n\nThe cache is only used in joined queries and has no effect on non-joined queries. Note that the cache size limit applies per attribute and per secondary index. Each attribute within each disk chunk operates within this limit. In the worst case, the total memory\n\nusage can be estimated by multiplying the limit by the number of disk chunks and the number of attributes used in joined queries.\n\nSetting `secondary_index_block_cache = 0` disables the cache.\n\n<!-- intro -->\n\n##### Example:",
    "translations": {
      "chinese": "通过复制，一个节点可能需要将一个大文件（例如100GB）发送到另一个节点。假设网络传输速率为1GB/s，使用一系列4-5MB的包。传输整个文件需要100秒。默认的5秒超时只允许传输5GB数据，之后连接将被断开。增加超时是一个解决方法，但不具备可扩展性（例如，下一个文件可能是150GB，仍会导致失败）。然而，默认情况下`reset_network_timeout_on_packet`设置为1，超时应用于单个数据包，而不是整个传输。只要传输在进行中（且在超时时间内实际上通过网络接收数据），连接就会保持活跃。如果传输卡住，导致数据包间发生超时，则连接会被断开。\n\n请注意，如果设置了分布式表，主节点和代理节点都应进行调整。主节点影响的是`agent_query_timeout`；代理节点影响的是`network_timeout`。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nRT表内存块刷新检查周期，单位为秒（或[特殊后缀](../Server_settings/Special_suffixes.md)）。可选，默认值为10小时。\n\n完全适合内存块的动态更新RT表仍可能导致不断增长的二进制日志，影响磁盘使用和崩溃恢复时间。通过此指令，搜索服务器会周期性执行刷新检查，可保存符合条件的内存块，从而实现随后的二进制日志清理。详情参见[二进制日志](../Logging/Binary_logging.md)。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nRT块合并线程允许启动的最大I/O操作次数（每秒）。可选，默认值为0（无限制）。\n\n此指令允许你限制来自`OPTIMIZE`语句的I/O影响。保障所有RT优化活动生成的磁盘IOPS（每秒I/O次数）不会超过配置的限制。限制rt_merge_iops可以减少合并引起的搜索性能下降。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nRT块合并线程允许启动的单次最大I/O操作大小。可选，默认值为0（无限制）。\n\n此指令允许你限制来自`OPTIMIZE`语句的I/O影响。大小超过此限制的I/O操作会被拆分成两个或多个I/O，并作为独立的操作计入[rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops)限制。因此，保证所有优化活动每秒生成的磁盘I/O不超过(rt_merge_iops * rt_merge_maxiosize) 字节。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\n防止在旋转包含大量数据以预缓存的表时`searchd`卡顿。可选，默认值为1（启用无缝旋转）。在Windows系统上，无缝旋转默认关闭。\n\n表中可能包含需要预缓存到内存的数据。目前，`.spa`、`.spb`、`.spi`和`.spm`文件将被完全预缓存（它们分别包含属性数据、blob属性数据、关键词表和已删除行映射）。未启用无缝旋转时，旋转表会尽量少用内存，过程如下：\n\n1. 新查询暂时被拒绝（错误码“重试”）；\n\n2. `searchd`等待所有当前运行的查询完成；\n\n3. 旧表释放，文件重命名；\n\n4. 新表文件重命名，分配所需内存；\n\n5. 新表属性和词典数据预加载到内存；\n\n6. `searchd`开始为新表服务查询。\n\n但是如果属性或词典数据过大，预加载步骤可能需要较长时间——在预加载1-5GB及以上文件时可能耗时几分钟。\n\n启用无缝旋转后，旋转过程如下：\n\n1. 分配新表的内存存储；\n\n2. 异步预加载新表属性和词典数据到内存；\n\n3. 预加载成功后，释放旧表，同时重命名两个表的文件；\n\n4. 预加载失败时，释放新表；\n\n5. 任何时刻，查询从旧表或新表副本中提供服务。\n\n无缝旋转导致旋转期间峰值内存使用增加（因为预加载期间需同时将旧表和新表的`.spa/.spb/.spi/.spm`数据保留在内存中），但平均内存使用保持不变。\n\n<!-- intro -->\n\n##### 示例：\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\n此选项指定二级索引使用的块缓存大小。可选，默认值为8MB。当二级索引处理包含大量值的过滤器（例如IN()过滤器）时，它们会读取并处理这些值的元数据块。\n\n在连接查询中，此过程对左表的每批行重复进行，每批可能在单次连接查询内重新读取相同的元数据。这会严重影响性能。元数据块缓存将这些块保存在内存中，以供后续批次重复使用。\n\n该缓存仅在连接查询中使用，对非连接查询无影响。缓存大小限制是针对每个属性和每个二级索引的。每个磁盘块中的每个属性都在此限制范围内运行。最坏情况下，总内存使用量可估算为限制大小乘以磁盘块数量再乘以连接查询中使用的属性数量。\n\n设置`secondary_index_block_cache = 0`可禁用缓存。\n\n<!-- intro -->\n\n##### 示例：",
      "russian": "При репликации узлу может потребоваться отправить большой файл (например, 100 ГБ) другому узлу. Предположим, что сеть может передавать данные со скоростью 1 ГБ/с, с серией пакетов размером 4-5 МБ каждый. Для передачи всего файла потребуется 100 секунд. Таймаут по умолчанию 5 секунд позволит передать только 5 ГБ, после чего соединение будет разорвано. Увеличение таймаута может быть обходным решением, но оно не масштабируемо (например, следующий файл может быть 150 ГБ, что снова приведёт к сбою). Однако при установке параметра по умолчанию `reset_network_timeout_on_packet` в 1 таймаут применяется не ко всей передаче, а к отдельным пакетам. Пока передача продолжается (и данные действительно поступают по сети в течение периода таймаута), соединение остаётся активным. Если передача зависает и таймаут происходит между пакетами, соединение будет разорвано.\n\nОбратите внимание, что при настройке распределённой таблицы каждый узел — как мастер, так и агенты — должен быть настроен. На стороне мастера действует параметр `agent_query_timeout`, на агентах — `network_timeout`.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_64\n\n<!-- end -->\n\n### rt_flush_period\n\n<!-- example conf rt_flush_period -->\n\nПериод проверки сброса чанков RT таблиц в ОЗУ, в секундах (или с использованием [специальных суффиксов](../Server_settings/Special_suffixes.md)). Опционально, по умолчанию 10 часов.\n\nАктивно обновляемые RT таблицы, полностью помещающиеся в чанки ОЗУ, могут приводить к постоянно увеличивающимся бинарным логам, что влияет на использование диска и время восстановления после сбоя. С помощью этой директивы поисковый сервер выполняет периодические проверки для сброса, и подходящие чанки ОЗУ могут быть сохранены, что позволяет впоследствии очищать бинарные логи. Подробнее см. в разделе [Бинарное логирование](../Logging/Binary_logging.md).\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_65\n\n<!-- end -->\n\n### rt_merge_iops\n\n<!-- example conf rt_merge_iops -->\n\nМаксимальное количество операций ввода-вывода (в секунду), которые поток слияния чанков RT таблиц может начать. Опционально, по умолчанию 0 (без ограничений).\n\nДанная директива позволяет ограничить влияние операций ввода-вывода, связанных с операторами `OPTIMIZE`. Гарантируется, что все операции оптимизации RT не будут генерировать больше дисковых операций ввода-вывода (IOPS) в секунду, чем заданный лимит. Ограничение rt_merge_iops может уменьшить деградацию производительности поиска, вызванную слиянием.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_66\n\n<!-- end -->\n\n### rt_merge_maxiosize\n\n<!-- example conf rt_merge_maxiosize -->\n\nМаксимальный размер операции ввода-вывода, который поток слияния чанков RT таблиц может начать. Опционально, по умолчанию 0 (без ограничений).\n\nДанная директива позволяет снизить влияние операций ввода-вывода, связанных с операторами `OPTIMIZE`. Операции ввода-вывода, превышающие данный лимит, будут разбиты на две или более операций, которые затем учитываются как отдельные операции с точки зрения ограничения [rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops). Тем самым гарантируется, что все операции оптимизации не создадут более (rt_merge_iops * rt_merge_maxiosize) байт дискового ввода-вывода в секунду.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_67\n\n<!-- end -->\n\n### seamless_rotate\n\n<!-- example conf seamless_rotate -->\n\nПредотвращает зависания `searchd` при ротации таблиц с огромным количеством данных для предзагрузки в кэш. Опционально, по умолчанию 1 (включена бесшовная ротация). На Windows-системах бесшовная ротация по умолчанию отключена.\n\nТаблицы могут содержать данные, которые необходимо предзагрузить в ОЗУ. В настоящее время файлы `.spa`, `.spb`, `.spi` и `.spm` полностью предзагружаются (они содержат данные атрибутов, данные блоб-атрибутов, таблицу ключевых слов и карту удалённых строк соответственно). Без бесшовной ротации ротация таблицы старается использовать как можно меньше ОЗУ и работает следующим образом:\n\n1. Новые запросы временно отклоняются (с кодом ошибки \"retry\");\n\n2. `searchd` ждёт завершения всех текущих запросов;\n\n3. Старая таблица освобождается, её файлы переименовываются;\n\n4. Новые файлы таблицы переименовываются, выделяется необходимая ОЗУ;\n\n5. Новые атрибуты и данные словаря таблицы предзагружаются в ОЗУ;\n\n6. `searchd` возобновляет обслуживание запросов из новой таблицы.\n\nОднако если данных атрибутов или словаря много, этап предзагрузки может занять заметное время — до нескольких минут для файлов размером 1-5+ ГБ.\n\nПри включённой бесшовной ротации ротация происходит так:\n\n1. Выделяется RAM-хранилище для новой таблицы;\n\n2. Асинхронно предзагружаются атрибуты и данные словаря новой таблицы;\n\n3. При успешной предзагрузке старая таблица освобождается, и файлы обеих таблиц переименовываются;\n\n4. При неудаче новая таблица освобождается;\n\n5. В любой момент запросы обслуживаются либо из старой, либо из новой копии таблицы.\n\nБесшовная ротация требует большего пикового объёма памяти во время ротации (поскольку обе копии данных `.spa/.spb/.spi/.spm` — старая и новая — должны находиться в ОЗУ при предзагрузке новой копии). Среднее использование памяти остаётся прежним.\n\n<!-- intro -->\n\n##### Пример:\n\n<!-- request Example -->\n\nCODE_BLOCK_68\n\n<!-- end -->\n\n### secondary_index_block_cache\n\n<!-- example conf secondary_index_block_cache -->\n\nЭтот параметр задаёт размер кэша блоков, используемых вторичными индексами. Опционально, по умолчанию 8 МБ. Вторичные индексы при работе с фильтрами, содержащими множество значений (например, фильтры IN()), читают и обрабатывают метаданные блоков для этих значений.\n\nВ объединённых запросах этот процесс повторяется для каждой партии строк из левой таблицы, и каждая партия может повторно считывать одни и те же метаданные в рамках одного объединённого запроса. Это может существенно влиять на производительность. Кэш блоков метаданных хранит эти блоки в памяти, чтобы они\n\nмогли повторно использоваться последующими партиями.\n\nКэш используется только в объединённых запросах и не влияет на обычные (необъединённые) запросы. Обратите внимание, что ограничение размера кэша применяется на каждый атрибут и на каждый вторичный индекс. Каждый атрибут в каждом дисковом чанке работает в пределах этого ограничения. В худшем случае общий объём\n\nиспользуемой памяти можно оценить, умножив лимит на количество дисковых чанков и количество атрибутов, используемых в объединённых запросах.\n\nУстановка `secondary_index_block_cache = 0` отключает кэш.\n\n<!-- intro -->\n\n##### Пример:"
    },
    "is_code_or_comment": false
  }
}
