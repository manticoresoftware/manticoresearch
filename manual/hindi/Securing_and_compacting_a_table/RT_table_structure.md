# वास्तविक समय की तालिका संरचना
एक साधारण तालिका को एक बाहरी स्रोत से एक विशेष उपकरण `indexer` का उपयोग करके बनाया जा सकता है, जो विन्यास से "रेसिपी" पढ़ता है, डेटा स्रोतों से कनेक्ट करता है, दस्तावेज़ लाता है, और तालिका फ़ाइलें बनाता है। यह एक लंबी प्रक्रिया है। यदि आपका डेटा बदलता है, तो तालिका पुरानी हो जाती है, और आपको इसे ताज़ा स्रोतों से फिर से बनाना पड़ता है। यदि आपका डेटा धीरे-धीरे बदलता है, जैसे कि एक ब्लॉग या समाचार फ़ीड जहाँ पुराने दस्तावेज़ कभी नहीं बदलते और केवल नए जोड़े जाते हैं, तो पुनर्निर्माण में अधिक समय लगेगा, क्योंकि आपको हर बार संग्रहण स्रोतों को फिर से प्रोसेस करना होगा।

इस समस्या से निपटने का एक तरीका यह है कि एक ठोस तालिका के बजाय कई तालिकाओं का उपयोग किया जाए। उदाहरण के लिए, आप पिछले वर्षों में उत्पादित स्रोतों को प्रोसेस कर सकते हैं और तालिका को सहेज सकते हैं। फिर, केवल वर्तमान वर्ष के स्रोतों को लें और उन्हें एक अलग तालिका में डालें, और आवश्यकतानुसार इसे पुनर्निर्माण करें। फिर आप दोनों तालिकाओं को वितरित तालिका के भागों के रूप में रख सकते हैं और इसका उपयोग क्वेरी के लिए कर सकते हैं। यहाँ मुद्दा यह है कि हर बार जब आप पुनर्निर्माण करते हैं, तो आप केवल पिछले 12 महीनों से डेटा प्रोसेस करते हैं, और पुरानी डेटा वाली तालिका बिना छेड़छाड़ के अनुपयोगी रहती है। आप आगे बढ़ सकते हैं और पिछले 12 महीनों की तालिका को मासिक, साप्ताहिक, या दैनिक तालिकाओं में विभाजित कर सकते हैं, और इसी तरह।

यह दृष्टिकोण काम करता है, लेकिन आपको अपनी वितरित तालिका को मैन्युअल रूप से बनाए रखना होगा। अर्थात्, नए भाग जोड़ें, पुराने को हटाएं, और आंशिक तालिकाओं की कुल संख्या को बहुत बड़ा न रखें (बہुत सारी तालिकाओं के साथ, खोज प्रक्रिया धीमी हो सकती है, और ओएस आमतौर पर एक साथ खोले गए फ़ाइलों की संख्या को सीमित करता है)। इसके निपटारे के लिए, आप मैन्युअल रूप से कई तालिकाओं को एक साथ विलय कर सकते हैं [indexer --merge](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Merging_tables.md) चलाकर। हालाँकि, यह केवल कई तालिकाओं की समस्या का समाधान करता है, जिससे रखरखाव अधिक चुनौतीपूर्ण हो जाता है। और 'प्रति-घंटा' पुन: अनुक्रमण के साथ, आपके पास स्रोतों में नए डेटा के आने और तालिका के पुनर्निर्माण के बीच एक स्पष्ट समय अंतर होगा, जो इस डेटा को खोज के लिए भरता है।

एक वास्तविक समय की तालिका इस समस्या को हल करने के लिए डिज़ाइन की गई है। इसमें दो भाग होते हैं:

1. एक विशेष RAM-आधारित तालिका (जिसे RAM भाग कहा जाता है) जिसमें अभी आए डेटा के भाग होते हैं।
2. पूर्व में निर्मित साधारण तालिकाओं का संग्रह जिसे डिस्क भाग कहा जाता है।

यह एक मानक [वितरित तालिका](../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md) के बहुत समान है, जो कई स्थानीय तालिकाओं से बनी है।

आपको ऐसी तालिका बनाने के लिए `indexer` चलाने की आवश्यकता नहीं है, जो विन्यास और तालिका डेटा स्रोतों से "रेसिपी" पढ़ता है। इसके बजाय, वास्तविक समय तालिका नई दस्तावेज़ों को 'सम्मिलित' और मौजूदा दस्तावेज़ों को 'स्थानापन्न' करने की क्षमता प्रदान करती है। 'सम्मिलित' आदेश चलाते समय, आप नए दस्तावेज़ों को सर्वर पर भेजते हैं। फिर यह जोड़े गए दस्तावेज़ों से एक छोटी तालिका बनाता है और इसे तुरंत ऑनलाइन लाता है। इसलिए, 'सम्मिलित' आदेश पूरा होने के ठीक बाद, आप सभी तालिका भागों में खोज कर सकते हैं, जिसमें अभी जोड़े गए दस्तावेज़ भी शामिल हैं।

खोज सर्वर स्वचालित रूप से तालिका को बनाए रखता है, इसलिए आपको इसके बारे में चिंता करने की आवश्यकता नहीं है। हालाँकि, आप 'किस प्रकार इसे बनाए रखा जाता है' के बारे में कुछ विवरण जानने में रुचि रखते होंगे।

**पहले, चूंकि अनुक्रमित डेटा RAM में संग्रहीत होता है - आपातकालीन पावर-ऑफ के बारे में क्या?** क्या तब मैं अपनी तालिका खो दूंगा? खैर, पूर्णता से पहले, सर्वर एक विशेष 'बिनलॉग' में नए डेटा को सहेजता है। यह एक या एक से अधिक फ़ाइलों से बना होता है, जो आपके स्थायी संग्रहण पर जीवन्त रहती हैं, जो आप अधिक से अधिक परिवर्तन जोड़ते हैं। आप यह समायोजित कर सकते हैं कि नए प्रश्न (या लेनदेन) निबंधित होने की आवृत्ति कितनी हो, और बिनलॉग फ़ाइल पर 'सिंक' आदेश कितनी बार निष्पादित होता है ताकि ओएस वास्तव में डेटा को सुरक्षित संग्रहण में सहेज सके। सबसे पारanoid दृष्टिकोण हर लेनदेन के बाद फ्लश और सिंक करना है। यह सबसे धीमा लेकिन सबसे सुरक्षित तरीका है। सबसे कम महंगा तरीका बिनलॉग को पूरी तरह से बंद करना है। यह सबसे तेज़ विधि है, लेकिन आप अपने अनुक्रमित डेटा को खोने का जोखिम उठाते हैं। इंटरमीडिएट विकल्प, जैसे हर सेकंड फ्लश/सिंक करना, भी प्रदान किए जाते हैं।

बिनलॉग विशेष रूप से नए आते हुए लेनदेन के अनुक्रमिक सहेजने के लिए डिज़ाइन किया गया है; यह एक तालिका नहीं है और इस पर खोज नहीं की जा सकती। यह सिर्फ एक बीमा नीति है ताकि सर्वर आपका डेटा न खो सके। यदि अचानक कोई व्यवधान उत्पन्न होता है और सब कुछ एक सॉफ्टवेयर या हार्डवेयर समस्या के कारण क्रैश हो जाता है, तो सर्वर RAM भाग का सबसे ताजा उपलब्ध डंप लोड करेगा और फिर बिनलॉग को पुनः चलाएगा, संग्रहीत लेनदेन को दोहराएगा। अंततः, यह अंतिम परिवर्तन के क्षण में जिस स्थिति में था, उसमें पहुंच जाएगा।

**दूसरा, सीमाओं के बारे में क्या?** अगर मैं 10TB डेटा प्रोसेस करना चाहता हूँ, लेकिन वह RAM में फिट नहीं होता! वास्तविक समय तालिका के लिए RAM सीमित होती है और इसे कॉन्फ़िगर किया जा सकता है। जब एक निश्चित मात्रा में डेटा अनुक्रमित होता है, तो सर्वर तालिका के RAM भाग को छोटे लेनदेन को मिलाकर प्रबंधित करता है, उनकी संख्या और कुल आकार को छोटा रखता है। हालांकि, यह प्रक्रिया कभी-कभी सम्मिलन के दौरान देरी का कारण बन सकती है। जब विलय करना मदद नहीं करता, और नए सम्मिलन [RAM सीमा](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_mem_limit) को हिट करते हैं, तो सर्वर RAM-आधारित तालिका को एक साधारण तालिका में परिवर्तित कर देता है जो डिस्क पर संग्रहीत होती है (जिसे डिस्क भाग कहा जाता है)। यह तालिका RT तालिका के दूसरे भाग में तालिकाओं के संग्रह में जोड़ी जाती है और ऑनलाइन सुलभ हो जाती है। फिर RAM फ्लश होती है, और स्थान को मुक्त किया जाता है।

जब RAM से डेटा सुरक्षित रूप से डिस्क पर सहेजा जाता है, जो निम्नलिखित स्थितियों में होती है:

* जब सर्वर एक डिस्क तालिका के रूप में एकत्रित डेटा को सहेजता है
* या जब यह स्वच्छ शटडाउन के दौरान RAM भाग का डंप करता है या [मैन्युअल फ्लशिंग](../Securing_and_compacting_a_table/Flushing_RAM_chunk_to_disk.md#FLUSH-TABLE) द्वारा

उस तालिका के लिए बिनलॉग अब आवश्यक नहीं है। इसलिए, इसे नष्ट कर दिया जाता है। यदि सभी तालिकाएँ सहेजी जाती हैं, तो बिनलॉग को हटा दिया जाएगा।
**तीसरा, डिस्क संग्रह के बारे में क्या?**  यदि कई डिस्क भागों के होने से खोज धीमी हो जाती है, तो मैं उन्हें वितरित तालिका तरीके से मैन्युअल रूप से बनाऊं, या एक RT तालिका द्वारा डिस्क भागों (या, 'खंडों') के रूप में निर्मित किया जाए, तो इसमें क्या अंतर है? ठीक है, दोनों मामलों में, आप कई तालिकाओं को एक में मिला सकते हैं। उदाहरण के लिए, आप कल की घंटे भर की तालिकाओं को मिला सकते हैं और इसके बजाय कल के लिए एक 'दैनिक' तालिका रख सकते हैं। मैन्युअल रखरखाव के साथ, आपको स्कीमा और आदेशों के बारे में खुद सोचना होगा। एक RT तालिका के साथ, सर्वर [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) आदेश प्रदान करता है, जो वही करता है, लेकिन आपको अनावश्यक आंतरिक विवरणों से दूर रखता है।

**चौथा, यदि मेरा "दस्तावेज़" एक 'मिनी-तालिका' है और मुझे इसकी अब जरूरत नहीं है, तो मैं इसे बस फेंक सकता हूँ। लेकिन यदि यह 'अनुकूलित' है, यानी दूसरों के साथ मिलकर, तो मैं इसे कैसे पूर्ववत या हटा सकता हूँ?** हाँ, निर्धारित दस्तावेज़ 'मिश्रित' होते हैं, और बिना पूरे तालिका को फिर से बनाए बिना एक को हटाने का कोई आसान तरीका नहीं है। और यदि सामान्य तालिकाओं के लिए, फिर से बनाना या संयोजन बस रखरखाव का एक सामान्य तरीका है, तो वास्तविक समय की तालिका में यह केवल संचालन की सरलता बनाए रखता है, लेकिन 'वास्तविक समय' नहीं। समस्या को हल करने के लिए, मैंटिकोर एक चाल का उपयोग करता है: जब आप एक दस्तावेज़ को हटा देते हैं, जो दस्तावेज़ ID द्वारा पहचाना जाता है, तो सर्वर केवल संख्या को ट्रैक करता है। अन्य हटाए गए दस्तावेज़ों के साथ, उनके IDs को एक sogenannten [kill-list](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md#Table-kill-list) में सहेजा गया है। जब आप तालिका पर खोज करते हैं, तो सर्वर पहले सभी मेल खाते दस्तावेज़ों को प्राप्त करता है, और फिर किल-लिस्ट में पाए जाने वाले दस्तावेज़ों को बाहर फेंक देता है (यह सबसे बुनियादी विवरण है; वास्तव में, आंतरिक रूप से यह अधिक जटिल है)। बात यह है - 'तत्काल' हटाने के लिए, दस्तावेज़ वास्तव में हटा नहीं जाते हैं, बल्कि बस 'हटाए गए' के रूप में चिह्नित होते हैं। वे विभिन्न तालिका संरचनाओं में स्थान को घेरते हैं, मूल रूप से कचरा होते हैं। शब्द सांख्यिकी, जो रैंकिंग को प्रभावित करती है, भी प्रभावित नहीं होती, जिसका मतलब है कि यह ठीक उसी तरह काम करता है जैसे इसे घोषित किया गया है: हम सभी दस्तावेज़ों के बीच खोज करते हैं, और फिर बस हटाए गए के रूप में चिह्नित किए गए दस्तावेज़ों को अंतिम परिणाम से छिपा देते हैं। जब एक दस्तावेज़ को [बदल दिया जाता है](../Data_creation_and_modification/Updating_documents/REPLACE.md), इसका मतलब है कि इसे तालिका के पुराने भागों में समाप्त कर दिया गया है और इसे फिर से नवीनतम भाग में डाला गया है। 'किललिस्ट द्वारा छिपाने' के सभी परिणाम भी इस मामले में हैं।

जब तालिका के किसी भाग का पुनर्निर्माण होता है, जैसे, जब RAM खंड के कुछ लेनदेन (खंड) एकत्र किए जाते हैं, या जब RAM खंड को डिस्क खंड में परिवर्तित किया जाता है, या जब दो डिस्क खंडों को एक साथ मिलाया जाता है, तो सर्वर प्रभावित भागों पर एक व्यापक पुनरावृत्ति करता है और सभी से शारीरिक रूप से हटाए गए दस्तावेज़ों को बाहर करता है। यानी, यदि वे कुछ शब्दों के दस्तावेज़ सूचियों में थे - तो वे मिटा दिए जाते हैं। यदि यह एक अनूठा शब्द था - तो इसे पूरी तरह से हटा दिया जाता है।

संक्षेप में: हटाना दो चरणों में काम करता है:
1. सबसे पहले, हम वास्तविक समय में दस्तावेज़ों को 'हटाए गए' के रूप में चिह्नित करते हैं और उन्हें खोज परिणामों में दबाते हैं।
2. RT तालिका खंड के साथ किसी ऑपरेशन के दौरान, हम अंततः स्थायी रूप से हटाए गए दस्तावेज़ों को शारीरिक रूप से मिटा देते हैं।

**पाँचवा, यदि एक RT तालिका में सामान्य डिस्क तालिकाएँ हैं, तो क्या मैं बस अपनी तैयार पुरानी डिस्क तालिका को इसमें जोड़ सकता हूँ?** नहीं। अनावश्यक जटिलता से बचना और आकस्मिक खराबी को रोकना संभव नहीं है। हालाँकि, यदि आपकी RT तालिका अभी बनाई गई है और इसमें कोई डेटा नहीं है, तो आप अपने डिस्क तालिका को [ATTACH TABLE](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Attaching_one_table_to_another.md) कर सकते हैं। आपकी पुरानी तालिका RT तालिका के अंदर स्थानांतरित की जाएगी और इसकी एक भाग बन जाएगी।

RT तालिका संरचना के बारे में संक्षेप में: यह सामान्य डिस्क तालिकाओं का एक चालाकी से संगठित संग्रह है जिसमें तेज़ इन-मेमोरी तालिका है, जो वास्तविक समय के सम्मिलनों और अर्ध-वास्तविक समय के हटाने के लिए बनी है। RT तालिका में एक सामान्य स्कीमा, सामान्य सेटिंग्स हैं, और इसे विवरणों में गहराई से खोने के बिना आसानी से बनाए रखा जा सकता है। 
<!-- proofread -->


