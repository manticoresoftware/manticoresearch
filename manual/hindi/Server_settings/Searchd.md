# Section "Searchd" in configuration

नीचे दी गई सेटिंग्स का उपयोग `searchd` अनुभाग में Manticore खोज कॉन्फ़िगरेशन फ़ाइल में सर्वर के व्यवहार को नियंत्रित करने के लिए किया जाना है। प्रत्येक सेटिंग का संक्षिप्त विवरण नीचे दिया गया है:

### access_plain_attrs

यह सेटिंग [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान `mmap_preread` है।

`access_plain_attrs` निर्देश आपको इस searchd इंस्टेंस द्वारा प्रबंधित सभी तालिकाओं के लिए [access_plain_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) का डिफ़ॉल्ट मान परिभाषित करने की अनुमति देता है। प्रति-तालिका निर्देशों की उच्च प्राथमिकता होती है और वे इस इंस्टेंस-व्यापी डिफ़ॉल्ट को ओवरराइड करेंगे, जो अधिक सूक्ष्म नियंत्रण प्रदान करता है।

### access_blob_attrs

यह सेटिंग [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान `mmap_preread` है।

`access_blob_attrs` निर्देश आपको इस searchd इंस्टेंस द्वारा प्रबंधित सभी तालिकाओं के लिए [access_blob_attrs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) का डिफ़ॉल्ट मान परिभाषित करने की अनुमति देता है। प्रति-तालिका निर्देशों की उच्च प्राथमिकता होती है और वे इस इंस्टेंस-व्यापी डिफ़ॉल्ट को ओवरराइड करेंगे, जो अधिक सूक्ष्म नियंत्रण प्रदान करता है।

### access_doclists

यह सेटिंग [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान `file` है।

`access_doclists` निर्देश आपको इस searchd इंस्टेंस द्वारा प्रबंधित सभी तालिकाओं के लिए [access_doclists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) का डिफ़ॉल्ट मान परिभाषित करने की अनुमति देता है। प्रति-तालिका निर्देशों की उच्च प्राथमिकता होती है और वे इस इंस्टेंस-व्यापी डिफ़ॉल्ट को ओवरराइड करेंगे, जो अधिक सूक्ष्म नियंत्रण प्रदान करता है।

### access_hitlists

यह सेटिंग [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान `file` है।

`access_hitlists` निर्देश आपको इस searchd इंस्टेंस द्वारा प्रबंधित सभी तालिकाओं के लिए [access_hitlists](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) का डिफ़ॉल्ट मान परिभाषित करने की अनुमति देता है। प्रति-तालिका निर्देशों की उच्च प्राथमिकता होती है और वे इस इंस्टेंस-व्यापी डिफ़ॉल्ट को ओवरराइड करेंगे, जो अधिक सूक्ष्म नियंत्रण प्रदान करता है।

### access_dict

यह सेटिंग [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान `mmap_preread` है।

`access_dict` निर्देश आपको इस searchd इंस्टेंस द्वारा प्रबंधित सभी तालिकाओं के लिए [access_dict](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Accessing-table-files) का डिफ़ॉल्ट मान परिभाषित करने की अनुमति देता है। प्रति-तालिका निर्देशों की उच्च प्राथमिकता होती है और वे इस इंस्टेंस-व्यापी डिफ़ॉल्ट को ओवरराइड करेंगे, जो अधिक सूक्ष्म नियंत्रण प्रदान करता है।

### agent_connect_timeout

यह सेटिंग [agent_connect_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_connect_timeout) पैरामीटर के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है।


### agent_query_timeout

यह सेटिंग [agent_query_timeout](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_query_timeout) पैरामीटर के लिए इंस्टेंस-व्यापी डिफ़ॉल्ट्स सेट करती है। इसे `OPTION agent_query_timeout=XXX` खंड का उपयोग करके प्रति-प्रश्न आधार पर ओवरराइड किया जा सकता है।


### agent_retry_count

यह सेटिंग एक पूर्णांक है जो निर्दिष्ट करता है कि Manticore कैसे कई बार दूरस्थ एजेंटों के साथ एक वितरित तालिका के माध्यम से कनेक्ट और प्रश्न करने का प्रयास करेगा, इसके बाद एक घातक प्रश्न त्रुटि रिपोर्ट करेगा। डिफ़ॉल्ट मान 0 है (यानि कोई पुनः प्रयास नहीं)। आप इस मान को `OPTION retry_count=XXX` खंड का उपयोग करके प्रति-प्रश्न आधार पर भी सेट कर सकते हैं। यदि एक प्रति-प्रश्न विकल्प प्रदान किया गया है, तो यह कॉन्फ़िगरेशन में निर्दिष्ट मान को ओवरराइड करेगा।

ध्यान दें कि यदि आप अपने वितरित तालिका की परिभाषा में [एजेंट मिरर्स](../Creating_a_cluster/Remote_nodes/Mirroring.md#Agent-mirrors) का उपयोग करते हैं, तो सर्वर प्रत्येक कनेक्शन प्रयास के लिए चयनित [ha_strategy](../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy) के अनुसार एक अलग मिरर का चयन करेगा। इस मामले में, `agent_retry_count` सभी मिरर के लिए एक सेट में एकत्र किया जाएगा।

उदाहरण के लिए, यदि आपके पास 10 मिरर हैं और `agent_retry_count=5` सेट करते हैं, तो सर्वर 50 बार प्रयास करेगा, मान लें कि औसत 5 प्रयास प्रत्येक 10 मिरर के लिए हैं (जब `ha_strategy = roundrobin` विकल्प हो, तो यह मामला होगा)।

हालांकि, `agent` के लिए [retry_count](../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent) विकल्प के रूप में प्रदान किया गया मान एक निरपेक्ष सीमा के रूप में कार्य करता है। दूसरे शब्दों में, एजेंट परिभाषा में `[retry_count=2]` विकल्प हमेशा अधिकतम 2 प्रयासों का अर्थ है, चाहे आपने एजेंट के लिए 1 या 10 मिरर निर्दिष्ट किया हो।

### agent_retry_delay

यह सेटिंग मिलीसेकंड (या [special_suffixes](../Server_settings/Special_suffixes.md)) में एक पूर्णांक है जो विफलता के मामले में Manticore द्वारा एक दूरस्थ एजेंट को प्रश्न पूछने का पुनः प्रयास करने से पहले का विलंब निर्दिष्ट करती है। यह मान केवल तब प्रासंगिक है जब एक गैर-शून्य [agent_retry_count](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) या गैर-शून्य प्रति-प्रश्न `retry_count` निर्दिष्ट किया गया हो। डिफ़ॉल्ट मान 500 है। आप इस मान को `OPTION retry_delay=XXX` खंड का उपयोग करके प्रति-प्रश्न आधार पर भी सेट कर सकते हैं। यदि एक प्रति-प्रश्न विकल्प प्रदान किया गया है, तो यह कॉन्फ़िगरेशन में निर्दिष्ट मान को ओवरराइड करेगा। 


### attr_flush_period

<!-- example conf attr_flush_period -->
जब [Update](../Data_creation_and_modification/Updating_documents/UPDATE.md) का उपयोग करके दस्तावेज़ विशेषताओं को रीयल-टाइम में संशोधित किया जाता है, तो परिवर्तन पहले विशेषताओं की एक इन-मेमोरी प्रति में लिखे जाते हैं। ये अपडेट एक मेमोरी-मैप्ड फ़ाइल में होते हैं, जिसका अर्थ है कि OS तय करता है कि कब परिवर्तनों को डिस्क पर लिखा जाए। `searchd` के सामान्य शटडाउन के दौरान (`SIGTERM` सिग्नल द्वारा ट्रिगर), सभी परिवर्तन मजबूरी से डिस्क पर लिखे जाते हैं।

आप `searchd` को निर्देश भी दे सकते हैं कि वह डेटा की हानि को रोकने के लिए इन परिवर्तनों को समय-समय पर डिस्क पर वापस लिख दे। इन फ्लश के बीच का अंतराल `attr_flush_period` द्वारा निर्धारित किया जाता है, जो सेकंड में निर्दिष्ट किया जाता है (या [विशेष_प्रत्यय](../Server_settings/Special_suffixes.md))।

डिफ़ॉल्ट रूप से, मान 0 है, जो आवधिक फ्लशिंग को अक्षम करता है। हालांकि, सामान्य शटडाउन के दौरान फ्लशिंग फिर भी होगी।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
attr_flush_period = 900 # persist updates to disk every 15 minutes
```
<!-- end -->

### auto_optimize

<!-- example conf auto_optimize -->
यह सेटिंग टेबल कंपैक्शन के स्वचालित [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) प्रक्रिया को नियंत्रित करता है।

डिफ़ॉल्ट रूप से, टेबल कंपैक्शन स्वचालित रूप से होता है। आप `auto_optimize` सेटिंग के साथ इस व्यवहार को संशोधित कर सकते हैं:
* स्वचालित टेबल कंपैक्शन को अक्षम करने के लिए 0 (आप अभी भी मैन्युअल रूप से `OPTIMIZE` कॉल कर सकते हैं)
* इसे स्पष्ट रूप से सक्षम करने के लिए 1
* इसे सक्षम करने के लिए, साथ ही अनुकूलन सीमा को 2 से गुणा करने के लिए।

डिफ़ॉल्ट रूप से, OPTIMIZE तब तक चलता है जब तक डिस्क चंक्स की संख्या तार्किक CPU कोर की संख्या के 2 गुना के बराबर या उससे कम न हो।

हालांकि, यदि टेबल में KNN इंडेक्स के साथ विशेषताएं हैं, तो यह सीमा अलग होती है। इस मामले में, यह भौतिक CPU कोर की संख्या को 2 से विभाजित करके सेट किया जाता है ताकि KNN खोज प्रदर्शन में सुधार किया जा सके।

ध्यान दें कि `auto_optimize` को चालू या बंद करने से आपको मैन्युअल रूप से [OPTIMIZE TABLE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE) चलाने से नहीं रोका जाता।

<!-- intro -->
##### उदाहरण:

<!-- request Disable -->
```ini
auto_optimize = 0 # disable automatic OPTIMIZE
```

<!-- request Throttle -->
```ini
auto_optimize = 2 # OPTIMIZE starts at 16 chunks (on 4 cpu cores server)
```

<!-- end -->

### auto_schema

<!-- example conf auto_schema -->
मैनटिकोर उन टेबल के स्वचालित निर्माण का समर्थन करता है जो अभी तक मौजूद नहीं हैं लेकिन INSERT कथनों में निर्दिष्ट हैं। यह सुविधा डिफ़ॉल्ट रूप से सक्षम है। इसे अक्षम करने के लिए, अपनी कॉन्फ़िगरेशन में स्पष्ट रूप से `auto_schema = 0` सेट करें। इसे फिर से सक्षम करने के लिए, `auto_schema = 1` सेट करें या कॉन्फ़िगरेशन से `auto_schema` सेटिंग को हटा दें।

ध्यान रखें कि `/bulk` HTTP एंडपॉइंट स्वचालित टेबल निर्माण का समर्थन नहीं करता।

> नोट: [ऑटो स्कीमा कार्यक्षमता](../Data_creation_and_modification/Adding_documents_to_a_table/Adding_documents_to_a_real-time_table.md#Auto-schema) को [मैनटिकोर बडी](../Installation/Manticore_Buddy.md) की आवश्यकता होती है। यदि यह काम नहीं करता है, तो सुनिश्चित करें कि बडी इंस्टॉल है।

<!-- request Disable -->
```ini
auto_schema = 0 # disable automatic table creation
```

<!-- request Enable -->
```ini
auto_schema = 1 # enable automatic table creation
```

<!-- end -->

### binlog_flush

<!-- example conf binlog_flush -->
यह सेटिंग बाइनरी लॉग लेनदेन फ्लश/सिंक मोड को नियंत्रित करता है। यह वैकल्पिक है, डिफ़ॉल्ट मान 2 (हर लेनदेन को फ्लश, हर सेकंड सिंक)।

निर्देश निर्धारित करता है कि बाइनरी लॉग को किस बारंबारता से OS को फ्लश और डिस्क पर सिंक किया जाएगा। तीन समर्थित मोड हैं:

* 0, हर सेकंड फ्लश और सिंक करें। यह सर्वोत्तम प्रदर्शन प्रदान करता है, लेकिन सर्वर क्रैश या OS/हार्डवेयर क्रैश की स्थिति में लगभग 1 सेकंड के कमिट किए गए लेनदेन खो सकते हैं।
* 1, हर लेनदेन पर फ्लश और सिंक करें। यह मोड सबसे खराब प्रदर्शन प्रदान करता है लेकिन यह गारंटी देता है कि हर कमिट किए गए लेनदेन का डेटा बचाया जाता है।
* 2, हर लेनदेन पर फ्लश, हर सेकंड सिंक करें। यह मोड अच्छा प्रदर्शन देता है और यह सुनिश्चित करता है कि हर कमिट किए गए लेनदेन को सर्वर क्रैश के मामले में बचाया जाता है। हालांकि, OS/हार्डवेयर क्रैश की स्थिति में, लगभग 1 सेकंड के कमिट किए गए लेनदेन खो सकते हैं।

MySQL और InnoDB से परिचित लोगों के लिए, यह निर्देश `innodb_flush_log_at_trx_commit` के समान है। अधिकांश मामलों में, डिफ़ॉल्ट हाइब्रिड मोड 2 गति और सुरक्षा के बीच एक अच्छा संतुलन प्रदान करता है, सर्वर क्रैश के खिलाफ पूर्ण RT टेबल डेटा सुरक्षा के साथ और कुछ हार्डवेयर क्रैश सुरक्षा।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
binlog_flush = 1 # ultimate safety, low speed
```
<!-- end -->

### binlog_common

<!-- example conf binlog_common -->
यह सेटिंग बाइनरी लॉग फ़ाइलों के प्रबंधन को नियंत्रित करती है। यह वैकल्पिक है, डिफ़ॉल्ट मान 0 (प्रत्येक टेबल के लिए अलग फ़ाइल)।

बाइनरी लॉग फ़ाइलों के प्रबंधन के लिए आप दो तरीके चुन सकते हैं:

* प्रत्येक टेबल के लिए अलग फ़ाइल (डिफ़ॉल्ट, `0`): प्रत्येक टेबल अपने परिवर्तनों को अपनी स्वयं की लॉग फ़ाइल में सहेजता है। यह सेटअप तब अच्छा होता है जब आपके पास कई टेबल हों जो अलग-अलग समय पर अपडेट होते हैं। यह टेबल को दूसरों के इंतजार किए बिना अपडेट करने की अनुमति देता है। साथ ही, यदि किसी टेबल की लॉग फ़ाइल में समस्या है, तो यह दूसरों को प्रभावित नहीं करता।
* सभी टेबल के लिए एक फ़ाइल (`1`): सभी टेबल एक ही बाइनरी लॉग फ़ाइल का उपयोग करते हैं। यह विधि फ़ाइलों को संभालने में आसान बनाती है क्योंकि उनकी संख्या कम होती है। हालांकि, यह फ़ाइलों को आवश्यकता से अधिक समय तक रख सकता है यदि एक टेबल अभी भी अपने अपडेट को सहेजना चाहता है। यह सेटिंग अधिक समय लेने वाली हो सकती है यदि कई टेबल एक साथ अपडेट करने की आवश्यकता रखते हैं क्योंकि सभी परिवर्तनों को एक फ़ाइल में लिखने के लिए प्रतीक्षा करना पड़ता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
binlog_common = 1 # use a single binary log file for all tables
```
<!-- end -->

### binlog_max_log_size

<!-- example conf binlog_max_log_size -->
यह सेटिंग अधिकतम बाइनरी लॉग फ़ाइल आकार को नियंत्रित करती है। यह वैकल्पिक है, डिफ़ॉल्ट मान 256 MB है।

एक नई बिनलॉग फ़ाइल मजबूरी से खोली जाएगी जब वर्तमान बिनलॉग फ़ाइल इस आकार सीमा को पार कर जाएगी। इससे लॉग के कोण में सूक्ष्मता आती है और कुछ बीमार कार्यभार के तहत बिनलॉग डिस्क उपयोग में अधिक कुशल हो सकती है। 0 का मान इंगित करता है कि बिनलॉग फ़ाइल को आकार के आधार पर फिर से नहीं खोला जाना चाहिए।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
binlog_max_log_size = 16M
```
<!-- end -->


### binlog_path

<!-- example conf binlog_path -->
यह सेटिंग बाइनरी लॉग (जिसे लेनदेन लॉग भी कहा जाता है) फ़ाइलों के लिए पथ निर्धारित करती है। यह वैकल्पिक है, डिफ़ॉल्ट मान बिल्ड-टाइम कॉन्फ़िगर किया गया डेटा निर्देशिका है (जैसे लिनक्स में `/var/lib/manticore/data/binlog.*`)।

बाइनरी लॉग का उपयोग आरटी टेबल डेटा की क्रैश रिकवरी और सामान्य डिस्क इंडिक्स के विशेषता अपडेट के लिए किया जाता है, जिन्हें अन्यथा फ्लश करने तक केवल RAM में संग्रहीत किया जाएगा। जब लॉगिंग सक्षम होती है, तो प्रत्येक लेनदेन जो एक आरटी टेबल में COMMIT किया जाता है उसे एक लॉग फ़ाइल में लिखा जाता है। लॉग फिर अनक्लीन शटडाउन के बाद प्रारंभ पर स्वचालित रूप से पुनः खेला जाता है, लॉग किए गए परिवर्तनों को पुनः प्राप्त करता है।

`binlog_path` निर्देशिका बाइनरी लॉग फ़ाइलों का स्थान निर्दिष्ट करता है। इसमें केवल पथ होना चाहिए; `searchd` आवश्यकतानुसार निर्देशिका में कई `binlog.*` फ़ाइलें बनाएगा और हटा देगा (बाइनरी लॉग डेटा, मेटाडेटा, और लॉक फ़ाइलें, आदि सहित)।

खाली मान बाइनरी लॉगिंग को बंद कर देता है, जो प्रदर्शन में सुधार करता है लेकिन आरटी टेबल डेटा को जोखिम में डालता है।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
binlog_path = # disable logging
binlog_path = /var/lib/manticore/data # /var/lib/manticore/data/binlog.001 etc will be created
```
<!-- अंत -->


### buddy_path

<!-- उदाहरण कॉन्फ़ buddy_path -->
यह सेटिंग Manticore Buddy बाइनरी के लिए पथ निर्धारित करती है। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान निर्माण के समय कॉन्फ़िगर किया गया पथ होता है, जो विभिन्न ऑपरेटिंग सिस्टम में भिन्न होता है। आमतौर पर, आपको इस सेटिंग को संशोधित करने की आवश्यकता नहीं होती है। हालांकि, यह उपयोगी हो सकता है यदि आप Manticore Buddy को डिबग मोड में चलाना चाहते हैं, Manticore Buddy में परिवर्तन करना चाहते हैं, या एक नया प्लगइन लागू करना चाहते हैं। बाद के मामले में, आप `git clone` Buddy को https://github.com/manticoresoftware/manticoresearch-buddy से कर सकते हैं, निर्देशिका `./plugins/` में एक नया प्लगइन जोड़ सकते हैं, और आसान विकास के लिए `composer install --prefer-source` चला सकते हैं जब आप निर्देशिका को Buddy स्रोत में बदल दें।

यह सुनिश्चित करने के लिए कि आप `composer` चला सकें, आपकी मशीन में PHP 8.2 या उच्चतर स्थापित होना चाहिए जिसमें निम्नलिखित एक्सटेंशन हों:

```
--enable-dom
--with-libxml
--enable-tokenizer
--enable-xml
--enable-xmlwriter
--enable-xmlreader
--enable-simplexml
--enable-phar
--enable-bcmath
--with-gmp
--enable-debug
--with-mysqli
--enable-mysqlnd
```

आप विशेष `manticore-executor-dev` संस्करण का विकल्प भी चुन सकते हैं जो Linux amd64 के लिए उपलब्ध है, उदाहरण के लिए: https://github.com/manticoresoftware/executor/releases/tag/v1.0.13

यदि आप इस मार्ग पर जाते हैं, तो dev संस्करण के Manticore executor को `/usr/bin/php` से लिंक करना न भूलें।

Manticore Buddy को बंद करने के लिए, मान को खाली सेट करें जैसा कि उदाहरण में दिखाया गया है।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
buddy_path = manticore-executor -n /usr/share/manticore/modules/manticore-buddy/src/main.php --debug # use the default Manticore Buddy in Linux, but run it in debug mode
buddy_path = manticore-executor -n /opt/homebrew/share/manticore/modules/manticore-buddy/bin/manticore-buddy/src/main.php --debug # use the default Manticore Buddy in MacOS arm64, but run it in debug mode
buddy_path = manticore-executor -n /Users/username/manticoresearch-buddy/src/main.php --debug # use Manticore Buddy from a non-default location
buddy_path = # disables Manticore Buddy
buddy_path = manticore-executor -n /Users/username/manticoresearch-buddy/src/main.php --debugv --skip=manticoresoftware/buddy-plugin-replace # debugv - enables more detailed logging, --skip - skips plugins
```
<!-- अंत -->

### client_timeout

<!-- उदाहरण कॉन्फ़ client_timeout -->
यह सेटिंग अनुरोधों के बीच अधिकतम समय निर्धारित करती है (सेकंड में या [विशेष_suffixes](../Server_settings/Special_suffixes.md)) जब स्थायी कनेक्शनों का उपयोग किया जा रहा हो। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान पांच मिनट है।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
client_timeout = 1h
```
<!-- अंत -->


### collation_libc_locale

<!-- उदाहरण कॉन्फ़ collation_libc_locale -->
सर्वर libc स्थानीयता। वैकल्पिक, डिफ़ॉल्ट C है।

libc स्थानीयता को निर्दिष्ट करता है, जो libc-आधारित समुच्चयों को प्रभावित करता है। विवरण के लिए [collations](../Searching/Collations.md) अनुभाग को देखें।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
collation_libc_locale = fr_FR
```
<!-- अंत -->


### collation_server

<!-- उदाहरण कॉन्फ़ collation_server -->
डिफ़ॉल्ट सर्वर समुच्चय। वैकल्पिक, डिफ़ॉल्ट libc_ci है।

यह आने वाले अनुरोधों के लिए उपयोग किए जाने वाले डिफ़ॉल्ट समुच्चय को निर्दिष्ट करता है। समुच्चय को प्रति-प्रश्न आधार पर अधिलेखित किया जा सकता है। उपलब्ध समुच्चयों और अन्य विवरणों की सूची के लिए [collations](../Searching/Collations.md) अनुभाग को देखें।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
collation_server = utf8_ci
```
<!-- अंत -->


### data_dir

<!-- उदाहरण कॉन्फ़ data_dir -->
जब निर्दिष्ट किया जाता है, तो यह सेटिंग [वास्तविक समय मोड](../Creating_a_table/Local_tables.md#Online-schema-management-%28RT-mode%29) को सक्षम करती है, जो डेटा स्कीमा प्रबंधन का एक अनिवार्य तरीका है। मान वह पथ होना चाहिए जहाँ आप अपनी सभी तालिकाएँ, बाइनरी लॉग और इस मोड में Manticore Search के उचित कार्य करने के लिए आवश्यक सब कुछ संग्रहीत करना चाहते हैं।
जब `data_dir` निर्दिष्ट किया गया है, तो [सामान्य तालिकाओं](../Creating_a_table/Local_tables/Plain_table.md) का अनुक्रमण अनुमति नहीं है। [इस अनुभाग](../Read_this_first.md#Real-time-table-vs-plain-table) में आरटी मोड और सामान्य मोड के बीच के अंतर के बारे में अधिक पढ़ें।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
data_dir = /var/lib/manticore
```
<!-- अंत -->

### diskchunk_flush_search_timeout

<!-- उदाहरण कॉन्फ़ diskchunk_flush_search_timeout -->
यदि तालिका में कोई खोजें नहीं हैं तो RAM chunk को ऑटो-फ्लश करने से रोकने के लिए समय सीमा। वैकल्पिक, डिफ़ॉल्ट 30 सेकंड है।

ऑटो-फ्लश निर्धारित करने से पहले खोजों के लिए समय की जाँच करें।
ऑटो-फ्लश केवल तभी होगा जब तालिका में पिछले `diskchunk_flush_search_timeout` सेकंड के भीतर कम से कम एक खोज हुई हो। यह [diskchunk_flush_write_timeout](../../Server_settings/Searchd.md#diskchunk_flush_write_timeout) के साथ मिलकर काम करता है। संबंधित [प्रति-तालिका सेटिंग](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_search_timeout) की प्राथमिकता अधिक है और यह इस उदाहरण-व्यापी डिफ़ॉल्ट को अधिलेखित करेगी, अधिक बारीक नियंत्रण प्रदान करते हुए।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
diskchunk_flush_search_timeout = 120s
```
<!-- अंत -->

### diskchunk_flush_write_timeout

<!-- उदाहरण कॉन्फ़ diskchunk_flush_write_timeout -->
RAM chunk को डिस्क पर ऑटो-फ्लश करने से पहले बिना लिखने के प्रतीक्षा करने के लिए समय सेकंड में। वैकल्पिक, डिफ़ॉल्ट 1 सेकंड है।

यदि `diskchunk_flush_write_timeout` सेकंड के भीतर RAM chunk में कोई लेखन नहीं होता है, तो chunk को डिस्क पर फ्लश किया जाएगा। यह [diskchunk_flush_search_timeout](../../Server_settings/Searchd.md#diskchunk_flush_search_timeout) के साथ मिलकर काम करता है। ऑटो-फ्लश को बंद करने के लिए, अपने कॉन्फ़िगरेशन में स्पष्ट रूप से `diskchunk_flush_write_timeout = -1` सेट करें। संबंधित [प्रति-तालिका सेटिंग](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#diskchunk_flush_write_timeout) की प्राथमिकता अधिक है और यह इस उदाहरण-व्यापी डिफ़ॉल्ट को अधिलेखित करेगी, अधिक बारीक नियंत्रण प्रदान करते हुए।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
diskchunk_flush_write_timeout = 60s
```
<!-- अंत -->

### docstore_cache_size

<!-- उदाहरण कॉन्फ़ docstore_cache_size -->
यह सेटिंग उस दस्तावेज़ भंडारण से दस्तावेज़ ब्लॉकों के अधिकतम आकार को निर्दिष्ट करती है जो मेमोरी में रखे जाते हैं। यह वैकल्पिक है, जिसका डिफ़ॉल्ट मान 16m (16 मेगाबाइट) है।

When `stored_fields` का प्रयोग किया जाता है, दस्तावेज़ ब्लॉक डिस्क से पढ़े जाते हैं और अनकंप्रेस किए जाते हैं। चूंकि प्रत्येक ब्लॉक सामान्यतः कई दस्तावेज़ों को रखता है, इसे अगले दस्तावेज़ को संसाधित करते समय पुनः उपयोग किया जा सकता है। इसके लिए, ब्लॉक को सर्वर-व्यापी कैश में रखा जाता है। कैश अनकंप्रेस किए गए ब्लॉकों को रखता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
docstore_cache_size = 8m
```
<!-- end -->

### इंजन

<!-- example conf engine -->
RT मोड में तालिकाएँ बनाते समय उपयोग किए जाने वाले डिफ़ॉल्ट विशेषता भंडारण इंजन। इसे `rowwise` (डिफ़ॉल्ट) या `columnar` के रूप में सेट किया जा सकता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
engine = columnar
```
<!-- end -->


### विस्तार_सीमा

<!-- example conf expansion_limit -->
यह सेटिंग एक एकल वाइल्डकार्ड के लिए अधिकतम विस्तारित कीवर्ड की संख्या निर्धारित करती है। यह वैकल्पिक है, जिसमें 0 (कोई सीमा नहीं) का डिफ़ॉल्ट मान है।

जब `dict = keywords` सक्षम के साथ तालिकाओं के खिलाफ उपस्ट्रिंग खोजें की जा रही हैं, तो एक एकल वाइल्डकार्ड संभावित रूप से हजारों या यहां तक कि लाखों मेल खाने वाले कीवर्ड उत्पन्न कर सकता है (पूरे ऑक्सफोर्ड शब्दकोश पर `a*` मिलाने के बारे में सोचें)। यह निर्देश आपको ऐसे विस्तार के प्रभाव को सीमित करने की अनुमति देता है। `expansion_limit = N` सेट करने से विस्तार को एकल वाइल्डकार्ड के लिए मेल खाने वाले सबसे अधिक सामान्य कीवर्ड के N से अधिक तक सीमित कर दिया जाता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
expansion_limit = 16
```
<!-- end -->

### विस्तार_विलय_सीमा_दस्तावेज़

<!-- example conf expansion_merge_threshold_docs -->
यह सेटिंग विस्तारित कीवर्ड में दस्तावेज़ों की अधिकतम संख्या निर्धारित करती है जो सभी ऐसे कीवर्ड को एक साथ विलय करने की अनुमति देती है। यह वैकल्पिक है, जिसमें 32 का डिफ़ॉल्ट मान है।

जब `dict = keywords` सक्षम के साथ तालिकाओं के खिलाफ उपस्ट्रिंग खोजें की जा रही हैं, तो एक एकल वाइल्डकार्ड संभावित रूप से हजारों या यहां तक कि लाखों मेल खाने वाले कीवर्ड उत्पन्न कर सकता है। यह निर्देश आपको कितने कीवर्ड एक साथ विलय कर सकते हैं, इसकी सीमा बढ़ाने की अनुमति देता है जिससे मिलान में तेजी आती है, लेकिन खोज में अधिक मेमोरी का उपयोग होता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
expansion_merge_threshold_docs = 1024
```
<!-- end -->

### विस्तार_विलय_सीमा_हिट्स

<!-- example conf expansion_merge_threshold_hits -->
यह सेटिंग विस्तारित कीवर्ड में हिट की अधिकतम संख्या निर्धारित करती है जो सभी ऐसे कीवर्ड को एक साथ विलय करने की अनुमति देती है। यह वैकल्पिक है, जिसमें 256 का डिफ़ॉल्ट मान है।

जब `dict = keywords` सक्षम के साथ तालिकाओं के खिलाफ उपस्ट्रिंग खोजें की जा रही हैं, तो एक एकल वाइल्डकार्ड संभावित रूप से हजारों या यहां तक कि लाखों मेल खाने वाले कीवर्ड उत्पन्न कर सकता है। यह निर्देश आपको कितने कीवर्ड एक साथ विलय कर सकते हैं, इसकी सीमा बढ़ाने की अनुमति देता है जिससे मिलान में तेजी आती है, लेकिन खोज में अधिक मेमोरी का उपयोग होता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
expansion_merge_threshold_hits = 512
```
<!-- end -->

### समूह_utc_में

यह सेटिंग निर्दिष्ट करती है कि एपीआई और SQL में समय के अनुसार समूह बनाना स्थानीय समय क्षेत्र में या UTC में गणना की जाएगी। यह वैकल्पिक है, जिसमें 0 (''स्थानीय समय क्षेत्र'') का डिफ़ॉल्ट मान है।

डिफ़ॉल्ट रूप से, सभी 'समय के अनुसार समूह' आवश्यकताएँ (जैसे एपीआई में दिन, सप्ताह, महीने और वर्ष के अनुसार समूह, साथ ही SQL में दिन, महीने, वर्ष, वर्षमहीना, वर्षमहीनादिन के अनुसार समूह) स्थानीय समय का उपयोग करके की जाती हैं। उदाहरण के लिए, अगर आपके पास `13:00 utc` और `15:00 utc` के साथ समय के अनुसार दस्तावेज़ हैं, समूह बनाने के मामले में, वे दोनों आपके स्थानीय समय क्षेत्र सेटिंग के अनुसार सुविधा समूहों में गिरेंगे। अगर आप `utc` में रहते हैं, तो यह एक दिन होगा, लेकिन अगर आप `utc+10` में रहते हैं, तो ये दस्तावेज़ अलग-अलग `दिन के अनुसार समूह` सुविधा समूहों में मिलेंगे (चूंकि 13:00 utc UTC+10 समय क्षेत्र में 23:00 स्थानीय समय है, लेकिन 15:00 अगले दिन के 01:00 है)। कभी-कभी ऐसा व्यवहार अस्वीकार्य होता है, और समय समूह को समय क्षेत्र पर निर्भर न करना वांछनीय होता है। आप परिभाषित वैश्विक TZ वातावरण चर के साथ सर्वर चला सकते हैं, लेकिन इससे न केवल समूह पर बल्कि लॉग में टाइमस्टैम्पिंग पर भी प्रभाव पड़ेगा, जो भी वांछनीय नहीं हो सकता है। इस विकल्प को 'चालू' करने से (चाहे कॉन्फ़िग में या SQL में [SET global](../Server_settings/Setting_variables_online.md#SET) कथन का उपयोग करके) सभी समय समूह आवश्यकताएँ UTC में गणना की जाएँगी, शेष समय-निर्भर कार्यों (जैसे सर्वर की लॉगिंग) को स्थानीय TZ में छोड़कर।


### समय क्षेत्र

यह सेटिंग तारीख/समय से संबंधित कार्यों के लिए उपयोग किए जाने वाले समय क्षेत्र को निर्दिष्ट करती है। डिफ़ॉल्ट रूप से, स्थानीय समय क्षेत्र का उपयोग किया जाता है, लेकिन आप IANA प्रारूप (जैसे, `Europe/Amsterdam`) में एक अलग समय क्षेत्र निर्दिष्ट कर सकते हैं।

ध्यान दें कि इस सेटिंग का लॉगिंग पर कोई प्रभाव नहीं पड़ता, जो हमेशा स्थानीय समय क्षेत्र में काम करता है।

इसके अलावा, ध्यान दें कि यदि `grouping_in_utc` का उपयोग किया जाता है, तो 'समय के अनुसार समूह' कार्य अभी भी UTC का उपयोग करेगा, जबकि अन्य तारीख/समय से संबंधित कार्य निर्दिष्ट समय क्षेत्र का उपयोग करेंगे। कुल मिलाकर, `grouping_in_utc` और `timezone` को मिलाना अनुशंसित नहीं है।

आप इस विकल्प को कॉन्फ़िग में या SQL में [SET global](../Server_settings/Setting_variables_online.md#SET) कथन का उपयोग करके कॉन्फ़िगर कर सकते हैं।


### ha_period_karma

<!-- example conf ha_period_karma -->
यह सेटिंग एजेंट मिरर सांख्यिकी विंडो आकार, सेकंड में (या [special_suffixes](../Server_settings/Special_suffixes.md)) को निर्दिष्ट करती है। यह वैकल्पिक है, जिसमें 60 सेकंड का डिफ़ॉल्ट मान होता है।

एक वितरित तालिका के लिए जिसमें एजेंट मिरर होते हैं (देखें [एजेंट](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md), मास्टर कई अलग-अलग प्रति-मीरर काउंटर को ट्रैक करता है। इन काउंटर को फ़ेलओवर और संतुलन के लिए उपयोग किया जाता है (मास्टर काउंटर के आधार पर उपयोग के लिए सबसे अच्छे मीरर का चयन करता है)। काउंटर `ha_period_karma` सेकंड के ब्लॉकों में एकत्रित होते हैं।

नए ब्लॉक की शुरुआत के बाद, मास्टर पिछले से संचित मानों का उपयोग कर सकता है जब तक कि नया आधा भरा नहीं हो जाता। इसके परिणामस्वरूप, कोई भी पिछला इतिहास मीरर चयन को अधिकतम 1.5 गुना ha_period_karma सेकंड के बाद रोक देता है।

हालांकि अधिकतम दो ब्लॉकों का उपयोग मीरर चयन के लिए किया जाता है, लेकिन परीक्षण उद्देश्यों के लिए पिछले 15 ब्लॉकों को संग्रहीत किया जाता है। इन ब्लॉकों की जांच [SHOW AGENT STATUS](../Node_info_and_management/Node_status.md#SHOW-AGENT-STATUS) कथन का उपयोग करके की जा सकती है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
ha_period_karma = 2m
```
<!-- end -->


### ha_ping_interval

<!-- example conf ha_ping_interval -->
यह सेटिंग एजेंट मिरर पिंग्स के बीच का अंतराल कॉन्फ़िगर करती है, मिलीसेकंड में (या [special_suffixes](../Server_settings/Special_suffixes.md))। यह वैकल्पिक है, जिसमें डिफ़ॉल्ट मान 1000 मिलीसेकंड है।

एक वितरित तालिका के लिए जिसमें एजेंट मिरर हैं (देखें अधिक जानकारी [एजेंट](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md)), मास्टर सभी मिरर को निष्क्रिय अवधि के दौरान एक पिंग कमांड भेजता है। इसका उद्देश्य वर्तमान एजेंट स्थिति (जिंदा या मृत, नेटवर्क राउंडट्रिप, आदि) को ट्रैक करना है। ऐसे पिंग्स के बीच का अंतराल इस निर्देश से परिभाषित होता है। पिंग को अक्षम करने के लिए, ha_ping_interval को 0 पर सेट करें।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
ha_ping_interval = 3s
```
<!-- end -->


### hostname_lookup

`hostname_lookup` विकल्प होस्ट नामों को नवीनीकरण के लिए रणनीति को परिभाषित करता है। डिफ़ॉल्ट रूप से, एजेंट होस्ट नामों के आईपी पते सर्वर स्टार्ट पर कैश किए जाते हैं ताकि DNS तक अत्यधिक पहुंच से बचा जा सके। हालांकि, कुछ मामलों में, आईपी गतिशील रूप से बदल सकता है (जैसे, क्लाउड होस्टिंग) और आईपी को कैश न करना वांछनीय हो सकता है। इस विकल्प को `request` पर सेट करने से कैशिंग अक्षम हो जाती है और प्रत्येक प्रश्न के लिए DNS से क्वेरी की जाती है। आईपी पतों को `FLUSH HOSTNAMES` कमांड का उपयोग करके भी मैन्युअल रूप से नवीनीकरण किया जा सकता है।

### jobs_queue_size

jobs_queue_size सेटिंग परिभाषित करती है कि एक समय में कतार में कितने "काम" हो सकते हैं। डिफ़ॉल्ट रूप से यह अनलिमिटेड है।

अधिकांश मामलों में, "काम" का अर्थ एक एकल स्थानीय तालिका (साधारण तालिका या वास्तविक समय तालिका का डिस्क टुकड़ा) के लिए एक क्वेरी है। उदाहरण के लिए, यदि आपके पास 2 स्थानीय तालिकाओं या 2 डिस्क टुकड़ों के साथ एक वास्तविक समय तालिका वाली एक वितरित तालिका है, तो इनमें से किसी भी एक पर खोज क्वेरी मुख्यतः 2 काम कतार में डाल देगी। फिर, थ्रेड पूल (जिसका आकार [threads](../Server_settings/Searchd.md#threads) द्वारा परिभाषित किया गया है) उन्हें संसाधित करेगा। हालांकि, कुछ मामलों में, यदि क्वेरी बहुत जटिल है, तो अधिक काम बनाए जा सकते हैं। इस सेटिंग को बदलना तभी अनुशंसित है जब [max_connections](../Server_settings/Searchd.md#max_connections) और [threads](../Server_settings/Searchd.md#threads) वांछित प्रदर्शन के बीच संतुलन खोजने के लिए पर्याप्त नहीं हैं।

### join_batch_size

तालिका जोड़ तब काम करते हैं जब मिलान के एक बैच को इकट्ठा किया जाता है, जो बाएँ तालिका पर निष्पादित क्वेरी के परिणाम होते हैं। इस बैच को फिर दाएँ तालिका पर एक एकल क्वेरी के रूप में संसाधित किया जाता है।

यह विकल्प आपको बैच के आकार को समायोजित करने की अनुमति देता है। डिफ़ॉल्ट मान `1000` है, और इस विकल्प को `0` पर सेट करने से बैचिंग अक्षम हो जाती है।

एक बड़ा बैच आकार प्रदर्शन में सुधार कर सकता है; हालाँकि, कुछ क्वेरियों के लिए, यह अत्यधिक मेमोरी खपत का कारण बन सकता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
join_batch_size = 2000
```
<!-- end -->

### join_cache_size

हर क्वेरी जो दाएँ तालिका पर निष्पादित होती है, विशेष JOIN ON परिस्थितियों द्वारा परिभाषित होती है, जो दाएँ तालिका से पुनः प्राप्त किया गया परिणाम सेट निर्धारित करती है।

यदि केवल कुछ अद्वितीय JOIN ON परिस्थितियाँ हैं, तो परिणामों को फिर से उपयोग करना बार-बार दाएँ तालिका पर क्वेरियों को निष्पादित करने की तुलना में अधिक प्रभावी हो सकता है। इसे सक्षम करने के लिए, परिणाम सेट को कैश में संग्रहीत किया जाता है।

यह विकल्प आपको इस कैश के आकार को कॉन्फ़िगर करने की अनुमति देता है। डिफ़ॉल्ट मान `20 MB` है, और इस विकल्प को 0 पर सेट करने से कैशिंग अक्षम हो जाती है।

ध्यान दें कि प्रत्येक थ्रेड अपनी खुद की कैश बनाए रखता है, इसलिए कुल मेमोरी उपयोग का अनुमान लगाते समय आपको क्वेरियाँ निष्पादित करने वाले थ्रेड की संख्या को ध्यान में रखना चाहिए।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
join_cache_size = 10M
```
<!-- end -->

### listen_backlog

<!-- example conf listen_backlog -->
listen_backlog सेटिंग इनकमिंग कनेक्शंस के लिए TCP सुनने की बैक्लॉग की लंबाई निर्धारित करती है। यह विशेष रूप से उन विंडोज बिल्ड के लिए प्रासंगिक है जो अनुरोधों को एक-एक करके संसाधित करते हैं। जब कनेक्शन कतार अपने सीमा तक पहुँच जाती है, तो नए इनकमिंग कनेक्शन्स को अस्वीकार कर दिया जाएगा।
गैर-विंडोज बिल्ड के लिए, डिफ़ॉल्ट मान ठीक से काम करना चाहिए, और आमतौर पर इस सेटिंग को समायोजित करने की आवश्यकता नहीं होती है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
listen_backlog = 20
```
<!-- end -->

### kibana_version_string

<!-- example conf kibana_version_string -->
Kibana या OpenSearch Dashboards को वापस करने के लिए एक सर्वर संस्करण स्ट्रिंग। वैकल्पिक - डिफ़ॉल्ट रूप से, इसे `7.6.0` पर सेट किया गया है।

Kibana और OpenSearch Dashboards के कुछ संस्करणों को सर्वर द्वारा एक विशेष संस्करण संख्या की रिपोर्ट की उम्मीद होती है, और इसके आधार पर भिन्न व्यवहार कर सकते हैं। ऐसे मुद्दों से बचने के लिए, आप इस सेटिंग का उपयोग कर सकते हैं, जो Manticore को Kibana या OpenSearch Dashboards को एक कस्टम संस्करण रिपोर्ट करता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
kibana_version_string = 1.2.3
```
<!-- end -->

### listen

<!-- example conf listen -->
यह सेटिंग आपको एक आईपी पता और पोर्ट, या यूनिक्स-डोमेन सॉकेट पथ निर्दिष्ट करने की अनुमति देती है, जिस पर Manticore कनेक्शन स्वीकार करेगा।

`listen` के लिए सामान्य सिंटैक्स है:

```ini
listen = ( address ":" port | port | path | address ":" port start - port end ) [ ":" protocol [ "_vip" ] [ "_readonly" ] ]
```

आप निर्दिष्ट कर सकते हैं:
* या तो एक आईपी पता (या होस्टनेम) और एक पोर्ट नंबर
* या केवल एक पोर्ट नंबर
* या एक यूनिक्स सॉकेट पथ (विंडोज पर समर्थित नहीं)
* या एक आईपी पता और पोर्ट रेंज

यदि आप एक पोर्ट नंबर निर्दिष्ट करते हैं लेकिन एक पता नहीं, तो `searchd` सभी नेटवर्क इंटरफेस पर सुनेंगे। यूनिक्स पथ को एक प्रारंभिक स्लैश द्वारा पहचाना जाता है। पोर्ट रेंज केवल पुनरुत्पादन प्रोटोकॉल के लिए सेट किया जा सकता है।

आप इस सॉकेट पर कनेक्शनों के लिए उपयोग किए जाने वाले प्रोटोकॉल हैंडलर (श्रोता) को भी निर्दिष्ट कर सकते हैं। श्रोता हैं:

* **निर्दिष्ट नहीं किया गया** - Manticore इस पोर्ट पर कनेक्शन स्वीकार करेगा:
  - अन्य Manticore एजेंटों से (यानी, एक दूरस्थ वितरित तालिका)
  - HTTP और HTTPS के माध्यम से क्लाइंट
  - [Manticore Buddy](https://manticoresearch.com/blog/manticoresearch-buddy-intro/). **यह सुनिश्चित करें कि आपके पास इस प्रकार का एक श्रोता (या नीचे उल्लेखित `http` श्रोता) है ताकि Manticore कार्यक्षमता में सीमाओं से बचा जा सके।**
* `mysql` MySQL प्रोटोकॉल MySQL ग्राहकों से कनेक्शनों के लिए। ध्यान दें:
  - संकुचित प्रोटोकॉल भी समर्थित है।
  - यदि [SSL](../Security/SSL.md#SSL) सक्षम है, तो आप एक एन्क्रिप्टेड कनेक्शन बना सकते हैं।
* `replication` - नोड्स संवाद के लिए प्रयुक्त प्रजनन प्रोटोकॉल। इसके बारे में अधिक जानकारी [replication](../Creating_a_cluster/Setting_up_replication/Setting_up_replication.md) सेक्शन में मिल सकती है। आप कई प्रजनन श्रोताओं को निर्दिष्ट कर सकते हैं, लेकिन उन्हें सभी को एक ही IP पर सुनना होगा; केवल पोर्ट अलग हो सकते हैं। जब आप एक पोर्ट रेंज के साथ एक प्रजनन श्रवक को परिभाषित करते हैं (जैसे, `listen = 192.168.0.1:9320-9328:replication`), तो Manticore तुरंत इन पोर्टों पर सुनना शुरू नहीं करता है। इसके बजाय, यह केवल तब निर्दिष्ट रेंज से यादृच्छिक मुक्त पोर्ट लेगा जब आप प्रजनन का उपयोग करना शुरू करेंगे। प्रजनन के ठीक से काम करने के लिए रेंज में कम से कम 2 पोर्ट की आवश्यकता होती है।
* `http` - **Not specified** के समान। Manticore इस पोर्ट पर दूरस्थ एजेंटों और ग्राहकों से HTTP और HTTPS के माध्यम से कनेक्शन स्वीकार करेगा।
* `https` - HTTPS प्रोटोकॉल। Manticore इस पोर्ट पर **केवल** HTTPS कनेक्शन स्वीकार करेगा। इसके बारे में अधिक जानकारी [SSL](../Security/SSL.md) सेक्शन में मिल सकती है।
* `sphinx` - पूर्ववर्ती बाइनरी प्रोटोकॉल। यह दूरस्थ [SphinxSE](../Extensions/SphinxSE.md) ग्राहकों से कनेक्शन सेवा देने के लिए उपयोग किया जाता है। कुछ Sphinx API ग्राहक कार्यान्वयन (एक उदाहरण Java वाला) श्रवक के स्पष्ट घोषणा की आवश्यकता होती है।

ग्राहक प्रोटोकॉलों में उपसर्ग `_vip` जोड़ने (यानी, सभी को छोड़कर `replication`, जैसे `mysql_vip` या `http_vip` या केवल `_vip`) कनेक्शन के लिए एक समर्पित थ्रेड बनाने के लिए मजबूर करता है ताकि विभिन्न सीमाओं को बायपास किया जा सके। यह गंभीर अधिभार की स्थिति में नोड रखरखाव के लिए उपयोगी है जब सर्वर या तो रुक जाता है या अन्यथा एक सामान्य पोर्ट के माध्यम से आपको कनेक्ट नहीं करने देता।

उपसर्ग `_readonly` श्रवक के लिए [पठनीय अवस्था](../Security/Read_only.md) सेट करता है और इसे केवल पठन प्रश्नों को स्वीकार करने तक सीमित करता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
listen = localhost
listen = localhost:5000 # listen for remote agents (binary API) and http/https requests on port 5000 at localhost
listen = 192.168.0.1:5000 # listen for remote agents (binary API) and http/https requests on port 5000 at 192.168.0.1
listen = /var/run/manticore/manticore.s # listen for binary API requests on unix socket
listen = /var/run/manticore/manticore.s:mysql # listen for mysql requests on unix socket
listen = 9312 # listen for remote agents (binary API) and http/https requests on port 9312 on any interface
listen = localhost:9306:mysql # listen for mysql requests on port 9306 at localhost
listen = localhost:9307:mysql_readonly # listen for mysql requests on port 9307 at localhost and accept only read queries
listen = 127.0.0.1:9308:http # listen for http requests as well as connections from remote agents (and binary API) on port 9308 at localhost
listen = 192.168.0.1:9320-9328:replication # listen for replication connections on ports 9320-9328 at 192.168.0.1
listen = 127.0.0.1:9443:https # listen for https requests (not http) on port 9443 at 127.0.0.1
listen = 127.0.0.1:9312:sphinx # listen for legacy Sphinx requests (e.g. from SphinxSE) on port 9312 at 127.0.0.1
```
<!-- end -->

कई `listen` निर्देश हो सकते हैं। `searchd` सभी निर्दिष्ट पोर्टों और सॉकेट्स पर ग्राहक कनेक्शनों के लिए सुनेगा। Manticore पैकेज में प्रदान की गई डिफ़ॉल्ट कॉन्फ़िगरेशन में पोर्ट पर सुनने की परिभाषा है:
* `9308` और `9312` दूरस्थ एजेंटों और गैर-MySQL आधारित ग्राहकों से कनेक्शनों के लिए 
* और MySQL कनेक्शनों के लिए पोर्ट `9306` पर।

यदि आप कॉन्फ़िगरेशन में कोई `listen` निर्दिष्ट नहीं करते हैं, तो Manticore कनेक्शनों का इंतजार करेगा:
* `127.0.0.1:9306` MySQL ग्राहकों के लिए
* `127.0.0.1:9312` HTTP/HTTPS और अन्य Manticore नोड्स और Manticore बाइनरी API आधारित ग्राहकों से कनेक्शनों के लिए।

#### विशेषाधिकार प्राप्त पोर्ट पर सुनना

डिफ़ॉल्ट रूप से, Linux आपको Manticore को 1024 से नीचे के पोर्ट पर सुनने की अनुमति नहीं देगा (उदाहरण के लिए, `listen = 127.0.0.1:80:http` या `listen = 127.0.0.1:443:https`) जब तक आप searchd को रूट के तहत नहीं चलाते। यदि आप अभी भी Manticore को प्रारंभ करने में सक्षम होना चाहते हैं ताकि यह गैर-रूट उपयोगकर्ता के तहत 1024 से कम पोर्ट पर सुने, तो इनमें से एक करने पर विचार करें (इनमें से कोई भी काम करना चाहिए):
* कमांड `setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/searchd` चलाएं
* Manticore के systemd यूनिट में `AmbientCapabilities=CAP_NET_BIND_SERVICE` जोड़ें और डेमन को फिर से लोड करें (`systemctl daemon-reload`)।

#### Sphinx API प्रोटोकॉल और TFO के बारे में तकनीकी विवरण
<details>
पूर्ववर्ती Sphinx प्रोटोकॉल में 2 चरण होते हैं: हैंडशेक आदान-प्रदान और डेटा प्रवाह। हैंडशेक में ग्राहक से 4 बाइट का एक पैकेट होता है, और डेमन से 4 बाइट का एक पैकेट केवल एक उद्देश्य के साथ - ग्राहक यह निर्धारित करता है कि दूरस्थ एक वास्तविक Sphinx डेमन है, डेमन यह निर्धारित करता है कि दूरस्थ एक वास्तविक Sphinx ग्राहक है। मुख्य डेटा प्रवाह काफी सरल है: चलो दोनों पक्ष अपने हैंडशेक की घोषणा करते हैं, और विपरीत उन्हें जांचता है। छोटा पैकेट के साथ उस क्रॉस का आदान-प्रदान विशेष `TCP_NODELAY` फ्लैग का उपयोग करने को दार्शनिक करता है, जो नागले के TCP एल्गोरिदम को बंद करता है और यह घोषणा करता है कि TCP कनेक्शन छोटे पैकेजों की बातचीत के रूप में किया जाएगा।
हालांकि, इस बातचीत में पहले बोलने वाले का सख्त रूप से परिभाषित नहीं है। ऐतिहासिक रूप से, सभी ग्राहक जो बाइनरी API का उपयोग करते हैं पहले बोलते हैं: हैंडशेक भेजते हैं, फिर डेमन से 4 बाइट पढ़ते हैं, फिर एक अनुरोध भेजते हैं और डेमन से एक उत्तर पढ़ते हैं।
जब हमने Sphinx प्रोटोकॉल की संगतता में सुधार किया, तो हमने इन बातों पर विचार किया:

1. आमतौर पर, मास्टर-एजेंट संवाद एक ज्ञात ग्राहक से एक ज्ञात होस्ट पर एक ज्ञात पोर्ट पर स्थापित किया जाता है। इसलिए, यह संभव नहीं है कि एंडपॉइंट गलत हैंडशेक प्रदान करेगा। इसलिए, हम अप्रत्यक्ष रूप से मान सकते हैं कि दोनों पक्ष मान्य हैं और वास्तव में Sphinx प्रोटोकॉल में बात कर रहे हैं।
2. इस धारणा को देखते हुए, हम एक हैंडशेक को वास्तविक अनुरोध से 'चिपका' सकते हैं और इसे एक पैकेट में भेज सकते हैं। यदि बैकएंड एक पूर्ववर्ती Sphinx डेमन है, तो वह इस चिपके पैकेट को 4 बाइट के हैंडशेक के रूप में पढ़ेगा, फिर अनुरोध का शरीर। चूंकि वे दोनों एक पैकेट में आए थे, बैकएंड सॉकेट में -1 RTT है, और फ्रंटएंड बफर फिर भी इस तथ्य के बावजूद काम करता है।
3. धारणा को आगे बढ़ाते हुए: चूंकि 'query' पैकेट काफी छोटा है, और हैंडशेक तो और भी छोटा है, चलो दोनों को प्रारंभिक 'SYN' TCP पैकेट में आधुनिक TFO (tcp-fast-open) तकनीक का उपयोग करते हुए भेजते हैं। अर्थात: हम चिपके हैंडशेक + शरीर पैकेट के साथ एक दूरस्थ नोड से कनेक्ट करते हैं। डेमन कनेक्शन स्वीकार करता है और तुरंत उसके पास हैंडशेक और शरीर दोनों होते हैं एक सॉकेट बफर में, जैसे वे पहले TCP 'SYN' पैकेट में आए थे। इससे एक और RTT समाप्त हो जाता है।
4. अंततः, डेमन को इस सुधार को स्वीकार करने के लिए सिखाना। वास्तव में, एप्लिकेशन की तरफ से, इसका तात्पर्य है कि `TCP_NODELAY` का उपयोग न करें। और, सिस्टम की तरफ से, इसका तात्पर्य है कि यह सुनिश्चित करें कि डेमन की तरफ, TFO स्वीकार करना सक्रिय है, और ग्राहक की तरफ, TFO भेजना भी सक्रिय है। डिफ़ॉल्ट रूप से, आधुनिक सिस्टम में, ग्राहक TFO पहले से ही डिफ़ॉल्ट रूप से सक्रिय है, इसलिए आपको सभी चीजों के काम करने के लिए केवल सर्वर TFO को ट्यून करना होगा।

इन सभी सुधारों ने वास्तव में प्रोटोकॉल को बदले बिना TCP प्रोटोकॉल के 1.5 RTT को कनेक्शन से समाप्त करने की अनुमति दी। जो यदि प्रश्न और उत्तर को एक ही TCP पैकेट में रखा जा सके, तो पूरी बाइनरी API सत्र को 3.5 RTT से 2 RTT तक कम कर देता है - जो नेटवर्क बातचीत को लगभग 2 गुना तेज बना देता है।

So, सभी हमारे सुधार एक प्रारंभिक रूप सेUndefined कथन के चारों ओर निर्धारित हैं: 'जो पहला बोलता है।' यदि एक ग्राहक सबसे पहले बोलता है, तो हम इन सभी अनुकूलन लागू कर सकते हैं और प्रभावी ढंग से कनेक्ट + हैंडशेक + क्वेरी को एक ही TFO पैकेज में प्रोसेस कर सकते हैं। इसके अलावा, हम प्राप्त पैकेज की शुरुआत पर देख सकते हैं और एक वास्तविक प्रोटोकॉल निर्धारित कर सकते हैं। यही कारण है कि आप API/http/https के माध्यम से एक ही पोर्ट से कनेक्ट कर सकते हैं। यदि डेमन को सबसे पहले बोलना है, तो ये सभी अनुकूलन असंभव हैं, और मल्टीप्रोटोकॉल भी असंभव है। यही कारण है कि हमारे पास MySQL के लिए एक समर्पित पोर्ट है और हमने इसे सभी अन्य प्रोटोकॉल के साथ एक ही पोर्ट में एकीकृत नहीं किया। अचानक, सभी ग्राहकों में से, एक ऐसा लिखा गया था जिसमें उल्लेख किया गया था कि डेमन को पहले हैंडशेक भेजना चाहिए। अर्थात - सभी वर्णित सुधारों का कोई संभव नहीं। यह SphinxSE प्लगइन mysql/mariadb के लिए है। तो, विशेष रूप से इस एकल ग्राहक के लिए, हमने 'sphinx' प्रोटोकॉल परिभाषा को सबसे विरासत तरीके से काम करने के लिए समर्पित किया। अर्थात्: दोनों पक्ष 'TCP_NODELAY' सक्रिय करते हैं और छोटे पैकेज के साथ आदान-प्रदान करते हैं। डेमन कनेक्ट पर अपना हैंडशेक भेजता है, फिर ग्राहक अपना भेजता है, और फिर सब कुछ सामान्य तरीके से काम करता है। यह बहुत अनुकूल नहीं है, लेकिन बस काम करता है। यदि आप SphinxSE का उपयोग करके Manticore से कनेक्ट करते हैं - तो आपको 'sphinx' प्रोटोकॉल के साथ स्पष्ट रूप से stated एक श्रोता समर्पित करना होगा। अन्य ग्राहकों के लिए - इस श्रोता का उपयोग करने से बचें क्योंकि यह धीमा है। यदि आप अन्य विरासत Sphinx API ग्राहकों का उपयोग कर रहे हैं - तो पहले जांचें कि क्या वे गैर-समर्पित मल्टीप्रोटोकॉल पोर्ट के साथ काम करने में सक्षम हैं। मास्टर-एजेंट लिंक के लिए गैर-समर्पित (मल्टीप्रोटोकॉल) पोर्ट का उपयोग करना और क्लाइंट और सर्वर TFO को सक्षम करना अच्छी तरह से काम करता है और निश्चित रूप से नेटवर्क बैकएंड का काम तेज करेगा, विशेष रूप से यदि आपके पास बहुत हल्के और तेज़ क्वेरी हैं।
</details>

### listen_tfo

यह सेटिंग सभी श्रोताओं के लिए TCP_FASTOPEN फ्लैग की अनुमति देती है। डिफ़ॉल्ट रूप से, इसे सिस्टम द्वारा प्रबंधित किया जाता है लेकिन इसे '0' पर सेट करके स्पष्ट रूप से बंद किया जा सकता है।

TCP Fast Open विस्तार के बारे में सामान्य ज्ञान के लिए, कृपया [विकिपीडिया](https://en.wikipedia.org/wiki/TCP_Fast_Open) से परामर्श करें। संक्षेप में, यह कनेक्शन स्थापित करते समय एक TCP राउंड-ट्रिप को समाप्त करने की अनुमति देता है।

व्यवहार में, कई स्थितियों में TFO का उपयोग ग्राहक-एजेंट नेटवर्क दक्षता को अनुकूलित कर सकता है, जैसे कि यदि [स्थायी एजेंट](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) खेल में हैं, लेकिन सक्रिय कनेक्शन नहीं रखते हैं, और कबूतर शाखा के लिए अधिकतम कनेक्शन की संख्या के लिए कोई सीमा नहीं है।

आधुनिक OS पर, TFO समर्थन आमतौर पर सिस्टम स्तर पर 'चालू' होता है, लेकिन यह सिर्फ एक 'क्षमता' है, नियम नहीं। लिनक्स (जैसा कि सबसे प्रगतिशील) ने इसे 2011 से समर्थित किया है, 3.7 से शुरू होने वाले कर्नेल पर (सर्वर-पक्ष के लिए)। विंडोज ने इसकी समर्थन कुछ विंडोज 10 के निर्माणों से किया है। अन्य ऑपरेटिंग सिस्टम (FreeBSD, MacOS) भी खेल में हैं।

लिनक्स सिस्टम सर्वर जांचता है चर `/proc/sys/net/ipv4/tcp_fastopen` और इसके अनुसार व्यवहार करता है। बिट 0 ग्राहक पक्ष को प्रबंधित करता है, बिट 1 श्रोताओं के नियमों को प्रबंधित करता है। डिफ़ॉल्ट रूप से, सिस्टम ने इस पैरामीटर को 1 पर सेट किया है, यानी, ग्राहक सक्षम हैं, श्रोता अक्षम हैं।

### log

<!-- example conf log -->
लॉग सेटिंग उस लॉग फ़ाइल का नाम निर्दिष्ट करती है जहां सभी `searchd` चलने के समय की घटनाएं लॉग की जाएंगी। यदि निर्दिष्ट नहीं किया गया, तो डिफ़ॉल्ट नाम 'searchd.log' है।

वैकल्पिक रूप से, आप फ़ाइल नाम के रूप में 'syslog' का उपयोग कर सकते हैं। इस स्थिति में, घटनाएँ syslog डेमन को भेजी जाएंगी। syslog विकल्प का उपयोग करने के लिए, आपको निर्माण के दौरान Manticore को `-–with-syslog` विकल्प के साथ कॉन्फ़िगर करना होगा।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
log = /var/log/searchd.log
```
<!-- end -->


### max_batch_queries

<!-- example conf max_batch_queries -->
बैच प्रति क्वेरी की मात्रा को सीमित करता है। वैकल्पिक, डिफ़ॉल्ट 32 है।

searchd को [multi-queries](../Searching/Multi-queries.md) का उपयोग करते समय एकल बैच में प्रस्तुत की गई क्वेरियों की मात्रा की एक सत्यता जांच करने के लिए मजबूर करता है। जांच को छोड़ने के लिए इसे 0 पर सेट करें।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
max_batch_queries = 256
```
<!-- end -->

### max_connections

<!-- example max_connections -->
एक साथ अधिकतम ग्राहक कनेक्शन की संख्या। डिफ़ॉल्ट रूप से अनलिमिटेड। यह आमतौर पर किसी भी प्रकार के स्थायी कनेक्शन का उपयोग करते समय ही ध्यान देने योग्य होते हैं, जैसे कि cli mysql सत्र या दूरस्थ वितरण तालिकाओं से स्थायी दूरस्थ कनेक्शन। जब सीमा को पार किया जाता है, तो आप अभी भी [VIP कनेक्शन](../Connecting_to_the_server/MySQL_protocol.md#VIP-connection) का उपयोग करके सर्वर से कनेक्ट कर सकते हैं। VIP कनेक्शन सीमा की गिनती में शामिल नहीं होते हैं।

<!-- request Example -->
```ini
max_connections = 10
```

<!-- end -->

### max_threads_per_query

<!-- example max_threads_per_query -->
एक ऑपरेशन उपयोग कर सकने वाले थ्रेडों की प्रति उदाहरण सीमा। डिफ़ॉल्ट रूप से, उपयुक्त ऑपरेशनों को सभी CPU कोर कब्जा करने की अनुमति होती है, जिससे अन्य संचालन के लिए कोई जगह नहीं बचती। उदाहरण के लिए, एक काफी बड़े पर्कोलेट तालिका के खिलाफ 'call pq' क एक्ज़ामिनेशन कई सेकंड के लिए सभी थ्रेडों का इस्तेमाल कर सकती है। 'max_threads_per_query' को, कहने के लिए, [threads](../Server_settings/Searchd.md#threads) का आधा सेट करना यह सुनिश्चित करेगा कि आप ऐसे 'call pq' संचालन को समानांतर में चला सकते हैं।

आप इस सेटिंग को रनटाइम के दौरान सत्र या एक वैश्विक चर के रूप में भी सेट कर सकते हैं।

अतिरिक्त रूप से, आप [threads OPTION](../Searching/Options.md#threads) की मदद से प्रति-क्वेरी आधार पर व्यवहार को नियंत्रित कर सकते हैं।

<!-- intro -->
##### उदाहरण:
<!-- request Example -->

```ini
max_threads_per_query = 4
```

<!-- end -->

### max_filters

<!-- example conf max_filters -->
प्रति-क्वेरी फ़िल्टर की अधिकतम अनुमति संख्या। यह सेटिंग केवल आंतरिक सत्यता जांचों के लिए उपयोग की जाती है और सीधे RAM उपयोग या प्रदर्शन को प्रभावित नहीं करती है। वैकल्पिक, डिफ़ॉल्ट 256 है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
max_filters = 1024
```
<!-- end -->


### max_filter_values

<!-- example conf max_filter_values -->
प्रति-फ़िल्टर मानों की अधिकतम अनुमति संख्या। यह सेटिंग केवल आंतरिक सत्यता जांचों के लिए उपयोग की जाती है और सीधे RAM उपयोग या प्रदर्शन को प्रभावित नहीं करती है। वैकल्पिक, डिफ़ॉल्ट 4096 है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
max_filter_values = 16384
```
<!-- end -->


### max_open_files

<!-- example conf max_open_files -->
सर्वर द्वारा खोले जाने के लिए अधिकतम फ़ाइलों की संख्या को "सॉफ्ट लिमिट" कहा जाता है। ध्यान दें कि बड़े खंडित वास्तविक समय की तालिकाओं की सेवा करते समय, इस सीमा को उच्च पर सेट करने की आवश्यकता हो सकती है, क्योंकि प्रत्येक डिस्क खंड में एक दर्जन या अधिक फ़ाइलें हो सकती हैं। उदाहरण के लिए, 1000 खंडों के साथ एक वास्तविक समय की तालिका को एक साथ हजारों फ़ाइलें खोलने की आवश्यकता हो सकती है। यदि आप लॉग में 'बहुत अधिक खुली फ़ाइलें' त्रुटि का सामना करते हैं, तो इस विकल्प को समायोजित करने का प्रयास करें, क्योंकि यह समस्या को हल करने में मदद कर सकता है।

एक "हार्ड लिमिट" भी है जिसे विकल्प द्वारा परिभाषित नहीं किया जा सकता। यह सीमा सिस्टम द्वारा परिभाषित की जाती है और इसे Linux पर फ़ाइल `/etc/security/limits.conf` में बदला जा सकता है। अन्य ऑपरेटिंग सिस्टम में अलग-अलग दृष्टिकोण हो सकते हैं, इसलिए अधिक जानकारी के लिए अपने मैनुअल से परामर्श करें।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
max_open_files = 10000
```
<!-- अंत -->

<!-- उदाहरण संवर्धन max_open_files max -->
प्रत्यक्ष संख्यात्मक मूल्यों के अलावा, आप उपलब्ध वर्तमान हार्ड लिमिट के बराबर सीमा सेट करने के लिए 'max' जादुई शब्द का उपयोग कर सकते हैं।

<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
max_open_files = max
```
<!-- अंत -->


### max_packet_size

<!-- उदाहरण संवर्धन max_packet_size -->
अधिकतम अनुमत नेटवर्क पैकेट आकार। यह सेटिंग क्लाइंट से क्वेरी पैकेट और एक वितरित वातावरण में दूरस्थ एजेंटों से प्रतिक्रिया पैकेट दोनों को सीमित करती है। केवल आंतरिक दिमागी जांचों के लिए उपयोग किया जाता है, यह सीधे RAM उपयोग या प्रदर्शन पर प्रभाव नहीं डालता है। वैकल्पिक, डिफ़ॉल्ट 128M है।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
max_packet_size = 32M
```
<!-- अंत -->


### mysql_version_string

<!-- उदाहरण संवर्धन mysql_version_string -->
MySQL प्रोटोकॉल के माध्यम से लौटाने के लिए एक सर्वर संस्करण स्ट्रिंग। वैकल्पिक, डिफ़ॉल्ट खाली है (Manticore संस्करण लौटाता है)।

कई चुनिंदा MySQL क्लाइंट पुस्तकालय MySQL द्वारा उपयोग किए जाने वाले खास संस्करण संख्या प्रारूप पर निर्भर करते हैं, और इसके अलावा, कभी-कभी रिपोर्ट की गई संस्करण संख्या के आधार पर एक अलग निष्पादन पथ चुनते हैं (इशारों पर संकेत की गई क्षमताओं के बजाय)। उदाहरण के लिए, Python MySQLdb 1.2.2 जब संस्करण संख्या X.Y.ZZ प्रारूप में नहीं होती है तो एक अपवाद फेंकता है; MySQL .NET कनेक्टर 6.3.x आंतरिक रूप से संस्करण संख्या 1.x पर एक निश्चित ध्वज संयोजन के साथ विफल रहता है, आदि। इसे हल करने के लिए, आप `mysql_version_string` निर्देश का उपयोग कर सकते हैं और `searchd` को MySQL प्रोटोकॉल के माध्यम से कनेक्ट करने वाले क्लाइंट के लिए एक अलग संस्करण रिपोर्ट करने के लिए कह सकते हैं। (डिफ़ॉल्ट रूप से, यह अपने स्वयं के संस्करण की रिपोर्ट करता है।)


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
mysql_version_string = 5.0.37
```
<!-- अंत -->


### net_workers

नेटवर्क थ्रेड की संख्या, डिफ़ॉल्ट 1 है।

यह सेटिंग बुनियादी भेजने की दरों के लिए उपयोगी है जब केवल एक थ्रेड सभी आने वाले क्वेरीज को प्रबंधित करने के लिए पर्याप्त नहीं होता है।


### net_wait_tm

नेटवर्क थ्रेड के व्यस्त लूप अंतराल को नियंत्रित करता है। डिफ़ॉल्ट -1 है, और इसे -1, 0, या एक सकारात्मक पूर्णांक पर सेट किया जा सकता है।

ऐसे मामलों में जहां सर्वर को एक शुद्ध मास्टर के रूप में कॉन्फ़िगर किया गया है और केवल एजेंटों को अनुरोध का रूट करता है, यह महत्वपूर्ण है कि बिना किसी देरी के अनुरोधों को संभालना और नेटवर्क थ्रेड को सोने की अनुमति नहीं देनी चाहिए। इसके लिए एक व्यस्त लूप है। एक आने वाले अनुरोध के बाद, नेटवर्क थ्रेड यदि `net_wait_tm` एक सकारात्मक संख्या है तो `10 * net_wait_tm` मिलीसेकंड के लिए CPU पोल का उपयोग करता है या केवल CPU के साथ पोल करता है यदि `net_wait_tm` `0` है। इसके अलावा, व्यस्त लूप को `net_wait_tm = -1` के साथ निष्क्रिय किया जा सकता है - इस मामले में, पोलर टाइमआउट को सिस्टम पोलिंग कॉल पर वास्तविक एजेंट के टाइमआउट पर सेट करता है।

> **चेतावनी:** एक CPU व्यस्त लूप वास्तव में CPU कोर को लोड करता है, इसलिए इस मान को किसी भी गैर-डिफ़ॉल्ट मान पर सेट करने से निष्क्रिय सर्वर के साथ भी ध्यान देने योग्य CPU उपयोग होगा।


### net_throttle_accept

नेटवर्क लूप के प्रत्येक पुनरावृत्ति पर कितने क्लाइंट स्वीकार किए जाते हैं, इसे परिभाषित करता है। डिफ़ॉल्ट 0 (असीमित) है, जो अधिकांश उपयोगकर्ताओं के लिए ठीक होना चाहिए। यह उच्च लोड परिदृश्यों में नेटवर्क लूप की थ्रूपुट को नियंत्रित करने के लिए एक बारीक-समायोजन विकल्प है।


### net_throttle_action

नेटवर्क लूप के प्रत्येक पुनरावृत्ति पर कितने अनुरोधों को संसाधित किया जाता है, इसे परिभाषित करता है। डिफ़ॉल्ट 0 (असीमित) है, जो अधिकांश उपयोगकर्ताओं के लिए ठीक होना चाहिए। यह उच्च लोड परिदृश्यों में नेटवर्क लूप की थ्रूपुट को नियंत्रित करने के लिए एक बारीक-समायोजन विकल्प है।

### network_timeout

<!-- उदाहरण संवर्धन network_timeout -->
नेटवर्क क्लाइंट अनुरोध पढ़ने/लिखने का टाइमआउट, सेकंड में (या [विशेष उपसर्ग](../Server_settings/Special_suffixes.md)). वैकल्पिक, डिफ़ॉल्ट 5 सेकंड है। `searchd` एक क्लाइंट कनेक्शन को मजबूरन बंद कर देगा जो इस टाइमआउट के भीतर क्वेरी भेजने या परिणाम पढ़ने में विफल रहता है।

यह भी ध्यान दें [reset_network_timeout_on_packet](../Server_settings/Searchd.md#reset_network_timeout_on_packet) पैरामीटर। यह पैरामीटर `network_timeout` के व्यवहार को बदलता है ताकि यह पूरे `query` या `result` पर लागू होने के बजाय व्यक्तिगत पैकेट पर लागू हो। आमतौर पर, एक क्वेरी/परिणाम एक या दो पैकेट में फिट होता है। हालांकि, जब बड़ी मात्रा में डेटा की आवश्यकता होती है तो, इस पैरामीटर का सक्रिय संचालन बनाए रखने में अत्यधिक मूल्यवान हो सकता है।

<!-- अनुरोध उदाहरण -->

```ini
network_timeout = 10s
```
<!-- अंत -->

### node_address

<!-- उदाहरण संवर्धन node_address -->
यह सेटिंग आपको नोड के नेटवर्क पते को निर्दिष्ट करने की अनुमति देती है। डिफ़ॉल्ट रूप से, इसे पुनरुत्पादन [listen](../Server_settings/Searchd.md#listen) पते पर सेट किया गया है। यह अधिकांश मामलों में सही है; हालाँकि, वहाँ ऐसे हालात हैं जहाँ आपको इसे मैन्युअल रूप से निर्दिष्ट करना पड़ता है:

* फ़ायरवॉल के पीछे नोड
* नेटवर्क पते का अनुवाद सक्षम (NAT)
* कंटेनर परिनियोजन, जैसे Docker या क्लाउड परिनियोजन
* एक से अधिक क्षेत्र में नोड वाले क्लस्टर


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
node_address = 10.101.0.10
```
<!-- अंत -->

### not_terms_only_allowed

<!-- उदाहरण संवर्धन not_terms_only_allowed -->
यह सेटिंग यह निर्धारित करती है कि क्या केवल [निगेशन](../Searching/Full_text_matching/Operators.md#Negation-operator) पूर्ण-पाठ ऑपरेटर के साथ क्वेरीज की अनुमति दी जाए। वैकल्पिक, डिफ़ॉल्ट 0 है (केवल NOT ऑपरेटर के साथ क्वेरीज को विफल करें)।


<!-- intro -->
##### उदाहरण:

<!-- अनुरोध उदाहरण -->

```ini
not_terms_only_allowed = 1
```
<!-- अंत -->

### optimize_cutoff

<!-- उदाहरण संवर्धन optimize_cutoff -->
डिफ़ॉल्ट तालिका संकुचन थreshोल्ड सेट करता है। यहाँ और पढ़ें - [अनुकूलित डिस्क चंक्स की संख्या](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks)। इस सेटिंग को प्रति-प्रश्न विकल्प [कटऑफ](../Securing_and_compacting_a_table/Compacting_a_table.md#Number-of-optimized-disk-chunks) के साथ ओवरराइड किया जा सकता है। इसे [SET GLOBAL](../Server_settings/Setting_variables_online.md#SET) के माध्यम से गतिशील रूप से भी बदला जा सकता है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
optimize_cutoff = 4
```
<!-- end -->

### persistent_connections_limit

<!-- example conf persistent_connections_limit -->
यह सेटिंग दूरस्थ [स्थायी एजेंटों](../Creating_a_table/Creating_a_distributed_table/Creating_a_local_distributed_table.md) के लिए समकालीन स्थायी कनेक्शनों की अधिकतम संख्या निर्धारित करती है। प्रत्येक बार जब `agent_persistent` के तहत परिभाषित एजेंट से कनेक्ट किया जाता है, तो हम मौजूदा कनेक्शन (यदि कोई हो) का पुनः उपयोग करने का प्रयास करते हैं, या कनेक्ट करते हैं और भविष्य के उपयोग के लिए कनेक्शन को सहेजते हैं। हालाँकि, कुछ मामलों में, ऐसे स्थायी कनेक्शनों की संख्या को सीमित करना समझदारी है। यह निर्देशांक सीमा को परिभाषित करता है। यह सभी वितरित तालिकाओं के बीच प्रत्येक एजेंट के होस्ट पर कनेक्शनों की संख्या को प्रभावित करता है।

एजेंट की कॉन्फ़िगरेशन में [max_connections](../Server_settings/Searchd.md#max_connections) विकल्प के बराबर या इससे कम मान सेट करना उचित है।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
persistent_connections_limit = 29 # assume that each host of agents has max_connections = 30 (or 29).
```
<!-- end -->


### pid_file

<!-- example conf pid_file -->
pid_file Manticore खोज में एक अनिवार्य कॉन्फ़िगरेशन विकल्प है जो उस फ़ाइल के पथ को निर्दिष्ट करता है जहाँ `searchd` सर्वर की प्रक्रिया ID संग्रहीत होती है।

searchd प्रक्रिया ID फ़ाइल को स्टार्टअप पर फिर से बनाया और लॉक किया जाता है, और इसमें सर्वर के चलने के दौरान मुख्य सर्वर प्रक्रिया ID होती है। इसे सर्वर बंद होने पर हटा दिया जाता है।
इस फ़ाइल का उद्देश्य Manticore को विभिन्न आंतरिक कार्य करने में सक्षम बनाना है, जैसे कि यह जांचना कि क्या पहले से ही कोई चलती हुई `searchd` उदाहरण है, `searchd` को रोकना, और इसे सूचित करना कि इसे तालिकाओं को घुमाना चाहिए। इस फ़ाइल का उपयोग बाहरी स्वचालन स्क्रिप्ट के लिए भी किया जा सकता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
pid_file = /var/run/manticore/searchd.pid
```
<!-- end -->


### predicted_time_costs

<!-- example conf predicted_time_costs -->
क्वेरी समय भविष्यवाणी मॉडल के लिए लागत, नैनोसेकंड में। वैकल्पिक, डिफ़ॉल्ट है `doc=64, hit=48, skip=2048, match=64`।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
predicted_time_costs = doc=128, hit=96, skip=4096, match=128
```
<!-- end -->

<!-- example conf predicted_time_costs 1 -->
क्वेरियों को उनकी क्रियान्वयन समय के आधार पर पूर्णता से पहले समाप्त करना (मैक्स क्वेरी समय सेटिंग के साथ) एक अच्छा सुरक्षा जाल है, लेकिन इसके साथ एक अंतर्निहित कमी है: अदिर्ष्ट (अस्थिर) परिणाम। यानी, यदि आप वही (जटिल) खोज क्वेरी समय सीमा के साथ कई बार दोहराते हैं, तो समय सीमा विभिन्न चरणों में पहुँची जाएगी, और आपको *भिन्न* परिणाम सेट मिलेंगे।

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SELECT … OPTION max_query_time
```
<!-- request API -->

```api
SetMaxQueryTime()
```
<!-- end -->

एक नया विकल्प है, [SELECT … OPTION max_predicted_time](../Searching/Options.md#max_predicted_time), जो आपको क्वेरी समय *और* स्थिर, पुनरुद्धारणीय परिणाम प्राप्त करने की अनुमति देता है। क्वेरी का मूल्यांकन करते समय वास्तविक वर्तमान समय की नियमित रूप से जांच करने के बजाय, जो अदिर्ष्ट है, यह सरल रैखिक मॉडल का उपयोग करके वर्तमान चलने वाले समय की भविष्यवाणी करता है:

```ini
predicted_time =
    doc_cost * processed_documents +
    hit_cost * processed_hits +
    skip_cost * skiplist_jumps +
    match_cost * found_matches
```

जब `predicted_time` एक निर्दिष्ट सीमा तक पहुँचता है, तो क्वेरी जल्दी समाप्त कर दी जाती है।

बेशक, यह व्यावहारिक समय पर एक कठोर सीमा नहीं है (हालांकि, यह *प्रसंस्करण* कार्य किए जाने की मात्रा पर एक कठोर सीमा है), और साधारण रैखिक मॉडल को किसी भी तरह से आदर्श रूप से सटीक नहीं माना जा सकता है। इसलिए, दीवार घड़ी का समय *किसी भी* लक्ष्य सीमा के नीचे या ऊपर हो सकता है। हालाँकि, त्रुटि के मार्जिन काफी स्वीकार्य हैं: उदाहरण के लिए, हमारे 100 मिलीसेकंड लक्ष्य सीमा के प्रयोगों में, परीक्षण क्वेरियों की अधिकांश संख्या 95 से 105 मिलीसेकंड की सीमा में थी, और *सभी* क्वेरियाँ 80 से 120 मिलीसेकंड की सीमा में थीं। साथ ही, एक अच्छे साइड इफेक्ट के रूप में, मॉडल वाले क्वेरी समय का उपयोग करने से वास्तविक रन समय को मापने में कुछ कम gettimeofday() कॉल भी होती हैं।

कोई दो सर्वर निर्माताएँ और मॉडल समान नहीं होते हैं, इसलिए `predicted_time_costs` निर्देश आपको ऊपर दिए गए मॉडल के लिए लागत को कस्टमाइज़ करने की अनुमति देता है। सुविधा के लिए, ये पूर्णांक हैं, जो नैनोसेकंड में गिने जाते हैं। (max_predicted_time में लिमिट मिलीसेकंड में गिनी जाती है, और लागत मानों को 0.000128 मिलीसेकंड के बजाय 128 नैनोसेकंड के रूप में निर्दिष्ट करना कुछ अधिक त्रुटि-प्रवण है।) सभी चार लागतों को एक साथ निर्दिष्ट करना आवश्यक नहीं है, क्योंकि जो चूक जाती हैं, वे डिफ़ॉल्ट मान लेंगी। हालाँकि, हम पठनीयता के लिए सभी को निर्दिष्ट करने की दृढ़ सिफारिश करते हैं।


### preopen_tables

<!-- example conf preopen_tables -->
preopen_tables कॉन्फ़िगरेशन निर्देश यह निर्दिष्ट करता है कि क्या स्टार्टअप पर सभी तालिकाओं को मजबूरपूर्वक प्रीओपन करना है। डिफ़ॉल्ट मान 1 है, जिसका अर्थ है कि सभी तालिकाएँ प्रीओपन की जाएँगी चाहे प्रति-तालिका [preopen](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#Other-performance-related-settings) सेटिंग क्या हो। यदि 0 पर सेट किया जाए, तो प्रति-तालिका सेटिंग प्रभाव में आ सकती है, और उनका डिफ़ॉल्ट 0 होगा।

तालिकाओं को प्रीओपन करना खोज क्वेरियों और घुमावों के बीच दौड़ को रोक सकता है जो कभी-कभी क्वेरियों के विफल होने का कारण बनता है। हालाँकि, यह अधिक फ़ाइल हैंडल का भी उपयोग करता है। अधिकांश परिदृश्यों में, तालिकाओं को प्रीओपन करने की सिफारिश की जाती है।

यहाँ एक उदाहरण कॉन्फ़िगरेशन है:

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
preopen_tables = 1
```
<!-- end -->

### pseudo_sharding

<!-- example conf pseudo_sharding -->
pseudo_sharding कॉन्फ़िगरेशन विकल्प स्थानीय प्लेन और वास्तविक समय की तालिकाओं को खोज क्वेरियों के समांतरकरण को सक्षम करता है, चाहे वे सीधे या वितरित तालिका के माध्यम से क्वेरी किए जाएँ। यह सुविधा स्वचालित रूप से `searchd.threads` में निर्दिष्ट थ्रेड्स की संख्या तक क्वेरियों को समांतरित कर देगी।

ध्यान दें कि यदि आपके कार्यकर्ता थ्रेड पहले से व्यस्त हैं, क्योंकि आपके पास:
* उच्च क्वेरी सह-सक्रियता
* किसी भी प्रकार की भौतिक शार्दिंग:
  - कई प्लेन/वास्तविक समय की तालिकाओं की वितरित तालिका
  - बहुत ज्यादा डिस्क चंक्स वाली वास्तविक समय की तालिका

फिर, pseudo_sharding सक्षम करने से कोई लाभ नहीं हो सकता है और यहां तक कि थ्रूपुट में थोड़ा सा कमी भी आ सकती है। यदि आप कम विलंबता की तुलना में उच्च थ्रूपुट को प्राथमिकता देते हैं, तो इस विकल्प को अक्षम करना अनुशंसित है।

डिफ़ॉल्ट रूप से सक्षम।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
pseudo_sharding = 0
```
<!-- end -->


### replication_connect_timeout

`replication_connect_timeout` निर्देश दूरस्थ नोड से कनेक्ट करने के लिए समय सीमा को परिभाषित करता है। डिफ़ॉल्ट रूप से, मान को मिलीसेकंड में माना जाता है, लेकिन इसमें [दूसरा उपसर्ग](../../Server_settings/Special_suffixes.md) हो सकता है। डिफ़ॉल्ट मान 1000 (1 सेकंड) है।

दूरस्थ नोड से कनेक्ट करते समय, Manticore अधिकतम इस समय की मात्रा के लिए कनेक्शन सफलतापूर्वक पूरा करने का इंतजार करेगा। यदि समय सीमा समाप्त हो जाती है लेकिन कनेक्शन स्थापित नहीं हुआ है, और `retries` सक्षम हैं, तो पुनः प्रयास शुरू किया जाएगा।


### replication_query_timeout

`replication_query_timeout` उस समय की मात्रा को सेट करता है जिसे searchd एक दूरस्थ नोड को एक क्वेरी पूरा करने के लिए इंतजार करेगा। डिफ़ॉल्ट मान 3000 मिलीसेकंड (3 सेकंड) है, लेकिन इसे विभिन्न समय की यूनिट को सूचित करने के लिए `suffixed` किया जा सकता है।

एक कनेक्शन स्थापित करने के बाद, Manticore अधिकतम `replication_query_timeout` का इंतजार करेगा ताकि दूरस्थ नोड पूरा हो सके। ध्यान दें कि यह समय सीमा `replication_connect_timeout` से अलग है, और दूरस्थ नोड द्वारा उत्पन्न कुल संभावित देरी दोनों मानों का योग होगी।


### replication_retry_count

यह सेटिंग एक पूर्णांक है जो यह निर्दिष्ट करती है कि Manticore कितनी बार एक दूरस्थ नोड से कनेक्ट और क्वेरी करने का प्रयास करेगा पुनर्प्रजनन के दौरान पहले एक गंभीर क्वेरी त्रुटि की रिपोर्ट करने से पहले। डिफ़ॉल्ट मान 3 है।


### replication_retry_delay

यह सेटिंग मिलीसेकंड में एक पूर्णांक है (या [special_suffixes](../Server_settings/Special_suffixes.md)) जो यह निर्दिष्ट करती है कि Manticore वापसी प्रयास करने से पहले कितनी देरी होगी यदि पुनर्प्रजनन के दौरान असफलता होती है। यह मान केवल तभी महत्वपूर्ण है जब कोई गैर-शून्य मान निर्दिष्ट किया गया हो। डिफ़ॉल्ट मान 500 है।

### qcache_max_bytes

<!-- example conf qcache_max_bytes -->
यह कॉन्फ़िगरेशन बाइट्स में कैश में परिणाम सेट के लिए अधिकतम RAM आवंटित करता है। डिफ़ॉल्ट मान 16777216 है, जो 16 मेगाबाइट के बराबर है। यदि मान 0 पर सेट किया गया हो, तो क्वेरी कैश अक्षम है। क्वेरी कैश के बारे में अधिक जानकारी के लिए, कृपया विवरण के लिए [क्वेरी कैश](../Searching/Query_cache.md) देखें।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
qcache_max_bytes = 16777216
```
<!-- end -->


### qcache_thresh_msec

पूर्णांक, मिलीसेकंड में। एक क्वेरी परिणाम कैश किए जाने के लिए न्यूनतम दीवार समय सीमा। डिफ़ॉल्ट रूप से 3000, या 3 सेकंड। 0 का मतलब है सब कुछ कैश करना। विवरण के लिए [क्वेरी कैश](../Searching/Query_cache.md) देखें। इस मान को समय [special_suffixes](../Server_settings/Special_suffixes.md) के साथ भी व्यक्त किया जा सकता है, लेकिन इसका उपयोग सावधानी से करें और खुद को मान के नाम के साथ भ्रमित न करें, जिसमें '_msec' शामिल है।


### qcache_ttl_sec

पूर्णांक, सेकंड में। कैश किए गए परिणाम सेट के लिए समाप्ति अवधि। डिफ़ॉल्ट 60, या 1 मिनट है। न्यूनतम संभव मान 1 सेकंड है। विवरण के लिए [क्वेरी कैश](../Searching/Query_cache.md) देखें। इस मान को समय [special_suffixes](../Server_settings/Special_suffixes.md) के साथ भी व्यक्त किया जा सकता है, लेकिन इसका उपयोग सावधानी से करें और खुद को मान के नाम के साथ भ्रमित न करें, जिसमें '_sec' शामिल है।


### query_log_format

<!-- example conf query_log_format -->
क्वेरी लॉग प्रारूप। वैकल्पिक, अनुमत मान `plain` और `sphinxql` हैं, डिफ़ॉल्ट `sphinxql` है।

`sphinxql` मोड मान्य SQL बयानों को लॉग करता है। `plain` मोड क्वेरी को एक साधारण पाठ प्रारूप में लॉग करता है (अधिकतर शुद्ध पूर्ण-पाठ उपयोग के मामलों के लिए उपयुक्त)। यह निर्देश आपको खोज सर्वर स्टार्टअप पर दोनों प्रारूपों के बीच स्विच करने की अनुमति देता है। लॉग प्रारूप को अस्थायी रूप से भी बदला जा सकता है, `SET GLOBAL query_log_format=sphinxql` सिंटैक्स का उपयोग करके। अधिक विवरण के लिए [क्वेरी लॉगिंग](../Logging/Query_logging.md) देखें।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
query_log_format = sphinxql
```
<!-- end -->

### query_log_min_msec

सीमा (मिलीसेकंड में) जो क्वेरी को क्वेरी लॉग में लिखने से रोकती है। वैकल्पिक, डिफ़ॉल्ट 0 (सभी क्वेरियों को क्वेरी लॉग में लिखा जाता है)। यह निर्देश निर्दिष्ट करता है कि केवल उन क्वेरियों को लॉग किया जाएगा जिनका निष्पादन समय निर्दिष्ट सीमा को पार करता है (यह मान भी समय [special_suffixes](../Server_settings/Special_suffixes.md) के साथ व्यक्त किया जा सकता है, लेकिन इसका उपयोग सावधानी से करें और खुद को मान के नाम के साथ भ्रमित न करें, जिसमें `_msec` शामिल है)।

### query_log

<!-- example conf query_log -->
क्वेरी लॉग फ़ाइल नाम। वैकल्पिक, डिफ़ॉल्ट खाली है (क्वेरियों को लॉग न करें)। सभी खोज क्वेरियाँ (जैसे SELECT ... लेकिन INSERT/REPLACE/UPDATE क्वेरियों को नहीं) इस फ़ाइल में लॉग की जाएंगी। प्रारूप का वर्णन [क्वेरी लॉगिंग](../Logging/Query_logging.md) में किया गया है। 'plain' प्रारूप के मामले में, आप लॉग फ़ाइल के पथ के रूप में 'syslog' का उपयोग कर सकते हैं। इस मामले में, सभी खोज क्वेरियाँ `LOG_INFO` प्राथमिकता के साथ syslog डेमन को भेजी जाएंगी, जो '[query]' से पूर्ववर्ती होगी, टाइमस्टैम्प के बजाय। syslog विकल्प का उपयोग करने के लिए, Manticore को निर्माण पर `-–with-syslog` के साथ कॉन्फ़िगर किया जाना चाहिए।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
query_log = /var/log/query.log
```
<!-- end -->


### query_log_mode

<!-- example conf query_log_mode -->
query_log_mode निर्देश आपको searchd और क्वेरी लॉग फ़ाइलों के लिए अनुमति सेट करने की अनुमति देता है। डिफ़ॉल्ट रूप से, ये लॉग फ़ाइलें 600 अनुमति के साथ बनाई जाती हैं, जिसका अर्थ है कि केवल उस उपयोगकर्ता के पास जो सर्वर चलाता है और रूट उपयोगकर्ता लॉग फ़ाइलें पढ़ सकते हैं।
यह निर्देश उपयोगी हो सकता है यदि आप अन्य उपयोगकर्ताओं को लॉग फ़ाइलें पढ़ने की अनुमति देना चाहते हैं, उदाहरण के लिए, गैर-रूट उपयोगकर्ताओं पर चलने वाले निगरानी समाधानों के लिए।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
query_log_mode  = 666
```
<!-- end -->

### read_buffer_docs

<!-- example conf read_buffer_docs -->
read_buffer_docs निर्देश दस्तावेज़ सूचियों के लिए प्रति-कीवर्ड पढ़ने वाले बफर आकार को नियंत्रित करता है। प्रत्येक कीवर्ड की उपस्थिति के लिए प्रत्येक खोज क्वेरी में, दस्तावेज़ सूची और हिट सूची के लिए दो संबंधित पढ़ने वाले बफर होते हैं। यह सेटिंग आपको दस्तावेज़ सूची बफर आकार को नियंत्रित करने की अनुमति देती है।

A larger buffer size might increase per-query RAM use, but it could possibly decrease I/O time. It makes sense to set larger values for slow storage, but for storage capable of high IOPS, experimenting should be done in the low values area.

The default value is 256K, and the minimal value is 8K. You may also set [read_buffer_docs](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_docs) on a per-table basis, which will override anything set on the server's config level.


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
read_buffer_docs = 128K
```
<!-- end -->


### read_buffer_hits

<!-- example conf read_buffer_hits -->
The read_buffer_hits directive specifies the per-keyword read buffer size for hit lists in search queries. By default, the size is 256K and the minimum value is 8K. For every keyword occurrence in a search query, there are two associated read buffers, one for the document list and one for the hit list. Increasing the buffer size can increase per-query RAM use but decrease I/O time. For slow storage, larger buffer sizes make sense, while for storage capable of high IOPS, experimenting should be done in the low values area.

This setting can also be specified on a per-table basis using the read_buffer_hits option in [read_buffer_hits](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#read_buffer_hits) which will override the server-level setting.

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
read_buffer_hits = 128K
```
<!-- end -->

### read_unhinted

<!-- example conf read_unhinted -->
Unhinted read size. Optional, default is 32K, minimal 1K

When querying, some reads know in advance exactly how much data is there to be read, but some currently do not. Most prominently, hit list size is not currently known in advance. This setting lets you control how much data to read in such cases. It impacts hit list I/O time, reducing it for lists larger than unhinted read size, but raising it for smaller lists. It does **not** affect RAM usage because the read buffer will already be allocated. So it should not be greater than read_buffer.


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
read_unhinted = 32K
```
<!-- end -->

### reset_network_timeout_on_packet

<!-- example conf reset_network_timeout_on_packet -->
Refines the behavior of networking timeouts (such as `network_timeout`, `read_timeout`, and `agent_query_timeout`).

When set to 0, timeouts limit the maximum time for sending the entire request/query.
When set to 1 (default), timeouts limit the maximum time between network activities.

With replication, a node may need to send a large file (for example, 100GB) to another node. Assume the network can transfer data at 1GB/s, with a series of packets of 4-5MB each. To transfer the entire file, you would need 100 seconds. A default timeout of 5 seconds would only allow the transfer of 5GB before the connection is dropped. Increasing the timeout could be a workaround, but it is not scalable (for instance, the next file might be 150GB, leading to failure again). However, with the default `reset_network_timeout_on_packet` set to 1, the timeout is applied not to the entire transfer but to individual packets. As long as the transfer is in progress (and data is actually being received over the network during the timeout period), it is kept alive. If the transfer gets stuck, such that a timeout occurs between packets, it will be dropped.

Note that if you set up a distributed table, each node — both master and agents — should be tuned. On the master side, `agent_query_timeout` is affected; on agents, `network_timeout` is relevant.

<!-- intro -->

##### उदाहरण:

<!-- request Example -->

```ini
reset_network_timeout_on_packet = 0
```

<!-- end -->


### rt_flush_period

<!-- example conf rt_flush_period -->
RT tables RAM chunk flush check period, in seconds (or [special_suffixes](../Server_settings/Special_suffixes.md)). Optional, default is 10 hours.

Actively updated RT tables that fully fit in RAM chunks can still result in ever-growing binlogs, impacting disk use and crash recovery time. With this directive, the search server performs periodic flush checks, and eligible RAM chunks can be saved, enabling consequential binlog cleanup. See [Binary logging](../Logging/Binary_logging.md) for more details.

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
rt_flush_period = 3600 # 1 hour
```
<!-- end -->


### rt_merge_iops

<!-- example conf rt_merge_iops -->
A maximum number of I/O operations (per second) that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).

This directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. It is guaranteed that all RT optimization activities will not generate more disk IOPS (I/Os per second) than the configured limit. Limiting rt_merge_iops can reduce search performance degradation caused by merging.

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
rt_merge_iops = 40
```
<!-- end -->

### rt_merge_maxiosize

<!-- example conf rt_merge_maxiosize -->
A maximum size of an I/O operation that the RT chunks merge thread is allowed to start. Optional, default is 0 (no limit).

This directive lets you throttle down the I/O impact arising from the `OPTIMIZE` statements. I/Os larger than this limit will be broken down into two or more I/Os, which will then be accounted for as separate I/Os with regards to the [rt_merge_iops](../Server_settings/Searchd.md#rt_merge_iops) limit. Thus, it is guaranteed that all optimization activities will not generate more than (rt_merge_iops * rt_merge_maxiosize) bytes of disk I/O per second.


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
rt_merge_maxiosize = 1M
```
<!-- end -->


### seamless_rotate

<!-- example conf seamless_rotate -->
Prevents `searchd` stalls while rotating tables with huge amounts of data to precache. Optional, default is 1 (enable seamless rotation). On Windows systems, seamless rotation is disabled by default.

Tables में कुछ डेटा हो सकता है जिसे RAM में प्री-कैश किया जाना आवश्यक है। इस समय, `.spa`, `.spb`, `.spi`, और `.spm` फ़ाइलें पूरी तरह से प्री-कैश की गई हैं (वे क्रमशः एट्रिब्यूट डेटा, ब्लॉब एट्रिब्यूट डेटा, कीवर्ड तालिका, और किल्ड रो मैप को contain करती हैं।) Seamless rotate के बिना, एक तालिका को घुमाने का प्रयास RAM का न्यूनतम उपयोग करना है और यह इस प्रकार कार्य करता है:

1. नए प्रश्न अस्थायी रूप से अस्वीकार किए जाते हैं ( "retry" त्रुटि कोड के साथ) ;
2. `searchd` सभी वर्तमान में चल रहे प्रश्नों के समाप्त होने की प्रतीक्षा करता है;
3. पुरानी तालिका को डीक्लेर किया जाता है, और इसकी फ़ाइलों का नाम बदल दिया जाता है;
4. नए तालिका फ़ाइलों का नाम बदला जाता है, और आवश्यक RAM आवंटित की जाती है;
5. नए तालिका एट्रिब्यूट और शब्दकोश डेटा को RAM में लोड किया जाता है;
6. `searchd` नए तालिका से प्रश्नों की सेवा करना शुरू करता है।

हालांकि, यदि एट्रिब्यूट या शब्दकोश डेटा की मात्रा अधिक है, तो प्री-लोडिंग चरण में ध्यान देने योग्य मात्रा में समय लग सकता है - 1-5+ जीबी फ़ाइलों को प्री-लोड करने के मामले में कुछ मिनटों तक।

Seamless rotate सक्षम होने पर, घुमाव इस प्रकार कार्य करता है:

1. नए तालिका RAM स्टोरेज को आवंटित किया जाता है;
2. नए तालिका एट्रिब्यूट और शब्दकोश डेटा को असिंक्रोनस रूप से RAM में प्री-लोड किया जाता है;
3. सफल होने पर, पुरानी तालिका को डीक्लेर किया जाता है, और दोनों तालिकाओं की फ़ाइलों का नाम बदल दिया जाता है;
4. विफलता पर, नए तालिका को डीक्लेर किया जाता है;
5. किसी भी समय, प्रश्नों की सेवा या तो पुरानी या नई तालिका की प्रति से की जाती है।

Seamless rotate का अर्थ है कि घुमाव के दौरान उच्चतम मेमोरी उपयोग का खर्च (क्योंकि `.spa/.spb/.spi/.spm` डेटा की पुरानी और नई प्रतियाँ RAM में प्री-लोडिंग के दौरान होनी चाहिए)। औसत उपयोग समान रहता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
seamless_rotate = 1
```
<!-- end -->

### secondary_indexes
<!-- example conf secondary_indexes -->

यह विकल्प खोज प्रश्नों के लिए द्वितीयक अनुक्रमणिका के उपयोग को सक्षम / निष्क्रिय करता है। यह वैकल्पिक है, और डिफ़ॉल्ट 1 (सक्षम) है। ध्यान दें कि इसे अनुक्रमण के लिए सक्षम करने की आवश्यकता नहीं है क्योंकि यह हमेशा सक्षम है जब तक कि [Manticore Columnar Library](https://github.com/manticoresoftware/columnar) इंस्टॉल है। बाद वाला खोज के दौरान अनुक्रमणिकाओं का उपयोग करने के लिए भी आवश्यक है। यहां तीन मोड उपलब्ध हैं:

* `0`: खोज पर द्वितीयक अनुक्रमणिकाओं के उपयोग को निष्क्रिय करें। इन्हें व्यक्तिगत प्रश्नों के लिए [analyzer hints](../Searching/Options.md#Query-optimizer-hints) का उपयोग करके सक्षम किया जा सकता है
* `1`: खोज पर द्वितीयक अनुक्रमणिकाओं के उपयोग को सक्षम करें। इन्हें व्यक्तिगत प्रश्नों के लिए [analyzer hints](../Searching/Options.md#Query-optimizer-hints) का उपयोग करके निष्क्रिय किया जा सकता है
* `force`: सक्षम करने के समान, लेकिन द्वितीयक अनुक्रमणिकाओं को लोड करते समय कोई भी त्रुटियाँ रिपोर्ट की जाएंगी, और पूरा अनुक्रमणिका डेमन में लोड नहीं होगा।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
secondary_indexes = 1
```

<!-- end -->

### server_id

<!-- example conf server_id -->
पूर्णांक संख्या जो सर्वर पहचानकर्ता के रूप में कार्य करती है जिसका उपयोग प्रतिReplication क्लस्टर के हिस्से के लिए एक अद्वितीय छोटे UUID को बनाने के लिए किया जाता है। server_id क्लस्टर के नोड्स के बीच अद्वितीय होना चाहिए और 0 से 127 के बीच होना चाहिए। यदि server_id सेट नहीं है, तो इसे MAC पते और PID फ़ाइल के पथ का हैश के रूप में कैलकुलेट किया जाता है या छोटे UUID के लिए बीज के रूप में एक यादृच्छिक संख्या का उपयोग किया जाएगा।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
server_id = 1
```
<!-- end -->


### shutdown_timeout

<!-- example conf shutdown_timeout -->
`searchd --stopwait` इंतज़ार करने का समय, सेकंड में (या [special_suffixes](../Server_settings/Special_suffixes.md)). वैकल्पिक, डिफ़ॉल्ट 60 सेकंड है।

जब आप `searchd --stopwait` चलाते हैं तो आपके सर्वर को रुकने से पहले कुछ गतिविधियाँ करनी होती हैं, जैसे प्रश्नों को समाप्त करना, RT RAM टुकड़ों को फ्लश करना, एट्रिब्यूट को फ्लश करना, और बिनलॉग को अपडेट करना। इन कार्यों के लिए कुछ समय की आवश्यकता होती है। `searchd --stopwait` सर्वर के काम समाप्त करने के लिए `shutdown_time` सेकंड तक प्रतीक्षा करेगा। उपयुक्त समय आपके तालिका के आकार और लोड पर निर्भर करता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
shutdown_timeout = 3m # wait for up to 3 minutes
```
<!-- end -->


### shutdown_token

SHA1 हैश उस पासवर्ड का जो VIP Manticore SQL कनेक्शन से 'shutdown' कमांड को क्रियान्वित करने के लिए आवश्यक है। इसके बिना,[debug](../Reporting_bugs.md#DEBUG) 'shutdown' उप-कमांड कभी भी सर्वर को रोकने का कारण नहीं बनेगा। ध्यान दें कि इस तरह का साधारण हैशिंग को मजबूत सुरक्षा नहीं माना जाना चाहिए, क्योंकि हम सॉल्टेड हैश या किसी भी प्रकार के आधुनिक हैश फ़ंक्शन का उपयोग नहीं करते हैं। इसे एक स्थानीय नेटवर्क में हाउसकीपिंग डेमन्स के लिए एक सटीक उपाय के रूप में माना गया है।

### snippets_file_prefix

<!-- example conf snippets_file_prefix -->
एक पूर्ववर्ती जो स्निपेट बनाने के समय स्थानीय फ़ाइल नामों से जोड़ने के लिए होता है। वैकल्पिक, डिफ़ॉल्ट वर्तमान कार्यशील फ़ोल्डर है।

इस पूर्ववर्ती का उपयोग `load_files` या `load_files_scattered` विकल्पों के साथ वितरित स्निपेट निर्माण में किया जा सकता है।

ध्यान दें कि यह एक पूर्ववर्ती है और **नहीं** एक पथ! इसका मतलब है कि यदि एक पूर्ववर्ती "server1" पर सेट किया गया है और अनुरोध "file23" को संदर्भित करता है, तो `searchd` "server1file23" (इन सभी को बिना उद्धरण के) को खोलने का प्रयास करेगा। तो, यदि आपको इसे एक पथ के रूप में सेट करने की आवश्यकता है, तो आपको अंतिम स्लैश शामिल करना होगा।

अंतिम फ़ाइल पथ का निर्माण करने के बाद, सर्वर सभी सापेक्ष डाइर से बाहर निकलता है और अंतिम परिणाम की तुलना `snippet_file_prefix` के मान से करता है। यदि परिणाम पूर्ववर्ती के साथ शुरू नहीं होता है, तो इस तरह की फ़ाइल को त्रुटि संदेश के साथ अस्वीकृत कर दिया जाएगा।

उदाहरण के लिए, यदि आप इसे `/mnt/data` पर सेट करते हैं और कोई स्निपेट निर्माण के लिए फ़ाइल `../../../etc/passwd` को स्रोत के रूप में कॉल करता है, तो उन्हें त्रुटि संदेश मिलेगा:

`File '/mnt/data/../../../etc/passwd' escapes '/mnt/data/' scope`

इसके बजाय, फ़ाइल की सामग्री की।

इसके अलावा, जब एक सेट नहीं किया गया पैरामीटर और `/etc/passwd` को पढ़ते समय, यह वास्तव में /daemon/working/folder/etc/passwd को पढ़ेगा क्योंकि इस पैरामीटर का डिफ़ॉल्ट सर्वर का कार्यशील फ़ोल्डर है।

ध्यान दें कि यह एक स्थानीय विकल्प है; यह एजेंटों को किसी भी तरह से प्रभावित नहीं करता है। तो आप मास्टर सर्वर पर सुरक्षित रूप से एक पूर्ववर्ती सेट कर सकते हैं। एजेंटों के लिए रूट किया गया अनुरोध मास्टर की सेटिंग से प्रभावित नहीं होगा। हालांकि, वे एजेंट की अपनी सेटिंग्स से प्रभावित होंगे।

यह उपयोगी हो सकता है, उदाहरण के लिए, जब दस्तावेज़ भंडारण स्थान (चाहे स्थानीय भंडारण या NAS माउंटपॉइंट) सर्वरों के बीच असंगत होते हैं।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
snippets_file_prefix = /mnt/common/server1/
```
<!-- end -->

> **चेतावनी:** यदि आप FS रूट से फ़ाइलों तक पहुंचना चाहते हैं, तो आपको `snippets_file_prefix` को खाली मान (लाइन `snippets_file_prefix=` द्वारा) या रूट (लाइन `snippets_file_prefix=/` द्वारा) पर सेट करना होगा।


### sphinxql_state

<!-- example conf sphinxql_state -->
वह फ़ाइल जिसका पथ वर्तमान SQL स्थिति को सीरियलाइज किया जाएगा।

सर्वर स्टार्टअप पर, इस फ़ाइल को पुनः चलाया जाता है। योग्य स्थिति परिवर्तनों (जैसे, SET GLOBAL) पर, इस फ़ाइल को स्वचालित रूप से फिर से लिखा जाता है। इससे एक कठिनाई-निदान समस्या को रोका जा सकता है: यदि आप UDF फ़ंक्शंस लोड करते हैं लेकिन Manticore क्रैश हो जाता है, जब इसे (स्वचालित रूप से) पुनः प्रारंभ किया जाता है, तो आपके UDF और वैश्विक चर अब उपलब्ध नहीं होंगे। स्थायी स्थिति का उपयोग सुनिश्चित करता है कि कोई ऐसा आश्चर्य के बिना सम्मोहक वसूली हो।

`sphinxql_state` का उपयोग मनमाने आदेशों को निष्पादित करने के लिए नहीं किया जा सकता, जैसे कि `CREATE TABLE`।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
sphinxql_state = uservars.sql
```
<!-- end -->


### sphinxql_timeout

<!-- example conf sphinxql_timeout -->
SQL इंटरफ़ेस का उपयोग करते समय अनुरोधों के बीच प्रतीक्षा करने के लिए अधिकतम समय (सेकंड में, या [special_suffixes](../Server_settings/Special_suffixes.md))। वैकल्पिक, डिफ़ॉल्ट है 15 मिनट।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
sphinxql_timeout = 15m
```
<!-- end -->


### ssl_ca

<!-- example conf ssl_ca -->
SSL सर्टिफिकेट प्राधिकरण (CA) प्रमाणपत्र फ़ाइल का पथ (जिसे रूट सर्टिफिकेट भी कहा जाता है)। वैकल्पिक, डिफ़ॉल्ट है खाली। जब खाली नहीं होता है, तो `ssl_cert` में प्रमाणपत्र को इस रूट प्रमाणपत्र द्वारा हस्ताक्षरित होना चाहिए।

सर्वर इस CA फ़ाइल का उपयोग प्रमाणपत्र पर हस्ताक्षर को सत्यापित करने के लिए करता है। फ़ाइल को PEM प्रारूप में होना चाहिए।

<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
ssl_ca = keys/ca-cert.pem
```
<!-- end -->


### ssl_cert

<!-- example conf ssl_cert -->
सर्वर के SSL प्रमाणपत्र का पथ। वैकल्पिक, डिफ़ॉल्ट है खाली। 

सर्वर इस प्रमाणपत्र का उपयोग SSL के माध्यम से HTTP ट्रैफ़िक को एनक्रिप्ट करने के लिए एक स्वयं-हस्ताक्षरित सार्वजनिक कुंजी के रूप में करता है। फ़ाइल को PEM प्रारूप में होना चाहिए।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
ssl_cert = keys/server-cert.pem
```
<!-- end -->


### ssl_key

<!-- example conf ssl_key -->
SSL प्रमाणपत्र कुंजी का पथ। वैकल्पिक, डिफ़ॉल्ट है खाली। 

सर्वर इस निजी कुंजी का उपयोग SSL के माध्यम से HTTP ट्रैफ़िक को एनक्रिप्ट करने के लिए करता है। फ़ाइल को PEM प्रारूप में होना चाहिए।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
ssl_key = keys/server-key.pem
```
<!-- end -->


### subtree_docs_cache

<!-- example conf subtree_docs_cache -->
प्रत्येक प्रश्न के लिए अधिकतम सामान्य उपवृक्ष दस्तावेज़ कैश आकार। वैकल्पिक, डिफ़ॉल्ट है 0 (अक्षम)।

यह सेटिंग एक सामान्य उपवृक्ष ऑप्टिमाइज़र की RAM उपयोगिता को सीमित करती है (देखें [multi-queries](../Searching/Multi-queries.md))। अधिकतम, इस तरह की RAM डॉक्यूमेंट प्रविष्टियों को कैश करने के लिए खर्च की जाएगी। इसे 0 पर सेट करने से ऑप्टिमाइज़र अक्षम हो जाता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
subtree_docs_cache = 8M
```
<!-- end -->


### subtree_hits_cache

<!-- example conf subtree_hits_cache -->
प्रत्येक प्रश्न के लिए अधिकतम सामान्य उपवृक्ष हिट कैश आकार। वैकल्पिक, डिफ़ॉल्ट है 0 (अक्षम)।

यह सेटिंग एक सामान्य उपवृक्ष ऑप्टिमाइज़र की RAM उपयोगिता को सीमित करती है (देखें [multi-queries](../Searching/Multi-queries.md))। अधिकतम, इस तरह की RAM कीवर्ड उपस्थिति (हिट) को कैश करने के लिए खर्च की जाएगी। इसे 0 पर सेट करने से ऑप्टिमाइज़र अक्षम हो जाता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
subtree_hits_cache = 16M
```
<!-- end -->

### threads

<!-- example threads -->
Manticore डेमन के लिए कार्यरत थ्रेड्स की संख्या (या, थ्रेड पूल का आकार)। Manticore स्टार्ट पर इस संख्या के OS थ्रेड्स बनाता है, और वे डेमन के अंदर सभी कार्य करते हैं, जैसे कि क्वेरीज को निष्पादित करना, स्निप्पेट्स बनाना, आदि। कुछ कार्यों को उप-कार्य में विभाजित किया जा सकता है और समानांतर में निष्पादित किया जा सकता है, उदाहरण के लिए:

* रीयल-टाइम टेबल में खोजें
* स्थानीय तालिकाओं से बनी वितरित तालिका में खोजें
* पर्कोलेट क्वेरी कॉल
* और अन्य

डिफ़ॉल्ट रूप से, यह सर्वर पर CPU कोर की संख्या पर सेट होता है। Manticore स्टार्ट पर थ्रेड्स बनाता है और जब तक इसे रोका नहीं जाता तब तक उन्हें बनाए रखता है। जब भी उप-कार्य को इसकी आवश्यकता होती है, यह थ्रेड्स में से एक का उपयोग कर सकता है। जब उप-कार्य समाप्त होता है, तो यह थ्रेड को छोड़ देता है ताकि कोई अन्य उप-कार्य इसका उपयोग कर सके।

गंभीर I/O प्रकार के लोड के मामले में, इसे CPU कोर की संख्या से अधिक सेट करना समझ में आ सकता है।

<!-- request Example -->
```ini
threads = 10
```

<!-- end -->

### thread_stack

<!-- example conf thread_stack -->
एक कार्य (कोरौटीन, एक खोज क्वेरी कई कार्यों/कोरौटीन का कारण बन सकती है) के लिए अधिकतम स्टैक आकार। वैकल्पिक, डिफ़ॉल्ट है 128K।

प्रत्येक कार्य का अपना 128K स्टैक होता है। जब आप एक क्वेरी चलाते हैं, तो यह जांचा जाता है कि इसे कितने स्टैक की आवश्यकता है। यदि डिफ़ॉल्ट 128K पर्याप्त है, तो इसे बस संसाधित किया जाता है। यदि अधिक आवश्यक है, तो एक बढ़ी हुई स्टैक के साथ एक अन्य कार्य निर्धारित किया जाता है, जो प्रक्रिया जारी रखता है। इस तरह के उन्नत स्टैक का अधिकतम आकार इस सेटिंग द्वारा सीमित है।

एक उचित उच्च दर पर मान सेट करना बहुत गहरे क्वेरियों को संसाधित करने में मदद करेगा बिना यह implying किए कि समग्र RAM खपत बहुत अधिक बढ़ जाएगी। उदाहरण के लिए, इसे 1G पर सेट करना यह नहीं बताता है कि हर नया कार्य 1G RAM लेगा, लेकिन यदि हम देखते हैं कि इसे, चलो कहते हैं, 100M स्टैक की आवश्यकता है, तो हम बस उस कार्य के लिए 100M आवंटित करते हैं। अन्य कार्य उसी समय अपने डिफ़ॉल्ट 128K स्टैक के साथ चल रहे होंगे। इसी तरीके से, हम और अधिक जटिल क्वेरियों को भी चला सकते हैं जिन्हें 500M की आवश्यकता होती है। और केवल यदि हम आंतरिक रूप से देखते हैं कि कार्य को 1G से अधिक स्टैक की आवश्यकता है, तो हम असफल होंगे और बहुत कम thread_stack के बारे में रिपोर्ट करेंगे।

हालांकि, व्यावहारिक रूप से, यहां तक कि एक क्वेरी जिसे 16M स्टैक की आवश्यकता होती है, अक्सर पार्सिंग के लिए बहुत जटिल होती है और इसे संसाधित करने में बहुत अधिक समय और संसाधनों की आवश्यकता होती है। इसलिए, डेमन इसे संसाधित करेगा, लेकिन `thread_stack` सेटिंग द्वारा ऐसे क्वेरियों को सीमित करना काफी उचित लगता है।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
thread_stack = 8M
```
<!-- end -->


### unlink_old

<!-- example conf unlink_old -->
सफल रोटेशन पर `.old` तालिका प्रतियों को अनलिंक करने का निर्धारण करता है। वैकल्पिक, डिफ़ॉल्ट है 1 (अनलिंक करें)।


<!-- intro -->
##### उदाहरण:

<!-- request Example -->

```ini
unlink_old = 0
```
<!-- end -->


### watchdog

<!-- example conf watchdog -->
थ्रेडेड सर्वर वॉचडॉग। वैकल्पिक, डिफ़ॉल्ट है 1 (वॉचडॉग सक्रिय)।

जब एक मैंटिकोरे क्वेरी क्रैश होती है, तो यह पूरे सर्वर को बंद कर सकती है। वॉचडॉग फ़ीचर सक्षम होने पर, `searchd` एक अलग हल्का प्रक्रिया भी रखता है जो मुख्य सर्वर प्रक्रिया की निगरानी करता है और असामान्य समाप्ति के मामले में इसे स्वचालित रूप से पुनः चालू करता है। वॉचडॉग डिफ़ॉल्ट रूप से सक्षम है।

<!-- request Example -->

```ini
watchdog = 0 # disable watchdog
```
<!-- end -->
<!-- proofread -->
