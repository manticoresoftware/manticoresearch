# Восстановление кластера

В случае, если демон поиска Manticore останавливается без оставшихся узлов в кластере для обработки запросов, восстановление является необходимым. Из-за многомастера, использующегося для репликации библиотеки Galera, кластер репликации Manticore представляет собой единое логическое целое, которое поддерживает согласованность своих узлов и данных, а также статус всего кластера. Это позволяет безопасно записывать данные на нескольких узлах одновременно и обеспечивает целостность кластера.

Однако это также создает определенные проблемы. Рассмотрим несколько сценариев, используя кластер узлов A, B и C, чтобы увидеть, что нужно делать, когда некоторые или все узлы становятся недоступными.

### Случай 1

 Когда узел A останавливается, остальные узлы получают сообщение о "нормальном завершении работы". Размер кластера уменьшается, и происходит перерасчет квorum.

При запуске узла A он присоединяется к кластеру и не будет обрабатывать никакие операции записи, пока полностью не синхронизируется с кластером. Если кеш наборов записей на узлах-доноров B или C (который можно контролировать с помощью параметра кластера Galera [gcache.size](https://galeracluster.com/library/documentation/galera-parameters.html#gcache-size)) все еще содержит все транзакции, пропущенные на узле A, узел A получит быстрый инкрементальный перенос состояния ([IST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-ist)), то есть перенос только пропущенных транзакций. Если нет, произойдет перенос состояния снимка ([SST](https://galeracluster.com/library/documentation/state-transfer.html#state-transfer-sst)), который включает в себя перенос файлов таблиц.

### Случай 2

В сценарии, когда узлы A и B остановлены, размер кластера уменьшается до одного, и узел C формирует основной компонент для обработки операций записи. 

Узлы A и B могут быть запущены как обычно и присоединятся к кластеру после запуска. Узел C действует как донор, предоставляя перенос состояния для узлов A и B.

### Случай 3

Все узлы остановлены как обычно, и кластер выключен.

Проблема теперь состоит в том, как инициализировать кластер. Важно, чтобы при чистом завершении работы searchd узлы записывали номер последней выполненной транзакции в файл кластера [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) вместе с флагом `safe_to_bootstrap`. Узел, который был остановлен последним, будет иметь опцию `safe_to_bootstrap: 1` и самый продвинутый номер `seqno`.

Важно, чтобы этот узел стартовал первым для формирования кластера. Чтобы загрузить кластер, сервер должен быть запущен на этом узле с флагом [--new-cluster](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md). На Linux вы также можете запустить `manticore_new_cluster`, который запустит Manticore в режиме `--new-cluster` через systemd.

Если другой узел запустится первым и загрузит кластер, то самый продвинутый узел присоединится к этому кластеру, выполнит полный SST и получит файл таблицы, в котором некоторые транзакции отсутствуют по сравнению с файлами таблиц, которые он получил ранее. Именно поэтому важно сначала запустить узел, который был остановлен последним; он должен иметь флаг `safe_to_bootstrap: 1` в [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md).

### Случай 4

В случае сбоя или сетевой ошибки, из-за которой узел A исчез из кластера, узлы B и C попытаются повторно подключиться к узлу A. В случае неудачи они удалят узел A из кластера. Поскольку два из трех узлов все еще работают, кластер сохраняет свой квorum и продолжает работать нормально.

Когда узел A будет перезапущен, он автоматически присоединится к кластеру, как описано в [Случае 1](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-1).

### Случай 5

Узлы A и B отключились. Узел C не может создать квorum самостоятельно, так как 1 узел меньше половины от общего числа узлов (3). В результате кластер на узле C переводится в неподготовленное состояние и отказывает в любой операции записи с сообщением об ошибке.

Тем временем узел C ждет, когда другие узлы подключатся, и также пытается подключиться к ним. Если это произойдет, и сеть будет восстановлена, а узлы A и B будут снова в сети, кластер автоматически восстановится. Если узлы A и B временно отключены от узла C, но могут продолжать общаться друг с другом, они будут продолжать работать нормально, так как все еще образуют квorum.

<!-- example case 5 -->
Однако, если оба узла A и B потерпели сбой или перезапустились из-за сбоя питания, кто-то должен активировать основной компонент на узле C, используя следующую команду:

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SET CLUSTER posts GLOBAL 'pc.bootstrap' = 1
```
<!-- request JSON -->

```json
POST /cli -d "
SET CLUSTER posts GLOBAL 'pc.bootstrap' = 1
"
```
<!-- end -->

Важно отметить, что перед выполнением этой команды вы должны подтвердить, что другие узлы действительно недоступны. В противном случае может произойти сценарий "разделения разума", и могут образоваться отдельные кластеры.

### Случай 6

Все узлы потерпели сбой. В этой ситуации файл [grastate.dat](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md) в каталоге кластера не был обновлен и не содержит действительного номера последовательности `seqno`.

Если это произойдет, кто-то должен найти узел с самыми последними данными и запустить сервер на нем, используя командный ключ [--new-cluster-force](../../Creating_a_cluster/Setting_up_replication/Restarting_a_cluster.md). Все остальные узлы стартуют как обычно, как описано в [Случае 3](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-3)).
На Linux вы также можете использовать команду `manticore_new_cluster --force`, которая запустит Manticore в режиме `--new-cluster-force` через systemd.

### Случай 7

Разделение мозга может привести к переходу кластера в состояние, не являющееся первичным. Например, рассмотрим кластер, состоящий из четного числа узлов (четыре), таких как две пары узлов, расположенные в различных центрах обработки данных. Если сбой в сети прерывает соединение между центрами обработки данных, происходит разделение мозга, так как каждая группа узлов удерживает ровно половину квorum. В результате обе группы перестают обрабатывать транзакции записи, поскольку модель репликации Galera придает первостепенное значение согласованности данных, и кластер не может принимать транзакции записи без кворума. Однако узлы в обеих группах пытаются восстановить связь с узлами из другой группы в попытке восстановить кластер.

<!-- example case 7 -->
Если кто-то хочет восстановить кластер до восстановления сети, следует выполнить те же шаги, описанные в [Случае 5](../../Creating_a_cluster/Setting_up_replication/Cluster_recovery.md#Case-5), но только в одной группе узлов. 

После выполнения команды группа с узлом, на котором она была запущена, снова сможет обрабатывать транзакции записи.


<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SET CLUSTER posts GLOBAL 'pc.bootstrap' = 1
```
<!-- request JSON -->

```json
POST /cli -d "
SET CLUSTER posts GLOBAL 'pc.bootstrap' = 1
"
```
<!-- end -->

Однако важно отметить, что если команда будет выдана в обеих группах, это приведет к образованию двух отдельных кластеров, и последующее восстановление сети не приведет к воссоединению групп.
<!-- proofread -->
