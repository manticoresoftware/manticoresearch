# Удалённые таблицы

Удалённая таблица в Manticore Search представляется префиксом [agent](../../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md) в определении распределённой таблицы. Распределённая таблица может включать комбинацию локальных и удалённых таблиц. Если локальные таблицы не предоставлены, распределённая таблица будет полностью удалённой и служить только в качестве прокси. Например, у вас может быть экземпляр Manticore, который слушает на нескольких портах и обслуживает разные протоколы, а затем перенаправляет запросы на серверы backend, которые принимают соединения только через внутренний бинарный протокол Manticore, используя постоянные соединения для уменьшения накладных расходов на установление соединений.
Несмотря на то что полностью удалённая распределённая таблица сама не обслуживает локальные таблицы, она всё равно потребляет ресурсы машины, поскольку ей всё ещё нужно выполнять окончательные вычисления, такие как объединение результатов и вычисление окончательных агрегированных значений.

## agent

```ini
agent = address1 [ | address2 [...] ][:table-list]
agent = address1[:table-list [ | address2[:table-list [...] ] ] ]
```

Директива `agent` объявляет удалённые агенты, которые ищутся каждый раз, когда производится поиск в окружающей распределённой таблице. Эти агенты по сути являются указателями на сетевые таблицы. Указанное значение включает адрес и также может содержать несколько альтернатив (зеркала агентов) как для адреса, так и для списка таблиц.

Спецификация адреса должна быть одной из следующих:

```ini
address = hostname[:port] # например, server2:9312
address = /absolute/unix/socket/path # например, /var/run/manticore2.sock
```

`hostname` — это удалённое имя хоста, `port` — это номер удалённого TCP порта, `table-list` — это список имён таблиц, разделённых запятыми, а квадратные скобки [] указывают на необязательное условие.

Если имя таблицы опущено, предполагается, что оно такое же, как и у таблицы, в которой определена эта строка. Другими словами, при определении агентов для распределённой таблицы 'mycoolindex' вы можете просто указать адрес, и будет предполагаться, что вы запрашиваете таблицу mycoolindex на конечных точках агента.

Если номер порта опущен, предполагается, что он равен **9312**. Если он определён, но недействителен (например, 70000), агент будет пропущен.

Вы можете указать каждому агенту одну или несколько удалённых таблиц, находящихся на одном или нескольких сетевых серверах без ограничений. Это позволяет использовать несколько различных режимов:
* Шардинг на нескольких серверах агентов и создание произвольной топологии кластера
* Шардинг на нескольких серверах агентов, зеркалируемых для обеспечения высокой доступности и балансировки нагрузки
* Шардинг внутри localhost для использования нескольких ядер (однако, проще просто использовать несколько локальных таблиц)

Все агенты ищутся параллельно. Список индексов передаётся в точности агенту. Точный способ поиска этого списка внутри агента (т.е. последовательно или параллельно) зависит исключительно от конфигурации агента (см. настройку [threads](../../Server_settings/Searchd.md#threads)). Мастер не имеет удалённого контроля над этим.

Важно отметить, что опция `LIMIT` игнорируется в запросах к агенту. Это связано с тем, что каждый агент может содержать разные таблицы, поэтому ответственность за применение ограничения к окончательному набору результатов лежит на клиенте. Вот почему запрос к физической таблице отличается от запроса к распределённой таблице при просмотре в логах запросов. Запрос не может быть простой копией оригинального запроса, так как это не дало бы правильных результатов.

Например, если клиент делает запрос SELECT ... LIMIT 10, 10, и есть два агента, у второго агента есть только 10 документов, то передача оригинального запроса `LIMIT 10, 10` приведет к получению 0 документов от второго агента. Однако `LIMIT 10,10` должен вернуть документы 10-20 из результирующего набора. Для этого запрос должен быть отправлен агентам с более широким ограничением, например, значением max_matches по умолчанию 1000.

Например, если есть распределённая таблица dist, которая ссылается на удалённую таблицу user, запрос клиента `SELECT * FROM dist LIMIT 10,10` будет преобразован в `SELECT * FROM user LIMIT 0,1000` и отправлен на удалённую таблицу user. Как только распределённая таблица получит результат, она применит LIMIT 10,10 и вернет запрашиваемые 10 документов.

```sql
SELECT * FROM dist LIMIT 10,10;
```

запрос будет преобразован в:

```sql
SELECT * FROM user LIMIT 0,1000
```

Дополнительно значение может указывать параметры для каждого отдельного агента, такие как:
* [ha_strategy](../../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy) - `random`, `roundrobin`, `nodeads`, `noerrors` (перезаписывает глобальную настройку `ha_strategy` для конкретного агента)
* `conn` - `pconn`, постоянное (эквивалентно настройке `agent_persistent` на уровне таблицы)
* `blackhole` `0`,`1` (идентично настройке [agent_blackhole](../../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_blackhole) для агента)
* `retry_count` целочисленное значение (соответствующее [agent_retry_count](../../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_retry_count), но указанное значение не будет умножено на количество зеркал)

```ini
agent = address1:table-list[[ha_strategy=value, conn=value, blackhole=value]]
```

Пример:

```ini
# конфигурация на box1
# шардинг таблицы на 3 сервера
agent = box2:9312:shard1
agent = box3:9312:shard2

# конфигурация на box2
# шардинг таблицы на 3 сервера
agent = box1:9312:shard2
agent = box3:9312:shard3

# конфигурация на box3
# шардинг таблицы на 3 сервера
agent = box1:9312:shard1
agent = box2:9312:shard3

# параметры на каждого агента
agent = box1:9312:shard1[ha_strategy=nodeads]
agent = box2:9312:shard2[conn=pconn]
agent = box2:9312:shard2[conn=pconn,ha_strategy=nodeads]
agent = test:9312:any[blackhole=1]
agent = test:9312|box2:9312|box3:9312:any2[retry_count=2]
agent = test:9312|box2:9312:any2[retry_count=2,conn=pconn,ha_strategy=noerrors]
```

Для достижения оптимальной производительности рекомендуется размещать удаленные таблицы, находящиеся на одном сервере, в одной записи. Например, вместо:
```ini
agent = remote:9312:idx1
agent = remote:9312:idx2
```
вам следует предпочесть:
```ini
agent = remote:9312:idx1,idx2
```

## agent_persistent

```ini
agent_persistent = remotebox:9312:index2
```

Опция `agent_persistent` позволяет вам постоянно подключаться к агенту, что означает, что соединение не будет разорвано после выполнения запроса. Синтаксис этой директивы такой же, как у директивы `agent`. Однако, вместо открытия нового соединения с агентом для каждого запроса и его закрытия, главный сервер будет поддерживать соединение открытым и повторно использовать его для последующих запросов. Максимальное количество постоянных соединений на один хост агента определяется опцией [persistent_connections_limit](../../Server_settings/Searchd.md#persistent_connections_limit) в разделе searchd.

Важно отметить, что [persistent_connections_limit](../../Server_settings/Searchd.md#persistent_connections_limit) должен быть установлен на значение больше 0, чтобы использовать постоянные подключения к агенту. Если он не определен, по умолчанию он равен 0, и директива `agent_persistent` будет действовать так же, как и директива `agent`.

Использование постоянных соединений между мастер-агентом снижает нагрузку на TCP-порт и экономит время на установление соединений, что делает это более эффективным.

## agent_blackhole

```ini
agent_blackhole = testbox:9312:testindex1,testindex2
````

Директива `agent_blackhole` позволяет вам пересылать запросы к удаленным агентам без ожидания или обработки их ответов. Это полезно для отладки или тестирования производственных кластеров, так как вы можете настроить отдельный экземпляр для отладки/тестирования и перенаправить запросы к нему из производственного главного (агрегирующего) экземпляра, не вмешиваясь в производственные работы. Главный searchd попытается подключиться к черной дыры агента и отправить запросы как обычно, но не будет ждать или обрабатывать какие-либо ответы, и все сетевые ошибки на агентах черной дыры будут игнорироваться. Формат значения идентичен формату обычной директивы `agent`.

## agent_connect_timeout

```ini
agent_connect_timeout = 300
````

Директива `agent_connect_timeout` определяет тайм-аут для подключения к удаленным агентам. По умолчанию значение предполагается в миллисекундах, но может иметь [другой суффикс](../../Server_settings/Special_suffixes.md)). Значение по умолчанию - 1000 (1 секунда).

При подключении к удаленным агентам `searchd` будет ждать не более этого времени для успешного завершения подключения. Если тайм-аут истечет, но соединение не было установлено, и включены `retries`, будет инициирована повторная попытка.

## agent_query_timeout

```ini
agent_query_timeout = 10000 # наш запрос может быть долгим, разрешить до 10 сек
```

Директива `agent_query_timeout` устанавливает время, в течение которого searchd будет ждать, пока удаленный агент завершит запрос. Значение по умолчанию составляет 3000 миллисекунд (3 секунды), но может быть `с суффиксом`, чтобы указать единицу времени.

После установления соединения `searchd` будет ждать максимум agent_query_timeout для завершения удаленных запросов. Обратите внимание, что этот тайм-аут отделен от `agent_connection_timeout`, и общая возможная задержка, вызванная удаленным агентом, будет равна сумме обоих значений. Если тайм-аут agent_query_timeout достигнут, запрос **не** будет повторно отправлен, вместо этого будет выдано предупреждение.

Обратите внимание, что на поведение также влияет [reset_network_timeout_on_packet](../../Server_settings/Searchd.md#reset_network_timeout_on_packet)

## agent_retry_count

`agent_retry_count` - это целое число, которое указывает, сколько раз Manticore будет пытаться подключиться и запросить удаленных агентов в распределенной таблице, прежде чем сообщить о фатальной ошибке запроса. Он работает аналогично `agent_retry_count`, определенному в разделе "searchd" конфигурационного файла, но применяется конкретно к таблице.

## mirror_retry_count

`mirror_retry_count` выполняет ту же функцию, что и `agent_retry_count`. Если предоставлены оба значения, будет использоваться `mirror_retry_count`, и будет выдано предупреждение.

## Опции на уровне экземпляра

Следующие опции управляют общим поведением удаленных агентов и заданы в **разделе searchd конфигурационного файла**. Они устанавливают значения по умолчанию для всего экземпляра Manticore.

* `agent_connect_timeout` - значение по умолчанию для параметра `agent_connect_timeout`.
* `agent_query_timeout` - значение по умолчанию для параметра `agent_query_timeout`. Это также может быть переопределено на уровне конкретного запроса с использованием того же имени настройки в распределенной (сетевой) таблице.
* `agent_retry_count` - это целое число, которое указывает, сколько раз Manticore будет пытаться подключиться и запросить удаленных агентов в распределенной таблице, прежде чем сообщить о фатальной ошибке запроса. Значение по умолчанию - 0 (т.е. без повторных попыток). Это значение также может быть указано на уровне конкретного запроса с использованием условия 'OPTION retry_count=XXX'. Если предоставлен параметр на уровне запроса, он будет иметь преимущественную силу над значением, указанным в конфигурации.

Обратите внимание, что если вы используете **агентские зеркала** в определении вашей распределенной таблицы, сервер будет выбирать другое зеркало перед каждой попыткой подключения в соответствии с указанной [ha_strategy](../../Creating_a_cluster/Remote_nodes/Load_balancing.md#ha_strategy). В этом случае [agent_retry_count](../../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#agent_retry_count) будет агрегировано для всех зеркал в наборе.

Например, если у вас 10 зеркал и вы установите `agent_retry_count=5`, сервер будет пытаться сделать до 50 повторных попыток (предполагая, что в среднем 5 попыток на каждые 10 зеркал). В случае параметра `ha_strategy = roundrobin` это будет фактически ровно 5 попыток на каждое зеркало.
В то же время значение, указанное в опции [retry_count](../../Searching/Options.md#retry_count) в определении `agent`, служит как абсолютный предел. Другими словами, опция `[retry_count=2]` в определении агента означает, что будет максимум 2 попытки, независимо от того, есть ли 1 или 10 зеркал в линии.

### agent_retry_delay

Значение `agent_retry_delay` - это целое число, которое определяет количество времени в миллисекундах, которое Manticore Search будет ждать перед повторной попыткой запроса к удаленному агенту в случае сбоя. Это значение может быть задано как глобально в конфигурации searchd, так и для каждого запроса с помощью условия `OPTION retry_delay=XXX`. Если обе опции указаны, опция для запроса имеет приоритет над глобальной. Значение по умолчанию составляет 500 миллисекунд (0,5 секунды). Эта опция имеет значение только если agent_retry_count или перезапрос `OPTION retry_count` ненулевые.

### client_timeout

Опция `client_timeout` устанавливает максимальное время ожидания между запросами при использовании устойчивых соединений. Это значение выражается в секундах или с суффиксом времени. Значение по умолчанию составляет 5 минут.

Пример:

```ini
client_timeout = 1h
```

### hostname_lookup

Опция `hostname_lookup` определяет стратегию обновления имен хостов. По умолчанию IP-адреса имен хостов агентов кэшируются при запуске сервера, чтобы избежать чрезмерного доступа к DNS. Однако в некоторых случаях IP может динамически изменяться (например, облачный хостинг), и может быть желательным не кэшировать IP-адреса. Установка этой опции в `request` отключает кэширование и делает запрос к DNS для каждого запроса. IP-адреса также могут быть вручную обновлены с помощью команды `FLUSH HOSTNAMES`.

### listen_tfo

Опция `listen_tfo` позволяет использовать флаг TCP_FASTOPEN для всех слушателей. По умолчанию он управляется системой, но его можно явно отключить, установив в '0'.

Для получения дополнительной информации о расширении TCP Fast Open, пожалуйста, обратитесь к [Wikipedia](https://en.wikipedia.org/wiki/TCP_Fast_Open). Кратко, он позволяет исключить одну TCP-программу при установлении соединения.

На практике использование TFO может оптимизировать сетевую эффективность клиента-агента, аналогично тому, когда используется `agent_persistent`, но без удержания активных соединений и без ограничений по максимальному количеству соединений.

Большинство современных операционных систем поддерживают TFO. Linux (как одна из самых прогрессивных) поддерживает его с 2011 года, начиная с версий ядра 3.7 (для серверной стороны). Windows поддерживает его с некоторых сборок Windows 10. Другие системы, такие как FreeBSD и MacOS, также в игре.

Для Linux-систем сервер проверяет переменную `/proc/sys/net/ipv4/tcp_fastopen` и ведет себя соответственно. Бит 0 управляет клиентской стороной, в то время как бит 1 управляет слушателями. По умолчанию система имеет этот параметр, установленный в 1, т.е. клиенты включены и слушатели отключены.

### persistent_connections_limit

```ini
persistent_connections_limit = 29 # предположим, что каждый хост агентов имеет max_connections = 30 (или 29).
```

Опция `persistent_connections_limit` определяет максимальное количество одно-временных устойчивых соединений с удаленными устойчивыми агентами. Это настройка на уровне экземпляра и должна быть определена в разделе конфигурации searchd. Каждый раз, когда устанавливается соединение с агентом, определенным в `agent_persistent`, мы пытаемся повторно использовать существующее соединение (если таковое существует) или создать новое соединение и сохранить его для будущего использования. Однако в некоторых случаях может быть необходимо ограничить количество устойчивых соединений. Эта директива определяет предел и влияет на количество соединений с каждым хостом агента во всех распределенных таблицах.

Рекомендуется установить это значение равным или меньшим, чем опция [max_connections](../../Server_settings/Searchd.md#max_connections) в конфигурации агента.

## Создание распределенных фрагментов

Особенно случай распределенной таблицы - это одна локальная и несколько удаленных, которая используется исключительно для [создания распределенных фрагментов](../../Creating_a_table/Creating_a_distributed_table/Remote_tables.md#Distributed-snippets-creation), когда фрагменты берутся из файлов. В этом случае локальная таблица может выступать в качестве "шаблонной" таблицы, предоставляя настройки для токенизации при построении фрагментов.

### snippets_file_prefix

```ini
snippets_file_prefix = /mnt/common/server1/
```

`snippets_file_prefix` - это необязательный префикс, который может быть добавлен к локальным именам файлов при генерации фрагментов. Значение по умолчанию - текущая рабочая папка.

Чтобы узнать больше о создании распределенных фрагментов, смотрите [CALL SNIPPETS](../../Searching/Highlighting.md).

## Распределенные таблицы перколят (таблицы DPQ)

Вы можете создать распределенную таблицу из нескольких [перколят](../../Creating_a_table/Local_tables/Percolate_table.md) таблиц. Синтаксис для построения этого типа таблицы такой же, как и для других распределенных таблиц, и может включать несколько `local` таблиц, а также `agents`.

Для DPQ операции по перечислению сохраненных запросов и поиску по ним (с использованием [CALL PQ](../../Searching/Percolate_query.md#Performing-a-percolate-query-with-CALL-PQ)) являются прозрачными и работают так, как будто все таблицы были одной единственной локальной таблицей. Однако операции манипуляции с данными, такие как `insert`, `replace`, `truncate` недоступны.

Если вы включите не перколят таблицу в список агентов, поведение будет неопределенным. Если неправильный агент имеет ту же схему, что и внешняя схема таблицы PQ (id, query, tags, filters), это не вызовет ошибку при перечислении сохраненных правил PQ, и может загрязнить список фактических правил PQ, сохраненных в PQ таблицах, своими собственными строками не-PQ. В результате будьте осторожны и осведомлены о путанице, которую это может вызвать. `CALL PQ` к такому неправильному агенту вызовет ошибку.
Для получения дополнительной информации о выполнении запросов к распределенной таблице перколяции см. [выполнение запросов к распределенной таблице перколяции](../../Searching/Percolate_query.md#Performing-a-percolate-query-with-CALL-PQ).
<!-- proofread -->


