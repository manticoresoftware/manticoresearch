# Токенизация данных

Manticore не хранит текст в исходном виде для выполнения полнотекстового поиска. Вместо этого он извлекает слова и создает несколько структур, которые позволяют быстро выполнять полнотекстовый поиск. Из найденных слов создается словарь, который позволяет быстро проверить, присутствует ли слово в индексе или нет. В дополнение к этому другие структуры фиксируют документы и поля, в которых было найдено слово (а также его положение внутри поля). Все это используется при выполнении полнотекстового совпадения.

Процесс размечивания и классификации слов называется токенизацией. Токенизация применяется как на этапе индексации, так и на этапе поиска, и она работает на уровне символов и слов.

На уровне символов движок позволяет проходить только определенным символам. Это определяется [charset_table](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Все остальное заменяется на пробел (который считается разделителем слов по умолчанию). Charset_table также допускает отображения, такие как преобразование в нижний регистр или простая замена одного символа на другой. Кроме того, символы могут быть [игнорированы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars), [смешаны](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars), определены как [граница фразы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary).

На уровне слов основная настройка - это [min_word_len](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len), которая определяет минимальную длину слова в символах, принимаемых в индексе. Часто бывает необходимо сопоставлять единственное и множественное число слов. Для этого можно использовать [морфологические процессоры](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology).

Если мы хотим, чтобы слово сопоставлялось с другим из-за их синонимичности, можно использовать функцию [словоформ](../../Creating_a_table/NLP_and_tokenization/Wordforms.md), которая позволяет сопоставлять одно или несколько слов с другим словом.

Очень распространенные слова могут иметь нежелательные последствия при поиске, в основном из-за своей частоты они требуют много вычислений для обработки своих списков документов/результатов. Их можно занести в черный список с помощью функциональности [стоп-слов](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords). Это помогает не только ускорить запросы, но и уменьшить размер индекса.

Более продвинутый черный список - это [биграммы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index), который позволяет создать специальный токен между "биграммным" (распространенным) словом и редким словом. Это может значительно ускорить поиск при использовании распространенных слов в фразовых запросах.

При индексации содержания HTML важно не индексировать HTML-теги, так как они могут внести много "шума" в индекс. Можно использовать [очистку HTML](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#Stripping-HTML-tags) и настроить ее для очистки, но индексирования определенных атрибутов тегов или полного игнорирования содержимого определенных HTML-элементов.
<!-- proofread -->
