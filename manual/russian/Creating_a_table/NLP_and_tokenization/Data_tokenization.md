# Токенизация данных

Manticore не хранит текст точно таким, каким он является, для полнотекстового поиска. Вместо этого он разбивает текст на слова (называемые токенами) и строит несколько внутренних структур для обеспечения быстрого полнотекстового поиска. Эти структуры включают словарь, который помогает быстро проверить, существует ли слово в индексе. Другие структуры отслеживают, в каких документах и полях содержится слово, и даже где именно в поле оно появляется. Все это используется во время поиска для нахождения релевантных результатов.

Процесс разбивания и обработки текста таким образом называется **токенизацией**. Токенизация происходит как при добавлении данных в индекс, так и при выполнении поиска. Она работает как на уровне символов, так и на уровне слов.

### Токенизация на уровне символов

На уровне символов допускаются только определённые символы. Это контролируется с помощью [`charset_table`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Все остальные символы заменяются пробелом (который рассматривается как разделитель слов). `charset_table` также поддерживает такие операции, как преобразование символов в нижний регистр или замену одного символа на другой. Она также может определять символы для [игнорирования](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars), [объединения](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars) или обработки как [границу фразы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary).

### Токенизация на уровне слов

На уровне слов движок использует настройку [`min_word_len`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len), чтобы определить минимальную длину слова (в символах), которое должно индексироваться.

Manticore также поддерживает сопоставление слов в разных формах. Например, чтобы считать "car" и "cars" одним и тем же словом, вы можете использовать [морфологические процессоры](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology).

Если вы хотите, чтобы разные слова рассматривались как одно — например, "USA" и "United States" — вы можете определить их с помощью функции [word forms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md).

### Обработка распространённых и «шумных» слов

Очень распространённые слова (например, "the", "and", "is") могут замедлять поиск и увеличивать размер индекса. Вы можете отфильтровать их с помощью [стоп-слов](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords). Это может ускорить поиск и уменьшить размер индекса.

Более продвинутый метод фильтрации — это [биграммы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index), которые создают специальные токены, объединяя распространённое слово с редким. Это может значительно ускорить поиск по фразам, в которых участвуют распространённые слова.

### HTML-контент

Если вы индексируете HTML, обычно лучше не включать HTML-теги в индекс, так как они добавляют много лишнего содержимого. Вы можете использовать [очистку HTML](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#Stripping-HTML-tags), чтобы убрать теги, но при этом индексировать определённые атрибуты тегов или полностью пропускать некоторые элементы.

### Ограничение длины токена

Имейте в виду, что у Manticore есть **максимальная длина токена — 42 символа**. Любое слово длиннее этой длины будет **усечено**. Это ограничение применяется как во время индексации, так и при поиске, поэтому важно учитывать его при подготовке данных и формировании запросов.
