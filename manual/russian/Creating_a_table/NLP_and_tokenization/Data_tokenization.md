# Токенизация данных

Manticore не хранит текст точно в том виде, в каком он есть, для полнотекстового поиска. Вместо этого он разбивает текст на слова (называемые токенами) и строит несколько внутренних структур для обеспечения быстрого полнотекстового поиска. Эти структуры включают словарь, который помогает быстро проверить, существует ли слово в индексе. Другие структуры отслеживают, в каких документах и полях содержится слово, и даже где именно в поле оно появляется. Все это используется во время поиска для нахождения релевантных результатов.

Процесс разбиения и обработки текста таким образом называется **токенизацией**. Токенизация происходит как при добавлении данных в индекс, так и при выполнении поиска. Она работает как на уровне символов, так и на уровне слов.

### Токенизация на уровне символов

На уровне символов разрешены только определённые символы. Это контролируется с помощью [`charset_table`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Все остальные символы заменяются пробелом (который рассматривается как разделитель слов). `charset_table` также поддерживает такие функции, как преобразование символов в нижний регистр или замена одного символа другим. Она также может определять символы, которые нужно [игнорировать](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars), [объединять](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars) или рассматривать как [границу фразы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary).

### Токенизация на уровне слов

На уровне слов движок использует настройку [`min_word_len`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len), чтобы определить минимальную длину слова (в символах), которое должно индексироваться.

Manticore также поддерживает сопоставление слов с разными формами. Например, чтобы рассматривать "car" и "cars" как одно и то же слово, можно использовать [морфологические процессоры](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology).

Если вы хотите, чтобы разные слова рассматривались как одно — например, "USA" и "United States" — вы можете определить их с помощью функции [форм слов](../../Creating_a_table/NLP_and_tokenization/Wordforms.md).

### Обработка распространённых и шумных слов

Очень распространённые слова (например, "the", "and", "is") могут замедлять поиск и увеличивать размер индекса. Вы можете отфильтровать их с помощью [стоп-слов](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords). Это может сделать поиск быстрее и уменьшить размер индекса.

Более продвинутый метод фильтрации — это [биграммы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index), которые создают специальные токены, объединяя распространённое слово с редким. Это может значительно ускорить поиск фраз, когда в них участвуют распространённые слова.

### HTML-контент

Если вы индексируете HTML, обычно лучше не включать HTML-теги в индекс, так как они добавляют много ненужного содержимого. Вы можете использовать [удаление HTML-тегов](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#Stripping-HTML-tags), чтобы убрать теги, но при этом индексировать определённые атрибуты тегов или полностью пропускать определённые элементы.

### Ограничение длины токена

Имейте в виду, что в Manticore существует **максимальная длина токена — 42 символа**. Любое слово длиннее этого будет **усечено**. Это ограничение действует как при индексировании, так и при поиске, поэтому важно учитывать его при подготовке данных и запросов.
