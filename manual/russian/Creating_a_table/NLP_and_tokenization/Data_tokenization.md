# Токенизация данных

Manticore не хранит текст в точности таким, каким он есть, для полнотекстового поиска. Вместо этого он разбивает текст на слова (называемые токенами) и строит несколько внутренних структур для обеспечения быстрого полнотекстового поиска. Эти структуры включают словарь, который помогает быстро проверить, существует ли слово в индексе. Другие структуры отслеживают, в каких документах и полях содержится слово, а также где именно в поле оно появляется. Всё это используется во время поиска для нахождения релевантных результатов.

Процесс разбиения и обработки текста таким образом называется **токенизацией**. Токенизация происходит как при добавлении данных в индекс, так и при выполнении поиска. Она работает как на уровне символов, так и на уровне слов.

### Токенизация на уровне символов

На уровне символов разрешены только определённые символы. Это контролируется с помощью [`charset_table`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#charset_table). Все остальные символы заменяются пробелом (который рассматривается как разделитель слов). `charset_table` также поддерживает такие вещи, как преобразование символов в строчные или замену одного символа на другой. Также можно определить символы, которые нужно [игнорировать](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#ignore_chars), [смешивать](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#blend_chars) или рассматривать как [границу фразы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#phrase_boundary).

### Токенизация на уровне слов

На уровне слов движок использует настройку [`min_word_len`](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#min_word_len), чтобы определить минимальную длину слова (в символах), которое должно индексироваться.

Manticore также поддерживает сопоставление слов в различных формах. Например, чтобы рассматривать "car" и "cars" как одно и то же слово, можно использовать [морфологические процессоры](../../Creating_a_table/NLP_and_tokenization/Morphology.md#morphology).

Если вы хотите, чтобы разные слова рассматривались как одно и то же — например, "USA" и "United States" — вы можете определить их с помощью функции [word forms](../../Creating_a_table/NLP_and_tokenization/Wordforms.md).

### Обработка распространённых и шумных слов

Очень распространённые слова (например, "the", "and", "is") могут замедлять поиск и увеличивать размер индекса. Их можно отфильтровать с помощью [стоп-слов](../../Creating_a_table/NLP_and_tokenization/Ignoring_stop-words.md#stopwords). Это может сделать поиск быстрее, а индекс — меньше.

Более продвинутый метод фильтрации — это [биграммы](../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#bigram_index), которые создают специальные токены, объединяя распространённое слово с менее распространённым. Это может значительно ускорить поиск по фразам, содержащим распространённые слова.

### HTML-контент

Если вы индексируете HTML, обычно лучше не включать HTML-теги в индекс, так как они добавляют много ненужного содержимого. Вы можете использовать [удаление HTML-тегов](../../Creating_a_table/NLP_and_tokenization/Advanced_HTML_tokenization.md#Stripping-HTML-tags), чтобы убрать теги, но при этом индексировать определённые атрибуты тегов или полностью пропускать определённые элементы.

### Ограничение длины токена

Учтите, что в Manticore существует **максимальная длина токена — 42 символа**. Любое слово длиннее будет **усечено**. Это ограничение действует как при индексации, так и при поиске, поэтому важно, чтобы ваши данные и запросы учитывали это.
