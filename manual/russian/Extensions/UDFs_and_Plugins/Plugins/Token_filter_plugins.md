# Плагины фильтров токенов

Плагины фильтров токенов позволяют реализовать пользовательский токенизатор, который создает токены согласно пользовательским правилам. Существует два типа:

* Токенизатор во время индексации, объявляемый с помощью [index_token_filter](../../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter) в настройках таблицы
* Токенизатор во время запроса, объявляемый с помощью директивы OPTION [token_filter](../../../Searching/Options.md#token_filter)

В конвейере обработки текста фильтры токенов запускаются после базовой обработки токенизатором (которая обрабатывает текст из полей или запросов и создает из них токены).

## Токенизатор во время индексации

Токенизатор во время индексации создается `indexer` при индексации исходных данных в таблицу или RT таблицей при обработке операторов `INSERT` или `REPLACE`.

Плагин объявляется как `library name:plugin name:optional string of settings`. Функции инициализации плагина могут принимать произвольные настройки, которые передаются в виде строки в формате `option1=value1;option2=value2;..`.

Пример:

```ini
index_token_filter = my_lib.so:email_process:field=email;split=.io
```

Последовательность вызовов для фильтра токенов во время индексации следующая:

1.  `XXX_init()` вызывается сразу после того, как `indexer` создает фильтр токенов с пустым списком полей, а затем после того, как indexer получает схему таблицы с актуальным списком полей. Должен возвращать ноль при успешной инициализации или описание ошибки в противном случае.
2.  `XXX_begin_document` вызывается только для RT таблицы при `INSERT`/`REPLACE` для каждого документа. Должен возвращать ноль при успешном вызове или описание ошибки в противном случае. С помощью OPTION `token_filter_options` можно передать дополнительные параметры/настройки функции.
    ```sql
    INSERT INTO rt (id, title) VALUES (1, 'some text corp@space.io') OPTION token_filter_options='.io'
    ```
3.  `XXX_begin_field` вызывается один раз для каждого поля перед обработкой поля базовым токенизатором, с номером поля в качестве параметра.
4.  `XXX_push_token` вызывается один раз для каждого нового токена, созданного базовым токенизатором, с исходным токеном в качестве параметра. Должен возвращать токен, количество дополнительных токенов, созданных фильтром токенов, и дельту позиции для токена.
5.  `XXX_get_extra_token` вызывается несколько раз, если `XXX_push_token` сообщает о дополнительных токенах. Должен возвращать токен и дельту позиции для этого дополнительного токена.
6.  `XXX_end_field` вызывается один раз сразу после обработки исходных токенов из текущего поля.
7.  `XXX_deinit` вызывается в самом конце индексации.

Обязательными для определения являются функции: `XXX_begin_document`, `XXX_push_token` и `XXX_get_extra_token`.

## Фильтр токенов во время запроса

Токенизатор во время запроса создается при каждом поиске полнотекстового поиска для каждой задействованной таблицы.

Последовательность вызовов для фильтра токенов во время запроса следующая:

1.  `XXX_init()` вызывается один раз для каждой таблицы перед разбором запроса с параметрами — максимальная длина токена и строка, заданная опцией `token_filter`
    ```sql
    SELECT * FROM index WHERE MATCH ('test') OPTION token_filter='my_lib.so:query_email_process:io'
    ```
    Должен возвращать ноль при успешной инициализации или описание ошибки в противном случае.
2.  `XXX_push_token()` вызывается один раз для каждого нового токена, созданного базовым токенизатором, с параметрами: токен, созданный базовым токенизатором, указатель на необработанный токен в исходной строке запроса и длина необработанного токена. Должен возвращать токен и дельту позиции для токена.
3.  `XXX_pre_morph()` вызывается один раз для токена непосредственно перед передачей его морфологическому процессору с ссылкой на токен и флагом стоп-слова. Может установить флаг стоп-слова, чтобы пометить токен как стоп-слово.
4.  `XXX_post_morph()` вызывается один раз для токена после обработки морфологическим процессором с ссылкой на токен и флагом стоп-слова. Может установить флаг стоп-слова, чтобы пометить токен как стоп-слово. Должен возвращать флаг, ненулевое значение которого означает использование токена до морфологической обработки.
5.  `XXX_deinit()` вызывается в самом конце обработки запроса.

Отсутствие функций допускается.

<!-- proofread -->

