# Плагины фильтров токенов

Плагины фильтров токенов позволяют реализовать пользовательский токенизатор, который создает токены согласно пользовательским правилам. Существует два типа:

* Токенизатор во время индексирования, объявляемый через [index_token_filter](../../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter) в настройках таблицы
* Токенизатор во время запроса, объявляемый через директиву OPTION [token_filter](../../../Searching/Options.md#token_filter)

В конвейере обработки текста фильтры токенов запускаются после базовой обработки токенизатором (которая обрабатывает текст из полей или запросов и создает из них токены).

## Токенизатор во время индексирования

Токенизатор во время индексирования создается `indexer` при индексировании исходных данных в таблицу, либо RT таблицей при обработке операторов `INSERT` или `REPLACE`.

Плагин объявляется как `library name:plugin name:optional string of settings`. Функции инициализации плагина могут принимать произвольные настройки, которые передаются в виде строки в формате `option1=value1;option2=value2;..`.

Пример:

```ini
index_token_filter = my_lib.so:email_process:field=email;split=.io
```

Последовательность вызовов для фильтра токенов во время индексирования следующая:

1.  Вызов `XXX_init()` происходит сразу после создания фильтра токенов `indexer` с пустым списком полей, а затем после получения схемы таблицы с фактическим списком полей. Функция должна вернуть ноль при успешной инициализации, или описание ошибки в противном случае.
2.  `XXX_begin_document` вызывается только для RT таблицы при операциях `INSERT`/`REPLACE` для каждого документа. Должна вернуть ноль при успешном вызове или описание ошибки в противном случае. С помощью опции OPTION `token_filter_options` могут быть переданы дополнительные параметры/настройки функции.
    ```sql
    INSERT INTO rt (id, title) VALUES (1, 'some text corp@space.io') OPTION token_filter_options='.io'
    ```
3.  `XXX_begin_field` вызывается один раз для каждого поля перед обработкой поля базовым токенизатором, параметром передается номер поля.
4.  `XXX_push_token` вызывается один раз для каждого нового токена, продуцируемого базовым токенизатором, параметром передается исходный токен. Функция должна вернуть токен, число дополнительных токенов, созданных фильтром токенов, и смещение позиции (delta position) для токена.
5.  `XXX_get_extra_token` вызывается несколько раз, если `XXX_push_token` сообщает о дополнительных токенах. Должна вернуть токен и смещение позиции для каждого дополнительного токена.
6.  `XXX_end_field` вызывается один раз сразу после обработки исходных токенов из текущего поля.
7.  `XXX_deinit` вызывается в самом конце индексирования.

Обязательными для определения являются функции: `XXX_begin_document`, `XXX_push_token` и `XXX_get_extra_token`.

## Фильтр токенов во время запроса

Токенизатор во время запроса создается при каждом поиске full-text каждым задействованным индексом.

Последовательность вызовов фильтра токенов во время запроса следующая:

1.  `XXX_init()` вызывается один раз для каждой таблицы перед разбором запроса с параметрами — максимальной длиной токена и строкой, заданной опцией `token_filter`
    ```sql
    SELECT * FROM index WHERE MATCH ('test') OPTION token_filter='my_lib.so:query_email_process:io'
    ```
    Функция должна вернуть ноль при успешной инициализации или описание ошибки в противном случае.
2.  `XXX_push_token()` вызывается один раз для каждого нового токена, производимого базовым токенизатором, с параметрами: токен, произведенный базовым токенизатором, указатель на исходный токен в строке запроса и длина исходного токена. Должна возвращать токен и смещение позиции для токена.
3.  `XXX_pre_morph()` вызывается один раз для токена сразу перед передачей морфологическому процессору с ссылкой на токен и флагом стоп-слова. Может установить флаг стоп-слова, чтобы пометить токен как стоп-слово.
4.  `XXX_post_morph()` вызывается один раз для токена после обработки морфологическим процессором с ссылкой на токен и флагом стоп-слова. Может установить флаг стоп-слова, чтобы пометить токен как стоп-слово. Должна возвращать флаг, ненулевое значение которого означает использовать токен до морфологической обработки.
5.  `XXX_deinit()` вызывается в самом конце обработки запроса.

Отсутствие каких-либо функций допускается.

<!-- proofread -->

