# Плагины фильтров токенов

Плагины фильтров токенов позволяют вам реализовать пользовательский токенизатор, который создает токены согласно пользовательским правилам. Существует два типа:

* Токенизатор времени индексации, объявляемый с помощью [index_token_filter](../../../Creating_a_table/NLP_and_tokenization/Low-level_tokenization.md#index_token_filter) в настройках таблицы
* Токенизатор времени запроса, объявляемый с помощью директивы OPTION [token_filter](../../../Searching/Options.md#token_filter)

В конвейере обработки текста фильтры токенов будут запущены после обработки базового токенизатора (который обрабатывает текст из полей или запросов и создает из них токены).

## Токенизатор времени индексации

Токенизатор времени индексации создается `indexer` при индексировании исходных данных в таблицу или RT таблицей при обработке операторов `INSERT` или `REPLACE`.

Плагин объявляется как `library name:plugin name:optional string of settings`. Инициализирующие функции плагина могут принимать произвольные настройки, которые можно передать в виде строки в формате `option1=value1;option2=value2;..`.

Пример:

```ini
index_token_filter = my_lib.so:email_process:field=email;split=.io
```

Рабочий процесс вызова для фильтра токенов времени индексации выглядит следующим образом:

1.  `XXX_init()` вызывается сразу после того, как `indexer` создает фильтр токенов с пустым списком полей, а затем после того, как индексатор получает схему таблицы с фактическим списком полей. Он должен вернуть ноль для успешной инициализации или описание ошибки в противном случае.
2.  `XXX_begin_document` вызывается только для RT таблицы `INSERT`/`REPLACE` для каждого документа. Он должен вернуть ноль для успешного вызова или описание ошибки в противном случае. С помощью директивы OPTION `token_filter_options` дополнительные параметры/настройки могут быть переданы в функцию.
    ```sql
    INSERT INTO rt (id, title) VALUES (1, 'some text corp@space.io') OPTION token_filter_options='.io'
    ```
3.  `XXX_begin_field` вызывается один раз для каждого поля перед обработкой поля базовым токенизатором с номером поля в качестве параметра.
4.  `XXX_push_token` вызывается один раз для каждого нового токена, произведенного базовым токенизатором, с исходным токеном в качестве параметра. Он должен вернуть токен, количество дополнительных токенов, созданных фильтром токенов, и дельту позиции для токена.
5.  `XXX_get_extra_token` вызывается несколько раз в случае, если `XXX_push_token` сообщает о дополнительных токенах. Он должен вернуть токен и дельту позиции для этого дополнительного токена.
6.  `XXX_end_field` вызывается один раз сразу после обработки исходных токенов из текущего поля.
7.  `XXX_deinit` вызывается в самом конце индексирования.

Следующие функции обязательны для определения: `XXX_begin_document`, `XXX_push_token` и `XXX_get_extra_token`.

## Фильтр токенов времени запроса

Токенизатор времени запроса создается при поиске каждый раз, когда вызывается полнотекстовый поиск каждой вовлеченной таблицы.

Рабочий процесс вызова для фильтра токенов времени запроса выглядит следующим образом:

1.  `XXX_init()` вызывается один раз для каждой таблицы перед парсингом запроса с параметрами - максимальная длина токена и строка, заданная опцией `token_filter`
    ```sql
    SELECT * FROM index WHERE MATCH ('test') OPTION token_filter='my_lib.so:query_email_process:io'
    ```
    Он должен вернуть ноль для успешной инициализации или описание ошибки в противном случае.
2.  `XXX_push_token()` вызывается один раз для каждого нового токена, произведенного базовым токенизатором, с параметрами: токен, произведенный базовым токенизатором, указатель на необработанный токен в строке исходного запроса и длина необработанного токена. Он должен вернуть токен и дельту позиции для токена.
3.  `XXX_pre_morph()` вызывается один раз для токена непосредственно перед его передачей в процессор морфологии с указателем на токен и флагом стоп-слов. Он может установить флаг стоп-слов, чтобы пометить токен как стоп-слово.
4.  `XXX_post_morph()` вызывается один раз для токена после его обработки процессором морфологии с указателем на токен и флагом стоп-слов. Он может установить флаг стоп-слов, чтобы пометить токен как стоп-слово. Он должен вернуть флаг, ненулевое значение которого означает использование токена перед морфологической обработкой.
5.  `XXX_deinit()` вызывается в самом конце обработки запроса.

Отсутствие функций допускается.

<!-- proofread -->
