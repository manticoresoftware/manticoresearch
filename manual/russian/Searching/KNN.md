# Поиск векторов методом k-ближайших соседей

Manticore Search поддерживает возможность добавлять эмбеддинги, создаваемые моделями машинного обучения, к каждому документу и затем выполнять поиск ближайших соседей по ним. Это позволяет создавать такие функции, как поиск по схожести, рекомендации, семантический поиск и ранжирование релевантности на основе алгоритмов обработки естественного языка, а также другие, включая поиск изображений, видео и звука.

## Что такое эмбеддинг?

Эмбеддинг — это способ представления данных, таких как текст, изображения или звук, в виде векторов в пространстве высокой размерности. Эти векторы создаются таким образом, чтобы расстояние между ними отражало схожесть представленных данных. Этот процесс обычно использует алгоритмы, например, векторные представления слов (Word2Vec, BERT) для текста или нейронные сети для изображений. Высокая размерность пространства векторов, с большим числом компонентов на один вектор, позволяет представлять сложные и тонкие взаимосвязи между элементами. Их схожесть измеряется расстоянием между векторами, часто с помощью таких метрик, как евклидово расстояние или косинусное сходство.

Manticore Search позволяет выполнять поиск k-ближайших соседей (KNN) с помощью библиотеки HNSW. Эта функциональность является частью [Manticore Columnar Library](https://github.com/manticoresoftware/columnar).

<!-- example KNN -->

### Конфигурация таблицы для поиска KNN

Для выполнения поиска KNN необходимо сначала настроить таблицу. Векторы с плавающей точкой и поиск KNN поддерживаются только в таблицах реального времени (не в обычных таблицах). В таблице должен быть хотя бы один атрибут типа [float_vector](../Creating_a_table/Data_types.md#Float-vector), который служит вектором данных. Нужно указать следующие параметры:
* `knn_type`: обязательный параметр; в настоящее время поддерживается только `hnsw`.
* `knn_dims`: обязательный параметр, указывающий размерность индексируемых векторов.
* `hnsw_similarity`: обязательный параметр, указывающий функцию расстояния, используемую индексом HNSW. Допустимые значения:
  - `L2` - квадрат евклидова расстояния
  - `IP` - скалярное произведение
  - `COSINE` - косинусное сходство
  
  **Примечание:** При использовании косинусного сходства (`COSINE`) векторы автоматически нормализуются при вставке. Это означает, что сохраняемые значения могут отличаться от исходных, так как они преобразуются к единичным векторам (векторами с длиной 1.0) для эффективного вычисления косинусного сходства. Такая нормализация сохраняет направление вектора при стандартизации его длины.
* `hnsw_m`: необязательный параметр, определяющий максимальное число исходящих связей в графе. Значение по умолчанию — 16.
* `hnsw_ef_construction`: необязательный параметр, задающий компромисс между скоростью построения и точностью.

<!-- intro -->
##### SQL

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' );
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```

<!-- intro -->
##### Режим Plain (используя конфигурационный файл):

<!-- request Config -->
```ini
table test_vec {
    type = rt
	...
    rt_attr_float_vector = image_vector
    knn = {"attrs":[{"name":"image_vector","type":"hnsw","dims":4,"hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200}]}
}
```

<!-- end -->

<!-- example knn_insert -->

### Вставка векторных данных

#### Автоэмбеддинги (рекомендуется)

Самый простой способ работы с векторными данными — использовать **автоэмбеддинги**. С этой функцией вы создаёте таблицу с параметрами `MODEL_NAME` и `FROM`, затем просто вставляете текстовые данные — Manticore автоматически сгенерирует эмбеддинги для вас.

##### Создание таблицы с автоэмбеддингами

При создании таблицы для автоэмбеддингов укажите:
- `MODEL_NAME`: Модель для создания эмбеддингов
- `FROM`: Какие поля использовать для генерации эмбеддингов (пусто означает использовать все текстовые/строковые поля)
- `API_KEY`: Обязательный параметр для удалённых моделей (OpenAI, Voyage, Jina). Ключ API проверяется при создании таблицы посредством реального запроса к API.
- `API_URL`: Необязательный. Пользовательский URL точки доступа API. Если не указан, используется стандартный URL провайдера (например, `https://api.openai.com/v1/embeddings` для OpenAI).
- `API_TIMEOUT`: Необязательный. Таймаут HTTP-запросов к API в секундах. Значение по умолчанию — 10 секунд. Установите `'0'` для использования таймаута по умолчанию. Применяется как к валидационным запросам при создании таблицы, так и к генерации эмбеддингов при операциях INSERT.

**Поддерживаемые модели эмбеддингов:**
- **Sentence Transformers**: Любая [соответствующая модель на базе BERT из Hugging Face](https://huggingface.co/sentence-transformers/models) (например, `sentence-transformers/all-MiniLM-L6-v2`) — API ключ не требуется. Manticore загружает модель при создании таблицы.
- **OpenAI, Voyage, Jina**: Удалённые модели эмбеддингов (например, `openai/text-embedding-ada-002`, `voyage/voyage-3.5-lite`, `jina/jina-embeddings-v2-base-en`) — требуют параметр `API_KEY='<API_KEY>'`. Опционально можно указать `API_URL='<CUSTOM_URL>'` для пользовательской точки доступа API и `API_TIMEOUT='<SECONDS>'` для настройки таймаута HTTP (по умолчанию 10 секунд).

Подробности о настройке атрибута `float_vector` доступны [здесь](../Creating_a_table/Data_types.md#Float-vector).

<!-- intro -->
##### SQL:

<!-- request SQL -->

Использование sentence-transformers (без API ключа)
```sql
CREATE TABLE products (
    title TEXT, 
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2' 
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM='title'
);
```

Использование OpenAI (требуется параметр API_KEY)
```sql
CREATE TABLE products_openai (
    title TEXT,
    description TEXT, 
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='openai/text-embedding-ada-002' FROM='title,description' API_KEY='...'
);
```

Использование OpenAI с пользовательским URL и таймаутом (опционально)
```sql
CREATE TABLE products_openai_custom (
    title TEXT,
    description TEXT, 
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='openai/text-embedding-ada-002' FROM='title,description' 
    API_KEY='...' API_URL='https://custom-api.example.com/v1/embeddings' API_TIMEOUT='30'
);
```

Использование всех текстовых полей для генерации эмбеддингов (параметр FROM пуст)
```sql
CREATE TABLE products_all (
    title TEXT,
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM=''
);
```

<!-- end -->

##### Вставка данных с автоэмбеддингами

<!-- example inserting_embeddings -->

При использовании автоэмбеддингов **не указывайте векторное поле** в операторе INSERT. Эмбеддинги автоматически генерируются из текстовых полей, указанных в параметре `FROM`.

<!-- intro -->
##### SQL:

<!-- request SQL -->

Вставка только текстовых данных — эмбеддинги сгенерированы автоматически
```sql
INSERT INTO products (title) VALUES 
('machine learning artificial intelligence'),
('banana fruit sweet yellow');
```

Вставка нескольких полей — используются оба для генерации эмбеддингов, если FROM='title,description'  
```sql
INSERT INTO products_openai (title, description) VALUES
('smartphone', 'latest mobile device with advanced features'),
('laptop', 'portable computer for work and gaming');
```

Вставка пустого вектора (документ исключён из векторного поиска)
```sql
INSERT INTO products (title, embedding_vector) VALUES 
('no embedding item', ());
```

<!-- end -->

##### Поиск с автоэмбеддингами

<!-- example embeddings_search -->
Поиск работает аналогично — укажите текст вашего запроса, и Manticore сгенерирует эмбеддинги и найдёт похожие документы:

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SELECT id, knn_dist() FROM products WHERE knn(embedding_vector, 3, 'machine learning');
```

<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.12345678 |
|    2 | 0.87654321 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

Использование текстового запроса с автоэмбеддингами
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": "machine learning",
        "k": 3
    }
}
```

Использование запроса с вектором напрямую
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": [0.1, 0.2, 0.3, 0.4],
        "k": 3
    }
}
```

<!-- response JSON -->

```json
{
    "took": 0,
    "timed_out": false,
    "hits": {
        "total": 2,
        "total_relation": "eq",
        "hits": [
            {
                "_id": 1,
                "_score": 1,
                "_knn_dist": 0.12345678,
                "_source": {
                    "title": "machine learning artificial intelligence"
                }
            },
            {
                "_id": 2,
                "_score": 1,
                "_knn_dist": 0.87654321,
                "_source": {
                    "title": "banana fruit sweet yellow"
                }
            }
        ]
    }
}
```

<!-- end -->

#### Ручная вставка векторов

<!-- example manual_vector -->
В качестве альтернативы вы можете вручную вставлять заранее вычисленные данные векторов, убедившись, что они соответствуют размерности, которую вы указали при создании таблицы. Также можно вставить пустой вектор; это означает, что документ будет исключен из результатов поиска по векторам.

**Важно:** При использовании `hnsw_similarity='cosine'` векторы автоматически нормализуются при вставке до единичных векторов (векторов с математической длиной/модулем 1.0). Эта нормализация сохраняет направление вектора, одновременно стандартизируя его длину, что требуется для эффективных вычислений косинусного сходства. Это означает, что сохранённые значения будут отличаться от ваших исходных данных.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
insert into test values ( 1, 'yellow bag', (0.653448,0.192478,0.017971,0.339821) ), ( 2, 'white bag', (-0.148894,0.748278,0.091892,-0.095406) );
```
<!-- response SQL -->

```sql
Query OK, 2 rows affected (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /insert
{
	"table":"test_vec",
	"id":1,
	"doc": 	{ "title" : "yellow bag", "image_vector" : [0.653448,0.192478,0.017971,0.339821] }
}

POST /insert
{
	"table":"test_vec",
	"id":2,
	"doc": 	{ "title" : "white bag", "image_vector" : [-0.148894,0.748278,0.091892,-0.095406] }
}
```

<!-- response JSON -->

```json
{
	"table":"test",
	"_id":1,
	"created":true,
	"result":"created",
	"status":201
}

{
	"table":"test",
	"_id":2,
	"created":true,
	"result":"created",
	"status":201
}
```

<!-- end -->

<!-- example knn_search -->

### KNN поиск по векторам

Теперь вы можете выполнять поиск KNN с использованием параметра `knn` в формате SQL или JSON. Обе эти формы поддерживают одинаковые основные параметры, обеспечивая единый опыт работы независимо от выбранного формата:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <query vector> [,<options>] )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "query": "<text or vector>",
          "k": <k>,
          "ef": <ef>,
		  "rescore": <rescore>,
		  "oversampling": <oversampling>
      }
  }
  ```

Параметры:
* `field`: имя атрибута типа float vector, содержащего векторные данные.
* `k`: количество документов для возврата; ключевой параметр для индексов Hierarchical Navigable Small World (HNSW). Он определяет, сколько документов должен вернуть один HNSW-индекс. Однако фактическое количество документов в итоговых результатах может варьироваться. Например, если система работает с таблицами реального времени, разбитыми на дисковые чанки, каждый чанк может вернуть `k` документов, что приведёт к суммарному количеству, превышающему заданное `k` (так как итоговый подсчёт будет `num_chunks * k`). С другой стороны, итоговое число документов может быть меньше `k`, если после запроса `k` документов некоторые из них фильтруются по определённым атрибутам. Важно учесть, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс выборки работает иначе, поэтому эффект параметра `k` на число возвращаемых документов не актуален.
* `query`: (рекомендуемый параметр) Поисковый запрос, который может быть:
  - Текстовой строкой: автоматически конвертируется в эмбеддинги, если для поля настроены авто-эмбеддинги. Если авто-эмбеддинги не настроены, выдаётся ошибка.
  - Массивом векторов: работает так же, как `query_vector`.
* `query_vector`: (устаревший параметр) Поисковый вектор в виде массива чисел. Поддерживается для обратной совместимости.
  **Примечание:** Используйте либо `query`, либо `query_vector`, но не оба параметра в одном запросе.
* `ef`: дополнительный размер динамического списка, используемого во время поиска. Более высокое значение `ef` даёт более точный, но более медленный поиск.
* `rescore`: включает пересчёт результатов KNN (по умолчанию отключён). Установите `1` в SQL или `true` в JSON, чтобы включить пересчёт. После выполнения KNN-поиска с квантованными векторами (с возможным сверхвыбором) расстояния пересчитываются с использованием исходных (полноточных) векторов, и результаты пересортировываются для повышения точности ранжирования.
* `oversampling`: задаёт множитель (число с плавающей точкой), на который умножается `k` при выполнении KNN-поиска, что приводит к извлечению большего количества кандидатов, чем необходимо, используя квантованные вектора. По умолчанию сверхвыбор не применяется. Эти кандидаты могут быть переоценены позже, если включён пересчёт (rescore). Сверхвыбор также работает с неквантованными векторами. Поскольку он увеличивает `k`, что влияет на работу индекса HNSW, это может вызвать небольшое изменение точности результатов.

Документы всегда сортируются по их расстоянию от поискового вектора. Любые дополнительные критерии сортировки, которые вы укажете, будут применены после этой основной сортировки. Для получения расстояния существует встроенная функция [knn_dist()](../Functions/Other_functions.md#KNN_DIST%28%29).

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926), { ef=2000, oversampling=3.0, rescore=1 } );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.28146550 |
|    2 | 0.81527930 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"ef": 2000, 
		"rescore": true,
		"oversampling": 3.0
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":2,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 1,
				"_score":1,
				"_knn_dist":0.28146550,
				"_source":
				{
					"title":"yellow bag",
					"image_vector":[0.653448,0.192478,0.017971,0.339821]
				}
			},
			{
				"_id": 2,
				"_score":1,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- example knn_quantization -->

### Векторная квантование

Индексы HNSW должны быть полностью загружены в память для выполнения KNN-поиска, что может вести к значительному потреблению памяти. Чтобы сократить использование памяти, можно применить скалярное квантование — метод сжатия векторов высокой размерности путём представления каждого компонента (измерения) ограниченным набором дискретных значений. Manticore поддерживает 8-битное и 1-битное квантование, то есть каждый компонент вектора сжимается с 32-битного float до 8 бит или даже 1 бита, соответственно уменьшая использование памяти в 4 или 32 раза. Такие сжатые представления также позволяют быстрее вычислять расстояния, так как большее число компонентов векторов может быть обработано в одной SIMD-инструкции. Хотя скалярное квантование вводит некоторую ошибку аппроксимации, оно часто является разумным компромиссом между точностью поиска и эффективным использованием ресурсов. Для ещё большей точности квантование можно сочетать с пересчётом результатов и сверхвыбором: извлекается больше кандидатов, чем запрошено, и для них расстояния пересчитываются с использованием исходных 32-битных float-векторов.

Поддерживаемые типы квантования включают:
* `8bit`: каждый компонент вектора квантуется до 8 бит.
* `1bit`: каждый компонент вектора квантуется до 1 бита. Используется асимметричное квантование: запросные векторы квантуются до 4 бит, а сохраняемые — до 1 бита. Такой подход даёт большую точность по сравнению с более простыми методами, но с некоторой потерей производительности.
* `1bitsimple`: Каждый компонент вектора квантован до 1 бита. Этот метод быстрее, чем `1bit`, но обычно менее точен.

<!-- intro -->
##### SQL:

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' quantization='1bit');
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```
<!-- end -->

<!-- Example knn_similar_docs -->

### Найти похожие документы по id

> ПРИМЕЧАНИЕ: Поиск похожих документов по id требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если это не работает, убедитесь, что Buddy установлен.

Поиск документов, похожих на конкретный, основанный на его уникальном ID, — распространённая задача. Например, когда пользователь просматривает определённый элемент, Manticore Search может эффективно определить и вывести список элементов, наиболее похожих на него в векторном пространстве. Вот как это сделать:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <document id> )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "doc_id": <document id>,
          "k": <k>
      }
  }
  ```

Параметры:
* `field`: это имя атрибута с плавающим вектором, содержащим векторные данные.
* `k`: это количество документов, которые нужно вернуть, и ключевой параметр для иерархических навигируемых мирового малого мира (HNSW) индексов. Он определяет, сколько документов должен вернуть один индекс HNSW. Однако фактическое количество документов в итоговых результатах может отличаться. Например, если система работает с таблицами в реальном времени, разбитыми на дисковые чанкы, каждый из которых может вернуть `k` документов, итоговое число может превысить заданное `k` (так как сумма будет равна `num_chunks * k`). С другой стороны, окончательное количество документов может быть меньше `k`, если после запроса `k` документов некоторые отфильтровываются по определённым атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. В случае ramchunks процесс извлечения работает иначе, и воздействие параметра `k` на количество возвращаемых документов не применяется.
* `document id`: ID документа для поиска по сходству KNN.


<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, 1 );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
  "table": "test",
  "knn":
  {
    "field": "image_vector",
    "doc_id": 1,
    "k": 5
  }
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- Example knn_filtering -->

### Фильтрация результатов поиска KNN вектора

Manticore также поддерживает дополнительную фильтрацию документов, возвращаемых по KNN-поиску, либо по полнотекстовому совпадению, фильтрам атрибутов, либо по обоим сразу.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926) ) and match('white') and id < 10;
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"filter":
		{
			"bool":
			{
				"must":
				[
					{ "match": {"_all":"white"} },
			        { "range": { "id": { "lt": 10 } } }
				]
			}
		}
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- proofread -->

