# K-nearest neighbor vector search

Manticore Search поддерживает возможность добавления эмбеддингов, сгенерированных моделями машинного обучения, к каждому документу и последующего поиска ближайших соседей по ним. Это позволяет создавать такие функции, как поиск по похожести, рекомендательные системы, семантический поиск и ранжирование релевантности на основе NLP-алгоритмов, а также поиски по изображениям, видео и звуку.

## What is an embedding?

Эмбеддинг — это способ представления данных — таких как текст, изображения или звук — в виде векторов в пространстве высокой размерности. Эти векторы создаются так, чтобы расстояние между ними отражало сходство представляемых данных. Этот процесс обычно использует алгоритмы типа word embeddings (например, Word2Vec, BERT) для текста или нейронные сети для изображений. Высокая размерность векторного пространства, с множеством компонентов в каждом векторе, позволяет представлять сложные и тонкие отношения между объектами. Их сходство оценивается по расстоянию между векторами, часто измеряемому такими методами, как евклидово расстояние или косинусное сходство.

Manticore Search позволяет выполнять поиск k ближайших соседей (KNN) с помощью библиотеки HNSW. Эта функция входит в состав [Manticore Columnar Library](https://github.com/manticoresoftware/columnar).

<!-- example KNN -->

### Configuring a table for KNN search

Для выполнения KNN-поисков необходимо сначала настроить таблицу. Векторные данные с типом float и KNN-поиск поддерживаются только в таблицах реального времени (не в обычных таблицах). Таблица должна содержать по крайней мере один атрибут [float_vector](../Creating_a_table/Data_types.md#Float-vector), который служит вектором данных. Нужно указать следующие свойства:
* `knn_type`: Обязательный параметр; в данный момент поддерживается только `hnsw`.
* `knn_dims`: Обязательный параметр, задающий размерность индексируемых векторов.
* `hnsw_similarity`: Обязательный параметр, указывающий функцию расстояния, используемую индексом HNSW. Допустимые значения:
  - `L2` — квадрат L2
  - `IP` — внутреннее произведение
  - `COSINE` — косинусное сходство
  
  **Примечание:** При использовании `COSINE` сходства векторы автоматически нормализуются при вставке. Это означает, что сохранённые значения векторов могут отличаться от исходных, поскольку они будут преобразованы в единичные векторы (векторы с математической длиной/модулем 1.0) для эффективного вычисления косинусного сходства. Такая нормализация сохраняет направление вектора при стандартизации его длины.
* `hnsw_m`: Необязательный параметр, определяющий максимальное число исходящих связей в графе. По умолчанию 16.
* `hnsw_ef_construction`: Необязательный параметр, задающий компромисс между временем построения и точностью.

<!-- intro -->
##### SQL

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' );
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```

<!-- intro -->
##### Plain mode (using configuration file):

<!-- request Config -->
```ini
table test_vec {
    type = rt
	...
    rt_attr_float_vector = image_vector
    knn = {"attrs":[{"name":"image_vector","type":"hnsw","dims":4,"hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200}]}
}
```

<!-- end -->

<!-- example knn_insert -->

### Inserting vector data

#### Auto Embeddings (Recommended)

Самый простой способ работать с векторными данными — использовать **автоматические эмбеддинги**. С этой функцией вы создаёте таблицу с параметрами `MODEL_NAME` и `FROM`, а затем просто вставляете ваши текстовые данные — Manticore автоматически генерирует эмбеддинги.

##### Creating a table with auto embeddings

При создании таблицы для автоматических эмбеддингов укажите:
- `MODEL_NAME`: Модель эмбеддинга для использования
- `FROM`: Какие поля использовать для генерации эмбеддингов (пустое значение означает все текстовые/строковые поля)

**Поддерживаемые модели эмбеддингов:**
- **Sentence Transformers**: Любая [подходящая модель на базе BERT из Hugging Face](https://huggingface.co/sentence-transformers/models) (например, `sentence-transformers/all-MiniLM-L6-v2`) — API-ключ не требуется. Manticore скачивает модель при создании таблицы.
- **OpenAI**: Модели эмбеддингов OpenAI, например `openai/text-embedding-ada-002` — требует параметр `API_KEY='<OPENAI_API_KEY>'`
- **Voyage**: Модели эмбеддингов Voyage AI — требует параметр `API_KEY='<VOYAGE_API_KEY>'`
- **Jina**: Модели эмбеддингов Jina AI — требует параметр `API_KEY='<JINA_API_KEY>'`

Более подробная информация о настройке атрибута `float_vector` доступна [здесь](../Creating_a_table/Data_types.md#Float-vector).

<!-- intro -->
##### SQL:

<!-- request SQL -->

Использование sentence-transformers (без необходимости API-ключа)
```sql
CREATE TABLE products (
    title TEXT, 
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2' 
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM='title'
);
```

Использование OpenAI (требуется параметр API_KEY)
```sql
CREATE TABLE products_openai (
    title TEXT,
    description TEXT, 
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='openai/text-embedding-ada-002' FROM='title,description' API_KEY='...'
);
```

Использование всех текстовых полей для эмбеддингов (параметр FROM пустой)
```sql
CREATE TABLE products_all (
    title TEXT,
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM=''
);
```

<!-- end -->

##### Inserting data with auto embeddings

<!-- example inserting_embeddings -->

При использовании автоматических эмбеддингов **не указывайте поле вектора** в вашем INSERT-запросе. Эмбеддинги генерируются автоматически из текстовых полей, указанных в параметре `FROM`.

<!-- intro -->
##### SQL:

<!-- request SQL -->

Вставка только текстовых данных — эмбеддинги генерируются автоматически
```sql
INSERT INTO products (title) VALUES 
('machine learning artificial intelligence'),
('banana fruit sweet yellow');
```

Вставка нескольких полей — все они используются для эмбеддинга, если FROM='title,description'  
```sql
INSERT INTO products_openai (title, description) VALUES
('smartphone', 'latest mobile device with advanced features'),
('laptop', 'portable computer for work and gaming');
```

Вставка пустого вектора (документ исключён из векторного поиска)
```sql
INSERT INTO products (title, embedding_vector) VALUES 
('no embedding item', ());
```

<!-- end -->

##### Searching with auto embeddings

<!-- example embeddings_search -->
Поиск работает аналогично — вы передаете текст запроса, и Manticore генерирует эмбеддинги и находит похожие документы:

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SELECT id, knn_dist() FROM products WHERE knn(embedding_vector, 3, 'machine learning');
```

<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.12345678 |
|    2 | 0.87654321 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

Использование текстового запроса с авто-эмбеддингами
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": "machine learning",
        "k": 3
    }
}
```

Использование запроса по вектору напрямую
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": [0.1, 0.2, 0.3, 0.4],
        "k": 3
    }
}
```

<!-- response JSON -->

```json
{
    "took": 0,
    "timed_out": false,
    "hits": {
        "total": 2,
        "total_relation": "eq",
        "hits": [
            {
                "_id": 1,
                "_score": 1,
                "_knn_dist": 0.12345678,
                "_source": {
                    "title": "machine learning artificial intelligence"
                }
            },
            {
                "_id": 2,
                "_score": 1,
                "_knn_dist": 0.87654321,
                "_source": {
                    "title": "banana fruit sweet yellow"
                }
            }
        ]
    }
}
```

<!-- end -->

#### Manual Vector Insertion

<!-- example manual_vector -->
В качестве альтернативы, вы можете вручную вставлять уже вычисленные векторные данные, убедившись, что они соответствуют размерности, заданной при создании таблицы. Также можно вставлять пустой вектор; это означает, что документ будет исключён из результатов векторного поиска.

**Важно:** При использовании `hnsw_similarity='cosine'` векторы автоматически нормализуются при вставке до единичных векторов (векторы с математической длиной/величиной 1.0). Эта нормализация сохраняет направление вектора при стандартизации его длины, что необходимо для эффективных вычислений косинусного сходства. Это означает, что хранимые значения будут отличаться от ваших исходных входных значений.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
insert into test values ( 1, 'yellow bag', (0.653448,0.192478,0.017971,0.339821) ), ( 2, 'white bag', (-0.148894,0.748278,0.091892,-0.095406) );
```
<!-- response SQL -->

```sql
Query OK, 2 rows affected (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /insert
{
	"table":"test_vec",
	"id":1,
	"doc": 	{ "title" : "yellow bag", "image_vector" : [0.653448,0.192478,0.017971,0.339821] }
}

POST /insert
{
	"table":"test_vec",
	"id":2,
	"doc": 	{ "title" : "white bag", "image_vector" : [-0.148894,0.748278,0.091892,-0.095406] }
}
```

<!-- response JSON -->

```json
{
	"table":"test",
	"_id":1,
	"created":true,
	"result":"created",
	"status":201
}

{
	"table":"test",
	"_id":2,
	"created":true,
	"result":"created",
	"status":201
}
```

<!-- end -->

<!-- example knn_search -->

### KNN поиск по векторам

Теперь вы можете выполнить KNN поиск, используя конструкцию `knn` в формате SQL или JSON. Оба интерфейса поддерживают одинаковый набор основных параметров, обеспечивая единообразный опыт использования независимо от выбранного формата:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <query vector> [,<options>] )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "query": "<text or vector>",
          "k": <k>,
          "ef": <ef>,
		  "rescore": <rescore>,
		  "oversampling": <oversampling>
      }
  }
  ```

Параметры:
* `field`: Имя атрибута с плавающей точкой, содержащего данные вектора.
* `k`: Число документов, которые нужно вернуть, ключевой параметр для иерархических навигируемых индексов малого мира (HNSW). Он указывает количество документов, которые должен вернуть один индекс HNSW. Однако фактическое число документов в итоговых результатах может варьироваться. Например, если система работает с таблицами в реальном времени, разбитыми на дисковые чанки, каждый чанк может вернуть `k` документов, в итоге общее число может превысить заданное `k` (суммарно будет `num_chunks * k`). С другой стороны, итоговое количество документов может быть меньше `k`, если после запроса `k` документов некоторые отфильтровываются по конкретным атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс извлечения работает иначе, поэтому влияние параметра `k` на количество возвращаемых документов не применимо.
* `query`: (Рекомендуемый параметр) Запрос поиска, который может быть:
  - Текстовой строкой: Автоматически преобразуется в эмбеддинги, если для поля настроены авто-эмбеддинги. Вернёт ошибку, если авто-эмбеддинги не настроены.
  - Векторным массивом: Работает так же, как `query_vector`.
* `query_vector`: (Устаревший параметр) Вектор поиска в виде массива чисел. Пока поддерживается для обратной совместимости.
  **Примечание:** Используйте либо `query`, либо `query_vector`, не оба в одном запросе.
* `ef`: необязательный размер динамического списка, используемого во время поиска. Чем выше `ef`, тем точнее, но медленнее поиск.
* `rescore`: Включает пересчёт KNN (по умолчанию отключён). Установите в `1` в SQL или `true` в JSON для включения пересчёта. После выполнения KNN поиска с использованием квантизированных векторов (с возможным оверсемплингом) расстояния пересчитываются с использованием исходных (полной точности) векторов, а результаты пересортировываются для улучшения точности ранжирования.
* `oversampling`: Устанавливает коэффициент (число с плавающей точкой), на который умножается `k` при выполнении KNN поиска, что приводит к выбору большего числа кандидатов, чем нужно, используя квантизированные векторы. По умолчанию оверсемплинг не применяется. Эти кандидаты могут пересматриваться позже при включённом пересчёте (rescore). Оверсемплинг также работает с не квантизированными векторами. Поскольку он увеличивает `k`, а это влияет на работу индекса HNSW, возможно небольшое изменение точности результатов.

Документы всегда сортируются по расстоянию до поискового вектора. Любые дополнительные критерии сортировки применяются после этой основной сортировки. Для получения расстояния имеется встроенная функция [knn_dist()](../Functions/Other_functions.md#KNN_DIST%28%29).

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926), { ef=2000, oversampling=3.0, rescore=1 } );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.28146550 |
|    2 | 0.81527930 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"ef": 2000, 
		"rescore": true,
		"oversampling": 3.0
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":2,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 1,
				"_score":1,
				"_knn_dist":0.28146550,
				"_source":
				{
					"title":"yellow bag",
					"image_vector":[0.653448,0.192478,0.017971,0.339821]
				}
			},
			{
				"_id": 2,
				"_score":1,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- example knn_quantization -->

### Векторная квантизация

Для выполнения KNN поиска индексы HNSW должны быть полностью загружены в память, что может привести к значительному потреблению памяти. Чтобы снизить использование памяти, может применяться скалярная квантизация — метод сжатия векторов высокой размерности путём представления каждого компонента (измерения) ограниченным числом дискретных значений. Manticore поддерживает 8-битную и 1-битную квантизацию, что означает сжатие каждого компонента вектора с 32-битного float до 8 или даже 1 бита, снижая использование памяти в 4 или 32 раза соответственно. Такие сжатые представления также позволяют быстрее рассчитывать расстояния, так как больше компонентов вектора можно обработать одной SIMD-инструкцией. Хотя скалярная квантизация вводит некоторую аппроксимационную ошибку, она часто является оправданным компромиссом между точностью поиска и экономией ресурсов. Для лучшей точности квантизация может сочетаться с пересчётом и оверсемплингом: извлекается больше кандидатов, чем запрошено, и расстояния для них пересчитываются с использованием исходных 32-битных float векторов.

Поддерживаемые типы квантизации:
* `8bit`: Каждый компонент вектора квантизируется до 8 бит.
* `1bit`: Каждый компонент вектора квантизируется до 1 бита. Используется несимметричная квантизация: векторы запроса квантизируются до 4 бит, а хранимые — до 1 бита. Такой подход обеспечивает большую точность, чем более простые методы, но с некоторым снижением производительности.
* `1bitsimple`: Каждый компонент вектора квантизируется до 1 бита. Этот метод быстрее, чем `1bit`, но обычно менее точен.

<!-- intro -->
##### SQL:

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' quantization='1bit');
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```
<!-- end -->

<!-- Example knn_similar_docs -->

### Поиск похожих документов по id

> ПРИМЕЧАНИЕ: Поиск похожих документов по id требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если он не работает, убедитесь, что Buddy установлен.

Поиск документов, подобных конкретному на основе его уникального идентификатора, является распространённой задачей. Например, когда пользователь просматривает определённый элемент, Manticore Search может эффективно определить и отобразить список элементов, наиболее похожих на него в векторном пространстве. Вот как вы можете это сделать:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <document id> )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "doc_id": <document id>,
          "k": <k>
      }
  }
  ```

Параметры:
* `field`: Это имя атрибута с плавающей точкой, содержащего векторные данные.
* `k`: Это количество документов, которое нужно вернуть, и является ключевым параметром для индексов Hierarchical Navigable Small World (HNSW). Он указывает количество документов, которые должен вернуть один индекс HNSW. Однако фактическое количество документов в итоговых результатах может варьироваться. Например, если система работает с таблицами в реальном времени, разделёнными на дисковые чанки, каждый чанк может вернуть по `k` документов, что приведёт к общему числу больше указанного `k` (так как суммарное количество будет `num_chunks * k`). С другой стороны, итоговое количество документов может быть меньше `k`, если после запроса `k` документов некоторые из них отфильтровываются по определённым атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс выборки работает иначе, поэтому влияние параметра `k` на количество возвращаемых документов не применимо.
* `document id`: Идентификатор документа для поиска схожих документов методом KNN.


<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, 1 );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
  "table": "test",
  "knn":
  {
    "field": "image_vector",
    "doc_id": 1,
    "k": 5
  }
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- Example knn_filtering -->

### Фильтрация результатов KNN поиска по векторам

Manticore также поддерживает дополнительную фильтрацию документов, возвращаемых KNN поиском, либо по полнотекстовому совпадению, фильтрам атрибутов, либо по обоим способам.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926) ) and match('white') and id < 10;
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"filter":
		{
			"bool":
			{
				"must":
				[
					{ "match": {"_all":"white"} },
			        { "range": { "id": { "lt": 10 } } }
				]
			}
		}
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- proofread -->

