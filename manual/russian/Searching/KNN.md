# Поиск по векторам методом ближайших соседей (K-nearest neighbor)

Manticore Search поддерживает возможность добавлять эмбеддинги, созданные моделями машинного обучения, к каждому документу, а затем выполнять поиск ближайших соседей по ним. Это позволяет создавать функции, такие как поиск по похожести, рекомендации, семантический поиск и ранжирование релевантности на основе алгоритмов обработки естественного языка, а также, среди прочего, поиск изображений, видео и звука.

## Что такое embedding?

Эмбеддинг — это метод представления данных, таких как текст, изображения или звук, в виде векторов в высокоразмерном пространстве. Эти векторы созданы таким образом, чтобы расстояние между ними отражало схожесть представленных данных. Этот процесс обычно использует алгоритмы, такие как векторные представления слов (например, Word2Vec, BERT) для текста или нейронные сети для изображений. Высокая размерность пространства векторов, с большим количеством компонентов на вектор, позволяет представлять сложные и тонкие взаимосвязи между элементами. Их схожесть измеряется расстоянием между этими векторами, часто используя методы, такие как эвклидово расстояние или косинусная схожесть.

Manticore Search позволяет выполнять поиск K-ближайших соседей (KNN) по векторам с использованием библиотеки HNSW. Эта функциональность входит в состав [Manticore Columnar Library](https://github.com/manticoresoftware/columnar).

<!-- example KNN -->

### Настройка таблицы для поиска KNN

Для выполнения поиска KNN сначала необходимо настроить таблицу. Векторы с плавающей точкой и поиск KNN поддерживаются только в таблицах реального времени (не в обычных таблицах). Таблица должна содержать как минимум один атрибут типа float_vector, который служит вектором данных. Необходимо задать следующие свойства:
* `knn_type`: обязательный параметр; в настоящее время поддерживается только `hnsw`.
* `knn_dims`: обязательный параметр, задающий размерность индексируемых векторов.
* `hnsw_similarity`: обязательный параметр, определяющий функцию расстояния, используемую индексом HNSW. Допустимые значения:
  - `L2` - квадрат евклидова расстояния (Squared L2)
  - `IP` - внутреннее произведение (Inner product)
  - `COSINE` - косинусное сходство
* `hnsw_m`: необязательный параметр, задающий максимальное количество исходящих связей в графе. По умолчанию — 16.
* `hnsw_ef_construction`: необязательный параметр, определяющий компромисс между временем построения и точностью.

<!-- intro -->
##### SQL

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' );
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```

<!-- intro -->
##### Режим Plain (с использованием конфигурационного файла):

<!-- request Config -->
```ini
table test_vec {
    type = rt
	...
    rt_attr_float_vector = image_vector
    knn = {"attrs":[{"name":"image_vector","type":"hnsw","dims":4,"hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200}]}
}
```

<!-- end -->

<!-- example knn_insert -->

### Вставка векторных данных

#### Автоэмбеддинги (рекомендуется)

Самый простой способ работать с векторными данными — использовать **автоэмбеддинги**. С этой функцией вы создаёте таблицу с параметрами `MODEL_NAME` и `FROM`, а затем просто вставляете свои текстовые данные — Manticore автоматически сгенерирует эмбеддинги для вас.

##### Создание таблицы с автоэмбеддингами

При создании таблицы для автоэмбеддингов указывайте:
- `MODEL_NAME`: модель эмбеддингов, которую следует использовать
- `FROM`: поля, которые использовать для генерации эмбеддингов (пустое значение означает все текстовые/строковые поля)

**Поддерживаемые модели эмбеддингов:**
- **Sentence Transformers**: Любая [подходящая модель на основе BERT из Hugging Face](https://huggingface.co/sentence-transformers/models) (например, `sentence-transformers/all-MiniLM-L6-v2`) — ключ API не требуется. Manticore загружает модель при создании таблицы.
- **OpenAI**: Модели эмбеддингов OpenAI, такие как `openai/text-embedding-ada-002` — требует параметр `API_KEY='<OPENAI_API_KEY>'`
- **Voyage**: Модели эмбеддингов Voyage AI — требует параметр `API_KEY='<VOYAGE_API_KEY>'`
- **Jina**: Модели эмбеддингов Jina AI — требует параметр `API_KEY='<JINA_API_KEY>'`

<!-- intro -->
##### SQL:

<!-- request SQL -->

Использование sentence-transformers (ключ API не нужен)
```sql
CREATE TABLE products (
    title TEXT, 
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2' 
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM='title'
);
```

Использование OpenAI (требуется параметр API_KEY)
```sql
CREATE TABLE products_openai (
    title TEXT,
    description TEXT, 
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='openai/text-embedding-ada-002' FROM='title,description' API_KEY='...'
);
```

Использование всех текстовых полей для эмбеддингов (FROM пустой)
```sql
CREATE TABLE products_all (
    title TEXT,
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM=''
);
```

<!-- end -->

##### Вставка данных с автоэмбеддингами

<!-- example inserting_embeddings -->

При использовании автоэмбеддингов **не указывайте поле вектора** в операторе INSERT. Эмбеддинги генерируются автоматически из текстовых полей, указанных в параметре `FROM`.

<!-- intro -->
##### SQL:

<!-- request SQL -->

Вставка только текстовых данных — эмбеддинги создаются автоматически
```sql
INSERT INTO products (title) VALUES 
('machine learning artificial intelligence'),
('banana fruit sweet yellow');
```

Вставка нескольких полей — оба используются для эмбеддинга, если FROM='title,description'  
```sql
INSERT INTO products_openai (title, description) VALUES
('smartphone', 'latest mobile device with advanced features'),
('laptop', 'portable computer for work and gaming');
```

Вставка пустого вектора (документ исключен из векторного поиска)
```sql
INSERT INTO products (title, embedding_vector) VALUES 
('no embedding item', ());
```

<!-- end -->

##### Поиск с автоэмбеддингами

<!-- example embeddings_search -->
Поиск работает так же — предоставьте текст запроса, и Manticore сгенерирует эмбеддинги и найдёт похожие документы:

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SELECT id, knn_dist() FROM products WHERE knn(embedding_vector, 3, 'machine learning');
```

<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.12345678 |
|    2 | 0.87654321 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- end -->

#### Ручная вставка векторов

<!-- example manual_vector -->
В качестве альтернативы вы можете вручную вставлять предварительно вычисленные векторные данные, убедившись, что их размерность соответствует указанной при создании таблицы. Вы также можете вставлять пустой вектор; это означает, что документ будет исключён из результатов векторного поиска.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
insert into test values ( 1, 'yellow bag', (0.653448,0.192478,0.017971,0.339821) ), ( 2, 'white bag', (-0.148894,0.748278,0.091892,-0.095406) );
```
<!-- response SQL -->

```sql
Query OK, 2 rows affected (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /insert
{
	"table":"test_vec",
	"id":1,
	"doc": 	{ "title" : "yellow bag", "image_vector" : [0.653448,0.192478,0.017971,0.339821] }
}

POST /insert
{
	"table":"test_vec",
	"id":2,
	"doc": 	{ "title" : "white bag", "image_vector" : [-0.148894,0.748278,0.091892,-0.095406] }
}
```

<!-- response JSON -->

```json
{
	"table":"test",
	"_id":1,
	"created":true,
	"result":"created",
	"status":201
}

{
	"table":"test",
	"_id":2,
	"created":true,
	"result":"created",
	"status":201
}
```

<!-- end -->

<!-- example knn_search -->

### Поиск по векторам KNN

Теперь вы можете выполнять поиск KNN с помощью оператора `knn` как в SQL, так и в JSON-формате. Обе интерфейса поддерживают одинаковые основные параметры, обеспечивая единообразный опыт независимо от выбранного формата:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <query vector> [,<options>] )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "query_vector": [<query vector>],
          "k": <k>,
          "ef": <ef>,
  "rescore": <rescore>,
  "oversampling": <oversampling>
      }
  }
  ```

Параметры:
* `field`: имя атрибута float_vector, содержащего векторные данные.
* `k`: количество документов для возвращения — ключевой параметр индексирования Hierarchical Navigable Small World (HNSW). Он задаёт количество документов, которые должен вернуть один индекс HNSW. Однако фактическое число документов в итоговых результатах может отличаться. Например, если система работает с таблицами реального времени, разделёнными на дисковые чанки, каждый чанк может вернуть `k` документов, что приведёт к общему числу, превышающему заданное `k` (поскольку общее количество будет `num_chunks * k`). С другой стороны, итоговое число документов может быть меньше `k`, если после запроса `k` документов некоторые из них будут отфильтрованы по определённым атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. Для ramchunks процесс извлечения работает иначе, и эффект параметра `k` на количество возвращаемых документов не применяется.
* `query_vector`: вектор запроса.
* `ef`: необязательный размер динамического списка, используемого при поиске. Более высокий `ef` обеспечивает более точный, но более медленный поиск.
* `rescore`: включает пересчёт баллов KNN (по умолчанию отключено). Устанавливается в `1` в SQL или в `true` в JSON для включения пересчёта. После завершения поиска KNN с использованием квантованных векторов (с возможным оверсемплингом) расстояния пересчитываются с использованием исходных (полной точности) векторов, и результаты переупорядочиваются для улучшения точности ранжирования.
* `oversampling`: задаёт фактор (число с плавающей точкой), на который умножается `k` при выполнении KNN-поиска, что приводит к получению большего числа кандидатов, чем требуется, с использованием квантованных векторов. По умолчанию оверсемплинг не применяется. Эти кандидаты могут быть перепроверены позже, если включён пересчёт баллов. Оверсемплинг также работает с неквантованными векторами. Поскольку он увеличивает `k`, что влияет на работу индекса HNSW, возможны небольшие изменения в точности результатов.

Документы всегда сортируются по расстоянию до вектора запроса. Любые дополнительные критерии сортировки, которые вы укажете, применяются после этого первичного условия сортировки. Для получения расстояния есть встроенная функция [knn_dist()](../Functions/Other_functions.md#KNN_DIST%28%29).

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926), { ef=2000, oversampling=3.0, rescore=1 } );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.28146550 |
|    2 | 0.81527930 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query_vector": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"ef": 2000, 
		"rescore": true,
		"oversampling": 3.0
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":2,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 1,
				"_score":1,
				"_knn_dist":0.28146550,
				"_source":
				{
					"title":"yellow bag",
					"image_vector":[0.653448,0.192478,0.017971,0.339821]
				}
			},
			{
				"_id": 2,
				"_score":1,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->















































































































































































































