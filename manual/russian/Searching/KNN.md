# K-nearest neighbor vector search

Manticore Search поддерживает возможность добавления эмбеддингов, созданных вашими моделями машинного обучения, к каждому документу, а затем выполнения поиска ближайших соседей по ним. Это позволяет создавать такие функции, как поиск по схожести, рекомендации, семантический поиск и ранжирование релевантности на основе алгоритмов обработки естественного языка (NLP), а также поиск изображений, видео и звуков.

## Что такое эмбеддинг?

Эмбеддинг — это метод представления данных, таких как текст, изображения или звук, в виде векторов в высокоразмерном пространстве. Эти векторы создаются таким образом, чтобы расстояние между ними отражало степень сходства представляемых данных. Этот процесс обычно использует алгоритмы, такие как векторные представления слов (например, Word2Vec, BERT) для текста или нейронные сети для изображений. Высокая размерность векторного пространства, с большим количеством компонентов в каждом векторе, позволяет представить сложные и тонкие взаимосвязи между объектами. Их сходство оценивается по расстоянию между этими векторами, которое часто измеряется с помощью методов, таких как евклидово расстояние или косинусная близость.

Manticore Search предоставляет возможность выполнять поиск k-ближайших соседей (KNN) с использованием библиотеки HNSW. Эта функциональность является частью [Manticore Columnar Library](https://github.com/manticoresoftware/columnar).

<!-- example KNN -->

### Конфигурирование таблицы для поиска KNN

Для выполнения поиска KNN необходимо сначала настроить таблицу. Векторы с плавающей точкой и поиск KNN поддерживаются только в таблицах реального времени (не в обычных таблицах). Таблица должна содержать как минимум один атрибут типа float_vector, который используется как вектор данных. Нужно указать следующие свойства:
* `knn_type`: обязательный параметр; в настоящее время поддерживается только `hnsw`.
* `knn_dims`: обязательный параметр, указывающий размерность индексируемых векторов.
* `hnsw_similarity`: обязательный параметр, указывающий функцию расстояния, используемую индексом HNSW. Допустимые значения:
  - `L2` - Квадрат Евклидова расстояния (L2)
  - `IP` - Внутреннее произведение
  - `COSINE` - Косинусное сходство
* `hnsw_m`: необязательный параметр, определяющий максимальное количество исходящих связей в графе. По умолчанию 16.
* `hnsw_ef_construction`: необязательный параметр, определяющий компромисс между временем построения и точностью.

<!-- intro -->
##### SQL

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' );
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```

<!-- intro -->
##### Plain mode (использование конфигурационного файла):

<!-- request Config -->
```ini
table test_vec {
    type = rt
	...
    rt_attr_float_vector = image_vector
    knn = {"attrs":[{"name":"image_vector","type":"hnsw","dims":4,"hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200}]}
}
```

<!-- end -->

<!-- example knn_insert -->

### Вставка векторных данных

После создания таблицы необходимо вставить ваши векторные данные, убедившись, что они соответствуют размерности, указанной при создании таблицы. Также можно вставить пустой вектор; это означает, что документ не будет участвовать в результатах поиска по вектору.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
insert into test values ( 1, 'yellow bag', (0.653448,0.192478,0.017971,0.339821) ), ( 2, 'white bag', (-0.148894,0.748278,0.091892,-0.095406) );
```
<!-- response SQL -->

```sql
Query OK, 2 rows affected (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /insert
{
	"table":"test_vec",
	"id":1,
	"doc": 	{ "title" : "yellow bag", "image_vector" : [0.653448,0.192478,0.017971,0.339821] }
}

POST /insert
{
	"table":"test_vec",
	"id":2,
	"doc": 	{ "title" : "white bag", "image_vector" : [-0.148894,0.748278,0.091892,-0.095406] }
}
```

<!-- response JSON -->

```json
{
	"table":"test",
	"_id":1,
	"created":true,
	"result":"created",
	"status":201
}

{
	"table":"test",
	"_id":2,
	"created":true,
	"result":"created",
	"status":201
}
```

<!-- end -->

<!-- example knn_search -->

### Поиск KNN по вектору

Теперь вы можете выполнять поиск KNN, используя ключевое слово `knn` в SQL или JSON формате. Оба интерфейса поддерживают одинаковые основные параметры, что обеспечивает единообразие при выборе любого из форматов:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <query vector> [,<options>] )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "query_vector": [<query vector>],
          "k": <k>,
          "ef": <ef>,
  "rescore": <rescore>,
  "oversampling": <oversampling>
      }
  }
  ```

Параметры:
* `field`: имя атрибута float_vector, содержащего векторные данные.
* `k`: количество возвращаемых документов; ключевой параметр для индексов Hierarchical Navigable Small World (HNSW). Указывает количество документов, которые должен вернуть один индекс HNSW. Однако фактическое количество документов в итоговых результатах может отличаться. Например, если система работает с таблицами реального времени, разбитыми на дисковые чанки, каждый чанк может вернуть `k` документов, в итоге количество будет больше заданного `k` (суммарно — `num_chunks * k`). С другой стороны, итоговое число документов может быть меньше `k`, если после запроса `k` документов некоторые из них отфильтрованы по заданным атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. Для ramchunks процесс выборки работает иначе, и параметр `k` не влияет на количество возвращаемых документов.
* `query_vector`: вектор запроса для поиска.
* `ef`: необязательный размер динамического списка, используемого во время поиска. Чем выше `ef`, тем точнее, но медленнее поиск.
* `rescore`: включает дооценку KNN (по умолчанию выключено). Установите `1` в SQL или `true` в JSON, чтобы включить дооценку. После завершения KNN-поиска с использованием квантованных векторов (с возможным переотбором) расстояния пересчитываются с оригинальными (полной точности) векторами, и результаты пересортировываются для улучшения точности ранжирования.
* `oversampling`: задаёт коэффициент (вещественное число), на который умножается `k` при выполнении KNN-поиска, из-за чего извлекается больше кандидатов, чем необходимо, используя квантованные векторы. По умолчанию переотбор не применяется. Эти кандидаты могут быть повторно оценены, если включена дооценка.

Документы всегда сортируются по расстоянию до вектора запроса. Любые дополнительные критерии сортировки применяются после этого основного условия сортировки. Для получения расстояния существует встроенная функция [knn_dist()](../Functions/Other_functions.md#KNN_DIST%28%29).

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926), { ef=2000, oversampling=3.0, rescore=1 } );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.28146550 |
|    2 | 0.81527930 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query_vector": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"ef": 2000, 
		"rescore": true,
		"oversampling": 3.0
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":2,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 1,
				"_score":1,
				"_knn_dist":0.28146550,
				"_source":
				{
					"title":"yellow bag",
					"image_vector":[0.653448,0.192478,0.017971,0.339821]
				}
			},
			{
				"_id": 2,
				"_score":1,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- example knn_quantization -->

### Квантование векторов

Индексы HNSW должны быть полностью загружены в память для выполнения поиска KNN, что может привести к значительному потреблению памяти. Чтобы сократить использование памяти, можно применить скалярную квантизацию — технику, которая сжимает многомерные векторы, представляя каждый компонент (измерение) ограниченным набором дискретных значений. Manticore поддерживает квантизацию с 8-битной и 1-битной точностью, что означает, что каждый компонент вектора сжимается с 32-битного float до 8 бит или даже 1 бита, сокращая использование памяти соответственно в 4 раза или 32 раза. Эти сжатые представления также позволяют быстрее вычислять расстояния, так как больше компонентов вектора можно обработать за одну SIMD-инструкцию. Несмотря на то, что скалярная квантизация вводит некоторую погрешность приближения, она часто является оправданным компромиссом между точностью поиска и эффективностью использования ресурсов. Для ещё большей точности квантизацию можно комбинировать с повторной оценкой и оверсемплированием: извлекается больше кандидатов, чем запрошено, и расстояния для этих кандидатов пересчитываются с использованием изначальных 32-битных float векторов.

Поддерживаемые типы квантизации включают:
* `8bit`: Каждый компонент вектора квантизируется до 8 бит.
* `1bit`: Каждый компонент вектора квантизируется до 1 бита. Используется асимметричная квантизация, при этом вектора запросов квантизируются до 4 бит, а хранимые вектора — до 1 бита. Такой подход обеспечивает большую точность по сравнению с более простыми методами, хотя и с некоторыми компромиссами по производительности.
* `1bitsimple`: Каждый компонент вектора квантизируется до 1 бита. Этот метод быстрее, чем `1bit`, но обычно менее точен.

<!-- intro -->
##### SQL:

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' quantization='1bit');
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```
<!-- end -->

<!-- Example knn_similar_docs -->

### Найти похожие документы по id

> ПРИМЕЧАНИЕ: Поиск похожих документов по id требует [Manticore Buddy](../Installation/Manticore_Buddy.md). Если это не работает, убедитесь, что Buddy установлен.

Поиск документов, похожих на конкретный, основанный на его уникальном ID, является распространённой задачей. Например, когда пользователь просматривает определённый элемент, Manticore Search может эффективно определить и отобразить список элементов, которые наиболее похожи на него в векторном пространстве. Вот как это можно сделать:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <document id> )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "doc_id": <document id>,
          "k": <k>
      }
  }
  ```

Параметры:
* `field`: Название атрибута с плавающим вектором, содержащим векторные данные.
* `k`: Количество документов, которые необходимо вернуть, и ключевой параметр для иерархических навигационных небольших миров (HNSW) индексов. Этот параметр указывает количество документов, которое должен вернуть один индекс HNSW. Однако фактическое число документов в итоговых результатах может варьироваться. Например, если система работает с таблицами в реальном времени, разбитыми на дисковые чанки, каждый чанк может вернуть `k` документов, что приведёт к общему числу, превышающему заданное `k` (так как сумма будет равна `num_chunks * k`). С другой стороны, итоговое число документов может быть меньше `k`, если после запроса `k` документов некоторые из них отфильтрованы по определённым атрибутам. Важно отметить, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс извлечения работает иначе, и поэтому параметр `k` не влияет на количество возвращаемых документов.
* `document id`: ID документа для поиска по сходству KNN.


<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, 1 );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
  "table": "test",
  "knn":
  {
    "field": "image_vector",
    "doc_id": 1,
    "k": 5
  }
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- Example knn_filtering -->

### Фильтрация результатов векторного поиска KNN

Manticore также поддерживает дополнительную фильтрацию документов, возвращаемых поиском KNN, либо по полнотекстовому совпадению, либо с использованием фильтров атрибутов, либо и того, и другого.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926) ) and match('white') and id < 10;
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query_vector": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"filter":
		{
			"bool":
			{
				"must":
				[
					{ "match": {"_all":"white"} },
			        { "range": { "id": { "lt": 10 } } }
				]
			}
		}
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- proofread -->

