# Поиск по векторам методом k-ближайших соседей

Manticore Search поддерживает возможность добавления эмбеддингов, сгенерированных моделями машинного обучения, к каждому документу, а затем выполнение поиска ближайших соседей по ним. Это позволяет создавать такие функции, как поиск по сходству, рекомендации, семантический поиск и ранжирование по релевантности на основе алгоритмов NLP, среди прочего, включая поиск по изображениям, видео и звуку.

## Что такое эмбеддинг?

Эмбеддинг — это метод представления данных — таких как текст, изображения или звук — в виде векторов в многомерном пространстве. Эти векторы созданы таким образом, чтобы расстояние между ними отражало сходство представляемых ими данных. Этот процесс обычно использует такие алгоритмы, как word embeddings (например, Word2Vec, BERT) для текста или нейронные сети для изображений. Многомерная природа векторного пространства, с большим количеством компонентов на вектор, позволяет представлять сложные и тонкие взаимосвязи между элементами. Их сходство измеряется расстоянием между этими векторами, часто с использованием таких методов, как евклидово расстояние или косинусное сходство.

Manticore Search позволяет выполнять поиск по векторам методом k-ближайших соседей (KNN) с использованием библиотеки HNSW. Эта функциональность является частью [Manticore Columnar Library](https://github.com/manticoresoftware/columnar).

<!-- example KNN -->

### Настройка таблицы для KNN-поиска

Для выполнения KNN-поиска необходимо сначала настроить вашу таблицу. Векторы с плавающей точкой и KNN-поиск поддерживаются только в реальном времени (не в обычных таблицах). Таблица должна иметь хотя бы один атрибут типа [float_vector](../Creating_a_table/Data_types.md#Float-vector), который служит вектором данных. Необходимо указать следующие свойства:
* `knn_type`: Обязательная настройка; в настоящее время поддерживается только `hnsw`.
* `knn_dims`: Обязательная настройка, которая определяет размерность индексируемых векторов.
* `hnsw_similarity`: Обязательная настройка, которая определяет функцию расстояния, используемую индексом HNSW. Допустимые значения:
  - `L2` - Квадрат L2
  - `IP` - Скалярное произведение
  - `COSINE` - Косинусное сходство
  
  **Примечание:** При использовании сходства `COSINE` векторы автоматически нормализуются при вставке. Это означает, что сохраненные значения векторов могут отличаться от исходных входных значений, так как они будут преобразованы в единичные векторы (векторы с математической длиной/величиной 1.0) для обеспечения эффективных вычислений косинусного сходства. Эта нормализация сохраняет направление вектора, стандартизируя его длину.
* `hnsw_m`: Необязательная настройка, определяющая максимальное количество исходящих соединений в графе. По умолчанию 16.
* `hnsw_ef_construction`: Необязательная настройка, определяющая компромисс между временем построения и точностью. По умолчанию 200.

<!-- intro -->
##### SQL

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' );
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```

<!-- intro -->
##### Обычный режим (использование файла конфигурации) - Ручные векторы:

<!-- request Config -->
```ini
table test_vec {
    type = rt
	...
    rt_attr_float_vector = image_vector
    knn = {"attrs":[{"name":"image_vector","type":"hnsw","dims":4,"hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200}]}
}
```

**Примечание:** Для автоэмбеддингов в обычном режиме см. пример ниже, который показывает, как использовать параметры `model_name` и `from` в конфигурации `knn`.

<!-- end -->

<!-- example knn_insert -->

### Вставка векторных данных

#### Автоэмбеддинги (Рекомендуется)

Самый простой способ работы с векторными данными — использование **автоэмбеддингов**. С этой функцией вы создаете таблицу с параметрами `MODEL_NAME` и `FROM`, а затем просто вставляете свои текстовые данные — Manticore автоматически генерирует эмбеддинги для вас.

##### Создание таблицы с автоэмбеддингами

При создании таблицы для автоэмбеддингов укажите:
- `MODEL_NAME`: Модель эмбеддинга для использования
- `FROM`: Какие поля использовать для генерации эмбеддингов (пустое значение означает все текстовые/строковые поля)

**Поддерживаемые модели эмбеддингов:**
- **Sentence Transformers**: Любая [подходящая модель на основе BERT из Hugging Face](https://huggingface.co/sentence-transformers/models) (например, `sentence-transformers/all-MiniLM-L6-v2`) — ключ API не требуется. Manticore загружает модель при создании таблицы.
- **Qwen локальные эмбеддинги**: Модели эмбеддингов Qwen, такие как `Qwen/Qwen3-Embedding-0.6B` — ключ API не требуется. Manticore загружает модель при создании таблицы.
- **OpenAI**: Модели эмбеддингов OpenAI, такие как `openai/text-embedding-ada-002` - требует параметр `API_KEY='<OPENAI_API_KEY>'`
- **Voyage**: Модели эмбеддингов Voyage AI - требует параметр `API_KEY='<VOYAGE_API_KEY>'`
- **Jina**: Модели эмбеддингов Jina AI - требует параметр `API_KEY='<JINA_API_KEY>'`

Более подробную информацию о настройке атрибута `float_vector` можно найти [здесь](../Creating_a_table/Data_types.md#Float-vector).

<!-- intro -->
##### SQL:

<!-- request SQL -->

Использование sentence-transformers (ключ API не требуется)
```sql
CREATE TABLE products (
    title TEXT, 
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2' 
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM='title'
);
```

Использование локальных эмбеддингов Qwen (ключ API не требуется)
```sql
CREATE TABLE products_qwen (
    title TEXT, 
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='Qwen/Qwen3-Embedding-0.6B' FROM='title' CACHE_PATH='/opt/homebrew/var/manticore/.cache/manticore'
);
```

Использование OpenAI (требуется параметр API_KEY)
```sql
CREATE TABLE products_openai (
    title TEXT,
    description TEXT, 
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='openai/text-embedding-ada-002' FROM='title,description' API_KEY='...'
);
```

Использование всех текстовых полей для эмбеддингов (FROM пуст)
```sql
CREATE TABLE products_all (
    title TEXT,
    description TEXT,
    embedding_vector FLOAT_VECTOR KNN_TYPE='hnsw' HNSW_SIMILARITY='l2'
    MODEL_NAME='sentence-transformers/all-MiniLM-L6-v2' FROM=''
);
```

<!-- intro -->
##### Обычный режим (использование файла конфигурации):

<!-- request Config -->
```ini
table products {
    type = rt
    path = /path/to/products
    rt_field = title
    rt_field = description
    rt_attr_float_vector = embedding_vector
    knn = {"attrs":[{"name":"embedding_vector","type":"hnsw","hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200,"model_name":"sentence-transformers/all-MiniLM-L6-v2","from":"title"}]}
}
```

Использование OpenAI с ключом API в обычном режиме:
```ini
table products_openai {
    type = rt
    path = /path/to/products_openai
    rt_field = title
    rt_field = description
    rt_attr_float_vector = embedding_vector
    knn = {"attrs":[{"name":"embedding_vector","type":"hnsw","hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200,"model_name":"openai/text-embedding-ada-002","from":"title,description","api_key":"your-api-key-here"}]}
}
```

Использование всех текстовых полей (пустой FROM):
```ini
table products_all {
    type = rt
    path = /path/to/products_all
    rt_field = title
    rt_field = description
    rt_attr_float_vector = embedding_vector
    knn = {"attrs":[{"name":"embedding_vector","type":"hnsw","hnsw_similarity":"L2","hnsw_m":16,"hnsw_ef_construction":200,"model_name":"sentence-transformers/all-MiniLM-L6-v2","from":""}]}
}
```

**Важные примечания для обычного режима:**
- При использовании `model_name` вы **не должны** указывать `dims` — модель автоматически определяет размерность векторов. Параметры `dims` и `model_name` являются взаимоисключающими.
- Когда **не** используется `model_name` (ручная вставка векторов), вы **должны** указать `dims`, чтобы обозначить размерность векторов.
- Параметр `from` указывает, какие поля использовать для генерации эмбеддингов (список, разделенный запятыми, или пустая строка для всех текстовых/строковых полей). Этот параметр обязателен при использовании `model_name`.
- `cache_path` опционально указывает, где кэшировать загруженные локальные модели (например, модели Hugging Face, такие как sentence-transformers или Qwen). Используйте его, если ваш кэш-каталог Manticore отличается от стандартного или рабочего каталога сервера.
- Для моделей на основе API (OpenAI, Voyage, Jina) включите параметр `api_key` в конфигурацию knn

<!-- end -->

##### Вставка данных с автоэмбеддингами

<!-- example inserting_embeddings -->

При использовании автоэмбеддингов **не указывайте векторное поле** в вашем операторе INSERT. Эмбеддинги генерируются автоматически из текстовых полей, указанных в параметре `FROM`.

<!-- intro -->
##### SQL:

<!-- request SQL -->

Вставка только текстовых данных - эмбеддинги генерируются автоматически
```sql
INSERT INTO products (title) VALUES 
('machine learning artificial intelligence'),
('banana fruit sweet yellow');
```

Вставка нескольких полей - оба используются для эмбеддинга, если FROM='title,description'  
```sql
INSERT INTO products_openai (title, description) VALUES
('smartphone', 'latest mobile device with advanced features'),
('laptop', 'portable computer for work and gaming');
```

Вставка пустого вектора (документ исключен из векторного поиска)
```sql
INSERT INTO products (title, embedding_vector) VALUES 
('no embedding item', ());
```

<!-- end -->

##### Поиск с автоэмбеддингами

<!-- example embeddings_search -->
Поиск работает аналогичным образом - предоставьте ваш запрос в виде текста, и Manticore сгенерирует эмбеддинги и найдет похожие документы:

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
SELECT id, knn_dist() FROM products WHERE knn(embedding_vector, 3, 'machine learning');
```

<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.12345678 |
|    2 | 0.87654321 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

Использование текстового запроса с авто-эмбеддингами
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": "machine learning",
        "k": 3
    }
}
```

Использование векторного запроса напрямую
```json
POST /search
{
    "table": "products",
    "knn": {
        "field": "embedding_vector",
        "query": [0.1, 0.2, 0.3, 0.4],
        "k": 3
    }
}
```

<!-- response JSON -->

```json
{
    "took": 0,
    "timed_out": false,
    "hits": {
        "total": 2,
        "total_relation": "eq",
        "hits": [
            {
                "_id": 1,
                "_score": 1,
                "_knn_dist": 0.12345678,
                "_source": {
                    "title": "machine learning artificial intelligence"
                }
            },
            {
                "_id": 2,
                "_score": 1,
                "_knn_dist": 0.87654321,
                "_source": {
                    "title": "banana fruit sweet yellow"
                }
            }
        ]
    }
}
```

<!-- end -->

#### Ручная вставка векторов

<!-- example manual_vector -->
В качестве альтернативы, вы можете вручную вставлять предварительно вычисленные векторные данные, убедившись, что они соответствуют размерности, указанной вами при создании таблицы. Вы также можете вставить пустой вектор; это означает, что документ будет исключен из результатов векторного поиска.

**Важно:** При использовании `hnsw_similarity='cosine'` векторы автоматически нормализуются при вставке до единичных векторов (векторов с математической длиной/величиной, равной 1.0). Эта нормализация сохраняет направление вектора, стандартизируя его длину, что необходимо для эффективных вычислений косинусного сходства. Это означает, что сохраненные значения будут отличаться от ваших исходных входных значений.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
insert into test values ( 1, 'yellow bag', (0.653448,0.192478,0.017971,0.339821) ), ( 2, 'white bag', (-0.148894,0.748278,0.091892,-0.095406) );
```
<!-- response SQL -->

```sql
Query OK, 2 rows affected (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /insert
{
	"table":"test_vec",
	"id":1,
	"doc": 	{ "title" : "yellow bag", "image_vector" : [0.653448,0.192478,0.017971,0.339821] }
}

POST /insert
{
	"table":"test_vec",
	"id":2,
	"doc": 	{ "title" : "white bag", "image_vector" : [-0.148894,0.748278,0.091892,-0.095406] }
}
```

<!-- response JSON -->

```json
{
	"table":"test",
	"_id":1,
	"created":true,
	"result":"created",
	"status":201
}

{
	"table":"test",
	"_id":2,
	"created":true,
	"result":"created",
	"status":201
}
```

<!-- end -->

<!-- example knn_search -->

### KNN векторный поиск

Теперь вы можете выполнять KNN поиск, используя предложение `knn` в формате SQL или JSON. Оба интерфейса поддерживают одинаковые основные параметры, обеспечивая согласованный опыт независимо от выбранного формата:

- SQL: `select ... from <table name> where knn ( <field>, <query vector> [,<options>] )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "query": "<text or vector>",
          "ef": <ef>,
		  "rescore": <rescore>,
		  "oversampling": <oversampling>
      }
  }
  ```

Параметры:
* `field`: Это имя атрибута вектора с плавающей запятой, содержащего векторные данные.
* `k`: Устаревшая опция. Вместо этого используйте `limit` в запросе. Ранее использовалась для указания количества документов, которое должен возвращать один индекс HNSW. Однако фактическое количество документов, включенных в окончательные результаты, может отличаться. Например, если система работает с таблицами реального времени, разделенными на дисковые чанки, каждый чанк может возвращать `k` документов, что приводит к общему количеству, превышающему указанное `k` (так как совокупное количество будет `num_chunks * k`). С другой стороны, окончательное количество документов может быть меньше `k`, если после запроса `k` документов некоторые из них отфильтровываются на основе определенных атрибутов. Важно отметить, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс извлечения работает иначе, и поэтому влияние параметра `k` на количество возвращаемых документов неприменимо.
* `query`: (Рекомендуемый параметр) Поисковый запрос, который может быть:
  - Текстовой строкой: Автоматически преобразуется в эмбеддинги, если для поля настроены авто-эмбеддинги. Вернет ошибку, если у поля нет авто-эмбеддингов.
  - Векторным массивом: Работает так же, как `query_vector`.
* `query_vector`: (Устаревший параметр) Поисковый вектор в виде массива чисел. Все еще поддерживается для обратной совместимости.
  **Примечание:** Используйте либо `query`, либо `query_vector`, но не оба в одном запросе.
* `ef`: необязательный размер динамического списка, используемого во время поиска. Более высокое значение `ef` приводит к более точному, но более медленному поиску. По умолчанию равно 10.
* `rescore`: Включает пересчет оценок KNN (включено по умолчанию). Установите `0` в SQL или `false` в JSON, чтобы отключить пересчет. После завершения KNN поиска с использованием квантованных векторов (с возможным перевыборкой), расстояния пересчитываются с исходными (полноразрядными) векторами, и результаты пересортировываются для повышения точности ранжирования.
* `oversampling`: Устанавливает коэффициент (значение с плавающей запятой), на который умножается `k` при выполнении KNN поиска, что приводит к извлечению большего количества кандидатов, чем необходимо, с использованием квантованных векторов. По умолчанию применяется `oversampling=3.0`. Эти кандидаты могут быть позже переоценены, если пересчет оценок включен. Перевыборка также работает с неквантованными векторами. Поскольку она увеличивает `k`, что влияет на работу индекса HNSW, это может вызвать небольшое изменение точности результатов.

Документы всегда сортируются по расстоянию до поискового вектора. Любые дополнительные критерии сортировки, которые вы укажете, будут применены после этого основного условия сортировки. Для получения расстояния существует встроенная функция [knn_dist()](../Functions/Other_functions.md#KNN_DIST%28%29).

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, (0.286569,-0.031816,0.066684,0.032926), { ef=2000, oversampling=3.0, rescore=1 } );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    1 | 0.28146550 |
|    2 | 0.81527930 |
+------+------------+
2 rows in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"ef": 2000, 
		"rescore": true,
		"oversampling": 3.0
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":2,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 1,
				"_score":1,
				"_knn_dist":0.28146550,
				"_source":
				{
					"title":"yellow bag",
					"image_vector":[0.653448,0.192478,0.017971,0.339821]
				}
			},
			{
				"_id": 2,
				"_score":1,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- example knn_quantization -->

### Векторное квантование

Индексы HNSW должны быть полностью загружены в память для выполнения KNN поиска, что может привести к значительному потреблению памяти. Для уменьшения использования памяти может применяться скалярное квантование - техника, которая сжимает высокоразмерные векторы, представляя каждый компонент (размерность) ограниченным количеством дискретных значений. Manticore поддерживает 8-битное и 1-битное квантование, что означает, что каждый компонент вектора сжимается с 32-битного числа с плавающей запятой до 8 бит или даже 1 бита, уменьшая использование памяти в 4 или 32 раза соответственно. Эти сжатые представления также позволяют выполнять более быстрые вычисления расстояний, так как больше компонентов вектора может быть обработано одной инструкцией SIMD. Хотя скалярное квантование вносит некоторую ошибку аппроксимации, это часто является оправданным компромиссом между точностью поиска и эффективностью использования ресурсов. Для еще лучшей точности квантование можно комбинировать с пересчетом оценок и перевыборкой: извлекается больше кандидатов, чем запрошено, и расстояния для этих кандидатов пересчитываются с использованием исходных 32-битных векторов с плавающей запятой.

Поддерживаемые типы квантования включают:
* `8bit`: Каждый компонент вектора квантуется до 8 бит.
* `1bit`: Каждый компонент вектора квантуется до 1 бита. Используется асимметричное квантование, при этом векторы запросов квантуются до 4 бит, а хранимые векторы — до 1 бита. Этот подход обеспечивает более высокую точность по сравнению с более простыми методами, хотя и с некоторым компромиссом в производительности.
* `1bitsimple`: Каждый компонент вектора квантуется до 1 бита. Этот метод быстрее, чем `1bit`, но обычно менее точен.

<!-- intro -->
##### SQL:

<!-- request SQL -->
```sql
create table test ( title text, image_vector float_vector knn_type='hnsw' knn_dims='4' hnsw_similarity='l2' quantization='1bit');
```

<!-- response SQL -->

```sql
Query OK, 0 rows affected (0.01 sec)
```
<!-- end -->

<!-- Example knn_similar_docs -->

### Поиск похожих документов по id

> ПРИМЕЧАНИЕ: Поиск похожих документов по id требует наличия [Manticore Buddy](../Installation/Manticore_Buddy.md). Если это не работает, убедитесь, что Buddy установлен.

Поиск документов, похожих на конкретный, на основе его уникального ID, является распространённой задачей. Например, когда пользователь просматривает определённый элемент, Manticore Search может эффективно идентифицировать и отобразить список элементов, наиболее похожих на него в векторном пространстве. Вот как это можно сделать:

- SQL: `select ... from <table name> where knn ( <field>, <k>, <document id> )`
- JSON:
  ```
  POST /search
  {
      "table": "<table name>",
      "knn":
      {
          "field": "<field>",
          "doc_id": <document id>,
          "k": <k>
      }
  }
  ```

Параметры:
* `field`: Это имя атрибута вектора с плавающей точкой, содержащего векторные данные.
* `k`: Это количество возвращаемых документов и ключевой параметр для индексов Hierarchical Navigable Small World (HNSW). Он указывает количество документов, которое должен вернуть один индекс HNSW. Однако фактическое количество документов, включённых в окончательные результаты, может варьироваться. Например, если система работает с таблицами реального времени, разделёнными на дисковые чанки, каждый чанк может вернуть `k` документов, что приводит к общему количеству, превышающему указанное `k` (так как совокупное количество будет `num_chunks * k`). С другой стороны, итоговое количество документов может быть меньше `k`, если после запроса `k` документов некоторые из них отфильтровываются на основе определённых атрибутов. Важно отметить, что параметр `k` не применяется к ramchunks. В контексте ramchunks процесс извлечения работает иначе, и, следовательно, влияние параметра `k` на количество возвращаемых документов неприменимо.
* `document id`: ID документа для поиска сходства KNN.


<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, 1 );
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
  "table": "test",
  "knn":
  {
    "field": "image_vector",
    "doc_id": 1,
    "k": 5
  }
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- Example knn_filtering -->

### Фильтрация результатов векторного поиска KNN

Manticore также поддерживает дополнительную фильтрацию документов, возвращаемых поиском KNN, либо по полнотекстовому соответствию, либо по фильтрам атрибутов, либо по обоим.

<!-- intro -->
##### SQL:

<!-- request SQL -->

```sql
select id, knn_dist() from test where knn ( image_vector, 5, (0.286569,-0.031816,0.066684,0.032926) ) and match('white') and id < 10;
```
<!-- response SQL -->

```sql
+------+------------+
| id   | knn_dist() |
+------+------------+
|    2 | 0.81527930 |
+------+------------+
1 row in set (0.00 sec)
```

<!-- intro -->
##### JSON:

<!-- request JSON -->

```json
POST /search
{
	"table": "test",
	"knn":
	{
		"field": "image_vector",
		"query": [0.286569,-0.031816,0.066684,0.032926],
		"k": 5,
		"filter":
		{
			"bool":
			{
				"must":
				[
					{ "match": {"_all":"white"} },
			        { "range": { "id": { "lt": 10 } } }
				]
			}
		}
	}
}
```

<!-- response JSON -->

```json
{
	"took":0,
	"timed_out":false,
	"hits":
	{
		"total":1,
		"total_relation":"eq",
		"hits":
		[
			{
				"_id": 2,
				"_score":1643,
				"_knn_dist":0.81527930,
				"_source":
				{
					"title":"white bag",
					"image_vector":[-0.148894,0.748278,0.091892,-0.095406]
				}
			}
		]
	}
}
```

<!-- end -->

<!-- proofread -->
