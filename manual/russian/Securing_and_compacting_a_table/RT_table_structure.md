# Структура таблицы реального времени
Простая таблица может быть создана из внешнего источника с помощью специального инструмента под названием `indexer`, который читает "рецепт" из конфигурации, подключается к источникам данных, извлекает документы и строит файлы таблицы. Это длительный процесс. Если ваши данные изменяются, таблица устаревает, и вам приходится перестраивать её на основе обновлённых источников. Если ваши данные изменяются поэтапно, как в блоге или новостной ленте, где старые документы никогда не меняются, а добавляются только новые, то перестройка будет занимать всё больше времени, поскольку вам придётся обрабатывать архивные источники снова и снова при каждом проходе.
Один из способов решения этой проблемы заключается в использовании нескольких таблиц вместо одной единой таблицы. Например, вы можете обработать источники, созданные в предыдущие годы, и сохранить таблицу. Затем взять только источники за текущий год и поместить их в отдельную таблицу, перестраивая её по мере необходимости. После этого вы можете объединить обе таблицы в распределённую таблицу и использовать её для запросов. Суть в том, что при каждой перестройке обрабатываются данные не старше, чем за последние 12 месяцев, а таблица со старыми данными остаётся неизменной и не требует перестройки. Вы можете пойти дальше и разбить таблицу за последние 12 месяцев на месячные, недельные или ежедневные таблицы и так далее.
Этот подход работает, но вам нужно поддерживать вашу распределённую таблицу вручную. То есть, добавлять новые фрагменты, удалять старые и следить за тем, чтобы общее количество частичных таблиц не было слишком большим (при слишком большом количестве таблиц поиск может замедлиться, а операционная система обычно ограничивает число одновременно открытых файлов). Для решения этой проблемы вы можете вручную объединить несколько таблиц, запустив [indexer --merge](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Merging_tables.md). Однако это решает лишь проблему большого количества таблиц, усложняя их обслуживание. И даже при "почасовой" переиндексации, скорее всего, будет заметна задержка между поступлением новых данных в источники и перестройкой таблицы, которая включает эти данные для поиска.
Таблица реального времени предназначена для решения этой проблемы. Она состоит из двух частей:
1. Специальная таблица на основе оперативной памяти (называемая RAM chunk), которая содержит части данных, поступающих прямо сейчас.
2. Набор обычных таблиц, называемых disk chunks, которые были созданы в прошлом.
Это очень похоже на стандартную [распределённую таблицу](../Creating_a_table/Creating_a_distributed_table/Creating_a_distributed_table.md), созданную из нескольких локальных таблиц.
Вам не нужно создавать такую таблицу запуском `indexer`, который читает "рецепт" из конфигурации и таблиц источников данных. Вместо этого таблица реального времени предоставляет возможность "insert" для вставки новых документов и "replace" для замены существующих. При выполнении команды "insert" вы отправляете новые документы на сервер. Затем он создает небольшую таблицу из добавленных документов и мгновенно делает её доступной онлайн. Таким образом, сразу после завершения команды "insert" вы можете выполнять поиск по всем частям таблицы, включая только что добавленные документы.
Сервер поиска автоматически обслуживает таблицу, так что вам не о чем беспокоиться. Однако вам может быть интересно узнать несколько подробностей о том, "как она обслуживается".
**Во-первых, поскольку индексированные данные хранятся в оперативной памяти - что же происходит при аварийном отключении питания?** Потеряется ли тогда моя таблица? Перед завершением сервер сохраняет новые данные в специальный "binlog". Он состоит из одного или нескольких файлов, находящихся на вашем постоянном хранилище, и постепенно растёт по мере добавления всё новых изменений. Вы можете настроить, как часто новые запросы (или транзакции) сохраняются в binlog, и как часто команда "sync" выполняется над файлом binlog, чтобы принудить ОС действительно записывать данные на надёжное хранилище. Самый осторожный подход – выполнять flush и sync после каждой транзакции. Это самый медленный, но и самый надёжный метод. Наименее затратный способ – полностью отключить binlog. Это самый быстрый метод, но вы рискуете потерять индексированные данные. Также предусмотрены промежуточные варианты, такие как flush/sync каждую секунду.
Бинлог разработан специально для последовательного сохранения вновь поступающих транзакций; это не таблица, и по нему нельзя выполнять поиск. Это всего лишь страховка, гарантирующая, что сервер не потеряет ваши данные. Если произойдёт внезапное нарушение и всё сломается из-за программной или аппаратной проблемы, сервер загрузит самый свежий доступный дамп RAM chunk, а затем воспроизведёт binlog, повторяя сохранённые транзакции. В конечном итоге он достигнет того же состояния, в каком находился в момент последнего изменения.
**Во-вторых, что насчёт ограничений?** Что если я хочу обработать, скажем, 10ТБ данных, но их просто не помещается в оперативную память! ОЗУ для таблицы реального времени ограничено и может быть настроено. Когда индексируется определённое количество данных, сервер управляет оперативной частью таблицы путём объединения мелких транзакций, чтобы их число и общий размер оставались небольшими. Однако этот процесс иногда может вызывать задержки при вставке. Когда слияние больше не помогает и новые вставки достигают [RAM limit](../Creating_a_table/Local_tables/Plain_and_real-time_table_settings.md#rt_mem_limit), сервер преобразует таблицу, основанную на ОЗУ, в обычную таблицу, хранящуюся на диске (называемую disk chunk). Эта таблица добавляется в коллекцию таблиц во второй части таблицы реального времени и становится доступной онлайн. Затем ОЗУ очищается, и место освобождается.
Когда данные из ОЗУ надёжно сохраняются на диск, что происходит:
* когда сервер сохраняет собранные данные как таблицу на диске
* или когда он сбрасывает оперативную часть во время корректного завершения работы или при [ручной очистке](../Securing_and_compacting_a_table/Flushing_RAM_chunk_to_disk.md#FLUSH-TABLE)
бинлог для этой таблицы больше не нужен. Таким образом, он отбрасывается. Если все таблицы сохранены, бинлог будет удалён.
**Третье, как насчет дисковой коллекции?**  Если наличие многих дисковых частей делает поиск медленнее, в чем разница, если я создаю их вручную в распределенной таблице, или они производятся как дисковые части (или, 'чанки') RT таблицей? Ну, в обоих случаях вы можете объединить несколько таблиц в одну. Например, вы можете объединить почасовые таблицы за вчера и оставить одну 'ежедневную' таблицу за вчера вместо этого. При ручном обслуживании вам нужно думать о схеме и командах самостоятельно. С RT таблицей сервер предоставляет команду [OPTIMIZE](../Securing_and_compacting_a_table/Compacting_a_table.md#OPTIMIZE-TABLE), которая выполняет то же самое, но удерживает вас от ненужных внутренних деталей.

**Четвертое, если мой "документ" представляет собой 'мини-таблицу' и мне больше не нужен, я могу просто выбросить его. Но если он 'оптимизирован', т.е. смешан вместе с тоннами других документов, как я могу отменить или удалить его?** Да, индексированные документы 'смешаны' вместе, и нет простого способа удалить один, не перестраивая всю таблицу. И если для обычных таблиц перестройка или объединение - это просто нормальный способ обслуживания, для реальной таблицы это сохраняет только простоту манипуляций, но не 'реальное время'. Чтобы решить эту проблему, Manticore использует трюк: когда вы удаляете документ, идентифицированный по ID документа, сервер просто отслеживает номер. Вместе с другими удаленными документами их ID сохраняются в так называемом [kill-list](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Killlist_in_plain_tables.md#Table-kill-list). Когда вы ищете по таблице, сервер сначала извлекает все совпадающие документы, а затем выбрасывает документы, которые находятся в списке на удаление (это самое основное описание; на самом деле, внутренне все более сложно). Суть в том, что, ради 'немедленного' удаления, документы на самом деле не удаляются, а просто помечаются как 'удаленные'. Они все еще занимают место в разных структурах таблицы, будучи по сути мусором. Статистика слов, которая влияет на ранжирование, также не затрагивается, что означает, что это работает точно так, как заявлено: мы ищем среди всех документов, а затем просто скрываем отмеченные как удаленные из окончательного результата. Когда документ [заменяется](../Data_creation_and_modification/Updating_documents/REPLACE.md), это означает, что он убивается в старых частях таблицы и снова вставляется в самую свежую часть. Все последствия 'скрытия с помощью killlist' также действуют в этом случае.

Когда происходит перестройка какой-то части таблицы, например, когда некоторые транзакции (сегменты) RAM чанка объединяются, или когда RAM чанк преобразуется в дисковый чанк, или когда два дисковых чанка объединяются, сервер выполняет комплексную итерацию по затронутым частям и физически исключает удаленные документы из всех них. То есть, если они находились в списках документов некоторых слов - они стираются. Если это было уникальное слово - оно полностью удаляется.

В качестве резюме: удаление работает в две фазы:
1. Сначала мы помечаем документы как 'удаленные' в реальном времени и подавляем их в результатах поиска.
2. Во время какой-то операции с чанком RT таблицы мы окончательно физически стираем удаленные документы навсегда.

**Пятое, если RT таблица содержит обычные дисковые таблицы в своей коллекции, могу ли я просто добавить свою готовую старую дисковую таблицу к ней?** Нет. Невозможно избежать ненужной сложности и предотвратить случайное повреждение. Однако, если ваша RT таблица только что создана и не содержит данных, то вы можете [ATTACH TABLE](../Data_creation_and_modification/Adding_data_from_external_storages/Adding_data_to_tables/Attaching_one_table_to_another.md) свою дисковую таблицу к ней. Ваша старая таблица будет перемещена внутрь RT таблицы и станет ее частью.

В качестве резюме о структуре RT таблицы: это хитро организованная коллекция обычных дисковых таблиц с быстрой оперативной таблицей, предназначенная для вставок в реальном времени и полудинамических удалений документов. RT таблица имеет общую схему, общие настройки и может быть легко обслуживаться без глубокого погружения в детали. 
<!-- proofread -->















