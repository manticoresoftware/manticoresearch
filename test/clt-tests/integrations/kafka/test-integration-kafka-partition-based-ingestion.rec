––– block: ../../base/dind/init –––
––– block: ../../base/basic-initialization-manticore-kafka –––
––– comment –––
Start Kafka container with KRaft mode configuration
––– input –––
docker run -it -d --network=app-network --name kafka -e KAFKA_CFG_NODE_ID=0 -e KAFKA_CFG_PROCESS_ROLES=controller,broker -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093 -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092 -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER -e KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT bitnami/kafka:3.7.0 > /dev/null 2>&1; echo $?
––– output –––
0
––– comment –––
Create Kafka topic with 2 partitions for data distribution testing
––– input –––
docker exec kafka kafka-topics.sh --create --topic my-data --partitions 2 --bootstrap-server localhost:9092 2>&1 | grep -o 'Created topic my-data\.' | head -n 1
––– output –––
Created topic my-data.
––– comment –––
Verify topic creation and partition configuration
––– input –––
docker exec kafka kafka-topics.sh --describe --topic my-data --bootstrap-server localhost:9092
––– output –––
Topic: my-data	TopicId: #!/[a-zA-Z0-9_-]+/!#	PartitionCount: 2	ReplicationFactor: 1	Configs:
	Topic: my-data	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: my-data	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
––– comment –––
Create Kafka source for partition 0 with specific consumer configuration
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p1 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='0' batch=50;"; echo $?
––– output –––
0
––– comment –––
Create Kafka source for partition 1 with specific consumer configuration
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p2 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='1' batch=50;"; echo $?
––– output –––
0
––– comment –––
Create destination table for partition 0 data
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_1 (id bigint, name text);"; echo $?
––– output –––
0
––– comment –––
Create destination table for partition 1 data
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_2 (id bigint, name text);"; echo $?
––– output –––
0
––– comment –––
Create materialized view to route partition 0 data to destination table
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_1 TO destination_shard_1 AS SELECT id, term AS name FROM kafka_p1;"; echo $?
––– output –––
0
––– comment –––
Create materialized view to route partition 1 data to destination table
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_2 TO destination_shard_2 AS SELECT id, term AS name FROM kafka_p2;"; echo $?
––– output –––
0
––– comment –––
Verify both Kafka sources are created successfully
––– input –––
docker exec manticore mysql -h0 -P9306 -e "SHOW SOURCES\G;"
––– output –––
*************************** 1. row ***************************
name: kafka_p2
*************************** 2. row ***************************
name: kafka_p1
––– comment –––
Verify both materialized views are created successfully
––– input –––
docker exec manticore mysql -h0 -P9306 -e "SHOW MVS\G;"
––– output –––
*************************** 1. row ***************************
name: mv_2
*************************** 2. row ***************************
name: mv_1
––– comment –––
Download test dataset for partition distribution testing
––– input –––
docker exec kafka curl -s -o /tmp/dump.json https://raw.githubusercontent.com/manticoresoftware/manticoresearch-buddy/main/test/Kafka/dump.json
––– output –––
––– comment –––
Download import script with key-based partitioning for balanced data distribution
––– input –––
docker exec kafka curl -s -o /tmp/import.sh https://raw.githubusercontent.com/manticoresoftware/manticoresearch-buddy/main/test/Kafka/import.sh
––– output –––
––– comment –––
Make import script executable and execute data import to Kafka topic
––– input –––
docker exec kafka chmod +x /tmp/import.sh && docker exec kafka /tmp/import.sh; echo $?
––– output –––
0
––– comment –––
Wait until lag becomes zero and current offset is not zero for all partitions
––– input –––
timeout 120 bash -c 'while true; do STATS=$(docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group manticore 2>/dev/null | grep -E "^manticore.*my-data"); if [ -z "$STATS" ]; then sleep 3; continue; fi; ALL_READY=true; while IFS= read -r line; do if [[ -n "$line" ]]; then read -r group topic partition current_offset log_end_offset lag rest <<< "$line"; if [[ "$lag" -ne 0 ]] || [[ "$current_offset" -eq 0 ]]; then ALL_READY=false; fi; fi; done <<< "$STATS"; if [ "$ALL_READY" = true ]; then echo "All partitions processed successfully"; break; fi; sleep 3; done' || echo "Processing timeout reached"
––– output –––
All partitions processed successfully
––– comment –––
Verify final Kafka consumer group state shows zero lag and processed offsets
––– input –––
docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group manticore
––– output –––
Consumer group 'manticore' has no active members.
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
manticore       my-data         0          30              30              0               -               -               -
manticore       my-data         1          27              27              0               -               -               -
––– comment –––
Compare Kafka partition counts with Manticore shard counts for validation
––– input –––
KAFKA_STATS=$(docker exec kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group manticore 2>/dev/null | grep -E "^manticore.*my-data"); KAFKA_P0=0; KAFKA_P1=0; while IFS= read -r line; do if [[ -n "$line" ]]; then read -r group topic partition current_offset rest <<< "$line"; if [ "$partition" = "0" ]; then KAFKA_P0=$current_offset; elif [ "$partition" = "1" ]; then KAFKA_P1=$current_offset; fi; fi; done <<< "$KAFKA_STATS"; TOTAL_KAFKA=$((KAFKA_P0 + KAFKA_P1)); SHARD1_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_1\G;" | grep "count" | cut -d: -f2 | tr -d ' '); SHARD2_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_2\G;" | grep "count" | cut -d: -f2 | tr -d ' '); TOTAL_MANTICORE=$((SHARD1_COUNT + SHARD2_COUNT)); echo "Kafka Partition 0: $KAFKA_P0 records"; echo "Kafka Partition 1: $KAFKA_P1 records"; echo "Total Kafka records: $TOTAL_KAFKA"; echo "Manticore Shard 1: $SHARD1_COUNT records"; echo "Manticore Shard 2: $SHARD2_COUNT records"; echo "Total Manticore records: $TOTAL_MANTICORE"; if [ $TOTAL_KAFKA -eq $TOTAL_MANTICORE ] && [ $TOTAL_KAFKA -gt 0 ]; then echo "TEST PASSED: All Kafka records processed correctly in Manticore"; else echo "TEST FAILED: Kafka records do not match Manticore records"; fi; if [ $KAFKA_P0 -gt 0 ] && [ $KAFKA_P1 -gt 0 ] && [ $SHARD1_COUNT -gt 0 ] && [ $SHARD2_COUNT -gt 0 ]; then echo "Data distributed across both partitions and shards"; else echo "Data distribution may be uneven"; fi
––– output –––
Kafka Partition 0: 30 records
Kafka Partition 1: 27 records
Total Kafka records: 57
Manticore Shard 1: 30 records
Manticore Shard 2: 27 records
Total Manticore records: 57
TEST PASSED: All Kafka records processed correctly in Manticore
Data distributed across both partitions and shards
