â€“â€“â€“ block: ../../base/dind/init â€“â€“â€“
â€“â€“â€“ comment â€“â€“â€“
Check Kafka version against documentation
â€“â€“â€“ input â€“â€“â€“
apk add curl > /dev/null 2>&1; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ input â€“â€“â€“
bash ./test/clt-tests/integrations/kafka/script_versions_kafka.sh
â€“â€“â€“ output â€“â€“â€“
ðŸ” Checking for new versions of Kafka...
âœ… No new versions found after apache/kafka:4.1.0
âœ… Version check completed
Checking documentation versions...
Checking documentation file...
Script version: Kafka 4.1.0
Documentation version: Kafka 4.1.0
âœ… Documentation version matches script version
â€“â€“â€“ block: ../../base/basic-initialization-manticore-kafka â€“â€“â€“
â€“â€“â€“ comment â€“â€“â€“
Start Kafka container with KRaft mode configuration
â€“â€“â€“ input â€“â€“â€“
docker run -d --network=app-network --name kafka --user root \
  -v /docker:/docker \
  -e KAFKA_NODE_ID=0 \
  -e KAFKA_PROCESS_ROLES=controller,broker \
  -e KAFKA_CONTROLLER_QUORUM_VOTERS=0@kafka:9093 \
  -e KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://:9092 \
  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT \
  -e CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk \
  apache/kafka:4.1.0 > /dev/null 2>&1; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Download test data files using wget
â€“â€“â€“ input â€“â€“â€“
docker exec kafka wget -O /tmp/dump.json https://raw.githubusercontent.com/manticoresoftware/manticoresearch/fix/test-integration-kafka-partition-based-ingestion/test/clt-tests/integrations/kafka/dump.json 2>&1 | grep saved
â€“â€“â€“ output â€“â€“â€“
'/tmp/dump.json' saved
â€“â€“â€“ input â€“â€“â€“
docker exec kafka wget -O /tmp/import.sh https://raw.githubusercontent.com/manticoresoftware/manticoresearch/fix/test-integration-kafka-partition-based-ingestion/test/clt-tests/integrations/kafka/import.sh 2>&1 | grep saved
â€“â€“â€“ output â€“â€“â€“
'/tmp/import.sh' saved
â€“â€“â€“ comment â€“â€“â€“
Create Kafka topic with 2 partitions for data distribution testing
â€“â€“â€“ input â€“â€“â€“
docker exec kafka /opt/kafka/bin/kafka-topics.sh --create --topic my-data --partitions 2 --bootstrap-server localhost:9092 2>&1 | grep -o 'Created topic my-data\.' | head -n 1
â€“â€“â€“ output â€“â€“â€“
Created topic my-data.
â€“â€“â€“ comment â€“â€“â€“
Verify topic creation and partition configuration
â€“â€“â€“ input â€“â€“â€“
docker exec kafka /opt/kafka/bin/kafka-topics.sh --describe --topic my-data --bootstrap-server localhost:9092
â€“â€“â€“ output â€“â€“â€“
Topic: my-data	TopicId: #!/[a-zA-Z0-9_-]+/!#	PartitionCount: 2	ReplicationFactor: 1	Configs: min.insync.replicas=1
	Topic: my-data	Partition: 0	Leader: 0	Replicas: 0	Isr: 0	Elr: 	LastKnownElr:
	Topic: my-data	Partition: 1	Leader: 0	Replicas: 0	Isr: 0	Elr: 	LastKnownElr:
â€“â€“â€“ comment â€“â€“â€“
Create Kafka source for partition 0 with specific consumer configuration
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p1 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='0' batch=50;"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Create Kafka source for partition 1 with specific consumer configuration
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p2 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='1' batch=50;"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Create destination table for partition 0 data
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_1 (id bigint, name text);"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Create destination table for partition 1 data
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_2 (id bigint, name text);"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Create materialized view to route partition 0 data to destination table
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_1 TO destination_shard_1 AS SELECT id, term AS name FROM kafka_p1;"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Create materialized view to route partition 1 data to destination table
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_2 TO destination_shard_2 AS SELECT id, term AS name FROM kafka_p2;"; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Verify both Kafka sources are created successfully
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "SHOW SOURCES\G;"
â€“â€“â€“ output â€“â€“â€“
*************************** 1. row ***************************
name: kafka_p2
*************************** 2. row ***************************
name: kafka_p1
â€“â€“â€“ comment â€“â€“â€“
Verify both materialized views are created successfully
â€“â€“â€“ input â€“â€“â€“
docker exec manticore mysql -h0 -P9306 -e "SHOW MVS\G;"
â€“â€“â€“ output â€“â€“â€“
*************************** 1. row ***************************
name: mv_2
*************************** 2. row ***************************
name: mv_1
â€“â€“â€“ comment â€“â€“â€“
Import data to Kafka topic
â€“â€“â€“ input â€“â€“â€“
docker exec kafka chmod +x /tmp/import.sh && docker exec kafka /tmp/import.sh; echo $?
â€“â€“â€“ output â€“â€“â€“
0
â€“â€“â€“ comment â€“â€“â€“
Wait for data to be processed by monitoring table counts
â€“â€“â€“ input â€“â€“â€“
timeout 120 bash -c 'TOTAL_EXPECTED=57; while true; do SHARD1=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_1\G" | grep "count" | cut -d: -f2 | tr -d " "); SHARD2=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_2\G" | grep "count" | cut -d: -f2 | tr -d " "); TOTAL=$((SHARD1 + SHARD2)); if [ "$TOTAL" -ge "$TOTAL_EXPECTED" ]; then echo "Shard1: $SHARD1, Shard2: $SHARD2, Total: $TOTAL"; echo "All data processed successfully"; break; fi; sleep 3; done' || echo "Processing timeout reached"
â€“â€“â€“ output â€“â€“â€“
Shard1: #!/[0-9]+/!#, Shard2: #!/[0-9]+/!#, Total: 57
All data processed successfully
â€“â€“â€“ comment â€“â€“â€“
Verify data is distributed across both shards
â€“â€“â€“ input â€“â€“â€“
SHARD1_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_1\G" | grep "count" | cut -d: -f2 | tr -d " "); SHARD2_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_2\G" | grep "count" | cut -d: -f2 | tr -d " "); echo "Manticore Shard 1: $SHARD1_COUNT records"; echo "Manticore Shard 2: $SHARD2_COUNT records"; TOTAL=$((SHARD1_COUNT + SHARD2_COUNT)); echo "Total records: $TOTAL"
â€“â€“â€“ output â€“â€“â€“
Manticore Shard 1: #!/[0-9]+/!# records
Manticore Shard 2: #!/[0-9]+/!# records
Total records: 57
â€“â€“â€“ comment â€“â€“â€“
Verify both shards received data (partition-based distribution)
â€“â€“â€“ input â€“â€“â€“
if [ "$SHARD1_COUNT" -gt 0 ] && [ "$SHARD2_COUNT" -gt 0 ]; then echo "Data distributed across both shards"; else echo "Warning: Data went to single shard only"; fi
â€“â€“â€“ output â€“â€“â€“
Data distributed across both shards
â€“â€“â€“ comment â€“â€“â€“
Verify total count matches expected number of records
â€“â€“â€“ input â€“â€“â€“
if [ "$TOTAL" -eq 57 ]; then echo "Record count validation: PASSED"; else echo "Record count validation: FAILED (expected 57, got $TOTAL)"; fi
â€“â€“â€“ output â€“â€“â€“
Record count validation: PASSED
