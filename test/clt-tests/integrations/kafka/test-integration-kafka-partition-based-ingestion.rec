––– block: ../../base/dind/init –––
––– block: ../../base/basic-initialization-manticore-kafka –––
––– comment –––
Start Kafka 4.0.0 container with KRaft mode configuration
––– input –––
docker run -d --network=app-network --name kafka -e KAFKA_NODE_ID=1 -e KAFKA_PROCESS_ROLES=broker,controller -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092 -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093 -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 -e KAFKA_LOG_DIRS=/tmp/kraft-combined-logs -e CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk apache/kafka:4.0.0 > /dev/null 2>&1; echo $?
––– output –––
0
––– comment –––
Wait for Kafka broker to be ready
––– input –––
timeout 30 bash -c 'until docker exec kafka /opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 > /dev/null 2>&1; do sleep 1; done'; echo $?
––– output –––
0
––– comment –––
Create Kafka topic with 2 partitions for data distribution testing
––– input –––
docker exec kafka /opt/kafka/bin/kafka-topics.sh --create --topic my-data --partitions 2 --bootstrap-server localhost:9092 2>&1 | grep -o 'Created topic my-data\.' | head -n 1
––– output –––
Created topic my-data.
––– comment –––
Verify topic creation and partition configuration
––– input –––
docker exec kafka /opt/kafka/bin/kafka-topics.sh --describe --topic my-data --bootstrap-server localhost:9092
––– output –––
Topic: my-data	TopicId: #!/[a-zA-Z0-9_-]+/!#	PartitionCount: 2	ReplicationFactor: 1	Configs:#!/.*|	Configs: /!#
	Topic: my-data	Partition: 0	Leader: 1	Replicas: 1	Isr: 1#!/.*|	Isr: 1/!#
	Topic: my-data	Partition: 1	Leader: 1	Replicas: 1	Isr: 1#!/.*|	Isr: 1/!#
––– comment –––
Create Kafka source for partition 0 with specific consumer configuration
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p1 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='0' batch=50;"; echo $?
––– output –––
0
––– comment –––
Create Kafka source for partition 1 with specific consumer configuration
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE SOURCE kafka_p2 (id bigint, term text) type='kafka' broker_list='kafka:9092' topic_list='my-data' consumer_group='manticore' num_consumers='1' partition_list='1' batch=50;"; echo $?
––– output –––
0
––– comment –––
Create destination table for partition 0 data
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_1 (id bigint, name text);"; echo $?
––– output –––
0
––– comment –––
Create destination table for partition 1 data
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE TABLE destination_shard_2 (id bigint, name text);"; echo $?
––– output –––
0
––– comment –––
Create materialized view to route partition 0 data to destination table
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_1 TO destination_shard_1 AS SELECT id, term AS name FROM kafka_p1;"; echo $?
––– output –––
0
––– comment –––
Create materialized view to route partition 1 data to destination table
––– input –––
docker exec manticore mysql -h0 -P9306 -e "CREATE MATERIALIZED VIEW mv_2 TO destination_shard_2 AS SELECT id, term AS name FROM kafka_p2;"; echo $?
––– output –––
0
––– comment –––
Verify both Kafka sources are created successfully
––– input –––
docker exec manticore mysql -h0 -P9306 -e "SHOW SOURCES\G;"
––– output –––
*************************** 1. row ***************************
name: kafka_p2
*************************** 2. row ***************************
name: kafka_p1
––– comment –––
Verify both materialized views are created successfully
––– input –––
docker exec manticore mysql -h0 -P9306 -e "SHOW MVS\G;"
––– output –––
*************************** 1. row ***************************
name: mv_2
*************************** 2. row ***************************
name: mv_1
––– comment –––
Download test dataset for partition distribution testing
––– input –––
docker exec manticore curl -s -o /tmp/dump.json https://raw.githubusercontent.com/manticoresoftware/manticoresearch-buddy/main/test/Kafka/dump.json && docker cp manticore:/tmp/dump.json /tmp/dump.json && docker cp /tmp/dump.json kafka:/tmp/dump.json; echo $?
––– output –––
0
––– comment –––
Download import script with key-based partitioning for balanced data distribution
––– input –––
docker exec manticore curl -s -o /tmp/import.sh https://raw.githubusercontent.com/manticoresoftware/manticoresearch-buddy/main/test/Kafka/import.sh && docker cp manticore:/tmp/import.sh /tmp/import.sh && sed -i 's|/opt/bitnami/kafka/bin/|/opt/kafka/bin/|g' /tmp/import.sh && sed -i 's|--broker-list|--bootstrap-server|g' /tmp/import.sh && docker cp /tmp/import.sh kafka:/tmp/import.sh; echo $?
––– output –––
0
––– comment –––
Execute data import to Kafka topic
––– input –––
docker exec kafka bash /tmp/import.sh; echo $?
––– output –––
0
––– comment –––
Wait until lag becomes zero and current offset is not zero for all partitions
––– input –––
timeout 120 bash -c 'while true; do STATS=$(docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group manticore 2>/dev/null | grep -E "^manticore.*my-data"); if [ -z "$STATS" ]; then sleep 3; continue; fi; ALL_READY=true; while IFS= read -r line; do if [[ -n "$line" ]]; then read -r group topic partition current_offset log_end_offset lag rest <<< "$line"; if [[ "$lag" -ne 0 ]] || [[ "$current_offset" -eq 0 ]]; then ALL_READY=false; fi; fi; done <<< "$STATS"; if [ "$ALL_READY" = true ]; then echo "All partitions processed successfully"; break; fi; sleep 3; done' || echo "Processing timeout reached"
––– output –––
All partitions processed successfully
––– comment –––
Get partition counts from Kafka consumer group
––– input –––
KAFKA_STATS=$(docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group manticore | awk '/^manticore.*my-data/'); KAFKA_P0=$(echo "$KAFKA_STATS" | awk '$3==0 {print $4}'); KAFKA_P1=$(echo "$KAFKA_STATS" | awk '$3==1 {print $4}'); echo "Kafka Partition 0: $KAFKA_P0 records"; echo "Kafka Partition 1: $KAFKA_P1 records"
––– output –––
Consumer group 'manticore' has no active members.
Kafka Partition 0: %{NUMBER} records
Kafka Partition 1: %{NUMBER} records
––– comment –––
Check destination_shard_1 matches Kafka partition 0
––– input –––
SHARD1_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_1\G;" | grep "count" | cut -d: -f2 | tr -d ' '); echo "Manticore Shard 1: $SHARD1_COUNT records"; if [ "$SHARD1_COUNT" -eq "$KAFKA_P0" ]; then echo "Shard 1 matches Kafka partition 0"; else echo "Shard 1 ($SHARD1_COUNT) != Kafka partition 0 ($KAFKA_P0)"; fi
––– output –––
Manticore Shard 1: %{NUMBER} records
Shard 1 matches Kafka partition 0
––– comment –––
Check destination_shard_2 matches Kafka partition 1
––– input –––
SHARD2_COUNT=$(docker exec manticore mysql -h0 -P9306 -e "SELECT COUNT(*) FROM destination_shard_2\G;" | grep "count" | cut -d: -f2 | tr -d ' '); echo "Manticore Shard 2: $SHARD2_COUNT records"; if [ "$SHARD2_COUNT" -eq "$KAFKA_P1" ]; then echo "Shard 2 matches Kafka partition 1"; else echo "Shard 2 ($SHARD2_COUNT) != Kafka partition 1 ($KAFKA_P1)"; fi
––– output –––
Manticore Shard 2: %{NUMBER} records
Shard 2 matches Kafka partition 1
––– comment –––
Verify data is distributed across both shards
––– input –––
if [ "$SHARD1_COUNT" -gt 0 ] && [ "$SHARD2_COUNT" -gt 0 ]; then echo "Data distributed across both shards"; else echo "Warning: Data went to single shard only"; fi
––– output –––
Data distributed across both shards
